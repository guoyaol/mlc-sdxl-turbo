metadata = tvm.ir.load_json("""{
  \"root\": 1, 
  \"nodes\": [
    {
      \"type_key\": \"\"
    }, 
    {
      \"type_key\": \"Map\", 
      \"keys\": [
        \"relax.expr.Constant\"
      ], 
      \"data\": [2]
    }, 
    {
      \"type_key\": \"Array\", 
      \"data\": [3, 14, 25, 34]
    }, 
    {
      \"type_key\": \"relax.expr.Constant\", 
      \"attrs\": {
        \"_checked_type_\": \"13\", 
        \"data\": \"0\", 
        \"span\": \"0\", 
        \"struct_info_\": \"4\"
      }
    }, 
    {
      \"type_key\": \"relax.TensorStructInfo\", 
      \"attrs\": {
        \"dtype\": \"float32\", 
        \"ndim\": \"4\", 
        \"shape\": \"5\", 
        \"span\": \"0\", 
        \"vdevice\": \"0\"
      }
    }, 
    {
      \"type_key\": \"relax.expr.ShapeExpr\", 
      \"attrs\": {
        \"_checked_type_\": \"12\", 
        \"span\": \"0\", 
        \"struct_info_\": \"11\", 
        \"values\": \"6\"
      }
    }, 
    {
      \"type_key\": \"Array\", 
      \"data\": [7, 8, 9, 10]
    }, 
    {
      \"type_key\": \"IntImm\", 
      \"attrs\": {
        \"dtype\": \"int64\", 
        \"span\": \"0\", 
        \"value\": \"1\"
      }
    }, 
    {
      \"type_key\": \"IntImm\", 
      \"attrs\": {
        \"dtype\": \"int64\", 
        \"span\": \"0\", 
        \"value\": \"1\"
      }
    }, 
    {
      \"type_key\": \"IntImm\", 
      \"attrs\": {
        \"dtype\": \"int64\", 
        \"span\": \"0\", 
        \"value\": \"77\"
      }
    }, 
    {
      \"type_key\": \"IntImm\", 
      \"attrs\": {
        \"dtype\": \"int64\", 
        \"span\": \"0\", 
        \"value\": \"77\"
      }
    }, 
    {
      \"type_key\": \"relax.ShapeStructInfo\", 
      \"attrs\": {
        \"ndim\": \"4\", 
        \"span\": \"0\", 
        \"values\": \"6\"
      }
    }, 
    {
      \"type_key\": \"relax.ShapeType\", 
      \"attrs\": {
        \"ndim\": \"4\", 
        \"span\": \"0\"
      }
    }, 
    {
      \"type_key\": \"relax.DynTensorType\", 
      \"attrs\": {
        \"dtype\": \"float32\", 
        \"ndim\": \"4\", 
        \"span\": \"0\"
      }
    }, 
    {
      \"type_key\": \"relax.expr.Constant\", 
      \"attrs\": {
        \"_checked_type_\": \"24\", 
        \"data\": \"1\", 
        \"span\": \"0\", 
        \"struct_info_\": \"15\"
      }
    }, 
    {
      \"type_key\": \"relax.TensorStructInfo\", 
      \"attrs\": {
        \"dtype\": \"float32\", 
        \"ndim\": \"4\", 
        \"shape\": \"16\", 
        \"span\": \"0\", 
        \"vdevice\": \"0\"
      }
    }, 
    {
      \"type_key\": \"relax.expr.ShapeExpr\", 
      \"attrs\": {
        \"_checked_type_\": \"23\", 
        \"span\": \"0\", 
        \"struct_info_\": \"22\", 
        \"values\": \"17\"
      }
    }, 
    {
      \"type_key\": \"Array\", 
      \"data\": [18, 19, 20, 21]
    }, 
    {
      \"type_key\": \"IntImm\", 
      \"attrs\": {
        \"dtype\": \"int64\", 
        \"span\": \"0\", 
        \"value\": \"1\"
      }
    }, 
    {
      \"type_key\": \"IntImm\", 
      \"attrs\": {
        \"dtype\": \"int64\", 
        \"span\": \"0\", 
        \"value\": \"1\"
      }
    }, 
    {
      \"type_key\": \"IntImm\", 
      \"attrs\": {
        \"dtype\": \"int64\", 
        \"span\": \"0\", 
        \"value\": \"77\"
      }
    }, 
    {
      \"type_key\": \"IntImm\", 
      \"attrs\": {
        \"dtype\": \"int64\", 
        \"span\": \"0\", 
        \"value\": \"77\"
      }
    }, 
    {
      \"type_key\": \"relax.ShapeStructInfo\", 
      \"attrs\": {
        \"ndim\": \"4\", 
        \"span\": \"0\", 
        \"values\": \"17\"
      }
    }, 
    {
      \"type_key\": \"relax.ShapeType\", 
      \"attrs\": {
        \"ndim\": \"4\", 
        \"span\": \"0\"
      }
    }, 
    {
      \"type_key\": \"relax.DynTensorType\", 
      \"attrs\": {
        \"dtype\": \"float32\", 
        \"ndim\": \"4\", 
        \"span\": \"0\"
      }
    }, 
    {
      \"type_key\": \"relax.expr.Constant\", 
      \"attrs\": {
        \"_checked_type_\": \"33\", 
        \"data\": \"2\", 
        \"span\": \"0\", 
        \"struct_info_\": \"26\"
      }
    }, 
    {
      \"type_key\": \"relax.TensorStructInfo\", 
      \"attrs\": {
        \"dtype\": \"float32\", 
        \"ndim\": \"2\", 
        \"shape\": \"27\", 
        \"span\": \"0\", 
        \"vdevice\": \"0\"
      }
    }, 
    {
      \"type_key\": \"relax.expr.ShapeExpr\", 
      \"attrs\": {
        \"_checked_type_\": \"32\", 
        \"span\": \"0\", 
        \"struct_info_\": \"31\", 
        \"values\": \"28\"
      }
    }, 
    {
      \"type_key\": \"Array\", 
      \"data\": [29, 30]
    }, 
    {
      \"type_key\": \"IntImm\", 
      \"attrs\": {
        \"dtype\": \"int64\", 
        \"span\": \"0\", 
        \"value\": \"1\"
      }
    }, 
    {
      \"type_key\": \"IntImm\", 
      \"attrs\": {
        \"dtype\": \"int64\", 
        \"span\": \"0\", 
        \"value\": \"160\"
      }
    }, 
    {
      \"type_key\": \"relax.ShapeStructInfo\", 
      \"attrs\": {
        \"ndim\": \"2\", 
        \"span\": \"0\", 
        \"values\": \"28\"
      }
    }, 
    {
      \"type_key\": \"relax.ShapeType\", 
      \"attrs\": {
        \"ndim\": \"2\", 
        \"span\": \"0\"
      }
    }, 
    {
      \"type_key\": \"relax.DynTensorType\", 
      \"attrs\": {
        \"dtype\": \"float32\", 
        \"ndim\": \"2\", 
        \"span\": \"0\"
      }
    }, 
    {
      \"type_key\": \"relax.expr.Constant\", 
      \"attrs\": {
        \"_checked_type_\": \"42\", 
        \"data\": \"3\", 
        \"span\": \"0\", 
        \"struct_info_\": \"35\"
      }
    }, 
    {
      \"type_key\": \"relax.TensorStructInfo\", 
      \"attrs\": {
        \"dtype\": \"float32\", 
        \"ndim\": \"2\", 
        \"shape\": \"36\", 
        \"span\": \"0\", 
        \"vdevice\": \"0\"
      }
    }, 
    {
      \"type_key\": \"relax.expr.ShapeExpr\", 
      \"attrs\": {
        \"_checked_type_\": \"41\", 
        \"span\": \"0\", 
        \"struct_info_\": \"40\", 
        \"values\": \"37\"
      }
    }, 
    {
      \"type_key\": \"Array\", 
      \"data\": [38, 39]
    }, 
    {
      \"type_key\": \"IntImm\", 
      \"attrs\": {
        \"dtype\": \"int64\", 
        \"span\": \"0\", 
        \"value\": \"1\"
      }
    }, 
    {
      \"type_key\": \"IntImm\", 
      \"attrs\": {
        \"dtype\": \"int64\", 
        \"span\": \"0\", 
        \"value\": \"128\"
      }
    }, 
    {
      \"type_key\": \"relax.ShapeStructInfo\", 
      \"attrs\": {
        \"ndim\": \"2\", 
        \"span\": \"0\", 
        \"values\": \"37\"
      }
    }, 
    {
      \"type_key\": \"relax.ShapeType\", 
      \"attrs\": {
        \"ndim\": \"2\", 
        \"span\": \"0\"
      }
    }, 
    {
      \"type_key\": \"relax.DynTensorType\", 
      \"attrs\": {
        \"dtype\": \"float32\", 
        \"ndim\": \"2\", 
        \"span\": \"0\"
      }
    }
  ], 
  \"b64ndarrays\": [
    \"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\", 
    \"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\", 
    \"P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAgAAAAIgAQABAAAAAAAAAKAAAAAAAAAAgAIAAAAAAAAAAIA/+a1xPwUpZD+sZVc/GFlLPxH5Pz/vOzU/lhgrP2yGIT9QfRg/mvUPPwvoBz/PTQA/4UDyPrez5D6a6Nc+tNTLPsJtwD4ZqrU+l4CrPpvooT4C2pg+HE2QPqg6iD7Mm4A+ItRyPro+ZT7Ya1g+nFBMPrviQD6HGDY+1ugrPgZLIj7sNhk+0qQQPneNCD756QA+wGfzPRTK5T1o79g9zMzMPflXwT03h7Y9VVGsPa2toj0NlJk9wPyQPXjgiD1XOIE9s/tzPcFVZj1Ec1k9SUlNPYHNQT0q9jY9FbosPZIQIz1p8Rk94VQRPaozCT3ihgE9BJD0PMLh5jxx99k8FMbNPFFDwjxjZbc8EyOtPK1zozz7Tpo8Oa2RPBKHiTyd1YE8qCR1PCBuZzzxe1o8J0NOPGO5Qjzf1Dc8U4wtPArXIzzHrBo8wwUSPKzaCTyKJAI8rbn1O8j65zvCANs7isDOO8IvwzuaRLg7zfWtO6M6pDvOCps7iF6SO3Uuijunc4I7Dk92O82HaDvdhVs7Mz5PO2mmQzuetDg7jV8uO3OeJDsNaRs7grcSO3WCCjvwwgI7weT2OigV6TpQC9w6NbzPOlkdxDrmJLk6iMmuOoUCpTqCx5s6rhCTOqjWijpuEoM633p3OtmiaToTkVw6cDpQOoqURDptlTk6yTMvOtVmJTo1Jhw6GWoTOg8rCzobYgM6QRH4Odkw6jkhF905BbnQOQsMxTk+Bro5UJ6vOWHLpTkhhZw5scOTOaR/izn1sYM5Dah4OS6/ajmPnV057TdROdODRTlTdzo5DAkwOSUwJjlC5Bw5gB0UOW3UCzkIAgQ5PT/5OOpN6zhAJN44\", 
    \"P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAgAAAAIgAQABAAAAAAAAAIAAAAAAAAAAAAIAAAAAAAAAAIA/+DluP9avXT+sS04/Efk/PwalMj/gPSY/K7MaP5r1Dz/u9gU/zlP5PmAE6D6a6Nc+I+vIPhv4uj7//K0+m+ihPuqqlj4DNYw+CHmCPiLUcj42+GE+7UdSPnyuQz6HGDY+CXQpPj+wHT6QvRI+d40IPt8k/j3Vf+w9ZBTcPczMzD3HlL49eFmxPVcJpT0NlJk9bOqOPUz+hD0RhXc9wVVmPeNXVj1Adkc9GJ05PRW6LD0bvCA9SJMVPcswCz3ihgE9dxHxPNFU4DyowdA8TkPCPJHGtDyJOag8loucPDmtkTwJkIc8ME18PObIajzxe1o8tVBLPA4zPTxQEDA8CtcjPAZ3GDwu4Q08dwcEPK259TtFquQ7FcrUOwoExjuaRLg7gnmrO8yRnzuvfZQ7dS6KO3yWgDsNUm87erReOzM+TzvC2kA7DXczO1MBJzsNaRs72J4QO22UBjvwePo6KBXpOnXm2DpZ18k669O7Oo3Jrjr3pqI6C1yXOtnZjDpuEoM6ovFzOuMBYzokP1M6ipREOp3uNjpEOyo6omkeOhRqEzoBLgk6rE//OeSV7TkhF905k73NOdZ0vzn7KbI5YculOaBImjl1ko85pJqFOQ2oeDmMZGc54lNXOb9gSDlTdzo5KoUtORl5ITkmQxY5bdQLOSgfAjndLPI4jlzhOA==\"
  ], 
  \"attrs\": {\"tvm_version\": \"0.14.dev0\"}
}""")
# from tvm.script import ir as I
# from tvm.script import tir as T
# from tvm.script import relax as R

@I.ir_module
class Module:
    @T.prim_func(private=True)
    def add(A: T.Buffer((T.int64(1), T.int64(4), T.int64(64), T.int64(64)), "float32"), B: T.Buffer((T.int64(1), T.int64(4), T.int64(64), T.int64(64)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(4), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"op_pattern": 0, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0_ax1_ax2_ax3_fused_0 in T.thread_binding(T.int64(64), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_add"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) // T.int64(4096))
                    v_ax2 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(4096) // T.int64(64))
                    v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(64))
                    T.reads(A[v_ax0, v_ax1, v_ax2, v_ax3], B[v_ax0, v_ax1, v_ax2, v_ax3])
                    T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3])
                    T_add[v_ax0, v_ax1, v_ax2, v_ax3] = A[v_ax0, v_ax1, v_ax2, v_ax3] + B[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def add1(A: T.Buffer((), "float32"), T_add: T.Buffer((), "float32")):
        T.func_attr({"op_pattern": 0, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for u_fused_0 in T.thread_binding(1, thread="blockIdx.x"):
            for u_fused_1 in T.thread_binding(1, thread="threadIdx.x"):
                with T.block("T_add"):
                    vi = T.axis.spatial(1, T.int64(0))
                    T.reads(A[()])
                    T.writes(T_add[()])
                    T_add[()] = A[()] + T.float32(1)

    @T.prim_func(private=True)
    def argmax(A: T.Buffer((T.int64(1), T.int64(77)), "int32"), A_red: T.Buffer((T.int64(1),), "int64")):
        T.func_attr({"op_pattern": 4, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        A_red_temp_v0 = T.alloc_buffer((T.int64(1),), "int64")
        A_red_temp_v1 = T.alloc_buffer((T.int64(1),), "int32")
        for ax0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for ax0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                for k1 in range(T.int64(77)):
                    with T.block("A_red_temp"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k1 = T.axis.reduce(T.int64(77), k1)
                        T.reads(A[v_ax0, v_k1])
                        T.writes(A_red_temp_v0[v_ax0], A_red_temp_v1[v_ax0])
                        with T.init():
                            A_red_temp_v0[v_ax0] = T.int64(-1)
                            A_red_temp_v1[v_ax0] = -2147483648
                        v_A_red_temp_v0: T.int64 = T.Select(A_red_temp_v1[v_ax0] > A[v_ax0, v_k1] or A_red_temp_v1[v_ax0] == A[v_ax0, v_k1] and A_red_temp_v0[v_ax0] < v_k1, A_red_temp_v0[v_ax0], v_k1)
                        v_A_red_temp_v1: T.int32 = T.Select(A_red_temp_v1[v_ax0] > A[v_ax0, v_k1], A_red_temp_v1[v_ax0], A[v_ax0, v_k1])
                        A_red_temp_v0[v_ax0] = v_A_red_temp_v0
                        A_red_temp_v1[v_ax0] = v_A_red_temp_v1
        for ax0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for ax0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("A_red"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads(A_red_temp_v0[v_ax0])
                    T.writes(A_red[v_ax0])
                    A_red[v_ax0] = A_red_temp_v0[v_ax0]

    @T.prim_func(private=True)
    def cast(A: T.Buffer((T.int64(1), T.int64(77)), "int32"), compute: T.Buffer((T.int64(1), T.int64(77)), "int32")):
        T.func_attr({"op_pattern": 0, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0_i1_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(77), thread="threadIdx.x"):
                with T.block("compute"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(77), i0_i1_fused_0 * T.int64(77) + i0_i1_fused_1)
                    T.reads(A[v_i0, v_i1])
                    T.writes(compute[v_i0, v_i1])
                    compute[v_i0, v_i1] = A[v_i0, v_i1]

    @T.prim_func(private=True)
    def concatenate(A: T.Buffer((T.int64(1), T.int64(77), T.int64(768)), "float32"), B: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32"), T_concat: T.Buffer((T.int64(1), T.int64(77), T.int64(2048)), "float32")):
        T.func_attr({"op_pattern": 2, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(3)):
                    with T.block("T_concat"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(2048))
                        v_ax2 = T.axis.spatial(T.int64(2048), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(2048))
                        T.where((ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) * T.int64(256) + ax0_ax1_ax2_fused_2 < T.int64(157696))
                        T.reads(B[v_ax0, v_ax1, v_ax2 - T.int64(768)], A[v_ax0, v_ax1, v_ax2])
                        T.writes(T_concat[v_ax0, v_ax1, v_ax2])
                        T_concat[v_ax0, v_ax1, v_ax2] = T.if_then_else(T.int64(768) <= v_ax2, B[v_ax0, v_ax1, v_ax2 - T.int64(768)], A[v_ax0, v_ax1, v_ax2])

    @T.prim_func(private=True)
    def concatenate10(A: T.Buffer((T.int64(1), T.int64(320), T.int64(64), T.int64(64)), "float32"), B: T.Buffer((T.int64(1), T.int64(320), T.int64(64), T.int64(64)), "float32"), T_concat: T.Buffer((T.int64(1), T.int64(640), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"op_pattern": 2, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(40)):
                    with T.block("T_concat"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(640), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(4096))
                        v_ax2 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(4096) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.reads(B[v_ax0, v_ax1 - T.int64(320), v_ax2, v_ax3], A[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(T_concat[v_ax0, v_ax1, v_ax2, v_ax3])
                        T_concat[v_ax0, v_ax1, v_ax2, v_ax3] = T.if_then_else(T.int64(320) <= v_ax1, B[v_ax0, v_ax1 - T.int64(320), v_ax2, v_ax3], A[v_ax0, v_ax1, v_ax2, v_ax3])

    @T.prim_func(private=True)
    def concatenate11(A: T.Buffer((T.int64(1), T.int64(1280)), "float32"), B: T.Buffer((T.int64(1), T.int64(1280)), "float32"), T_concat: T.Buffer((T.int64(2), T.int64(1280)), "float32")):
        T.func_attr({"op_pattern": 2, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(10), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_concat"):
                    v_ax0 = T.axis.spatial(T.int64(2), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) // T.int64(1280))
                    v_ax1 = T.axis.spatial(T.int64(1280), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) % T.int64(1280))
                    T.reads(B[v_ax0 - T.int64(1), v_ax1], A[v_ax0, v_ax1])
                    T.writes(T_concat[v_ax0, v_ax1])
                    T_concat[v_ax0, v_ax1] = T.if_then_else(T.int64(1) <= v_ax0, B[v_ax0 - T.int64(1), v_ax1], A[v_ax0, v_ax1])

    @T.prim_func(private=True)
    def concatenate12(A: T.Buffer((T.int64(1), T.int64(4), T.int64(64), T.int64(64)), "float32"), B: T.Buffer((T.int64(1), T.int64(4), T.int64(64), T.int64(64)), "float32"), T_concat: T.Buffer((T.int64(2), T.int64(4), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"op_pattern": 2, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0_ax1_ax2_ax3_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_concat"):
                    v_ax0 = T.axis.spatial(T.int64(2), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) // T.int64(16384))
                    v_ax1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(16384) // T.int64(4096))
                    v_ax2 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(4096) // T.int64(64))
                    v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(64))
                    T.reads(B[v_ax0 - T.int64(1), v_ax1, v_ax2, v_ax3], A[v_ax0, v_ax1, v_ax2, v_ax3])
                    T.writes(T_concat[v_ax0, v_ax1, v_ax2, v_ax3])
                    T_concat[v_ax0, v_ax1, v_ax2, v_ax3] = T.if_then_else(T.int64(1) <= v_ax0, B[v_ax0 - T.int64(1), v_ax1, v_ax2, v_ax3], A[v_ax0, v_ax1, v_ax2, v_ax3])

    @T.prim_func(private=True)
    def concatenate13(A: T.Buffer((T.int64(1), T.int64(77), T.int64(2048)), "float32"), B: T.Buffer((T.int64(1), T.int64(77), T.int64(2048)), "float32"), T_concat: T.Buffer((T.int64(2), T.int64(77), T.int64(2048)), "float32")):
        T.func_attr({"op_pattern": 2, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(5)):
                    with T.block("T_concat"):
                        v_ax0 = T.axis.spatial(T.int64(2), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(157696))
                        v_ax1 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(157696) // T.int64(2048))
                        v_ax2 = T.axis.spatial(T.int64(2048), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(2048))
                        T.where((ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) * T.int64(256) + ax0_ax1_ax2_fused_2 < T.int64(315392))
                        T.reads(B[v_ax0 - T.int64(1), v_ax1, v_ax2], A[v_ax0, v_ax1, v_ax2])
                        T.writes(T_concat[v_ax0, v_ax1, v_ax2])
                        T_concat[v_ax0, v_ax1, v_ax2] = T.if_then_else(T.int64(1) <= v_ax0, B[v_ax0 - T.int64(1), v_ax1, v_ax2], A[v_ax0, v_ax1, v_ax2])

    @T.prim_func(private=True)
    def concatenate4(A: T.Buffer((T.int64(1), T.int64(1280), T.int64(16), T.int64(16)), "float32"), B: T.Buffer((T.int64(1), T.int64(1280), T.int64(16), T.int64(16)), "float32"), T_concat: T.Buffer((T.int64(1), T.int64(2560), T.int64(16), T.int64(16)), "float32")):
        T.func_attr({"op_pattern": 2, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(10)):
                    with T.block("T_concat"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(2560), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(256))
                        v_ax2 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256) // T.int64(16))
                        v_ax3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                        T.reads(B[v_ax0, v_ax1 - T.int64(1280), v_ax2, v_ax3], A[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(T_concat[v_ax0, v_ax1, v_ax2, v_ax3])
                        T_concat[v_ax0, v_ax1, v_ax2, v_ax3] = T.if_then_else(T.int64(1280) <= v_ax1, B[v_ax0, v_ax1 - T.int64(1280), v_ax2, v_ax3], A[v_ax0, v_ax1, v_ax2, v_ax3])

    @T.prim_func(private=True)
    def concatenate6(A: T.Buffer((T.int64(1), T.int64(1280), T.int64(32), T.int64(32)), "float32"), B: T.Buffer((T.int64(1), T.int64(640), T.int64(32), T.int64(32)), "float32"), T_concat: T.Buffer((T.int64(1), T.int64(1920), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"op_pattern": 2, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(30)):
                    with T.block("T_concat"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1920), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                        v_ax2 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(32))
                        v_ax3 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                        T.reads(B[v_ax0, v_ax1 - T.int64(1280), v_ax2, v_ax3], A[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(T_concat[v_ax0, v_ax1, v_ax2, v_ax3])
                        T_concat[v_ax0, v_ax1, v_ax2, v_ax3] = T.if_then_else(T.int64(1280) <= v_ax1, B[v_ax0, v_ax1 - T.int64(1280), v_ax2, v_ax3], A[v_ax0, v_ax1, v_ax2, v_ax3])

    @T.prim_func(private=True)
    def concatenate9(A: T.Buffer((T.int64(1), T.int64(640), T.int64(64), T.int64(64)), "float32"), B: T.Buffer((T.int64(1), T.int64(320), T.int64(64), T.int64(64)), "float32"), T_concat: T.Buffer((T.int64(1), T.int64(960), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"op_pattern": 2, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(60)):
                    with T.block("T_concat"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(960), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(4096))
                        v_ax2 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(4096) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.reads(B[v_ax0, v_ax1 - T.int64(640), v_ax2, v_ax3], A[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(T_concat[v_ax0, v_ax1, v_ax2, v_ax3])
                        T_concat[v_ax0, v_ax1, v_ax2, v_ax3] = T.if_then_else(T.int64(640) <= v_ax1, B[v_ax0, v_ax1 - T.int64(640), v_ax2, v_ax3], A[v_ax0, v_ax1, v_ax2, v_ax3])

    @T.prim_func(private=True)
    def divide(A: T.Buffer((T.int64(1), T.int64(4), T.int64(64), T.int64(64)), "float32"), B: T.Buffer((), "float32"), T_divide: T.Buffer((T.int64(1), T.int64(4), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"op_pattern": 0, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0_ax1_ax2_ax3_fused_0 in T.thread_binding(T.int64(64), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_divide"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) // T.int64(4096))
                    v_ax2 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(4096) // T.int64(64))
                    v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(64))
                    T.reads(A[v_ax0, v_ax1, v_ax2, v_ax3], B[()])
                    T.writes(T_divide[v_ax0, v_ax1, v_ax2, v_ax3])
                    T_divide[v_ax0, v_ax1, v_ax2, v_ax3] = A[v_ax0, v_ax1, v_ax2, v_ax3] / B[()]

    @T.prim_func(private=True)
    def divide1(A: T.Buffer((), "float32"), B: T.Buffer((), "float32"), T_divide: T.Buffer((), "float32")):
        T.func_attr({"op_pattern": 0, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for u_fused_0 in T.thread_binding(1, thread="blockIdx.x"):
            for u_fused_1 in T.thread_binding(1, thread="threadIdx.x"):
                with T.block("T_divide"):
                    vi = T.axis.spatial(1, T.int64(0))
                    T.reads(A[()], B[()])
                    T.writes(T_divide[()])
                    T_divide[()] = A[()] / B[()]

    @T.prim_func(private=True)
    def fused_broadcast_to1_strided_slice1_reshape12_cast3_multiply4_multiply5_tir_sin_tir_cos_concatenate1_strided_slice2_reshape13_strided_slice3_reshape13_concatenate1_cast4(inp_1: T.Buffer((), "int32"), param_0: T.Buffer((T.int64(1), T.int64(160)), "float32"), var_compute_intermediate: T.Buffer((T.int64(1), T.int64(320)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_broadcast_to_intermediate = T.alloc_buffer((T.int64(1),), "int32")
        var_T_strided_slice_with_axes_intermediate = T.alloc_buffer((T.int64(1),), "int32")
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(1)), "int32")
        var_compute_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(1)))
        var_T_multiply_intermediate = T.alloc_buffer((T.int64(1), T.int64(160)))
        var_T_multiply_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(160)))
        var_compute_intermediate_2 = T.alloc_buffer((T.int64(1), T.int64(160)))
        var_compute_intermediate_3 = T.alloc_buffer((T.int64(1), T.int64(160)))
        var_T_concat_intermediate = T.alloc_buffer((T.int64(1), T.int64(320)))
        var_T_strided_slice_with_axes_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(160)))
        var_T_reshape_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(160)))
        var_T_strided_slice_with_axes_intermediate_2 = T.alloc_buffer((T.int64(1), T.int64(160)))
        var_T_reshape_intermediate_2 = T.alloc_buffer((T.int64(1), T.int64(160)))
        var_T_concat_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(320)))
        for ax0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for ax0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_broadcast_to"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads(inp_1[()])
                    T.writes(var_T_broadcast_to_intermediate[v_ax0])
                    var_T_broadcast_to_intermediate[v_ax0] = inp_1[()]
        for ax0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for ax0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_strided_slice_with_axes"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads(var_T_broadcast_to_intermediate[v_ax0])
                    T.writes(var_T_strided_slice_with_axes_intermediate[v_ax0])
                    var_T_strided_slice_with_axes_intermediate[v_ax0] = var_T_broadcast_to_intermediate[v_ax0]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_reshape"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads(var_T_strided_slice_with_axes_intermediate[T.int64(0)])
                    T.writes(var_T_reshape_intermediate[v_ax0, v_ax1])
                    var_T_reshape_intermediate[v_ax0, v_ax1] = var_T_strided_slice_with_axes_intermediate[T.int64(0)]
        for i0_i1_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("compute"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads(var_T_reshape_intermediate[v_i0, v_i1])
                    T.writes(var_compute_intermediate_1[v_i0, v_i1])
                    var_compute_intermediate_1[v_i0, v_i1] = T.Cast("float32", var_T_reshape_intermediate[v_i0, v_i1])
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(160), thread="threadIdx.x"):
                with T.block("T_multiply"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(160), ax0_ax1_fused_0 * T.int64(160) + ax0_ax1_fused_1)
                    T.reads(var_compute_intermediate_1[v_ax0, T.int64(0)], param_0[v_ax0, v_ax1])
                    T.writes(var_T_multiply_intermediate[v_ax0, v_ax1])
                    var_T_multiply_intermediate[v_ax0, v_ax1] = var_compute_intermediate_1[v_ax0, T.int64(0)] * param_0[v_ax0, v_ax1]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(160), thread="threadIdx.x"):
                with T.block("T_multiply_1"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(160), ax0_ax1_fused_0 * T.int64(160) + ax0_ax1_fused_1)
                    T.reads(var_T_multiply_intermediate[v_ax0, v_ax1])
                    T.writes(var_T_multiply_intermediate_1[v_ax0, v_ax1])
                    var_T_multiply_intermediate_1[v_ax0, v_ax1] = var_T_multiply_intermediate[v_ax0, v_ax1]
        for i0_i1_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(160), thread="threadIdx.x"):
                with T.block("compute_1"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(160), i0_i1_fused_0 * T.int64(160) + i0_i1_fused_1)
                    T.reads(var_T_multiply_intermediate_1[v_i0, v_i1])
                    T.writes(var_compute_intermediate_2[v_i0, v_i1])
                    var_compute_intermediate_2[v_i0, v_i1] = T.sin(var_T_multiply_intermediate_1[v_i0, v_i1])
        for i0_i1_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(160), thread="threadIdx.x"):
                with T.block("compute_2"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(160), i0_i1_fused_0 * T.int64(160) + i0_i1_fused_1)
                    T.reads(var_T_multiply_intermediate_1[v_i0, v_i1])
                    T.writes(var_compute_intermediate_3[v_i0, v_i1])
                    var_compute_intermediate_3[v_i0, v_i1] = T.cos(var_T_multiply_intermediate_1[v_i0, v_i1])
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(2), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_concat"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(320), ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1)
                    T.where(ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1 < T.int64(320))
                    T.reads(var_compute_intermediate_3[v_ax0, v_ax1 - T.int64(160)], var_compute_intermediate_2[v_ax0, v_ax1])
                    T.writes(var_T_concat_intermediate[v_ax0, v_ax1])
                    var_T_concat_intermediate[v_ax0, v_ax1] = T.if_then_else(T.int64(160) <= v_ax1, var_compute_intermediate_3[v_ax0, v_ax1 - T.int64(160)], var_compute_intermediate_2[v_ax0, v_ax1])
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(160), thread="threadIdx.x"):
                with T.block("T_strided_slice_with_axes_1"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(160), ax0_ax1_fused_0 * T.int64(160) + ax0_ax1_fused_1)
                    T.reads(var_T_concat_intermediate[v_ax0, v_ax1 + T.int64(160)])
                    T.writes(var_T_strided_slice_with_axes_intermediate_1[v_ax0, v_ax1])
                    var_T_strided_slice_with_axes_intermediate_1[v_ax0, v_ax1] = var_T_concat_intermediate[v_ax0, v_ax1 + T.int64(160)]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(160), thread="threadIdx.x"):
                with T.block("T_reshape_1"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(160), ax0_ax1_fused_0 * T.int64(160) + ax0_ax1_fused_1)
                    T.reads(var_T_strided_slice_with_axes_intermediate_1[T.int64(0), v_ax1 % T.int64(160)])
                    T.writes(var_T_reshape_intermediate_1[v_ax0, v_ax1])
                    var_T_reshape_intermediate_1[v_ax0, v_ax1] = var_T_strided_slice_with_axes_intermediate_1[T.int64(0), v_ax1 % T.int64(160)]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(160), thread="threadIdx.x"):
                with T.block("T_strided_slice_with_axes_2"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(160), ax0_ax1_fused_0 * T.int64(160) + ax0_ax1_fused_1)
                    T.reads(var_T_concat_intermediate[v_ax0, v_ax1])
                    T.writes(var_T_strided_slice_with_axes_intermediate_2[v_ax0, v_ax1])
                    var_T_strided_slice_with_axes_intermediate_2[v_ax0, v_ax1] = var_T_concat_intermediate[v_ax0, v_ax1]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(160), thread="threadIdx.x"):
                with T.block("T_reshape_2"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(160), ax0_ax1_fused_0 * T.int64(160) + ax0_ax1_fused_1)
                    T.reads(var_T_strided_slice_with_axes_intermediate_2[T.int64(0), v_ax1 % T.int64(160)])
                    T.writes(var_T_reshape_intermediate_2[v_ax0, v_ax1])
                    var_T_reshape_intermediate_2[v_ax0, v_ax1] = var_T_strided_slice_with_axes_intermediate_2[T.int64(0), v_ax1 % T.int64(160)]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(2), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_concat_1"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(320), ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1)
                    T.where(ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1 < T.int64(320))
                    T.reads(var_T_reshape_intermediate_2[v_ax0, v_ax1 - T.int64(160)], var_T_reshape_intermediate_1[v_ax0, v_ax1])
                    T.writes(var_T_concat_intermediate_1[v_ax0, v_ax1])
                    var_T_concat_intermediate_1[v_ax0, v_ax1] = T.if_then_else(T.int64(160) <= v_ax1, var_T_reshape_intermediate_2[v_ax0, v_ax1 - T.int64(160)], var_T_reshape_intermediate_1[v_ax0, v_ax1])
        for i0_i1_fused_0 in T.thread_binding(T.int64(2), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("compute_3"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(320), i0_i1_fused_0 * T.int64(256) + i0_i1_fused_1)
                    T.where(i0_i1_fused_0 * T.int64(256) + i0_i1_fused_1 < T.int64(320))
                    T.reads(var_T_concat_intermediate_1[v_i0, v_i1])
                    T.writes(var_compute_intermediate[v_i0, v_i1])
                    var_compute_intermediate[v_i0, v_i1] = var_T_concat_intermediate_1[v_i0, v_i1]

    @T.prim_func(private=True)
    def fused_cast_reshape1(lv: T.Buffer((T.int64(1), T.int64(77)), "int32"), var_T_reshape_intermediate: T.Buffer((T.int64(77),), "int32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_compute_intermediate = T.alloc_buffer((T.int64(1), T.int64(77)), "int32")
        for i0_i1_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(77), thread="threadIdx.x"):
                with T.block("compute"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(77), i0_i1_fused_0 * T.int64(77) + i0_i1_fused_1)
                    T.reads(lv[v_i0, v_i1])
                    T.writes(var_compute_intermediate[v_i0, v_i1])
                    var_compute_intermediate[v_i0, v_i1] = lv[v_i0, v_i1]
        for ax0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for ax0_fused_1 in T.thread_binding(T.int64(77), thread="threadIdx.x"):
                with T.block("T_reshape"):
                    v_ax0 = T.axis.spatial(T.int64(77), ax0_fused_0 * T.int64(77) + ax0_fused_1)
                    T.reads(var_compute_intermediate[T.int64(0), v_ax0 % T.int64(77)])
                    T.writes(var_T_reshape_intermediate[v_ax0])
                    var_T_reshape_intermediate[v_ax0] = var_compute_intermediate[T.int64(0), v_ax0 % T.int64(77)]

    @T.prim_func(private=True)
    def fused_conv2d10_add20_add20(lv2553: T.Buffer((T.int64(1), T.int64(2560), T.int64(16), T.int64(16)), "float32"), unet_up_blocks_0_resnets_0_conv1_weight: T.Buffer((T.int64(1280), T.int64(2560), T.int64(3), T.int64(3)), "float32"), lv2555: T.Buffer((T.int64(1), T.int64(1280), T.int64(1), T.int64(1)), "float32"), lv2562: T.Buffer((T.int64(1), T.int64(1280), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(1280), T.int64(16), T.int64(16)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(2560), T.int64(18), T.int64(18)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(1280), T.int64(16), T.int64(16)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(1280), T.int64(16), T.int64(16)))
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(13)):
                    with T.block("pad_temp"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(2560), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(324))
                        v_i2 = T.axis.spatial(T.int64(18), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(324) // T.int64(18))
                        v_i3 = T.axis.spatial(T.int64(18), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(18))
                        T.where((i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1) * T.int64(256) + i0_i1_i2_i3_fused_2 < T.int64(829440))
                        T.reads(lv2553[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                        T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                        pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(17) and T.int64(1) <= v_i3 and v_i3 < T.int64(17), lv2553[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn_ff_yy_xx_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for nn_ff_yy_xx_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for nn_ff_yy_xx_fused_0, rc, ry, rx in T.grid(T.int64(5), T.int64(2560), T.int64(3), T.int64(3)):
                    with T.block("conv2d_nchw"):
                        v_nn = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ff = T.axis.spatial(T.int64(1280), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) // T.int64(256))
                        v_yy = T.axis.spatial(T.int64(16), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(256) // T.int64(16))
                        v_xx = T.axis.spatial(T.int64(16), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(16))
                        v_rc, v_ry, v_rx = T.axis.remap("RRR", [rc, ry, rx])
                        T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_up_blocks_0_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx])
                        T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                        with T.init():
                            var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                        var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_up_blocks_0_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(5)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(256))
                        v_ax2 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256) // T.int64(16))
                        v_ax3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                        T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv2555[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv2555[v_ax0, v_ax1, T.int64(0), T.int64(0)]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(5)):
                    with T.block("T_add_1"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(256))
                        v_ax2 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256) // T.int64(16))
                        v_ax3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                        T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3], lv2562[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] + lv2562[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d11_add20(lv2551: T.Buffer((T.int64(1), T.int64(2560), T.int64(16), T.int64(16)), "float32"), unet_up_blocks_0_resnets_0_conv_shortcut_weight: T.Buffer((T.int64(1280), T.int64(2560), T.int64(1), T.int64(1)), "float32"), lv2570: T.Buffer((T.int64(1), T.int64(1280), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(1280), T.int64(16), T.int64(16)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(2560), T.int64(16), T.int64(16)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(1280), T.int64(16), T.int64(16)))
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(10)):
                    with T.block("pad_temp"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(2560), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(256))
                        v_i2 = T.axis.spatial(T.int64(16), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(256) // T.int64(16))
                        v_i3 = T.axis.spatial(T.int64(16), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(16))
                        T.reads(lv2551[v_i0, v_i1, v_i2, v_i3])
                        T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                        pad_temp[v_i0, v_i1, v_i2, v_i3] = lv2551[v_i0, v_i1, v_i2, v_i3]
        for nn_ff_yy_xx_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for nn_ff_yy_xx_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for nn_ff_yy_xx_fused_0, rc, ry, rx in T.grid(T.int64(5), T.int64(2560), T.int64(1), T.int64(1)):
                    with T.block("conv2d_nchw"):
                        v_nn = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ff = T.axis.spatial(T.int64(1280), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) // T.int64(256))
                        v_yy = T.axis.spatial(T.int64(16), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(256) // T.int64(16))
                        v_xx = T.axis.spatial(T.int64(16), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(16))
                        v_rc = T.axis.reduce(T.int64(2560), rc)
                        v_ry = T.axis.reduce(T.int64(1), T.int64(0))
                        v_rx = T.axis.reduce(T.int64(1), T.int64(0))
                        T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_up_blocks_0_resnets_0_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx])
                        T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                        with T.init():
                            var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                        var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_up_blocks_0_resnets_0_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(5)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(256))
                        v_ax2 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256) // T.int64(16))
                        v_ax3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                        T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv2570[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv2570[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d12_add20_add20(lv3963: T.Buffer((T.int64(1), T.int64(1920), T.int64(16), T.int64(16)), "float32"), unet_up_blocks_0_resnets_2_conv1_weight: T.Buffer((T.int64(1280), T.int64(1920), T.int64(3), T.int64(3)), "float32"), lv3965: T.Buffer((T.int64(1), T.int64(1280), T.int64(1), T.int64(1)), "float32"), lv3972: T.Buffer((T.int64(1), T.int64(1280), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(1280), T.int64(16), T.int64(16)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(1920), T.int64(18), T.int64(18)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(1280), T.int64(16), T.int64(16)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(1280), T.int64(16), T.int64(16)))
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(10)):
                    with T.block("pad_temp"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1920), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(324))
                        v_i2 = T.axis.spatial(T.int64(18), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(324) // T.int64(18))
                        v_i3 = T.axis.spatial(T.int64(18), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(18))
                        T.where((i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1) * T.int64(256) + i0_i1_i2_i3_fused_2 < T.int64(622080))
                        T.reads(lv3963[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                        T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                        pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(17) and T.int64(1) <= v_i3 and v_i3 < T.int64(17), lv3963[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn_ff_yy_xx_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for nn_ff_yy_xx_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for nn_ff_yy_xx_fused_0, rc, ry, rx in T.grid(T.int64(5), T.int64(1920), T.int64(3), T.int64(3)):
                    with T.block("conv2d_nchw"):
                        v_nn = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ff = T.axis.spatial(T.int64(1280), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) // T.int64(256))
                        v_yy = T.axis.spatial(T.int64(16), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(256) // T.int64(16))
                        v_xx = T.axis.spatial(T.int64(16), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(16))
                        v_rc, v_ry, v_rx = T.axis.remap("RRR", [rc, ry, rx])
                        T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_up_blocks_0_resnets_2_conv1_weight[v_ff, v_rc, v_ry, v_rx])
                        T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                        with T.init():
                            var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                        var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_up_blocks_0_resnets_2_conv1_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(5)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(256))
                        v_ax2 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256) // T.int64(16))
                        v_ax3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                        T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv3965[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv3965[v_ax0, v_ax1, T.int64(0), T.int64(0)]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(5)):
                    with T.block("T_add_1"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(256))
                        v_ax2 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256) // T.int64(16))
                        v_ax3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                        T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3], lv3972[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] + lv3972[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d13_add20(lv3961: T.Buffer((T.int64(1), T.int64(1920), T.int64(16), T.int64(16)), "float32"), unet_up_blocks_0_resnets_2_conv_shortcut_weight: T.Buffer((T.int64(1280), T.int64(1920), T.int64(1), T.int64(1)), "float32"), lv3980: T.Buffer((T.int64(1), T.int64(1280), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(1280), T.int64(16), T.int64(16)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(1920), T.int64(16), T.int64(16)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(1280), T.int64(16), T.int64(16)))
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(8)):
                    with T.block("pad_temp"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1920), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(256))
                        v_i2 = T.axis.spatial(T.int64(16), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(256) // T.int64(16))
                        v_i3 = T.axis.spatial(T.int64(16), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(16))
                        T.where((i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1) * T.int64(256) + i0_i1_i2_i3_fused_2 < T.int64(491520))
                        T.reads(lv3961[v_i0, v_i1, v_i2, v_i3])
                        T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                        pad_temp[v_i0, v_i1, v_i2, v_i3] = lv3961[v_i0, v_i1, v_i2, v_i3]
        for nn_ff_yy_xx_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for nn_ff_yy_xx_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for nn_ff_yy_xx_fused_0, rc, ry, rx in T.grid(T.int64(5), T.int64(1920), T.int64(1), T.int64(1)):
                    with T.block("conv2d_nchw"):
                        v_nn = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ff = T.axis.spatial(T.int64(1280), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) // T.int64(256))
                        v_yy = T.axis.spatial(T.int64(16), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(256) // T.int64(16))
                        v_xx = T.axis.spatial(T.int64(16), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(16))
                        v_rc = T.axis.reduce(T.int64(1920), rc)
                        v_ry = T.axis.reduce(T.int64(1), T.int64(0))
                        v_rx = T.axis.reduce(T.int64(1), T.int64(0))
                        T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_up_blocks_0_resnets_2_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx])
                        T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                        with T.init():
                            var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                        var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_up_blocks_0_resnets_2_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(5)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(256))
                        v_ax2 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256) // T.int64(16))
                        v_ax3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                        T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv3980[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv3980[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d14_add25(lv4666: T.Buffer((T.int64(1), T.int64(1280), T.int64(32), T.int64(32)), "float32"), unet_up_blocks_0_upsamplers_0_conv_weight: T.Buffer((T.int64(1280), T.int64(1280), T.int64(3), T.int64(3)), "float32"), lv4668: T.Buffer((T.int64(1), T.int64(1280), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(1280), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(1280), T.int64(34), T.int64(34)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(1280), T.int64(32), T.int64(32)))
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(23)):
                    with T.block("pad_temp"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1280), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(1156))
                        v_i2 = T.axis.spatial(T.int64(34), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(1156) // T.int64(34))
                        v_i3 = T.axis.spatial(T.int64(34), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(34))
                        T.where((i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1) * T.int64(256) + i0_i1_i2_i3_fused_2 < T.int64(1479680))
                        T.reads(lv4666[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                        T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                        pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(33) and T.int64(1) <= v_i3 and v_i3 < T.int64(33), lv4666[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn_ff_yy_xx_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for nn_ff_yy_xx_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for nn_ff_yy_xx_fused_0, rc, ry, rx in T.grid(T.int64(20), T.int64(1280), T.int64(3), T.int64(3)):
                    with T.block("conv2d_nchw"):
                        v_nn = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ff = T.axis.spatial(T.int64(1280), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) // T.int64(1024))
                        v_yy = T.axis.spatial(T.int64(32), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(1024) // T.int64(32))
                        v_xx = T.axis.spatial(T.int64(32), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(32))
                        v_rc, v_ry, v_rx = T.axis.remap("RRR", [rc, ry, rx])
                        T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_up_blocks_0_upsamplers_0_conv_weight[v_ff, v_rc, v_ry, v_rx])
                        T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                        with T.init():
                            var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                        var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_up_blocks_0_upsamplers_0_conv_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(20)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                        v_ax2 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(32))
                        v_ax3 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                        T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv4668[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv4668[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d15_add13_add13(lv4672: T.Buffer((T.int64(1), T.int64(1920), T.int64(32), T.int64(32)), "float32"), unet_up_blocks_1_resnets_0_conv1_weight: T.Buffer((T.int64(640), T.int64(1920), T.int64(3), T.int64(3)), "float32"), lv4674: T.Buffer((T.int64(1), T.int64(640), T.int64(1), T.int64(1)), "float32"), lv4681: T.Buffer((T.int64(1), T.int64(640), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(640), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(1920), T.int64(34), T.int64(34)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(640), T.int64(32), T.int64(32)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(640), T.int64(32), T.int64(32)))
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(34)):
                    with T.block("pad_temp"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1920), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(1156))
                        v_i2 = T.axis.spatial(T.int64(34), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(1156) // T.int64(34))
                        v_i3 = T.axis.spatial(T.int64(34), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(34))
                        T.where((i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1) * T.int64(256) + i0_i1_i2_i3_fused_2 < T.int64(2219520))
                        T.reads(lv4672[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                        T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                        pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(33) and T.int64(1) <= v_i3 and v_i3 < T.int64(33), lv4672[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn_ff_yy_xx_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for nn_ff_yy_xx_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for nn_ff_yy_xx_fused_0, rc, ry, rx in T.grid(T.int64(10), T.int64(1920), T.int64(3), T.int64(3)):
                    with T.block("conv2d_nchw"):
                        v_nn = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ff = T.axis.spatial(T.int64(640), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) // T.int64(1024))
                        v_yy = T.axis.spatial(T.int64(32), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(1024) // T.int64(32))
                        v_xx = T.axis.spatial(T.int64(32), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(32))
                        v_rc, v_ry, v_rx = T.axis.remap("RRR", [rc, ry, rx])
                        T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_up_blocks_1_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx])
                        T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                        with T.init():
                            var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                        var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_up_blocks_1_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(10)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(640), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                        v_ax2 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(32))
                        v_ax3 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                        T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv4674[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv4674[v_ax0, v_ax1, T.int64(0), T.int64(0)]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(10)):
                    with T.block("T_add_1"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(640), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                        v_ax2 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(32))
                        v_ax3 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                        T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3], lv4681[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] + lv4681[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d16_add13(lv4670: T.Buffer((T.int64(1), T.int64(1920), T.int64(32), T.int64(32)), "float32"), unet_up_blocks_1_resnets_0_conv_shortcut_weight: T.Buffer((T.int64(640), T.int64(1920), T.int64(1), T.int64(1)), "float32"), lv4689: T.Buffer((T.int64(1), T.int64(640), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(640), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(1920), T.int64(32), T.int64(32)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(640), T.int64(32), T.int64(32)))
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(30)):
                    with T.block("pad_temp"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1920), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(1024))
                        v_i2 = T.axis.spatial(T.int64(32), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(1024) // T.int64(32))
                        v_i3 = T.axis.spatial(T.int64(32), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(32))
                        T.reads(lv4670[v_i0, v_i1, v_i2, v_i3])
                        T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                        pad_temp[v_i0, v_i1, v_i2, v_i3] = lv4670[v_i0, v_i1, v_i2, v_i3]
        for nn_ff_yy_xx_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for nn_ff_yy_xx_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for nn_ff_yy_xx_fused_0, rc, ry, rx in T.grid(T.int64(10), T.int64(1920), T.int64(1), T.int64(1)):
                    with T.block("conv2d_nchw"):
                        v_nn = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ff = T.axis.spatial(T.int64(640), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) // T.int64(1024))
                        v_yy = T.axis.spatial(T.int64(32), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(1024) // T.int64(32))
                        v_xx = T.axis.spatial(T.int64(32), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(32))
                        v_rc = T.axis.reduce(T.int64(1920), rc)
                        v_ry = T.axis.reduce(T.int64(1), T.int64(0))
                        v_rx = T.axis.reduce(T.int64(1), T.int64(0))
                        T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_up_blocks_1_resnets_0_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx])
                        T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                        with T.init():
                            var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                        var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_up_blocks_1_resnets_0_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(10)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(640), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                        v_ax2 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(32))
                        v_ax3 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                        T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv4689[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv4689[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d17_add13_add13(lv4841: T.Buffer((T.int64(1), T.int64(1280), T.int64(32), T.int64(32)), "float32"), unet_up_blocks_1_resnets_1_conv1_weight: T.Buffer((T.int64(640), T.int64(1280), T.int64(3), T.int64(3)), "float32"), lv4843: T.Buffer((T.int64(1), T.int64(640), T.int64(1), T.int64(1)), "float32"), lv4850: T.Buffer((T.int64(1), T.int64(640), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(640), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(1280), T.int64(34), T.int64(34)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(640), T.int64(32), T.int64(32)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(640), T.int64(32), T.int64(32)))
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(23)):
                    with T.block("pad_temp"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1280), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(1156))
                        v_i2 = T.axis.spatial(T.int64(34), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(1156) // T.int64(34))
                        v_i3 = T.axis.spatial(T.int64(34), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(34))
                        T.where((i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1) * T.int64(256) + i0_i1_i2_i3_fused_2 < T.int64(1479680))
                        T.reads(lv4841[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                        T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                        pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(33) and T.int64(1) <= v_i3 and v_i3 < T.int64(33), lv4841[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn_ff_yy_xx_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for nn_ff_yy_xx_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for nn_ff_yy_xx_fused_0, rc, ry, rx in T.grid(T.int64(10), T.int64(1280), T.int64(3), T.int64(3)):
                    with T.block("conv2d_nchw"):
                        v_nn = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ff = T.axis.spatial(T.int64(640), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) // T.int64(1024))
                        v_yy = T.axis.spatial(T.int64(32), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(1024) // T.int64(32))
                        v_xx = T.axis.spatial(T.int64(32), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(32))
                        v_rc, v_ry, v_rx = T.axis.remap("RRR", [rc, ry, rx])
                        T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_up_blocks_1_resnets_1_conv1_weight[v_ff, v_rc, v_ry, v_rx])
                        T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                        with T.init():
                            var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                        var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_up_blocks_1_resnets_1_conv1_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(10)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(640), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                        v_ax2 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(32))
                        v_ax3 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                        T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv4843[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv4843[v_ax0, v_ax1, T.int64(0), T.int64(0)]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(10)):
                    with T.block("T_add_1"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(640), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                        v_ax2 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(32))
                        v_ax3 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                        T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3], lv4850[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] + lv4850[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d18_add13(lv4839: T.Buffer((T.int64(1), T.int64(1280), T.int64(32), T.int64(32)), "float32"), unet_up_blocks_1_resnets_1_conv_shortcut_weight: T.Buffer((T.int64(640), T.int64(1280), T.int64(1), T.int64(1)), "float32"), lv4858: T.Buffer((T.int64(1), T.int64(640), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(640), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(1280), T.int64(32), T.int64(32)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(640), T.int64(32), T.int64(32)))
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(20)):
                    with T.block("pad_temp"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1280), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(1024))
                        v_i2 = T.axis.spatial(T.int64(32), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(1024) // T.int64(32))
                        v_i3 = T.axis.spatial(T.int64(32), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(32))
                        T.reads(lv4839[v_i0, v_i1, v_i2, v_i3])
                        T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                        pad_temp[v_i0, v_i1, v_i2, v_i3] = lv4839[v_i0, v_i1, v_i2, v_i3]
        for nn_ff_yy_xx_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for nn_ff_yy_xx_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for nn_ff_yy_xx_fused_0, rc, ry, rx in T.grid(T.int64(10), T.int64(1280), T.int64(1), T.int64(1)):
                    with T.block("conv2d_nchw"):
                        v_nn = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ff = T.axis.spatial(T.int64(640), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) // T.int64(1024))
                        v_yy = T.axis.spatial(T.int64(32), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(1024) // T.int64(32))
                        v_xx = T.axis.spatial(T.int64(32), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(32))
                        v_rc = T.axis.reduce(T.int64(1280), rc)
                        v_ry = T.axis.reduce(T.int64(1), T.int64(0))
                        v_rx = T.axis.reduce(T.int64(1), T.int64(0))
                        T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_up_blocks_1_resnets_1_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx])
                        T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                        with T.init():
                            var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                        var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_up_blocks_1_resnets_1_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(10)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(640), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                        v_ax2 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(32))
                        v_ax3 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                        T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv4858[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv4858[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d19_add13_add13(lv5010: T.Buffer((T.int64(1), T.int64(960), T.int64(32), T.int64(32)), "float32"), unet_up_blocks_1_resnets_2_conv1_weight: T.Buffer((T.int64(640), T.int64(960), T.int64(3), T.int64(3)), "float32"), lv5012: T.Buffer((T.int64(1), T.int64(640), T.int64(1), T.int64(1)), "float32"), lv5019: T.Buffer((T.int64(1), T.int64(640), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(640), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(960), T.int64(34), T.int64(34)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(640), T.int64(32), T.int64(32)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(640), T.int64(32), T.int64(32)))
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(17)):
                    with T.block("pad_temp"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(960), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(1156))
                        v_i2 = T.axis.spatial(T.int64(34), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(1156) // T.int64(34))
                        v_i3 = T.axis.spatial(T.int64(34), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(34))
                        T.where((i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1) * T.int64(256) + i0_i1_i2_i3_fused_2 < T.int64(1109760))
                        T.reads(lv5010[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                        T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                        pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(33) and T.int64(1) <= v_i3 and v_i3 < T.int64(33), lv5010[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn_ff_yy_xx_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for nn_ff_yy_xx_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for nn_ff_yy_xx_fused_0, rc, ry, rx in T.grid(T.int64(10), T.int64(960), T.int64(3), T.int64(3)):
                    with T.block("conv2d_nchw"):
                        v_nn = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ff = T.axis.spatial(T.int64(640), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) // T.int64(1024))
                        v_yy = T.axis.spatial(T.int64(32), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(1024) // T.int64(32))
                        v_xx = T.axis.spatial(T.int64(32), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(32))
                        v_rc, v_ry, v_rx = T.axis.remap("RRR", [rc, ry, rx])
                        T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_up_blocks_1_resnets_2_conv1_weight[v_ff, v_rc, v_ry, v_rx])
                        T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                        with T.init():
                            var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                        var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_up_blocks_1_resnets_2_conv1_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(10)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(640), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                        v_ax2 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(32))
                        v_ax3 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                        T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv5012[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv5012[v_ax0, v_ax1, T.int64(0), T.int64(0)]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(10)):
                    with T.block("T_add_1"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(640), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                        v_ax2 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(32))
                        v_ax3 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                        T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3], lv5019[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] + lv5019[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d1_add9_add11_divide2(lv62: T.Buffer((T.int64(1), T.int64(320), T.int64(64), T.int64(64)), "float32"), unet_down_blocks_0_resnets_0_conv2_weight: T.Buffer((T.int64(320), T.int64(320), T.int64(3), T.int64(3)), "float32"), lv64: T.Buffer((T.int64(1), T.int64(320), T.int64(1), T.int64(1)), "float32"), lv48: T.Buffer((T.int64(1), T.int64(320), T.int64(64), T.int64(64)), "float32"), var_T_divide_intermediate: T.Buffer((T.int64(1), T.int64(320), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(320), T.int64(66), T.int64(66)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(320), T.int64(64), T.int64(64)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(320), T.int64(64), T.int64(64)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(320), T.int64(64), T.int64(64)))
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(22)):
                    with T.block("pad_temp"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(320), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(4356))
                        v_i2 = T.axis.spatial(T.int64(66), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(4356) // T.int64(66))
                        v_i3 = T.axis.spatial(T.int64(66), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(66))
                        T.where((i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1) * T.int64(256) + i0_i1_i2_i3_fused_2 < T.int64(1393920))
                        T.reads(lv62[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                        T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                        pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(65) and T.int64(1) <= v_i3 and v_i3 < T.int64(65), lv62[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn_ff_yy_xx_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for nn_ff_yy_xx_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for nn_ff_yy_xx_fused_0, rc, ry, rx in T.grid(T.int64(20), T.int64(320), T.int64(3), T.int64(3)):
                    with T.block("conv2d_nchw"):
                        v_nn = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ff = T.axis.spatial(T.int64(320), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) // T.int64(4096))
                        v_yy = T.axis.spatial(T.int64(64), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(4096) // T.int64(64))
                        v_xx = T.axis.spatial(T.int64(64), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(64))
                        v_rc, v_ry, v_rx = T.axis.remap("RRR", [rc, ry, rx])
                        T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_down_blocks_0_resnets_0_conv2_weight[v_ff, v_rc, v_ry, v_rx])
                        T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                        with T.init():
                            var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                        var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_down_blocks_0_resnets_0_conv2_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(20)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(320), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(4096))
                        v_ax2 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(4096) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv64[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv64[v_ax0, v_ax1, T.int64(0), T.int64(0)]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(20)):
                    with T.block("T_add_1"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(320), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(4096))
                        v_ax2 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(4096) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.reads(lv48[v_ax0, v_ax1, v_ax2, v_ax3], var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = lv48[v_ax0, v_ax1, v_ax2, v_ax3] + var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(20)):
                    with T.block("T_divide"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(320), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(4096))
                        v_ax2 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(4096) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_conv2d1_add9_add9(lv50: T.Buffer((T.int64(1), T.int64(320), T.int64(64), T.int64(64)), "float32"), unet_down_blocks_0_resnets_0_conv1_weight: T.Buffer((T.int64(320), T.int64(320), T.int64(3), T.int64(3)), "float32"), lv52: T.Buffer((T.int64(1), T.int64(320), T.int64(1), T.int64(1)), "float32"), lv59: T.Buffer((T.int64(1), T.int64(320), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(320), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(320), T.int64(66), T.int64(66)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(320), T.int64(64), T.int64(64)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(320), T.int64(64), T.int64(64)))
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(22)):
                    with T.block("pad_temp"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(320), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(4356))
                        v_i2 = T.axis.spatial(T.int64(66), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(4356) // T.int64(66))
                        v_i3 = T.axis.spatial(T.int64(66), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(66))
                        T.where((i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1) * T.int64(256) + i0_i1_i2_i3_fused_2 < T.int64(1393920))
                        T.reads(lv50[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                        T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                        pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(65) and T.int64(1) <= v_i3 and v_i3 < T.int64(65), lv50[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn_ff_yy_xx_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for nn_ff_yy_xx_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for nn_ff_yy_xx_fused_0, rc, ry, rx in T.grid(T.int64(20), T.int64(320), T.int64(3), T.int64(3)):
                    with T.block("conv2d_nchw"):
                        v_nn = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ff = T.axis.spatial(T.int64(320), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) // T.int64(4096))
                        v_yy = T.axis.spatial(T.int64(64), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(4096) // T.int64(64))
                        v_xx = T.axis.spatial(T.int64(64), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(64))
                        v_rc, v_ry, v_rx = T.axis.remap("RRR", [rc, ry, rx])
                        T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_down_blocks_0_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx])
                        T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                        with T.init():
                            var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                        var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_down_blocks_0_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(20)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(320), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(4096))
                        v_ax2 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(4096) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv52[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv52[v_ax0, v_ax1, T.int64(0), T.int64(0)]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(20)):
                    with T.block("T_add_1"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(320), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(4096))
                        v_ax2 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(4096) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3], lv59[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] + lv59[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d20_add13(lv5008: T.Buffer((T.int64(1), T.int64(960), T.int64(32), T.int64(32)), "float32"), unet_up_blocks_1_resnets_2_conv_shortcut_weight: T.Buffer((T.int64(640), T.int64(960), T.int64(1), T.int64(1)), "float32"), lv5027: T.Buffer((T.int64(1), T.int64(640), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(640), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(960), T.int64(32), T.int64(32)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(640), T.int64(32), T.int64(32)))
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(15)):
                    with T.block("pad_temp"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(960), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(1024))
                        v_i2 = T.axis.spatial(T.int64(32), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(1024) // T.int64(32))
                        v_i3 = T.axis.spatial(T.int64(32), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(32))
                        T.reads(lv5008[v_i0, v_i1, v_i2, v_i3])
                        T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                        pad_temp[v_i0, v_i1, v_i2, v_i3] = lv5008[v_i0, v_i1, v_i2, v_i3]
        for nn_ff_yy_xx_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for nn_ff_yy_xx_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for nn_ff_yy_xx_fused_0, rc, ry, rx in T.grid(T.int64(10), T.int64(960), T.int64(1), T.int64(1)):
                    with T.block("conv2d_nchw"):
                        v_nn = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ff = T.axis.spatial(T.int64(640), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) // T.int64(1024))
                        v_yy = T.axis.spatial(T.int64(32), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(1024) // T.int64(32))
                        v_xx = T.axis.spatial(T.int64(32), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(32))
                        v_rc = T.axis.reduce(T.int64(960), rc)
                        v_ry = T.axis.reduce(T.int64(1), T.int64(0))
                        v_rx = T.axis.reduce(T.int64(1), T.int64(0))
                        T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_up_blocks_1_resnets_2_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx])
                        T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                        with T.init():
                            var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                        var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_up_blocks_1_resnets_2_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(10)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(640), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                        v_ax2 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(32))
                        v_ax3 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                        T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv5027[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv5027[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d21_add26(lv5177: T.Buffer((T.int64(1), T.int64(640), T.int64(64), T.int64(64)), "float32"), unet_up_blocks_1_upsamplers_0_conv_weight: T.Buffer((T.int64(640), T.int64(640), T.int64(3), T.int64(3)), "float32"), lv5179: T.Buffer((T.int64(1), T.int64(640), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(640), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(640), T.int64(66), T.int64(66)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(640), T.int64(64), T.int64(64)))
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(43)):
                    with T.block("pad_temp"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(640), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(4356))
                        v_i2 = T.axis.spatial(T.int64(66), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(4356) // T.int64(66))
                        v_i3 = T.axis.spatial(T.int64(66), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(66))
                        T.where((i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1) * T.int64(256) + i0_i1_i2_i3_fused_2 < T.int64(2787840))
                        T.reads(lv5177[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                        T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                        pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(65) and T.int64(1) <= v_i3 and v_i3 < T.int64(65), lv5177[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn_ff_yy_xx_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for nn_ff_yy_xx_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for nn_ff_yy_xx_fused_0, rc, ry, rx in T.grid(T.int64(40), T.int64(640), T.int64(3), T.int64(3)):
                    with T.block("conv2d_nchw"):
                        v_nn = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ff = T.axis.spatial(T.int64(640), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) // T.int64(4096))
                        v_yy = T.axis.spatial(T.int64(64), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(4096) // T.int64(64))
                        v_xx = T.axis.spatial(T.int64(64), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(64))
                        v_rc, v_ry, v_rx = T.axis.remap("RRR", [rc, ry, rx])
                        T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_up_blocks_1_upsamplers_0_conv_weight[v_ff, v_rc, v_ry, v_rx])
                        T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                        with T.init():
                            var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                        var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_up_blocks_1_upsamplers_0_conv_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(40)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(640), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(4096))
                        v_ax2 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(4096) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv5179[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv5179[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d22_add9_add9(lv5183: T.Buffer((T.int64(1), T.int64(960), T.int64(64), T.int64(64)), "float32"), unet_up_blocks_2_resnets_0_conv1_weight: T.Buffer((T.int64(320), T.int64(960), T.int64(3), T.int64(3)), "float32"), lv5185: T.Buffer((T.int64(1), T.int64(320), T.int64(1), T.int64(1)), "float32"), lv5192: T.Buffer((T.int64(1), T.int64(320), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(320), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(960), T.int64(66), T.int64(66)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(320), T.int64(64), T.int64(64)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(320), T.int64(64), T.int64(64)))
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(64)):
                    with T.block("pad_temp"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(960), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(4356))
                        v_i2 = T.axis.spatial(T.int64(66), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(4356) // T.int64(66))
                        v_i3 = T.axis.spatial(T.int64(66), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(66))
                        T.where((i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1) * T.int64(256) + i0_i1_i2_i3_fused_2 < T.int64(4181760))
                        T.reads(lv5183[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                        T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                        pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(65) and T.int64(1) <= v_i3 and v_i3 < T.int64(65), lv5183[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn_ff_yy_xx_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for nn_ff_yy_xx_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for nn_ff_yy_xx_fused_0, rc, ry, rx in T.grid(T.int64(20), T.int64(960), T.int64(3), T.int64(3)):
                    with T.block("conv2d_nchw"):
                        v_nn = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ff = T.axis.spatial(T.int64(320), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) // T.int64(4096))
                        v_yy = T.axis.spatial(T.int64(64), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(4096) // T.int64(64))
                        v_xx = T.axis.spatial(T.int64(64), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(64))
                        v_rc, v_ry, v_rx = T.axis.remap("RRR", [rc, ry, rx])
                        T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_up_blocks_2_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx])
                        T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                        with T.init():
                            var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                        var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_up_blocks_2_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(20)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(320), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(4096))
                        v_ax2 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(4096) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv5185[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv5185[v_ax0, v_ax1, T.int64(0), T.int64(0)]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(20)):
                    with T.block("T_add_1"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(320), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(4096))
                        v_ax2 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(4096) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3], lv5192[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] + lv5192[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d23_add9(lv5181: T.Buffer((T.int64(1), T.int64(960), T.int64(64), T.int64(64)), "float32"), unet_up_blocks_2_resnets_0_conv_shortcut_weight: T.Buffer((T.int64(320), T.int64(960), T.int64(1), T.int64(1)), "float32"), lv5200: T.Buffer((T.int64(1), T.int64(320), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(320), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(960), T.int64(64), T.int64(64)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(320), T.int64(64), T.int64(64)))
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(60)):
                    with T.block("pad_temp"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(960), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(4096))
                        v_i2 = T.axis.spatial(T.int64(64), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(4096) // T.int64(64))
                        v_i3 = T.axis.spatial(T.int64(64), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(64))
                        T.reads(lv5181[v_i0, v_i1, v_i2, v_i3])
                        T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                        pad_temp[v_i0, v_i1, v_i2, v_i3] = lv5181[v_i0, v_i1, v_i2, v_i3]
        for nn_ff_yy_xx_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for nn_ff_yy_xx_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for nn_ff_yy_xx_fused_0, rc, ry, rx in T.grid(T.int64(20), T.int64(960), T.int64(1), T.int64(1)):
                    with T.block("conv2d_nchw"):
                        v_nn = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ff = T.axis.spatial(T.int64(320), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) // T.int64(4096))
                        v_yy = T.axis.spatial(T.int64(64), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(4096) // T.int64(64))
                        v_xx = T.axis.spatial(T.int64(64), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(64))
                        v_rc = T.axis.reduce(T.int64(960), rc)
                        v_ry = T.axis.reduce(T.int64(1), T.int64(0))
                        v_rx = T.axis.reduce(T.int64(1), T.int64(0))
                        T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_up_blocks_2_resnets_0_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx])
                        T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                        with T.init():
                            var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                        var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_up_blocks_2_resnets_0_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(20)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(320), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(4096))
                        v_ax2 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(4096) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv5200[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv5200[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d24_add9_add9(lv5206: T.Buffer((T.int64(1), T.int64(640), T.int64(64), T.int64(64)), "float32"), unet_up_blocks_2_resnets_1_conv1_weight: T.Buffer((T.int64(320), T.int64(640), T.int64(3), T.int64(3)), "float32"), lv5208: T.Buffer((T.int64(1), T.int64(320), T.int64(1), T.int64(1)), "float32"), lv5215: T.Buffer((T.int64(1), T.int64(320), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(320), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(640), T.int64(66), T.int64(66)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(320), T.int64(64), T.int64(64)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(320), T.int64(64), T.int64(64)))
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(43)):
                    with T.block("pad_temp"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(640), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(4356))
                        v_i2 = T.axis.spatial(T.int64(66), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(4356) // T.int64(66))
                        v_i3 = T.axis.spatial(T.int64(66), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(66))
                        T.where((i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1) * T.int64(256) + i0_i1_i2_i3_fused_2 < T.int64(2787840))
                        T.reads(lv5206[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                        T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                        pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(65) and T.int64(1) <= v_i3 and v_i3 < T.int64(65), lv5206[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn_ff_yy_xx_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for nn_ff_yy_xx_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for nn_ff_yy_xx_fused_0, rc, ry, rx in T.grid(T.int64(20), T.int64(640), T.int64(3), T.int64(3)):
                    with T.block("conv2d_nchw"):
                        v_nn = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ff = T.axis.spatial(T.int64(320), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) // T.int64(4096))
                        v_yy = T.axis.spatial(T.int64(64), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(4096) // T.int64(64))
                        v_xx = T.axis.spatial(T.int64(64), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(64))
                        v_rc, v_ry, v_rx = T.axis.remap("RRR", [rc, ry, rx])
                        T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_up_blocks_2_resnets_1_conv1_weight[v_ff, v_rc, v_ry, v_rx])
                        T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                        with T.init():
                            var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                        var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_up_blocks_2_resnets_1_conv1_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(20)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(320), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(4096))
                        v_ax2 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(4096) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv5208[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv5208[v_ax0, v_ax1, T.int64(0), T.int64(0)]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(20)):
                    with T.block("T_add_1"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(320), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(4096))
                        v_ax2 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(4096) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3], lv5215[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] + lv5215[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d25_add9(lv5204: T.Buffer((T.int64(1), T.int64(640), T.int64(64), T.int64(64)), "float32"), unet_up_blocks_2_resnets_1_conv_shortcut_weight: T.Buffer((T.int64(320), T.int64(640), T.int64(1), T.int64(1)), "float32"), lv5223: T.Buffer((T.int64(1), T.int64(320), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(320), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(640), T.int64(64), T.int64(64)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(320), T.int64(64), T.int64(64)))
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(40)):
                    with T.block("pad_temp"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(640), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(4096))
                        v_i2 = T.axis.spatial(T.int64(64), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(4096) // T.int64(64))
                        v_i3 = T.axis.spatial(T.int64(64), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(64))
                        T.reads(lv5204[v_i0, v_i1, v_i2, v_i3])
                        T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                        pad_temp[v_i0, v_i1, v_i2, v_i3] = lv5204[v_i0, v_i1, v_i2, v_i3]
        for nn_ff_yy_xx_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for nn_ff_yy_xx_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for nn_ff_yy_xx_fused_0, rc, ry, rx in T.grid(T.int64(20), T.int64(640), T.int64(1), T.int64(1)):
                    with T.block("conv2d_nchw"):
                        v_nn = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ff = T.axis.spatial(T.int64(320), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) // T.int64(4096))
                        v_yy = T.axis.spatial(T.int64(64), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(4096) // T.int64(64))
                        v_xx = T.axis.spatial(T.int64(64), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(64))
                        v_rc = T.axis.reduce(T.int64(640), rc)
                        v_ry = T.axis.reduce(T.int64(1), T.int64(0))
                        v_rx = T.axis.reduce(T.int64(1), T.int64(0))
                        T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_up_blocks_2_resnets_1_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx])
                        T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                        with T.init():
                            var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                        var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_up_blocks_2_resnets_1_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(20)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(320), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(4096))
                        v_ax2 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(4096) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv5223[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv5223[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d26_add27(lv5251: T.Buffer((T.int64(1), T.int64(320), T.int64(64), T.int64(64)), "float32"), unet_conv_out_weight: T.Buffer((T.int64(4), T.int64(320), T.int64(3), T.int64(3)), "float32"), lv5253: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(4), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(320), T.int64(66), T.int64(66)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(64), T.int64(64)))
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(22)):
                    with T.block("pad_temp"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(320), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(4356))
                        v_i2 = T.axis.spatial(T.int64(66), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(4356) // T.int64(66))
                        v_i3 = T.axis.spatial(T.int64(66), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(66))
                        T.where((i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1) * T.int64(256) + i0_i1_i2_i3_fused_2 < T.int64(1393920))
                        T.reads(lv5251[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                        T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                        pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(65) and T.int64(1) <= v_i3 and v_i3 < T.int64(65), lv5251[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn_ff_yy_xx_fused_0 in T.thread_binding(T.int64(64), thread="blockIdx.x"):
            for nn_ff_yy_xx_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for rc, ry, rx in T.grid(T.int64(320), T.int64(3), T.int64(3)):
                    with T.block("conv2d_nchw"):
                        v_nn = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ff = T.axis.spatial(T.int64(4), (nn_ff_yy_xx_fused_0 * T.int64(256) + nn_ff_yy_xx_fused_1) // T.int64(4096))
                        v_yy = T.axis.spatial(T.int64(64), (nn_ff_yy_xx_fused_0 * T.int64(256) + nn_ff_yy_xx_fused_1) % T.int64(4096) // T.int64(64))
                        v_xx = T.axis.spatial(T.int64(64), (nn_ff_yy_xx_fused_0 * T.int64(256) + nn_ff_yy_xx_fused_1) % T.int64(64))
                        v_rc, v_ry, v_rx = T.axis.remap("RRR", [rc, ry, rx])
                        T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_conv_out_weight[v_ff, v_rc, v_ry, v_rx])
                        T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                        with T.init():
                            var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                        var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_conv_out_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0_ax1_ax2_ax3_fused_0 in T.thread_binding(T.int64(64), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_add"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) // T.int64(4096))
                    v_ax2 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(4096) // T.int64(64))
                    v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(64))
                    T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv5253[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                    T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                    var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv5253[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d27_add27(lv: T.Buffer((T.int64(1), T.int64(4), T.int64(64), T.int64(64)), "float32"), vae_post_quant_conv_weight: T.Buffer((T.int64(4), T.int64(4), T.int64(1), T.int64(1)), "float32"), lv2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(4), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(64), T.int64(64)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(64), T.int64(64)))
        for i0_i1_i2_i3_fused_0 in T.thread_binding(T.int64(64), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("pad_temp"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(4), (i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1) // T.int64(4096))
                    v_i2 = T.axis.spatial(T.int64(64), (i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1) % T.int64(4096) // T.int64(64))
                    v_i3 = T.axis.spatial(T.int64(64), (i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1) % T.int64(64))
                    T.reads(lv[v_i0, v_i1, v_i2, v_i3])
                    T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                    pad_temp[v_i0, v_i1, v_i2, v_i3] = lv[v_i0, v_i1, v_i2, v_i3]
        for nn_ff_yy_xx_fused_0 in T.thread_binding(T.int64(64), thread="blockIdx.x"):
            for nn_ff_yy_xx_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for rc, ry, rx in T.grid(T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("conv2d_nchw"):
                        v_nn = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ff = T.axis.spatial(T.int64(4), (nn_ff_yy_xx_fused_0 * T.int64(256) + nn_ff_yy_xx_fused_1) // T.int64(4096))
                        v_yy = T.axis.spatial(T.int64(64), (nn_ff_yy_xx_fused_0 * T.int64(256) + nn_ff_yy_xx_fused_1) % T.int64(4096) // T.int64(64))
                        v_xx = T.axis.spatial(T.int64(64), (nn_ff_yy_xx_fused_0 * T.int64(256) + nn_ff_yy_xx_fused_1) % T.int64(64))
                        v_rc = T.axis.reduce(T.int64(4), rc)
                        v_ry = T.axis.reduce(T.int64(1), T.int64(0))
                        v_rx = T.axis.reduce(T.int64(1), T.int64(0))
                        T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_post_quant_conv_weight[v_ff, v_rc, v_ry, v_rx])
                        T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                        with T.init():
                            var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                        var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_post_quant_conv_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0_ax1_ax2_ax3_fused_0 in T.thread_binding(T.int64(64), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_add"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) // T.int64(4096))
                    v_ax2 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(4096) // T.int64(64))
                    v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(64))
                    T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv2[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                    T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                    var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv2[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d28_add28(lv3: T.Buffer((T.int64(1), T.int64(4), T.int64(64), T.int64(64)), "float32"), vae_decoder_conv_in_weight: T.Buffer((T.int64(512), T.int64(4), T.int64(3), T.int64(3)), "float32"), lv5: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(512), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(66), T.int64(66)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(64), T.int64(64)))
        for i0_i1_i2_i3_fused_0 in T.thread_binding(T.int64(69), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("pad_temp"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(4), (i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1) // T.int64(4356))
                    v_i2 = T.axis.spatial(T.int64(66), (i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1) % T.int64(4356) // T.int64(66))
                    v_i3 = T.axis.spatial(T.int64(66), (i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1) % T.int64(66))
                    T.where(i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1 < T.int64(17424))
                    T.reads(lv3[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                    T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                    pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(65) and T.int64(1) <= v_i3 and v_i3 < T.int64(65), lv3[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn_ff_yy_xx_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for nn_ff_yy_xx_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for nn_ff_yy_xx_fused_0, rc, ry, rx in T.grid(T.int64(32), T.int64(4), T.int64(3), T.int64(3)):
                    with T.block("conv2d_nchw"):
                        v_nn = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ff = T.axis.spatial(T.int64(512), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) // T.int64(4096))
                        v_yy = T.axis.spatial(T.int64(64), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(4096) // T.int64(64))
                        v_xx = T.axis.spatial(T.int64(64), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(64))
                        v_rc, v_ry, v_rx = T.axis.remap("RRR", [rc, ry, rx])
                        T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_decoder_conv_in_weight[v_ff, v_rc, v_ry, v_rx])
                        T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                        with T.init():
                            var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                        var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_decoder_conv_in_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(32)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(4096))
                        v_ax2 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(4096) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv5[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv5[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d29_add28(lv8: T.Buffer((T.int64(1), T.int64(512), T.int64(64), T.int64(64)), "float32"), vae_decoder_mid_block_resnets_0_conv1_weight: T.Buffer((T.int64(512), T.int64(512), T.int64(3), T.int64(3)), "float32"), lv10: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(512), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(66), T.int64(66)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(64), T.int64(64)))
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(35)):
                    with T.block("pad_temp"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(512), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(4356))
                        v_i2 = T.axis.spatial(T.int64(66), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(4356) // T.int64(66))
                        v_i3 = T.axis.spatial(T.int64(66), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(66))
                        T.where((i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1) * T.int64(256) + i0_i1_i2_i3_fused_2 < T.int64(2230272))
                        T.reads(lv8[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                        T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                        pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(65) and T.int64(1) <= v_i3 and v_i3 < T.int64(65), lv8[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn_ff_yy_xx_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for nn_ff_yy_xx_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for nn_ff_yy_xx_fused_0, rc, ry, rx in T.grid(T.int64(32), T.int64(512), T.int64(3), T.int64(3)):
                    with T.block("conv2d_nchw"):
                        v_nn = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ff = T.axis.spatial(T.int64(512), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) // T.int64(4096))
                        v_yy = T.axis.spatial(T.int64(64), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(4096) // T.int64(64))
                        v_xx = T.axis.spatial(T.int64(64), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(64))
                        v_rc, v_ry, v_rx = T.axis.remap("RRR", [rc, ry, rx])
                        T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_decoder_mid_block_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx])
                        T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                        with T.init():
                            var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                        var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_decoder_mid_block_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(32)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(4096))
                        v_ax2 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(4096) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv10[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv10[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d29_add28_add29_divide8(lv13: T.Buffer((T.int64(1), T.int64(512), T.int64(64), T.int64(64)), "float32"), vae_decoder_mid_block_resnets_0_conv2_weight: T.Buffer((T.int64(512), T.int64(512), T.int64(3), T.int64(3)), "float32"), lv15: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), lv6: T.Buffer((T.int64(1), T.int64(512), T.int64(64), T.int64(64)), "float32"), var_T_divide_intermediate: T.Buffer((T.int64(1), T.int64(512), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(66), T.int64(66)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(64), T.int64(64)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(64), T.int64(64)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(64), T.int64(64)))
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(35)):
                    with T.block("pad_temp"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(512), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(4356))
                        v_i2 = T.axis.spatial(T.int64(66), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(4356) // T.int64(66))
                        v_i3 = T.axis.spatial(T.int64(66), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(66))
                        T.where((i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1) * T.int64(256) + i0_i1_i2_i3_fused_2 < T.int64(2230272))
                        T.reads(lv13[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                        T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                        pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(65) and T.int64(1) <= v_i3 and v_i3 < T.int64(65), lv13[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn_ff_yy_xx_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for nn_ff_yy_xx_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for nn_ff_yy_xx_fused_0, rc, ry, rx in T.grid(T.int64(32), T.int64(512), T.int64(3), T.int64(3)):
                    with T.block("conv2d_nchw"):
                        v_nn = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ff = T.axis.spatial(T.int64(512), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) // T.int64(4096))
                        v_yy = T.axis.spatial(T.int64(64), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(4096) // T.int64(64))
                        v_xx = T.axis.spatial(T.int64(64), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(64))
                        v_rc, v_ry, v_rx = T.axis.remap("RRR", [rc, ry, rx])
                        T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_decoder_mid_block_resnets_0_conv2_weight[v_ff, v_rc, v_ry, v_rx])
                        T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                        with T.init():
                            var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                        var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_decoder_mid_block_resnets_0_conv2_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(32)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(4096))
                        v_ax2 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(4096) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv15[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv15[v_ax0, v_ax1, T.int64(0), T.int64(0)]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(32)):
                    with T.block("T_add_1"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(4096))
                        v_ax2 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(4096) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.reads(lv6[v_ax0, v_ax1, v_ax2, v_ax3], var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = lv6[v_ax0, v_ax1, v_ax2, v_ax3] + var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(32)):
                    with T.block("T_divide"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(4096))
                        v_ax2 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(4096) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_conv2d29_add28_add29_divide8_divide8(lv61: T.Buffer((T.int64(1), T.int64(512), T.int64(64), T.int64(64)), "float32"), vae_decoder_mid_block_resnets_1_conv2_weight: T.Buffer((T.int64(512), T.int64(512), T.int64(3), T.int64(3)), "float32"), lv63: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), lv54: T.Buffer((T.int64(1), T.int64(512), T.int64(64), T.int64(64)), "float32"), var_T_divide_intermediate: T.Buffer((T.int64(1), T.int64(512), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(66), T.int64(66)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(64), T.int64(64)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(64), T.int64(64)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(64), T.int64(64)))
        var_T_divide_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(64), T.int64(64)))
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(35)):
                    with T.block("pad_temp"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(512), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(4356))
                        v_i2 = T.axis.spatial(T.int64(66), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(4356) // T.int64(66))
                        v_i3 = T.axis.spatial(T.int64(66), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(66))
                        T.where((i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1) * T.int64(256) + i0_i1_i2_i3_fused_2 < T.int64(2230272))
                        T.reads(lv61[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                        T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                        pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(65) and T.int64(1) <= v_i3 and v_i3 < T.int64(65), lv61[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn_ff_yy_xx_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for nn_ff_yy_xx_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for nn_ff_yy_xx_fused_0, rc, ry, rx in T.grid(T.int64(32), T.int64(512), T.int64(3), T.int64(3)):
                    with T.block("conv2d_nchw"):
                        v_nn = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ff = T.axis.spatial(T.int64(512), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) // T.int64(4096))
                        v_yy = T.axis.spatial(T.int64(64), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(4096) // T.int64(64))
                        v_xx = T.axis.spatial(T.int64(64), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(64))
                        v_rc, v_ry, v_rx = T.axis.remap("RRR", [rc, ry, rx])
                        T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_decoder_mid_block_resnets_1_conv2_weight[v_ff, v_rc, v_ry, v_rx])
                        T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                        with T.init():
                            var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                        var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_decoder_mid_block_resnets_1_conv2_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(32)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(4096))
                        v_ax2 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(4096) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv63[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv63[v_ax0, v_ax1, T.int64(0), T.int64(0)]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(32)):
                    with T.block("T_add_1"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(4096))
                        v_ax2 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(4096) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.reads(lv54[v_ax0, v_ax1, v_ax2, v_ax3], var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = lv54[v_ax0, v_ax1, v_ax2, v_ax3] + var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(32)):
                    with T.block("T_divide"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(4096))
                        v_ax2 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(4096) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(var_T_divide_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_divide_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(32)):
                    with T.block("T_divide_1"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(4096))
                        v_ax2 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(4096) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.reads(var_T_divide_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_divide_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_conv2d2_add12(lv86: T.Buffer((T.int64(1), T.int64(320), T.int64(64), T.int64(64)), "float32"), unet_down_blocks_0_downsamplers_0_conv_weight: T.Buffer((T.int64(320), T.int64(320), T.int64(3), T.int64(3)), "float32"), lv88: T.Buffer((T.int64(1), T.int64(320), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(320), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(320), T.int64(66), T.int64(66)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(320), T.int64(32), T.int64(32)))
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(22)):
                    with T.block("pad_temp"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(320), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(4356))
                        v_i2 = T.axis.spatial(T.int64(66), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(4356) // T.int64(66))
                        v_i3 = T.axis.spatial(T.int64(66), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(66))
                        T.where((i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1) * T.int64(256) + i0_i1_i2_i3_fused_2 < T.int64(1393920))
                        T.reads(lv86[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                        T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                        pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(65) and T.int64(1) <= v_i3 and v_i3 < T.int64(65), lv86[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn_ff_yy_xx_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for nn_ff_yy_xx_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for nn_ff_yy_xx_fused_0, rc, ry, rx in T.grid(T.int64(5), T.int64(320), T.int64(3), T.int64(3)):
                    with T.block("conv2d_nchw"):
                        v_nn = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ff = T.axis.spatial(T.int64(320), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) // T.int64(1024))
                        v_yy = T.axis.spatial(T.int64(32), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(1024) // T.int64(32))
                        v_xx = T.axis.spatial(T.int64(32), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(32))
                        v_rc, v_ry, v_rx = T.axis.remap("RRR", [rc, ry, rx])
                        T.reads(pad_temp[v_nn, v_rc, v_yy * T.int64(2) + v_ry, v_xx * T.int64(2) + v_rx], unet_down_blocks_0_downsamplers_0_conv_weight[v_ff, v_rc, v_ry, v_rx])
                        T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                        with T.init():
                            var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                        var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy * T.int64(2) + v_ry, v_xx * T.int64(2) + v_rx] * unet_down_blocks_0_downsamplers_0_conv_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(5)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(320), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                        v_ax2 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(32))
                        v_ax3 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                        T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv88[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv88[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d30_add31(lv104: T.Buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)), "float32"), vae_decoder_up_blocks_0_upsamplers_0_conv_weight: T.Buffer((T.int64(512), T.int64(512), T.int64(3), T.int64(3)), "float32"), lv106: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(130), T.int64(130)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)))
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(133)):
                    with T.block("pad_temp"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(512), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(16900))
                        v_i2 = T.axis.spatial(T.int64(130), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(16900) // T.int64(130))
                        v_i3 = T.axis.spatial(T.int64(130), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(130))
                        T.where((i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1) * T.int64(256) + i0_i1_i2_i3_fused_2 < T.int64(8652800))
                        T.reads(lv104[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                        T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                        pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(129) and T.int64(1) <= v_i3 and v_i3 < T.int64(129), lv104[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn_ff_yy_xx_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for nn_ff_yy_xx_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for nn_ff_yy_xx_fused_0, rc, ry, rx in T.grid(T.int64(128), T.int64(512), T.int64(3), T.int64(3)):
                    with T.block("conv2d_nchw"):
                        v_nn = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ff = T.axis.spatial(T.int64(512), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) // T.int64(16384))
                        v_yy = T.axis.spatial(T.int64(128), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(16384) // T.int64(128))
                        v_xx = T.axis.spatial(T.int64(128), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(128))
                        v_rc, v_ry, v_rx = T.axis.remap("RRR", [rc, ry, rx])
                        T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_decoder_up_blocks_0_upsamplers_0_conv_weight[v_ff, v_rc, v_ry, v_rx])
                        T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                        with T.init():
                            var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                        var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_decoder_up_blocks_0_upsamplers_0_conv_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(128)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(16384))
                        v_ax2 = T.axis.spatial(T.int64(128), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16384) // T.int64(128))
                        v_ax3 = T.axis.spatial(T.int64(128), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(128))
                        T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv106[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv106[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d30_add31_add32_divide9(lv114: T.Buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)), "float32"), vae_decoder_up_blocks_1_resnets_0_conv2_weight: T.Buffer((T.int64(512), T.int64(512), T.int64(3), T.int64(3)), "float32"), lv116: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), lv107: T.Buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)), "float32"), var_T_divide_intermediate: T.Buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(130), T.int64(130)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)))
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(133)):
                    with T.block("pad_temp"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(512), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(16900))
                        v_i2 = T.axis.spatial(T.int64(130), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(16900) // T.int64(130))
                        v_i3 = T.axis.spatial(T.int64(130), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(130))
                        T.where((i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1) * T.int64(256) + i0_i1_i2_i3_fused_2 < T.int64(8652800))
                        T.reads(lv114[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                        T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                        pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(129) and T.int64(1) <= v_i3 and v_i3 < T.int64(129), lv114[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn_ff_yy_xx_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for nn_ff_yy_xx_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for nn_ff_yy_xx_fused_0, rc, ry, rx in T.grid(T.int64(128), T.int64(512), T.int64(3), T.int64(3)):
                    with T.block("conv2d_nchw"):
                        v_nn = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ff = T.axis.spatial(T.int64(512), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) // T.int64(16384))
                        v_yy = T.axis.spatial(T.int64(128), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(16384) // T.int64(128))
                        v_xx = T.axis.spatial(T.int64(128), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(128))
                        v_rc, v_ry, v_rx = T.axis.remap("RRR", [rc, ry, rx])
                        T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_decoder_up_blocks_1_resnets_0_conv2_weight[v_ff, v_rc, v_ry, v_rx])
                        T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                        with T.init():
                            var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                        var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_decoder_up_blocks_1_resnets_0_conv2_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(128)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(16384))
                        v_ax2 = T.axis.spatial(T.int64(128), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16384) // T.int64(128))
                        v_ax3 = T.axis.spatial(T.int64(128), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(128))
                        T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv116[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv116[v_ax0, v_ax1, T.int64(0), T.int64(0)]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(128)):
                    with T.block("T_add_1"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(16384))
                        v_ax2 = T.axis.spatial(T.int64(128), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16384) // T.int64(128))
                        v_ax3 = T.axis.spatial(T.int64(128), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(128))
                        T.reads(lv107[v_ax0, v_ax1, v_ax2, v_ax3], var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = lv107[v_ax0, v_ax1, v_ax2, v_ax3] + var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(128)):
                    with T.block("T_divide"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(16384))
                        v_ax2 = T.axis.spatial(T.int64(128), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16384) // T.int64(128))
                        v_ax3 = T.axis.spatial(T.int64(128), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(128))
                        T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_conv2d31_add33(lv144: T.Buffer((T.int64(1), T.int64(512), T.int64(256), T.int64(256)), "float32"), vae_decoder_up_blocks_1_upsamplers_0_conv_weight: T.Buffer((T.int64(512), T.int64(512), T.int64(3), T.int64(3)), "float32"), lv146: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(512), T.int64(256), T.int64(256)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(258), T.int64(258)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(256), T.int64(256)))
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(521)):
                    with T.block("pad_temp"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(512), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(66564))
                        v_i2 = T.axis.spatial(T.int64(258), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(66564) // T.int64(258))
                        v_i3 = T.axis.spatial(T.int64(258), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(258))
                        T.where((i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1) * T.int64(256) + i0_i1_i2_i3_fused_2 < T.int64(34080768))
                        T.reads(lv144[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                        T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                        pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(257) and T.int64(1) <= v_i3 and v_i3 < T.int64(257), lv144[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn_ff_yy_xx_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for nn_ff_yy_xx_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for nn_ff_yy_xx_fused_0, rc, ry, rx in T.grid(T.int64(512), T.int64(512), T.int64(3), T.int64(3)):
                    with T.block("conv2d_nchw"):
                        v_nn = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ff = T.axis.spatial(T.int64(512), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) // T.int64(65536))
                        v_yy = T.axis.spatial(T.int64(256), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(65536) // T.int64(256))
                        v_xx = T.axis.spatial(T.int64(256), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(256))
                        v_rc, v_ry, v_rx = T.axis.remap("RRR", [rc, ry, rx])
                        T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_decoder_up_blocks_1_upsamplers_0_conv_weight[v_ff, v_rc, v_ry, v_rx])
                        T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                        with T.init():
                            var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                        var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_decoder_up_blocks_1_upsamplers_0_conv_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(512)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(65536))
                        v_ax2 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(65536) // T.int64(256))
                        v_ax3 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256))
                        T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv146[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv146[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d32_add34(lv149: T.Buffer((T.int64(1), T.int64(512), T.int64(256), T.int64(256)), "float32"), vae_decoder_up_blocks_2_resnets_0_conv1_weight: T.Buffer((T.int64(256), T.int64(512), T.int64(3), T.int64(3)), "float32"), lv151: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(256), T.int64(256), T.int64(256)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(258), T.int64(258)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(256), T.int64(256)))
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(521)):
                    with T.block("pad_temp"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(512), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(66564))
                        v_i2 = T.axis.spatial(T.int64(258), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(66564) // T.int64(258))
                        v_i3 = T.axis.spatial(T.int64(258), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(258))
                        T.where((i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1) * T.int64(256) + i0_i1_i2_i3_fused_2 < T.int64(34080768))
                        T.reads(lv149[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                        T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                        pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(257) and T.int64(1) <= v_i3 and v_i3 < T.int64(257), lv149[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn_ff_yy_xx_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for nn_ff_yy_xx_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for nn_ff_yy_xx_fused_0, rc, ry, rx in T.grid(T.int64(256), T.int64(512), T.int64(3), T.int64(3)):
                    with T.block("conv2d_nchw"):
                        v_nn = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ff = T.axis.spatial(T.int64(256), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) // T.int64(65536))
                        v_yy = T.axis.spatial(T.int64(256), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(65536) // T.int64(256))
                        v_xx = T.axis.spatial(T.int64(256), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(256))
                        v_rc, v_ry, v_rx = T.axis.remap("RRR", [rc, ry, rx])
                        T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_decoder_up_blocks_2_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx])
                        T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                        with T.init():
                            var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                        var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_decoder_up_blocks_2_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(256)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(65536))
                        v_ax2 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(65536) // T.int64(256))
                        v_ax3 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256))
                        T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv151[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv151[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d33_add34(lv164: T.Buffer((T.int64(1), T.int64(256), T.int64(256), T.int64(256)), "float32"), vae_decoder_up_blocks_2_resnets_1_conv1_weight: T.Buffer((T.int64(256), T.int64(256), T.int64(3), T.int64(3)), "float32"), lv166: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(256), T.int64(256), T.int64(256)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(258), T.int64(258)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(256), T.int64(256)))
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(261)):
                    with T.block("pad_temp"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(256), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(66564))
                        v_i2 = T.axis.spatial(T.int64(258), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(66564) // T.int64(258))
                        v_i3 = T.axis.spatial(T.int64(258), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(258))
                        T.where((i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1) * T.int64(256) + i0_i1_i2_i3_fused_2 < T.int64(17040384))
                        T.reads(lv164[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                        T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                        pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(257) and T.int64(1) <= v_i3 and v_i3 < T.int64(257), lv164[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn_ff_yy_xx_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for nn_ff_yy_xx_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for nn_ff_yy_xx_fused_0, rc, ry, rx in T.grid(T.int64(256), T.int64(256), T.int64(3), T.int64(3)):
                    with T.block("conv2d_nchw"):
                        v_nn = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ff = T.axis.spatial(T.int64(256), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) // T.int64(65536))
                        v_yy = T.axis.spatial(T.int64(256), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(65536) // T.int64(256))
                        v_xx = T.axis.spatial(T.int64(256), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(256))
                        v_rc, v_ry, v_rx = T.axis.remap("RRR", [rc, ry, rx])
                        T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_decoder_up_blocks_2_resnets_1_conv1_weight[v_ff, v_rc, v_ry, v_rx])
                        T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                        with T.init():
                            var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                        var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_decoder_up_blocks_2_resnets_1_conv1_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(256)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(65536))
                        v_ax2 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(65536) // T.int64(256))
                        v_ax3 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256))
                        T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv166[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv166[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d33_add34_add35_divide10(lv154: T.Buffer((T.int64(1), T.int64(256), T.int64(256), T.int64(256)), "float32"), vae_decoder_up_blocks_2_resnets_0_conv2_weight: T.Buffer((T.int64(256), T.int64(256), T.int64(3), T.int64(3)), "float32"), lv156: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), lv160: T.Buffer((T.int64(1), T.int64(256), T.int64(256), T.int64(256)), "float32"), var_T_divide_intermediate: T.Buffer((T.int64(1), T.int64(256), T.int64(256), T.int64(256)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(258), T.int64(258)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(256), T.int64(256)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(256), T.int64(256)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(256), T.int64(256)))
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(261)):
                    with T.block("pad_temp"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(256), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(66564))
                        v_i2 = T.axis.spatial(T.int64(258), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(66564) // T.int64(258))
                        v_i3 = T.axis.spatial(T.int64(258), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(258))
                        T.where((i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1) * T.int64(256) + i0_i1_i2_i3_fused_2 < T.int64(17040384))
                        T.reads(lv154[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                        T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                        pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(257) and T.int64(1) <= v_i3 and v_i3 < T.int64(257), lv154[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn_ff_yy_xx_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for nn_ff_yy_xx_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for nn_ff_yy_xx_fused_0, rc, ry, rx in T.grid(T.int64(256), T.int64(256), T.int64(3), T.int64(3)):
                    with T.block("conv2d_nchw"):
                        v_nn = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ff = T.axis.spatial(T.int64(256), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) // T.int64(65536))
                        v_yy = T.axis.spatial(T.int64(256), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(65536) // T.int64(256))
                        v_xx = T.axis.spatial(T.int64(256), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(256))
                        v_rc, v_ry, v_rx = T.axis.remap("RRR", [rc, ry, rx])
                        T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_decoder_up_blocks_2_resnets_0_conv2_weight[v_ff, v_rc, v_ry, v_rx])
                        T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                        with T.init():
                            var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                        var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_decoder_up_blocks_2_resnets_0_conv2_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(256)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(65536))
                        v_ax2 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(65536) // T.int64(256))
                        v_ax3 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256))
                        T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv156[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv156[v_ax0, v_ax1, T.int64(0), T.int64(0)]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(256)):
                    with T.block("T_add_1"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(65536))
                        v_ax2 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(65536) // T.int64(256))
                        v_ax3 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256))
                        T.reads(lv160[v_ax0, v_ax1, v_ax2, v_ax3], var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = lv160[v_ax0, v_ax1, v_ax2, v_ax3] + var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(256)):
                    with T.block("T_divide"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(65536))
                        v_ax2 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(65536) // T.int64(256))
                        v_ax3 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256))
                        T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_conv2d34_add34(lv147: T.Buffer((T.int64(1), T.int64(512), T.int64(256), T.int64(256)), "float32"), vae_decoder_up_blocks_2_resnets_0_conv_shortcut_weight: T.Buffer((T.int64(256), T.int64(512), T.int64(1), T.int64(1)), "float32"), lv159: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(256), T.int64(256), T.int64(256)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(256), T.int64(256)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(256), T.int64(256)))
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(512)):
                    with T.block("pad_temp"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(512), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(65536))
                        v_i2 = T.axis.spatial(T.int64(256), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(65536) // T.int64(256))
                        v_i3 = T.axis.spatial(T.int64(256), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(256))
                        T.reads(lv147[v_i0, v_i1, v_i2, v_i3])
                        T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                        pad_temp[v_i0, v_i1, v_i2, v_i3] = lv147[v_i0, v_i1, v_i2, v_i3]
        for nn_ff_yy_xx_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for nn_ff_yy_xx_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for nn_ff_yy_xx_fused_0, rc, ry, rx in T.grid(T.int64(256), T.int64(512), T.int64(1), T.int64(1)):
                    with T.block("conv2d_nchw"):
                        v_nn = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ff = T.axis.spatial(T.int64(256), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) // T.int64(65536))
                        v_yy = T.axis.spatial(T.int64(256), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(65536) // T.int64(256))
                        v_xx = T.axis.spatial(T.int64(256), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(256))
                        v_rc = T.axis.reduce(T.int64(512), rc)
                        v_ry = T.axis.reduce(T.int64(1), T.int64(0))
                        v_rx = T.axis.reduce(T.int64(1), T.int64(0))
                        T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_decoder_up_blocks_2_resnets_0_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx])
                        T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                        with T.init():
                            var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                        var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_decoder_up_blocks_2_resnets_0_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(256)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(65536))
                        v_ax2 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(65536) // T.int64(256))
                        v_ax3 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256))
                        T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv159[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv159[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d35_add36(lv187: T.Buffer((T.int64(1), T.int64(256), T.int64(512), T.int64(512)), "float32"), vae_decoder_up_blocks_2_upsamplers_0_conv_weight: T.Buffer((T.int64(256), T.int64(256), T.int64(3), T.int64(3)), "float32"), lv189: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(256), T.int64(512), T.int64(512)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(514), T.int64(514)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(512), T.int64(512)))
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(1033)):
                    with T.block("pad_temp"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(256), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(264196))
                        v_i2 = T.axis.spatial(T.int64(514), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(264196) // T.int64(514))
                        v_i3 = T.axis.spatial(T.int64(514), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(514))
                        T.where((i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1) * T.int64(256) + i0_i1_i2_i3_fused_2 < T.int64(67634176))
                        T.reads(lv187[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                        T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                        pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(513) and T.int64(1) <= v_i3 and v_i3 < T.int64(513), lv187[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn_ff_yy_xx_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for nn_ff_yy_xx_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for nn_ff_yy_xx_fused_0, rc, ry, rx in T.grid(T.int64(1024), T.int64(256), T.int64(3), T.int64(3)):
                    with T.block("conv2d_nchw"):
                        v_nn = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ff = T.axis.spatial(T.int64(256), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) // T.int64(262144))
                        v_yy = T.axis.spatial(T.int64(512), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(262144) // T.int64(512))
                        v_xx = T.axis.spatial(T.int64(512), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(512))
                        v_rc, v_ry, v_rx = T.axis.remap("RRR", [rc, ry, rx])
                        T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_decoder_up_blocks_2_upsamplers_0_conv_weight[v_ff, v_rc, v_ry, v_rx])
                        T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                        with T.init():
                            var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                        var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_decoder_up_blocks_2_upsamplers_0_conv_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(1024)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(262144))
                        v_ax2 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(262144) // T.int64(512))
                        v_ax3 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512))
                        T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv189[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv189[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d36_add37(lv192: T.Buffer((T.int64(1), T.int64(256), T.int64(512), T.int64(512)), "float32"), vae_decoder_up_blocks_3_resnets_0_conv1_weight: T.Buffer((T.int64(128), T.int64(256), T.int64(3), T.int64(3)), "float32"), lv194: T.Buffer((T.int64(1), T.int64(128), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(128), T.int64(512), T.int64(512)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(514), T.int64(514)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(128), T.int64(512), T.int64(512)))
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(1033)):
                    with T.block("pad_temp"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(256), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(264196))
                        v_i2 = T.axis.spatial(T.int64(514), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(264196) // T.int64(514))
                        v_i3 = T.axis.spatial(T.int64(514), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(514))
                        T.where((i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1) * T.int64(256) + i0_i1_i2_i3_fused_2 < T.int64(67634176))
                        T.reads(lv192[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                        T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                        pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(513) and T.int64(1) <= v_i3 and v_i3 < T.int64(513), lv192[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn_ff_yy_xx_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for nn_ff_yy_xx_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for nn_ff_yy_xx_fused_0, rc, ry, rx in T.grid(T.int64(512), T.int64(256), T.int64(3), T.int64(3)):
                    with T.block("conv2d_nchw"):
                        v_nn = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ff = T.axis.spatial(T.int64(128), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) // T.int64(262144))
                        v_yy = T.axis.spatial(T.int64(512), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(262144) // T.int64(512))
                        v_xx = T.axis.spatial(T.int64(512), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(512))
                        v_rc, v_ry, v_rx = T.axis.remap("RRR", [rc, ry, rx])
                        T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_decoder_up_blocks_3_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx])
                        T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                        with T.init():
                            var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                        var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_decoder_up_blocks_3_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(512)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(128), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(262144))
                        v_ax2 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(262144) // T.int64(512))
                        v_ax3 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512))
                        T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv194[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv194[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d37_add37(lv207: T.Buffer((T.int64(1), T.int64(128), T.int64(512), T.int64(512)), "float32"), vae_decoder_up_blocks_3_resnets_1_conv1_weight: T.Buffer((T.int64(128), T.int64(128), T.int64(3), T.int64(3)), "float32"), lv209: T.Buffer((T.int64(1), T.int64(128), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(128), T.int64(512), T.int64(512)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(128), T.int64(514), T.int64(514)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(128), T.int64(512), T.int64(512)))
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(517)):
                    with T.block("pad_temp"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(128), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(264196))
                        v_i2 = T.axis.spatial(T.int64(514), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(264196) // T.int64(514))
                        v_i3 = T.axis.spatial(T.int64(514), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(514))
                        T.where((i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1) * T.int64(256) + i0_i1_i2_i3_fused_2 < T.int64(33817088))
                        T.reads(lv207[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                        T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                        pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(513) and T.int64(1) <= v_i3 and v_i3 < T.int64(513), lv207[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn_ff_yy_xx_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for nn_ff_yy_xx_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for nn_ff_yy_xx_fused_0, rc, ry, rx in T.grid(T.int64(512), T.int64(128), T.int64(3), T.int64(3)):
                    with T.block("conv2d_nchw"):
                        v_nn = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ff = T.axis.spatial(T.int64(128), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) // T.int64(262144))
                        v_yy = T.axis.spatial(T.int64(512), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(262144) // T.int64(512))
                        v_xx = T.axis.spatial(T.int64(512), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(512))
                        v_rc, v_ry, v_rx = T.axis.remap("RRR", [rc, ry, rx])
                        T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_decoder_up_blocks_3_resnets_1_conv1_weight[v_ff, v_rc, v_ry, v_rx])
                        T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                        with T.init():
                            var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                        var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_decoder_up_blocks_3_resnets_1_conv1_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(512)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(128), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(262144))
                        v_ax2 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(262144) // T.int64(512))
                        v_ax3 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512))
                        T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv209[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv209[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d37_add37_add38_divide11(lv197: T.Buffer((T.int64(1), T.int64(128), T.int64(512), T.int64(512)), "float32"), vae_decoder_up_blocks_3_resnets_0_conv2_weight: T.Buffer((T.int64(128), T.int64(128), T.int64(3), T.int64(3)), "float32"), lv199: T.Buffer((T.int64(1), T.int64(128), T.int64(1), T.int64(1)), "float32"), lv203: T.Buffer((T.int64(1), T.int64(128), T.int64(512), T.int64(512)), "float32"), var_T_divide_intermediate: T.Buffer((T.int64(1), T.int64(128), T.int64(512), T.int64(512)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(128), T.int64(514), T.int64(514)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(128), T.int64(512), T.int64(512)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(128), T.int64(512), T.int64(512)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(128), T.int64(512), T.int64(512)))
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(517)):
                    with T.block("pad_temp"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(128), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(264196))
                        v_i2 = T.axis.spatial(T.int64(514), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(264196) // T.int64(514))
                        v_i3 = T.axis.spatial(T.int64(514), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(514))
                        T.where((i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1) * T.int64(256) + i0_i1_i2_i3_fused_2 < T.int64(33817088))
                        T.reads(lv197[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                        T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                        pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(513) and T.int64(1) <= v_i3 and v_i3 < T.int64(513), lv197[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn_ff_yy_xx_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for nn_ff_yy_xx_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for nn_ff_yy_xx_fused_0, rc, ry, rx in T.grid(T.int64(512), T.int64(128), T.int64(3), T.int64(3)):
                    with T.block("conv2d_nchw"):
                        v_nn = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ff = T.axis.spatial(T.int64(128), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) // T.int64(262144))
                        v_yy = T.axis.spatial(T.int64(512), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(262144) // T.int64(512))
                        v_xx = T.axis.spatial(T.int64(512), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(512))
                        v_rc, v_ry, v_rx = T.axis.remap("RRR", [rc, ry, rx])
                        T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_decoder_up_blocks_3_resnets_0_conv2_weight[v_ff, v_rc, v_ry, v_rx])
                        T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                        with T.init():
                            var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                        var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_decoder_up_blocks_3_resnets_0_conv2_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(512)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(128), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(262144))
                        v_ax2 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(262144) // T.int64(512))
                        v_ax3 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512))
                        T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv199[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv199[v_ax0, v_ax1, T.int64(0), T.int64(0)]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(512)):
                    with T.block("T_add_1"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(128), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(262144))
                        v_ax2 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(262144) // T.int64(512))
                        v_ax3 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512))
                        T.reads(lv203[v_ax0, v_ax1, v_ax2, v_ax3], var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = lv203[v_ax0, v_ax1, v_ax2, v_ax3] + var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(512)):
                    with T.block("T_divide"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(128), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(262144))
                        v_ax2 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(262144) // T.int64(512))
                        v_ax3 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512))
                        T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_conv2d38_add37(lv190: T.Buffer((T.int64(1), T.int64(256), T.int64(512), T.int64(512)), "float32"), vae_decoder_up_blocks_3_resnets_0_conv_shortcut_weight: T.Buffer((T.int64(128), T.int64(256), T.int64(1), T.int64(1)), "float32"), lv202: T.Buffer((T.int64(1), T.int64(128), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(128), T.int64(512), T.int64(512)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(512), T.int64(512)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(128), T.int64(512), T.int64(512)))
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(1024)):
                    with T.block("pad_temp"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(256), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(262144))
                        v_i2 = T.axis.spatial(T.int64(512), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(262144) // T.int64(512))
                        v_i3 = T.axis.spatial(T.int64(512), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(512))
                        T.reads(lv190[v_i0, v_i1, v_i2, v_i3])
                        T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                        pad_temp[v_i0, v_i1, v_i2, v_i3] = lv190[v_i0, v_i1, v_i2, v_i3]
        for nn_ff_yy_xx_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for nn_ff_yy_xx_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for nn_ff_yy_xx_fused_0, rc, ry, rx in T.grid(T.int64(512), T.int64(256), T.int64(1), T.int64(1)):
                    with T.block("conv2d_nchw"):
                        v_nn = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ff = T.axis.spatial(T.int64(128), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) // T.int64(262144))
                        v_yy = T.axis.spatial(T.int64(512), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(262144) // T.int64(512))
                        v_xx = T.axis.spatial(T.int64(512), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(512))
                        v_rc = T.axis.reduce(T.int64(256), rc)
                        v_ry = T.axis.reduce(T.int64(1), T.int64(0))
                        v_rx = T.axis.reduce(T.int64(1), T.int64(0))
                        T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_decoder_up_blocks_3_resnets_0_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx])
                        T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                        with T.init():
                            var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                        var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_decoder_up_blocks_3_resnets_0_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(512)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(128), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(262144))
                        v_ax2 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(262144) // T.int64(512))
                        v_ax3 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512))
                        T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv202[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv202[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d39_add39_divide12_add40_tir_clip(lv231: T.Buffer((T.int64(1), T.int64(128), T.int64(512), T.int64(512)), "float32"), vae_decoder_conv_out_weight: T.Buffer((T.int64(3), T.int64(128), T.int64(3), T.int64(3)), "float32"), lv233: T.Buffer((T.int64(1), T.int64(3), T.int64(1), T.int64(1)), "float32"), var_compute_intermediate: T.Buffer((T.int64(1), T.int64(3), T.int64(512), T.int64(512)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(128), T.int64(514), T.int64(514)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(3), T.int64(512), T.int64(512)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(3), T.int64(512), T.int64(512)))
        var_T_divide_intermediate = T.alloc_buffer((T.int64(1), T.int64(3), T.int64(512), T.int64(512)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(3), T.int64(512), T.int64(512)))
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(517)):
                    with T.block("pad_temp"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(128), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(264196))
                        v_i2 = T.axis.spatial(T.int64(514), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(264196) // T.int64(514))
                        v_i3 = T.axis.spatial(T.int64(514), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(514))
                        T.where((i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1) * T.int64(256) + i0_i1_i2_i3_fused_2 < T.int64(33817088))
                        T.reads(lv231[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                        T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                        pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(513) and T.int64(1) <= v_i3 and v_i3 < T.int64(513), lv231[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn_ff_yy_xx_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for nn_ff_yy_xx_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for nn_ff_yy_xx_fused_0, rc, ry, rx in T.grid(T.int64(12), T.int64(128), T.int64(3), T.int64(3)):
                    with T.block("conv2d_nchw"):
                        v_nn = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ff = T.axis.spatial(T.int64(3), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) // T.int64(262144))
                        v_yy = T.axis.spatial(T.int64(512), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(262144) // T.int64(512))
                        v_xx = T.axis.spatial(T.int64(512), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(512))
                        v_rc, v_ry, v_rx = T.axis.remap("RRR", [rc, ry, rx])
                        T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_decoder_conv_out_weight[v_ff, v_rc, v_ry, v_rx])
                        T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                        with T.init():
                            var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                        var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_decoder_conv_out_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(12)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(3), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(262144))
                        v_ax2 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(262144) // T.int64(512))
                        v_ax3 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512))
                        T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv233[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv233[v_ax0, v_ax1, T.int64(0), T.int64(0)]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(12)):
                    with T.block("T_divide"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(3), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(262144))
                        v_ax2 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(262144) // T.int64(512))
                        v_ax3 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512))
                        T.reads(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * T.float32(0.5)
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(12)):
                    with T.block("T_add_1"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(3), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(262144))
                        v_ax2 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(262144) // T.int64(512))
                        v_ax3 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512))
                        T.reads(var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + T.float32(0.5)
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(12)):
                    with T.block("compute"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(3), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(262144))
                        v_i2 = T.axis.spatial(T.int64(512), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(262144) // T.int64(512))
                        v_i3 = T.axis.spatial(T.int64(512), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(512))
                        T.reads(var_T_add_intermediate_1[v_i0, v_i1, v_i2, v_i3])
                        T.writes(var_compute_intermediate[v_i0, v_i1, v_i2, v_i3])
                        var_compute_intermediate[v_i0, v_i1, v_i2, v_i3] = T.max(T.min(var_T_add_intermediate_1[v_i0, v_i1, v_i2, v_i3], T.float32(1)), T.float32(0))

    @T.prim_func(private=True)
    def fused_conv2d3_add13_add13(lv91: T.Buffer((T.int64(1), T.int64(320), T.int64(32), T.int64(32)), "float32"), unet_down_blocks_1_resnets_0_conv1_weight: T.Buffer((T.int64(640), T.int64(320), T.int64(3), T.int64(3)), "float32"), lv93: T.Buffer((T.int64(1), T.int64(640), T.int64(1), T.int64(1)), "float32"), lv100: T.Buffer((T.int64(1), T.int64(640), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(640), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(320), T.int64(34), T.int64(34)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(640), T.int64(32), T.int64(32)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(640), T.int64(32), T.int64(32)))
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(6)):
                    with T.block("pad_temp"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(320), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(1156))
                        v_i2 = T.axis.spatial(T.int64(34), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(1156) // T.int64(34))
                        v_i3 = T.axis.spatial(T.int64(34), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(34))
                        T.where((i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1) * T.int64(256) + i0_i1_i2_i3_fused_2 < T.int64(369920))
                        T.reads(lv91[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                        T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                        pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(33) and T.int64(1) <= v_i3 and v_i3 < T.int64(33), lv91[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn_ff_yy_xx_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for nn_ff_yy_xx_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for nn_ff_yy_xx_fused_0, rc, ry, rx in T.grid(T.int64(10), T.int64(320), T.int64(3), T.int64(3)):
                    with T.block("conv2d_nchw"):
                        v_nn = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ff = T.axis.spatial(T.int64(640), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) // T.int64(1024))
                        v_yy = T.axis.spatial(T.int64(32), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(1024) // T.int64(32))
                        v_xx = T.axis.spatial(T.int64(32), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(32))
                        v_rc, v_ry, v_rx = T.axis.remap("RRR", [rc, ry, rx])
                        T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_down_blocks_1_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx])
                        T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                        with T.init():
                            var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                        var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_down_blocks_1_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(10)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(640), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                        v_ax2 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(32))
                        v_ax3 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                        T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv93[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv93[v_ax0, v_ax1, T.int64(0), T.int64(0)]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(10)):
                    with T.block("T_add_1"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(640), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                        v_ax2 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(32))
                        v_ax3 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                        T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3], lv100[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] + lv100[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d4_add13_add13(lv259: T.Buffer((T.int64(1), T.int64(640), T.int64(32), T.int64(32)), "float32"), unet_down_blocks_1_resnets_1_conv1_weight: T.Buffer((T.int64(640), T.int64(640), T.int64(3), T.int64(3)), "float32"), lv261: T.Buffer((T.int64(1), T.int64(640), T.int64(1), T.int64(1)), "float32"), lv268: T.Buffer((T.int64(1), T.int64(640), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(640), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(640), T.int64(34), T.int64(34)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(640), T.int64(32), T.int64(32)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(640), T.int64(32), T.int64(32)))
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(12)):
                    with T.block("pad_temp"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(640), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(1156))
                        v_i2 = T.axis.spatial(T.int64(34), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(1156) // T.int64(34))
                        v_i3 = T.axis.spatial(T.int64(34), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(34))
                        T.where((i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1) * T.int64(256) + i0_i1_i2_i3_fused_2 < T.int64(739840))
                        T.reads(lv259[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                        T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                        pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(33) and T.int64(1) <= v_i3 and v_i3 < T.int64(33), lv259[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn_ff_yy_xx_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for nn_ff_yy_xx_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for nn_ff_yy_xx_fused_0, rc, ry, rx in T.grid(T.int64(10), T.int64(640), T.int64(3), T.int64(3)):
                    with T.block("conv2d_nchw"):
                        v_nn = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ff = T.axis.spatial(T.int64(640), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) // T.int64(1024))
                        v_yy = T.axis.spatial(T.int64(32), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(1024) // T.int64(32))
                        v_xx = T.axis.spatial(T.int64(32), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(32))
                        v_rc, v_ry, v_rx = T.axis.remap("RRR", [rc, ry, rx])
                        T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_down_blocks_1_resnets_1_conv1_weight[v_ff, v_rc, v_ry, v_rx])
                        T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                        with T.init():
                            var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                        var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_down_blocks_1_resnets_1_conv1_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(10)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(640), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                        v_ax2 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(32))
                        v_ax3 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                        T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv261[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv261[v_ax0, v_ax1, T.int64(0), T.int64(0)]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(10)):
                    with T.block("T_add_1"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(640), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                        v_ax2 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(32))
                        v_ax3 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                        T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3], lv268[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] + lv268[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d4_add13_add15_divide3(lv103: T.Buffer((T.int64(1), T.int64(640), T.int64(32), T.int64(32)), "float32"), unet_down_blocks_1_resnets_0_conv2_weight: T.Buffer((T.int64(640), T.int64(640), T.int64(3), T.int64(3)), "float32"), lv105: T.Buffer((T.int64(1), T.int64(640), T.int64(1), T.int64(1)), "float32"), lv109: T.Buffer((T.int64(1), T.int64(640), T.int64(32), T.int64(32)), "float32"), var_T_divide_intermediate: T.Buffer((T.int64(1), T.int64(640), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(640), T.int64(34), T.int64(34)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(640), T.int64(32), T.int64(32)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(640), T.int64(32), T.int64(32)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(640), T.int64(32), T.int64(32)))
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(12)):
                    with T.block("pad_temp"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(640), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(1156))
                        v_i2 = T.axis.spatial(T.int64(34), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(1156) // T.int64(34))
                        v_i3 = T.axis.spatial(T.int64(34), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(34))
                        T.where((i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1) * T.int64(256) + i0_i1_i2_i3_fused_2 < T.int64(739840))
                        T.reads(lv103[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                        T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                        pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(33) and T.int64(1) <= v_i3 and v_i3 < T.int64(33), lv103[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn_ff_yy_xx_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for nn_ff_yy_xx_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for nn_ff_yy_xx_fused_0, rc, ry, rx in T.grid(T.int64(10), T.int64(640), T.int64(3), T.int64(3)):
                    with T.block("conv2d_nchw"):
                        v_nn = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ff = T.axis.spatial(T.int64(640), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) // T.int64(1024))
                        v_yy = T.axis.spatial(T.int64(32), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(1024) // T.int64(32))
                        v_xx = T.axis.spatial(T.int64(32), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(32))
                        v_rc, v_ry, v_rx = T.axis.remap("RRR", [rc, ry, rx])
                        T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_down_blocks_1_resnets_0_conv2_weight[v_ff, v_rc, v_ry, v_rx])
                        T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                        with T.init():
                            var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                        var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_down_blocks_1_resnets_0_conv2_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(10)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(640), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                        v_ax2 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(32))
                        v_ax3 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                        T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv105[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv105[v_ax0, v_ax1, T.int64(0), T.int64(0)]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(10)):
                    with T.block("T_add_1"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(640), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                        v_ax2 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(32))
                        v_ax3 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                        T.reads(lv109[v_ax0, v_ax1, v_ax2, v_ax3], var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = lv109[v_ax0, v_ax1, v_ax2, v_ax3] + var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(10)):
                    with T.block("T_divide"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(640), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                        v_ax2 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(32))
                        v_ax3 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                        T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_conv2d5_add13(lv89: T.Buffer((T.int64(1), T.int64(320), T.int64(32), T.int64(32)), "float32"), unet_down_blocks_1_resnets_0_conv_shortcut_weight: T.Buffer((T.int64(640), T.int64(320), T.int64(1), T.int64(1)), "float32"), lv108: T.Buffer((T.int64(1), T.int64(640), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(640), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(320), T.int64(32), T.int64(32)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(640), T.int64(32), T.int64(32)))
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(5)):
                    with T.block("pad_temp"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(320), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(1024))
                        v_i2 = T.axis.spatial(T.int64(32), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(1024) // T.int64(32))
                        v_i3 = T.axis.spatial(T.int64(32), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(32))
                        T.reads(lv89[v_i0, v_i1, v_i2, v_i3])
                        T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                        pad_temp[v_i0, v_i1, v_i2, v_i3] = lv89[v_i0, v_i1, v_i2, v_i3]
        for nn_ff_yy_xx_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for nn_ff_yy_xx_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for nn_ff_yy_xx_fused_0, rc, ry, rx in T.grid(T.int64(10), T.int64(320), T.int64(1), T.int64(1)):
                    with T.block("conv2d_nchw"):
                        v_nn = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ff = T.axis.spatial(T.int64(640), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) // T.int64(1024))
                        v_yy = T.axis.spatial(T.int64(32), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(1024) // T.int64(32))
                        v_xx = T.axis.spatial(T.int64(32), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(32))
                        v_rc = T.axis.reduce(T.int64(320), rc)
                        v_ry = T.axis.reduce(T.int64(1), T.int64(0))
                        v_rx = T.axis.reduce(T.int64(1), T.int64(0))
                        T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_down_blocks_1_resnets_0_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx])
                        T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                        with T.init():
                            var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                        var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_down_blocks_1_resnets_0_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(10)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(640), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                        v_ax2 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(32))
                        v_ax3 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                        T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv108[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv108[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d6_add19(lv422: T.Buffer((T.int64(1), T.int64(640), T.int64(32), T.int64(32)), "float32"), unet_down_blocks_1_downsamplers_0_conv_weight: T.Buffer((T.int64(640), T.int64(640), T.int64(3), T.int64(3)), "float32"), lv424: T.Buffer((T.int64(1), T.int64(640), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(640), T.int64(16), T.int64(16)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(640), T.int64(34), T.int64(34)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(640), T.int64(16), T.int64(16)))
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(12)):
                    with T.block("pad_temp"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(640), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(1156))
                        v_i2 = T.axis.spatial(T.int64(34), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(1156) // T.int64(34))
                        v_i3 = T.axis.spatial(T.int64(34), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(34))
                        T.where((i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1) * T.int64(256) + i0_i1_i2_i3_fused_2 < T.int64(739840))
                        T.reads(lv422[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                        T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                        pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(33) and T.int64(1) <= v_i3 and v_i3 < T.int64(33), lv422[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn_ff_yy_xx_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for nn_ff_yy_xx_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for nn_ff_yy_xx_fused_0, rc, ry, rx in T.grid(T.int64(3), T.int64(640), T.int64(3), T.int64(3)):
                    with T.block("conv2d_nchw"):
                        v_nn = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ff = T.axis.spatial(T.int64(640), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) // T.int64(256))
                        v_yy = T.axis.spatial(T.int64(16), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(256) // T.int64(16))
                        v_xx = T.axis.spatial(T.int64(16), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(16))
                        v_rc, v_ry, v_rx = T.axis.remap("RRR", [rc, ry, rx])
                        T.where((nn_ff_yy_xx_fused_0 * T.int64(256) + nn_ff_yy_xx_fused_1) * T.int64(256) + nn_ff_yy_xx_fused_2 < T.int64(163840))
                        T.reads(pad_temp[v_nn, v_rc, v_yy * T.int64(2) + v_ry, v_xx * T.int64(2) + v_rx], unet_down_blocks_1_downsamplers_0_conv_weight[v_ff, v_rc, v_ry, v_rx])
                        T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                        with T.init():
                            var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                        var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy * T.int64(2) + v_ry, v_xx * T.int64(2) + v_rx] * unet_down_blocks_1_downsamplers_0_conv_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(3)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(640), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(256))
                        v_ax2 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256) // T.int64(16))
                        v_ax3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) * T.int64(256) + ax0_ax1_ax2_ax3_fused_2 < T.int64(163840))
                        T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv424[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv424[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d7_add20_add20(lv427: T.Buffer((T.int64(1), T.int64(640), T.int64(16), T.int64(16)), "float32"), unet_down_blocks_2_resnets_0_conv1_weight: T.Buffer((T.int64(1280), T.int64(640), T.int64(3), T.int64(3)), "float32"), lv429: T.Buffer((T.int64(1), T.int64(1280), T.int64(1), T.int64(1)), "float32"), lv436: T.Buffer((T.int64(1), T.int64(1280), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(1280), T.int64(16), T.int64(16)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(640), T.int64(18), T.int64(18)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(1280), T.int64(16), T.int64(16)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(1280), T.int64(16), T.int64(16)))
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(4)):
                    with T.block("pad_temp"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(640), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(324))
                        v_i2 = T.axis.spatial(T.int64(18), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(324) // T.int64(18))
                        v_i3 = T.axis.spatial(T.int64(18), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(18))
                        T.where((i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1) * T.int64(256) + i0_i1_i2_i3_fused_2 < T.int64(207360))
                        T.reads(lv427[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                        T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                        pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(17) and T.int64(1) <= v_i3 and v_i3 < T.int64(17), lv427[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn_ff_yy_xx_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for nn_ff_yy_xx_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for nn_ff_yy_xx_fused_0, rc, ry, rx in T.grid(T.int64(5), T.int64(640), T.int64(3), T.int64(3)):
                    with T.block("conv2d_nchw"):
                        v_nn = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ff = T.axis.spatial(T.int64(1280), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) // T.int64(256))
                        v_yy = T.axis.spatial(T.int64(16), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(256) // T.int64(16))
                        v_xx = T.axis.spatial(T.int64(16), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(16))
                        v_rc, v_ry, v_rx = T.axis.remap("RRR", [rc, ry, rx])
                        T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_down_blocks_2_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx])
                        T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                        with T.init():
                            var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                        var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_down_blocks_2_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(5)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(256))
                        v_ax2 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256) // T.int64(16))
                        v_ax3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                        T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv429[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv429[v_ax0, v_ax1, T.int64(0), T.int64(0)]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(5)):
                    with T.block("T_add_1"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(256))
                        v_ax2 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256) // T.int64(16))
                        v_ax3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                        T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3], lv436[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] + lv436[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d8_add20_add20(lv1131: T.Buffer((T.int64(1), T.int64(1280), T.int64(16), T.int64(16)), "float32"), unet_down_blocks_2_resnets_1_conv1_weight: T.Buffer((T.int64(1280), T.int64(1280), T.int64(3), T.int64(3)), "float32"), lv1133: T.Buffer((T.int64(1), T.int64(1280), T.int64(1), T.int64(1)), "float32"), lv1140: T.Buffer((T.int64(1), T.int64(1280), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(1280), T.int64(16), T.int64(16)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(1280), T.int64(18), T.int64(18)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(1280), T.int64(16), T.int64(16)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(1280), T.int64(16), T.int64(16)))
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(7)):
                    with T.block("pad_temp"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1280), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(324))
                        v_i2 = T.axis.spatial(T.int64(18), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(324) // T.int64(18))
                        v_i3 = T.axis.spatial(T.int64(18), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(18))
                        T.where((i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1) * T.int64(256) + i0_i1_i2_i3_fused_2 < T.int64(414720))
                        T.reads(lv1131[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                        T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                        pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(17) and T.int64(1) <= v_i3 and v_i3 < T.int64(17), lv1131[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn_ff_yy_xx_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for nn_ff_yy_xx_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for nn_ff_yy_xx_fused_0, rc, ry, rx in T.grid(T.int64(5), T.int64(1280), T.int64(3), T.int64(3)):
                    with T.block("conv2d_nchw"):
                        v_nn = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ff = T.axis.spatial(T.int64(1280), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) // T.int64(256))
                        v_yy = T.axis.spatial(T.int64(16), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(256) // T.int64(16))
                        v_xx = T.axis.spatial(T.int64(16), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(16))
                        v_rc, v_ry, v_rx = T.axis.remap("RRR", [rc, ry, rx])
                        T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_down_blocks_2_resnets_1_conv1_weight[v_ff, v_rc, v_ry, v_rx])
                        T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                        with T.init():
                            var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                        var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_down_blocks_2_resnets_1_conv1_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(5)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(256))
                        v_ax2 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256) // T.int64(16))
                        v_ax3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                        T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv1133[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv1133[v_ax0, v_ax1, T.int64(0), T.int64(0)]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(5)):
                    with T.block("T_add_1"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(256))
                        v_ax2 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256) // T.int64(16))
                        v_ax3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                        T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3], lv1140[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] + lv1140[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d8_add20_add21_divide6(lv439: T.Buffer((T.int64(1), T.int64(1280), T.int64(16), T.int64(16)), "float32"), unet_down_blocks_2_resnets_0_conv2_weight: T.Buffer((T.int64(1280), T.int64(1280), T.int64(3), T.int64(3)), "float32"), lv441: T.Buffer((T.int64(1), T.int64(1280), T.int64(1), T.int64(1)), "float32"), lv445: T.Buffer((T.int64(1), T.int64(1280), T.int64(16), T.int64(16)), "float32"), var_T_divide_intermediate: T.Buffer((T.int64(1), T.int64(1280), T.int64(16), T.int64(16)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(1280), T.int64(18), T.int64(18)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(1280), T.int64(16), T.int64(16)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(1280), T.int64(16), T.int64(16)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(1280), T.int64(16), T.int64(16)))
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(7)):
                    with T.block("pad_temp"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1280), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(324))
                        v_i2 = T.axis.spatial(T.int64(18), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(324) // T.int64(18))
                        v_i3 = T.axis.spatial(T.int64(18), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(18))
                        T.where((i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1) * T.int64(256) + i0_i1_i2_i3_fused_2 < T.int64(414720))
                        T.reads(lv439[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                        T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                        pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(17) and T.int64(1) <= v_i3 and v_i3 < T.int64(17), lv439[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn_ff_yy_xx_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for nn_ff_yy_xx_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for nn_ff_yy_xx_fused_0, rc, ry, rx in T.grid(T.int64(5), T.int64(1280), T.int64(3), T.int64(3)):
                    with T.block("conv2d_nchw"):
                        v_nn = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ff = T.axis.spatial(T.int64(1280), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) // T.int64(256))
                        v_yy = T.axis.spatial(T.int64(16), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(256) // T.int64(16))
                        v_xx = T.axis.spatial(T.int64(16), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(16))
                        v_rc, v_ry, v_rx = T.axis.remap("RRR", [rc, ry, rx])
                        T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_down_blocks_2_resnets_0_conv2_weight[v_ff, v_rc, v_ry, v_rx])
                        T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                        with T.init():
                            var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                        var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_down_blocks_2_resnets_0_conv2_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(5)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(256))
                        v_ax2 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256) // T.int64(16))
                        v_ax3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                        T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv441[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv441[v_ax0, v_ax1, T.int64(0), T.int64(0)]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(5)):
                    with T.block("T_add_1"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(256))
                        v_ax2 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256) // T.int64(16))
                        v_ax3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                        T.reads(lv445[v_ax0, v_ax1, v_ax2, v_ax3], var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = lv445[v_ax0, v_ax1, v_ax2, v_ax3] + var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(5)):
                    with T.block("T_divide"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(256))
                        v_ax2 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256) // T.int64(16))
                        v_ax3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                        T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_conv2d9_add20(lv425: T.Buffer((T.int64(1), T.int64(640), T.int64(16), T.int64(16)), "float32"), unet_down_blocks_2_resnets_0_conv_shortcut_weight: T.Buffer((T.int64(1280), T.int64(640), T.int64(1), T.int64(1)), "float32"), lv444: T.Buffer((T.int64(1), T.int64(1280), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(1280), T.int64(16), T.int64(16)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(640), T.int64(16), T.int64(16)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(1280), T.int64(16), T.int64(16)))
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(3)):
                    with T.block("pad_temp"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(640), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(256))
                        v_i2 = T.axis.spatial(T.int64(16), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(256) // T.int64(16))
                        v_i3 = T.axis.spatial(T.int64(16), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(16))
                        T.where((i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1) * T.int64(256) + i0_i1_i2_i3_fused_2 < T.int64(163840))
                        T.reads(lv425[v_i0, v_i1, v_i2, v_i3])
                        T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                        pad_temp[v_i0, v_i1, v_i2, v_i3] = lv425[v_i0, v_i1, v_i2, v_i3]
        for nn_ff_yy_xx_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for nn_ff_yy_xx_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for nn_ff_yy_xx_fused_0, rc, ry, rx in T.grid(T.int64(5), T.int64(640), T.int64(1), T.int64(1)):
                    with T.block("conv2d_nchw"):
                        v_nn = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ff = T.axis.spatial(T.int64(1280), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) // T.int64(256))
                        v_yy = T.axis.spatial(T.int64(16), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(256) // T.int64(16))
                        v_xx = T.axis.spatial(T.int64(16), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(16))
                        v_rc = T.axis.reduce(T.int64(640), rc)
                        v_ry = T.axis.reduce(T.int64(1), T.int64(0))
                        v_rx = T.axis.reduce(T.int64(1), T.int64(0))
                        T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_down_blocks_2_resnets_0_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx])
                        T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                        with T.init():
                            var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                        var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_down_blocks_2_resnets_0_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(5)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(256))
                        v_ax2 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256) // T.int64(16))
                        v_ax3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                        T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv444[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv444[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d_add9(inp_0: T.Buffer((T.int64(1), T.int64(4), T.int64(64), T.int64(64)), "float32"), unet_conv_in_weight: T.Buffer((T.int64(320), T.int64(4), T.int64(3), T.int64(3)), "float32"), lv47: T.Buffer((T.int64(1), T.int64(320), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(320), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(66), T.int64(66)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(320), T.int64(64), T.int64(64)))
        for i0_i1_i2_i3_fused_0 in T.thread_binding(T.int64(69), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("pad_temp"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(4), (i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1) // T.int64(4356))
                    v_i2 = T.axis.spatial(T.int64(66), (i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1) % T.int64(4356) // T.int64(66))
                    v_i3 = T.axis.spatial(T.int64(66), (i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1) % T.int64(66))
                    T.where(i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1 < T.int64(17424))
                    T.reads(inp_0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                    T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                    pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(65) and T.int64(1) <= v_i3 and v_i3 < T.int64(65), inp_0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn_ff_yy_xx_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for nn_ff_yy_xx_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for nn_ff_yy_xx_fused_0, rc, ry, rx in T.grid(T.int64(20), T.int64(4), T.int64(3), T.int64(3)):
                    with T.block("conv2d_nchw"):
                        v_nn = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ff = T.axis.spatial(T.int64(320), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) // T.int64(4096))
                        v_yy = T.axis.spatial(T.int64(64), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(4096) // T.int64(64))
                        v_xx = T.axis.spatial(T.int64(64), (nn_ff_yy_xx_fused_0 * T.int64(65536) + nn_ff_yy_xx_fused_1 * T.int64(256) + nn_ff_yy_xx_fused_2) % T.int64(64))
                        v_rc, v_ry, v_rx = T.axis.remap("RRR", [rc, ry, rx])
                        T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_conv_in_weight[v_ff, v_rc, v_ry, v_rx])
                        T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                        with T.init():
                            var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                        var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_conv_in_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(20)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(320), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(4096))
                        v_ax2 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(4096) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv47[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv47[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_group_norm10_silu9(lv4839: T.Buffer((T.int64(1), T.int64(1280), T.int64(32), T.int64(32)), "float32"), unet_up_blocks_1_resnets_1_norm1_weight: T.Buffer((T.int64(1280),), "float32"), unet_up_blocks_1_resnets_1_norm1_bias: T.Buffer((T.int64(1280),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(1), T.int64(1280), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(40), T.int64(32), T.int64(32)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(1), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(1), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(40)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(40)))
        T_group_norm = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(40), T.int64(32), T.int64(32)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(1280), T.int64(32), T.int64(32)))
        compute = T.alloc_buffer((T.int64(1), T.int64(1280), T.int64(32), T.int64(32)))
        for ax0_ax1_ax2_ax3_ax4_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_ax4_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_ax4_fused_0 in range(T.int64(20)):
                    with T.block("T_reshape"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) // T.int64(40960))
                        v_ax2 = T.axis.spatial(T.int64(40), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(40960) // T.int64(1024))
                        v_ax3 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(1024) // T.int64(32))
                        v_ax4 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(32))
                        T.reads(lv4839[T.int64(0), (v_ax1 * T.int64(40) + (v_ax4 // T.int64(32) + v_ax3) // T.int64(32) + v_ax2) % T.int64(1280), (v_ax4 // T.int64(32) + v_ax3) % T.int64(32), v_ax4 % T.int64(32)])
                        T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv4839[T.int64(0), (v_ax1 * T.int64(40) + (v_ax4 // T.int64(32) + v_ax3) // T.int64(32) + v_ax2) % T.int64(1280), (v_ax4 // T.int64(32) + v_ax3) % T.int64(32), v_ax4 % T.int64(32)]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for k2, k3, k4 in T.grid(T.int64(40), T.int64(32), T.int64(32)):
                    with T.block("A_red_temp"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), ax0_ax1_fused_0 * T.int64(32) + ax0_ax1_fused_1)
                        v_k2, v_k3, v_k4 = T.axis.remap("RRR", [k2, k3, k4])
                        T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                        T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                        with T.init():
                            A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                            A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                        v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                        v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                        A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                        A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(5), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape_1"):
                    v_ax0 = T.axis.spatial(T.int64(32), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) // T.int64(40))
                    v_ax1 = T.axis.spatial(T.int64(40), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) % T.int64(40))
                    T.reads(unet_up_blocks_1_resnets_1_norm1_weight[(v_ax0 * T.int64(40) + v_ax1) % T.int64(1280)])
                    T.writes(T_reshape_1[v_ax0, v_ax1])
                    T_reshape_1[v_ax0, v_ax1] = unet_up_blocks_1_resnets_1_norm1_weight[(v_ax0 * T.int64(40) + v_ax1) % T.int64(1280)]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(5), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape_2"):
                    v_ax0 = T.axis.spatial(T.int64(32), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) // T.int64(40))
                    v_ax1 = T.axis.spatial(T.int64(40), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) % T.int64(40))
                    T.reads(unet_up_blocks_1_resnets_1_norm1_bias[(v_ax0 * T.int64(40) + v_ax1) % T.int64(1280)])
                    T.writes(T_reshape_2[v_ax0, v_ax1])
                    T_reshape_2[v_ax0, v_ax1] = unet_up_blocks_1_resnets_1_norm1_bias[(v_ax0 * T.int64(40) + v_ax1) % T.int64(1280)]
        for ax0_ax1_ax2_ax3_ax4_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_ax4_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_ax4_fused_0 in range(T.int64(20)):
                    with T.block("T_group_norm"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) // T.int64(40960))
                        v_ax2 = T.axis.spatial(T.int64(40), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(40960) // T.int64(1024))
                        v_ax3 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(1024) // T.int64(32))
                        v_ax4 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(32))
                        T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                        T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(2.4414062500000001e-05)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(2.4414062500000001e-05) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(2.4414062500000001e-05) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(2.4414062500000001e-05)) + T.float32(1.0000000000000001e-05)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(20)):
                    with T.block("T_reshape_3"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                        v_ax2 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(32))
                        v_ax3 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                        T.reads(T_group_norm[T.int64(0), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(1280) // T.int64(40), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(40), (v_ax3 // T.int64(32) + v_ax2) % T.int64(32), v_ax3 % T.int64(32)])
                        T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[T.int64(0), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(1280) // T.int64(40), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(40), (v_ax3 // T.int64(32) + v_ax2) % T.int64(32), v_ax3 % T.int64(32)]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(20)):
                    with T.block("compute"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1280), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(1024))
                        v_i2 = T.axis.spatial(T.int64(32), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(1024) // T.int64(32))
                        v_i3 = T.axis.spatial(T.int64(32), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(32))
                        T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                        T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                        compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(20)):
                    with T.block("T_multiply"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                        v_ax2 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(32))
                        v_ax3 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                        T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_group_norm11_silu10(lv5008: T.Buffer((T.int64(1), T.int64(960), T.int64(32), T.int64(32)), "float32"), unet_up_blocks_1_resnets_2_norm1_weight: T.Buffer((T.int64(960),), "float32"), unet_up_blocks_1_resnets_2_norm1_bias: T.Buffer((T.int64(960),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(1), T.int64(960), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(30), T.int64(32), T.int64(32)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(1), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(1), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(30)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(30)))
        T_group_norm = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(30), T.int64(32), T.int64(32)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(960), T.int64(32), T.int64(32)))
        compute = T.alloc_buffer((T.int64(1), T.int64(960), T.int64(32), T.int64(32)))
        for ax0_ax1_ax2_ax3_ax4_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_ax4_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_ax4_fused_0 in range(T.int64(15)):
                    with T.block("T_reshape"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) // T.int64(30720))
                        v_ax2 = T.axis.spatial(T.int64(30), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(30720) // T.int64(1024))
                        v_ax3 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(1024) // T.int64(32))
                        v_ax4 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(32))
                        T.reads(lv5008[T.int64(0), (v_ax1 * T.int64(30) + (v_ax4 // T.int64(32) + v_ax3) // T.int64(32) + v_ax2) % T.int64(960), (v_ax4 // T.int64(32) + v_ax3) % T.int64(32), v_ax4 % T.int64(32)])
                        T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv5008[T.int64(0), (v_ax1 * T.int64(30) + (v_ax4 // T.int64(32) + v_ax3) // T.int64(32) + v_ax2) % T.int64(960), (v_ax4 // T.int64(32) + v_ax3) % T.int64(32), v_ax4 % T.int64(32)]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for k2, k3, k4 in T.grid(T.int64(30), T.int64(32), T.int64(32)):
                    with T.block("A_red_temp"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), ax0_ax1_fused_0 * T.int64(32) + ax0_ax1_fused_1)
                        v_k2, v_k3, v_k4 = T.axis.remap("RRR", [k2, k3, k4])
                        T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                        T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                        with T.init():
                            A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                            A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                        v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                        v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                        A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                        A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(4), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape_1"):
                    v_ax0 = T.axis.spatial(T.int64(32), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) // T.int64(30))
                    v_ax1 = T.axis.spatial(T.int64(30), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) % T.int64(30))
                    T.where(ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1 < T.int64(960))
                    T.reads(unet_up_blocks_1_resnets_2_norm1_weight[(v_ax0 * T.int64(30) + v_ax1) % T.int64(960)])
                    T.writes(T_reshape_1[v_ax0, v_ax1])
                    T_reshape_1[v_ax0, v_ax1] = unet_up_blocks_1_resnets_2_norm1_weight[(v_ax0 * T.int64(30) + v_ax1) % T.int64(960)]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(4), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape_2"):
                    v_ax0 = T.axis.spatial(T.int64(32), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) // T.int64(30))
                    v_ax1 = T.axis.spatial(T.int64(30), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) % T.int64(30))
                    T.where(ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1 < T.int64(960))
                    T.reads(unet_up_blocks_1_resnets_2_norm1_bias[(v_ax0 * T.int64(30) + v_ax1) % T.int64(960)])
                    T.writes(T_reshape_2[v_ax0, v_ax1])
                    T_reshape_2[v_ax0, v_ax1] = unet_up_blocks_1_resnets_2_norm1_bias[(v_ax0 * T.int64(30) + v_ax1) % T.int64(960)]
        for ax0_ax1_ax2_ax3_ax4_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_ax4_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_ax4_fused_0 in range(T.int64(15)):
                    with T.block("T_group_norm"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) // T.int64(30720))
                        v_ax2 = T.axis.spatial(T.int64(30), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(30720) // T.int64(1024))
                        v_ax3 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(1024) // T.int64(32))
                        v_ax4 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(32))
                        T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                        T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(3.2552083333333333e-05)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(3.2552083333333333e-05) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(3.2552083333333333e-05) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(3.2552083333333333e-05)) + T.float32(1.0000000000000001e-05)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(15)):
                    with T.block("T_reshape_3"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(960), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                        v_ax2 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(32))
                        v_ax3 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                        T.reads(T_group_norm[T.int64(0), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(960) // T.int64(30), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(30), (v_ax3 // T.int64(32) + v_ax2) % T.int64(32), v_ax3 % T.int64(32)])
                        T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[T.int64(0), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(960) // T.int64(30), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(30), (v_ax3 // T.int64(32) + v_ax2) % T.int64(32), v_ax3 % T.int64(32)]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(15)):
                    with T.block("compute"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(960), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(1024))
                        v_i2 = T.axis.spatial(T.int64(32), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(1024) // T.int64(32))
                        v_i3 = T.axis.spatial(T.int64(32), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(32))
                        T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                        T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                        compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(15)):
                    with T.block("T_multiply"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(960), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                        v_ax2 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(32))
                        v_ax3 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                        T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_group_norm12_silu11(lv5181: T.Buffer((T.int64(1), T.int64(960), T.int64(64), T.int64(64)), "float32"), unet_up_blocks_2_resnets_0_norm1_weight: T.Buffer((T.int64(960),), "float32"), unet_up_blocks_2_resnets_0_norm1_bias: T.Buffer((T.int64(960),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(1), T.int64(960), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(30), T.int64(64), T.int64(64)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(1), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(1), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(30)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(30)))
        T_group_norm = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(30), T.int64(64), T.int64(64)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(960), T.int64(64), T.int64(64)))
        compute = T.alloc_buffer((T.int64(1), T.int64(960), T.int64(64), T.int64(64)))
        for ax0_ax1_ax2_ax3_ax4_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_ax4_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_ax4_fused_0 in range(T.int64(60)):
                    with T.block("T_reshape"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) // T.int64(122880))
                        v_ax2 = T.axis.spatial(T.int64(30), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(122880) // T.int64(4096))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(4096) // T.int64(64))
                        v_ax4 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(64))
                        T.reads(lv5181[T.int64(0), (v_ax1 * T.int64(30) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) % T.int64(960), (v_ax4 // T.int64(64) + v_ax3) % T.int64(64), v_ax4 % T.int64(64)])
                        T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv5181[T.int64(0), (v_ax1 * T.int64(30) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) % T.int64(960), (v_ax4 // T.int64(64) + v_ax3) % T.int64(64), v_ax4 % T.int64(64)]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for k2, k3, k4 in T.grid(T.int64(30), T.int64(64), T.int64(64)):
                    with T.block("A_red_temp"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), ax0_ax1_fused_0 * T.int64(32) + ax0_ax1_fused_1)
                        v_k2, v_k3, v_k4 = T.axis.remap("RRR", [k2, k3, k4])
                        T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                        T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                        with T.init():
                            A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                            A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                        v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                        v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                        A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                        A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(4), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape_1"):
                    v_ax0 = T.axis.spatial(T.int64(32), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) // T.int64(30))
                    v_ax1 = T.axis.spatial(T.int64(30), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) % T.int64(30))
                    T.where(ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1 < T.int64(960))
                    T.reads(unet_up_blocks_2_resnets_0_norm1_weight[(v_ax0 * T.int64(30) + v_ax1) % T.int64(960)])
                    T.writes(T_reshape_1[v_ax0, v_ax1])
                    T_reshape_1[v_ax0, v_ax1] = unet_up_blocks_2_resnets_0_norm1_weight[(v_ax0 * T.int64(30) + v_ax1) % T.int64(960)]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(4), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape_2"):
                    v_ax0 = T.axis.spatial(T.int64(32), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) // T.int64(30))
                    v_ax1 = T.axis.spatial(T.int64(30), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) % T.int64(30))
                    T.where(ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1 < T.int64(960))
                    T.reads(unet_up_blocks_2_resnets_0_norm1_bias[(v_ax0 * T.int64(30) + v_ax1) % T.int64(960)])
                    T.writes(T_reshape_2[v_ax0, v_ax1])
                    T_reshape_2[v_ax0, v_ax1] = unet_up_blocks_2_resnets_0_norm1_bias[(v_ax0 * T.int64(30) + v_ax1) % T.int64(960)]
        for ax0_ax1_ax2_ax3_ax4_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_ax4_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_ax4_fused_0 in range(T.int64(60)):
                    with T.block("T_group_norm"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) // T.int64(122880))
                        v_ax2 = T.axis.spatial(T.int64(30), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(122880) // T.int64(4096))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(4096) // T.int64(64))
                        v_ax4 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(64))
                        T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                        T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(8.1380208333333332e-06)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(8.1380208333333332e-06) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(8.1380208333333332e-06) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(8.1380208333333332e-06)) + T.float32(1.0000000000000001e-05)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(60)):
                    with T.block("T_reshape_3"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(960), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(4096))
                        v_ax2 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(4096) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.reads(T_group_norm[T.int64(0), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(960) // T.int64(30), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(30), (v_ax3 // T.int64(64) + v_ax2) % T.int64(64), v_ax3 % T.int64(64)])
                        T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[T.int64(0), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(960) // T.int64(30), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(30), (v_ax3 // T.int64(64) + v_ax2) % T.int64(64), v_ax3 % T.int64(64)]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(60)):
                    with T.block("compute"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(960), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(4096))
                        v_i2 = T.axis.spatial(T.int64(64), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(4096) // T.int64(64))
                        v_i3 = T.axis.spatial(T.int64(64), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(64))
                        T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                        T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                        compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(60)):
                    with T.block("T_multiply"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(960), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(4096))
                        v_ax2 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(4096) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_group_norm13_silu12(lv5204: T.Buffer((T.int64(1), T.int64(640), T.int64(64), T.int64(64)), "float32"), unet_up_blocks_2_resnets_1_norm1_weight: T.Buffer((T.int64(640),), "float32"), unet_up_blocks_2_resnets_1_norm1_bias: T.Buffer((T.int64(640),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(1), T.int64(640), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(20), T.int64(64), T.int64(64)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(1), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(1), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(20)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(20)))
        T_group_norm = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(20), T.int64(64), T.int64(64)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(640), T.int64(64), T.int64(64)))
        compute = T.alloc_buffer((T.int64(1), T.int64(640), T.int64(64), T.int64(64)))
        for ax0_ax1_ax2_ax3_ax4_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_ax4_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_ax4_fused_0 in range(T.int64(40)):
                    with T.block("T_reshape"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) // T.int64(81920))
                        v_ax2 = T.axis.spatial(T.int64(20), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(81920) // T.int64(4096))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(4096) // T.int64(64))
                        v_ax4 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(64))
                        T.reads(lv5204[T.int64(0), (v_ax1 * T.int64(20) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) % T.int64(640), (v_ax4 // T.int64(64) + v_ax3) % T.int64(64), v_ax4 % T.int64(64)])
                        T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv5204[T.int64(0), (v_ax1 * T.int64(20) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) % T.int64(640), (v_ax4 // T.int64(64) + v_ax3) % T.int64(64), v_ax4 % T.int64(64)]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for k2, k3, k4 in T.grid(T.int64(20), T.int64(64), T.int64(64)):
                    with T.block("A_red_temp"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), ax0_ax1_fused_0 * T.int64(32) + ax0_ax1_fused_1)
                        v_k2, v_k3, v_k4 = T.axis.remap("RRR", [k2, k3, k4])
                        T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                        T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                        with T.init():
                            A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                            A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                        v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                        v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                        A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                        A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(3), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape_1"):
                    v_ax0 = T.axis.spatial(T.int64(32), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) // T.int64(20))
                    v_ax1 = T.axis.spatial(T.int64(20), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) % T.int64(20))
                    T.where(ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1 < T.int64(640))
                    T.reads(unet_up_blocks_2_resnets_1_norm1_weight[(v_ax0 * T.int64(20) + v_ax1) % T.int64(640)])
                    T.writes(T_reshape_1[v_ax0, v_ax1])
                    T_reshape_1[v_ax0, v_ax1] = unet_up_blocks_2_resnets_1_norm1_weight[(v_ax0 * T.int64(20) + v_ax1) % T.int64(640)]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(3), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape_2"):
                    v_ax0 = T.axis.spatial(T.int64(32), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) // T.int64(20))
                    v_ax1 = T.axis.spatial(T.int64(20), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) % T.int64(20))
                    T.where(ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1 < T.int64(640))
                    T.reads(unet_up_blocks_2_resnets_1_norm1_bias[(v_ax0 * T.int64(20) + v_ax1) % T.int64(640)])
                    T.writes(T_reshape_2[v_ax0, v_ax1])
                    T_reshape_2[v_ax0, v_ax1] = unet_up_blocks_2_resnets_1_norm1_bias[(v_ax0 * T.int64(20) + v_ax1) % T.int64(640)]
        for ax0_ax1_ax2_ax3_ax4_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_ax4_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_ax4_fused_0 in range(T.int64(40)):
                    with T.block("T_group_norm"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) // T.int64(81920))
                        v_ax2 = T.axis.spatial(T.int64(20), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(81920) // T.int64(4096))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(4096) // T.int64(64))
                        v_ax4 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(64))
                        T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                        T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(1.2207031250000001e-05)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(1.2207031250000001e-05) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(1.2207031250000001e-05) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(1.2207031250000001e-05)) + T.float32(1.0000000000000001e-05)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(40)):
                    with T.block("T_reshape_3"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(640), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(4096))
                        v_ax2 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(4096) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.reads(T_group_norm[T.int64(0), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(640) // T.int64(20), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(20), (v_ax3 // T.int64(64) + v_ax2) % T.int64(64), v_ax3 % T.int64(64)])
                        T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[T.int64(0), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(640) // T.int64(20), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(20), (v_ax3 // T.int64(64) + v_ax2) % T.int64(64), v_ax3 % T.int64(64)]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(40)):
                    with T.block("compute"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(640), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(4096))
                        v_i2 = T.axis.spatial(T.int64(64), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(4096) // T.int64(64))
                        v_i3 = T.axis.spatial(T.int64(64), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(64))
                        T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                        T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                        compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(40)):
                    with T.block("T_multiply"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(640), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(4096))
                        v_ax2 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(4096) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_group_norm14_silu13(lv6: T.Buffer((T.int64(1), T.int64(512), T.int64(64), T.int64(64)), "float32"), vae_decoder_mid_block_resnets_0_norm1_weight: T.Buffer((T.int64(512),), "float32"), vae_decoder_mid_block_resnets_0_norm1_bias: T.Buffer((T.int64(512),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(1), T.int64(512), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(16), T.int64(64), T.int64(64)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(1), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(1), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(16)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(16)))
        T_group_norm = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(16), T.int64(64), T.int64(64)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(64), T.int64(64)))
        compute = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(64), T.int64(64)))
        for ax0_ax1_ax2_ax3_ax4_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_ax4_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_ax4_fused_0 in range(T.int64(32)):
                    with T.block("T_reshape"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) // T.int64(65536))
                        v_ax2 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(65536) // T.int64(4096))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(4096) // T.int64(64))
                        v_ax4 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(64))
                        T.reads(lv6[T.int64(0), (v_ax1 * T.int64(16) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) % T.int64(512), (v_ax4 // T.int64(64) + v_ax3) % T.int64(64), v_ax4 % T.int64(64)])
                        T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv6[T.int64(0), (v_ax1 * T.int64(16) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) % T.int64(512), (v_ax4 // T.int64(64) + v_ax3) % T.int64(64), v_ax4 % T.int64(64)]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for k2, k3, k4 in T.grid(T.int64(16), T.int64(64), T.int64(64)):
                    with T.block("A_red_temp"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), ax0_ax1_fused_0 * T.int64(32) + ax0_ax1_fused_1)
                        v_k2, v_k3, v_k4 = T.axis.remap("RRR", [k2, k3, k4])
                        T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                        T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                        with T.init():
                            A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                            A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                        v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                        v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                        A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                        A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(2), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape_1"):
                    v_ax0 = T.axis.spatial(T.int64(32), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) // T.int64(16))
                    v_ax1 = T.axis.spatial(T.int64(16), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) % T.int64(16))
                    T.reads(vae_decoder_mid_block_resnets_0_norm1_weight[(v_ax0 * T.int64(16) + v_ax1) % T.int64(512)])
                    T.writes(T_reshape_1[v_ax0, v_ax1])
                    T_reshape_1[v_ax0, v_ax1] = vae_decoder_mid_block_resnets_0_norm1_weight[(v_ax0 * T.int64(16) + v_ax1) % T.int64(512)]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(2), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape_2"):
                    v_ax0 = T.axis.spatial(T.int64(32), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) // T.int64(16))
                    v_ax1 = T.axis.spatial(T.int64(16), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) % T.int64(16))
                    T.reads(vae_decoder_mid_block_resnets_0_norm1_bias[(v_ax0 * T.int64(16) + v_ax1) % T.int64(512)])
                    T.writes(T_reshape_2[v_ax0, v_ax1])
                    T_reshape_2[v_ax0, v_ax1] = vae_decoder_mid_block_resnets_0_norm1_bias[(v_ax0 * T.int64(16) + v_ax1) % T.int64(512)]
        for ax0_ax1_ax2_ax3_ax4_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_ax4_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_ax4_fused_0 in range(T.int64(32)):
                    with T.block("T_group_norm"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) // T.int64(65536))
                        v_ax2 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(65536) // T.int64(4096))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(4096) // T.int64(64))
                        v_ax4 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(64))
                        T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                        T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(1.52587890625e-05)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(1.52587890625e-05) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(1.52587890625e-05) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(1.52587890625e-05)) + T.float32(9.9999999999999995e-07)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(32)):
                    with T.block("T_reshape_3"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(4096))
                        v_ax2 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(4096) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.reads(T_group_norm[T.int64(0), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(512) // T.int64(16), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(16), (v_ax3 // T.int64(64) + v_ax2) % T.int64(64), v_ax3 % T.int64(64)])
                        T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[T.int64(0), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(512) // T.int64(16), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(16), (v_ax3 // T.int64(64) + v_ax2) % T.int64(64), v_ax3 % T.int64(64)]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(32)):
                    with T.block("compute"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(512), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(4096))
                        v_i2 = T.axis.spatial(T.int64(64), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(4096) // T.int64(64))
                        v_i3 = T.axis.spatial(T.int64(64), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(64))
                        T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                        T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                        compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(32)):
                    with T.block("T_multiply"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(4096))
                        v_ax2 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(4096) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_group_norm16_silu14(lv107: T.Buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)), "float32"), vae_decoder_up_blocks_1_resnets_0_norm1_weight: T.Buffer((T.int64(512),), "float32"), vae_decoder_up_blocks_1_resnets_0_norm1_bias: T.Buffer((T.int64(512),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(16), T.int64(128), T.int64(128)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(1), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(1), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(16)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(16)))
        T_group_norm = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(16), T.int64(128), T.int64(128)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)))
        compute = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)))
        for ax0_ax1_ax2_ax3_ax4_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_ax4_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_ax4_fused_0 in range(T.int64(128)):
                    with T.block("T_reshape"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) // T.int64(262144))
                        v_ax2 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(262144) // T.int64(16384))
                        v_ax3 = T.axis.spatial(T.int64(128), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(16384) // T.int64(128))
                        v_ax4 = T.axis.spatial(T.int64(128), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(128))
                        T.reads(lv107[T.int64(0), (v_ax1 * T.int64(16) + (v_ax4 // T.int64(128) + v_ax3) // T.int64(128) + v_ax2) % T.int64(512), (v_ax4 // T.int64(128) + v_ax3) % T.int64(128), v_ax4 % T.int64(128)])
                        T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv107[T.int64(0), (v_ax1 * T.int64(16) + (v_ax4 // T.int64(128) + v_ax3) // T.int64(128) + v_ax2) % T.int64(512), (v_ax4 // T.int64(128) + v_ax3) % T.int64(128), v_ax4 % T.int64(128)]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for k2, k3, k4 in T.grid(T.int64(16), T.int64(128), T.int64(128)):
                    with T.block("A_red_temp"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), ax0_ax1_fused_0 * T.int64(32) + ax0_ax1_fused_1)
                        v_k2, v_k3, v_k4 = T.axis.remap("RRR", [k2, k3, k4])
                        T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                        T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                        with T.init():
                            A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                            A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                        v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                        v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                        A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                        A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(2), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape_1"):
                    v_ax0 = T.axis.spatial(T.int64(32), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) // T.int64(16))
                    v_ax1 = T.axis.spatial(T.int64(16), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) % T.int64(16))
                    T.reads(vae_decoder_up_blocks_1_resnets_0_norm1_weight[(v_ax0 * T.int64(16) + v_ax1) % T.int64(512)])
                    T.writes(T_reshape_1[v_ax0, v_ax1])
                    T_reshape_1[v_ax0, v_ax1] = vae_decoder_up_blocks_1_resnets_0_norm1_weight[(v_ax0 * T.int64(16) + v_ax1) % T.int64(512)]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(2), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape_2"):
                    v_ax0 = T.axis.spatial(T.int64(32), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) // T.int64(16))
                    v_ax1 = T.axis.spatial(T.int64(16), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) % T.int64(16))
                    T.reads(vae_decoder_up_blocks_1_resnets_0_norm1_bias[(v_ax0 * T.int64(16) + v_ax1) % T.int64(512)])
                    T.writes(T_reshape_2[v_ax0, v_ax1])
                    T_reshape_2[v_ax0, v_ax1] = vae_decoder_up_blocks_1_resnets_0_norm1_bias[(v_ax0 * T.int64(16) + v_ax1) % T.int64(512)]
        for ax0_ax1_ax2_ax3_ax4_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_ax4_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_ax4_fused_0 in range(T.int64(128)):
                    with T.block("T_group_norm"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) // T.int64(262144))
                        v_ax2 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(262144) // T.int64(16384))
                        v_ax3 = T.axis.spatial(T.int64(128), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(16384) // T.int64(128))
                        v_ax4 = T.axis.spatial(T.int64(128), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(128))
                        T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                        T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(3.814697265625e-06)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(3.814697265625e-06) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(3.814697265625e-06) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(3.814697265625e-06)) + T.float32(9.9999999999999995e-07)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(128)):
                    with T.block("T_reshape_3"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(16384))
                        v_ax2 = T.axis.spatial(T.int64(128), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16384) // T.int64(128))
                        v_ax3 = T.axis.spatial(T.int64(128), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(128))
                        T.reads(T_group_norm[T.int64(0), ((v_ax3 // T.int64(128) + v_ax2) // T.int64(128) + v_ax1) % T.int64(512) // T.int64(16), ((v_ax3 // T.int64(128) + v_ax2) // T.int64(128) + v_ax1) % T.int64(16), (v_ax3 // T.int64(128) + v_ax2) % T.int64(128), v_ax3 % T.int64(128)])
                        T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[T.int64(0), ((v_ax3 // T.int64(128) + v_ax2) // T.int64(128) + v_ax1) % T.int64(512) // T.int64(16), ((v_ax3 // T.int64(128) + v_ax2) // T.int64(128) + v_ax1) % T.int64(16), (v_ax3 // T.int64(128) + v_ax2) % T.int64(128), v_ax3 % T.int64(128)]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(128)):
                    with T.block("compute"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(512), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(16384))
                        v_i2 = T.axis.spatial(T.int64(128), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(16384) // T.int64(128))
                        v_i3 = T.axis.spatial(T.int64(128), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(128))
                        T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                        T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                        compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(128)):
                    with T.block("T_multiply"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(16384))
                        v_ax2 = T.axis.spatial(T.int64(128), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16384) // T.int64(128))
                        v_ax3 = T.axis.spatial(T.int64(128), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(128))
                        T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_group_norm17_silu15(lv147: T.Buffer((T.int64(1), T.int64(512), T.int64(256), T.int64(256)), "float32"), vae_decoder_up_blocks_2_resnets_0_norm1_weight: T.Buffer((T.int64(512),), "float32"), vae_decoder_up_blocks_2_resnets_0_norm1_bias: T.Buffer((T.int64(512),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(1), T.int64(512), T.int64(256), T.int64(256)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(16), T.int64(256), T.int64(256)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(1), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(1), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(16)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(16)))
        T_group_norm = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(16), T.int64(256), T.int64(256)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(256), T.int64(256)))
        compute = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(256), T.int64(256)))
        for ax0_ax1_ax2_ax3_ax4_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_ax4_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_ax4_fused_0 in range(T.int64(512)):
                    with T.block("T_reshape"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) // T.int64(1048576))
                        v_ax2 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(1048576) // T.int64(65536))
                        v_ax3 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(65536) // T.int64(256))
                        v_ax4 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(256))
                        T.reads(lv147[T.int64(0), (v_ax1 * T.int64(16) + (v_ax4 // T.int64(256) + v_ax3) // T.int64(256) + v_ax2) % T.int64(512), (v_ax4 // T.int64(256) + v_ax3) % T.int64(256), v_ax4 % T.int64(256)])
                        T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv147[T.int64(0), (v_ax1 * T.int64(16) + (v_ax4 // T.int64(256) + v_ax3) // T.int64(256) + v_ax2) % T.int64(512), (v_ax4 // T.int64(256) + v_ax3) % T.int64(256), v_ax4 % T.int64(256)]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for k2, k3, k4 in T.grid(T.int64(16), T.int64(256), T.int64(256)):
                    with T.block("A_red_temp"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), ax0_ax1_fused_0 * T.int64(32) + ax0_ax1_fused_1)
                        v_k2, v_k3, v_k4 = T.axis.remap("RRR", [k2, k3, k4])
                        T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                        T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                        with T.init():
                            A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                            A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                        v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                        v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                        A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                        A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(2), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape_1"):
                    v_ax0 = T.axis.spatial(T.int64(32), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) // T.int64(16))
                    v_ax1 = T.axis.spatial(T.int64(16), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) % T.int64(16))
                    T.reads(vae_decoder_up_blocks_2_resnets_0_norm1_weight[(v_ax0 * T.int64(16) + v_ax1) % T.int64(512)])
                    T.writes(T_reshape_1[v_ax0, v_ax1])
                    T_reshape_1[v_ax0, v_ax1] = vae_decoder_up_blocks_2_resnets_0_norm1_weight[(v_ax0 * T.int64(16) + v_ax1) % T.int64(512)]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(2), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape_2"):
                    v_ax0 = T.axis.spatial(T.int64(32), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) // T.int64(16))
                    v_ax1 = T.axis.spatial(T.int64(16), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) % T.int64(16))
                    T.reads(vae_decoder_up_blocks_2_resnets_0_norm1_bias[(v_ax0 * T.int64(16) + v_ax1) % T.int64(512)])
                    T.writes(T_reshape_2[v_ax0, v_ax1])
                    T_reshape_2[v_ax0, v_ax1] = vae_decoder_up_blocks_2_resnets_0_norm1_bias[(v_ax0 * T.int64(16) + v_ax1) % T.int64(512)]
        for ax0_ax1_ax2_ax3_ax4_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_ax4_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_ax4_fused_0 in range(T.int64(512)):
                    with T.block("T_group_norm"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) // T.int64(1048576))
                        v_ax2 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(1048576) // T.int64(65536))
                        v_ax3 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(65536) // T.int64(256))
                        v_ax4 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(256))
                        T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                        T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(9.5367431640625e-07)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(9.5367431640625e-07) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(9.5367431640625e-07) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(9.5367431640625e-07)) + T.float32(9.9999999999999995e-07)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(512)):
                    with T.block("T_reshape_3"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(65536))
                        v_ax2 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(65536) // T.int64(256))
                        v_ax3 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256))
                        T.reads(T_group_norm[T.int64(0), ((v_ax3 // T.int64(256) + v_ax2) // T.int64(256) + v_ax1) % T.int64(512) // T.int64(16), ((v_ax3 // T.int64(256) + v_ax2) // T.int64(256) + v_ax1) % T.int64(16), (v_ax3 // T.int64(256) + v_ax2) % T.int64(256), v_ax3 % T.int64(256)])
                        T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[T.int64(0), ((v_ax3 // T.int64(256) + v_ax2) // T.int64(256) + v_ax1) % T.int64(512) // T.int64(16), ((v_ax3 // T.int64(256) + v_ax2) // T.int64(256) + v_ax1) % T.int64(16), (v_ax3 // T.int64(256) + v_ax2) % T.int64(256), v_ax3 % T.int64(256)]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(512)):
                    with T.block("compute"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(512), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(65536))
                        v_i2 = T.axis.spatial(T.int64(256), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(65536) // T.int64(256))
                        v_i3 = T.axis.spatial(T.int64(256), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(256))
                        T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                        T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                        compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(512)):
                    with T.block("T_multiply"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(65536))
                        v_ax2 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(65536) // T.int64(256))
                        v_ax3 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256))
                        T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_group_norm18_silu16(lv152: T.Buffer((T.int64(1), T.int64(256), T.int64(256), T.int64(256)), "float32"), vae_decoder_up_blocks_2_resnets_0_norm2_weight: T.Buffer((T.int64(256),), "float32"), vae_decoder_up_blocks_2_resnets_0_norm2_bias: T.Buffer((T.int64(256),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(1), T.int64(256), T.int64(256), T.int64(256)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(8), T.int64(256), T.int64(256)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(1), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(1), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(8)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(8)))
        T_group_norm = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(8), T.int64(256), T.int64(256)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(256), T.int64(256)))
        compute = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(256), T.int64(256)))
        for ax0_ax1_ax2_ax3_ax4_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_ax4_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_ax4_fused_0 in range(T.int64(256)):
                    with T.block("T_reshape"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) // T.int64(524288))
                        v_ax2 = T.axis.spatial(T.int64(8), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(524288) // T.int64(65536))
                        v_ax3 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(65536) // T.int64(256))
                        v_ax4 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(256))
                        T.reads(lv152[T.int64(0), (v_ax1 * T.int64(8) + (v_ax4 // T.int64(256) + v_ax3) // T.int64(256) + v_ax2) % T.int64(256), (v_ax4 // T.int64(256) + v_ax3) % T.int64(256), v_ax4 % T.int64(256)])
                        T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv152[T.int64(0), (v_ax1 * T.int64(8) + (v_ax4 // T.int64(256) + v_ax3) // T.int64(256) + v_ax2) % T.int64(256), (v_ax4 // T.int64(256) + v_ax3) % T.int64(256), v_ax4 % T.int64(256)]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for k2, k3, k4 in T.grid(T.int64(8), T.int64(256), T.int64(256)):
                    with T.block("A_red_temp"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), ax0_ax1_fused_0 * T.int64(32) + ax0_ax1_fused_1)
                        v_k2, v_k3, v_k4 = T.axis.remap("RRR", [k2, k3, k4])
                        T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                        T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                        with T.init():
                            A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                            A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                        v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                        v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                        A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                        A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape_1"):
                    v_ax0 = T.axis.spatial(T.int64(32), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) // T.int64(8))
                    v_ax1 = T.axis.spatial(T.int64(8), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) % T.int64(8))
                    T.reads(vae_decoder_up_blocks_2_resnets_0_norm2_weight[(v_ax0 * T.int64(8) + v_ax1) % T.int64(256)])
                    T.writes(T_reshape_1[v_ax0, v_ax1])
                    T_reshape_1[v_ax0, v_ax1] = vae_decoder_up_blocks_2_resnets_0_norm2_weight[(v_ax0 * T.int64(8) + v_ax1) % T.int64(256)]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape_2"):
                    v_ax0 = T.axis.spatial(T.int64(32), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) // T.int64(8))
                    v_ax1 = T.axis.spatial(T.int64(8), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) % T.int64(8))
                    T.reads(vae_decoder_up_blocks_2_resnets_0_norm2_bias[(v_ax0 * T.int64(8) + v_ax1) % T.int64(256)])
                    T.writes(T_reshape_2[v_ax0, v_ax1])
                    T_reshape_2[v_ax0, v_ax1] = vae_decoder_up_blocks_2_resnets_0_norm2_bias[(v_ax0 * T.int64(8) + v_ax1) % T.int64(256)]
        for ax0_ax1_ax2_ax3_ax4_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_ax4_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_ax4_fused_0 in range(T.int64(256)):
                    with T.block("T_group_norm"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) // T.int64(524288))
                        v_ax2 = T.axis.spatial(T.int64(8), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(524288) // T.int64(65536))
                        v_ax3 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(65536) // T.int64(256))
                        v_ax4 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(256))
                        T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                        T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(1.9073486328125e-06)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(1.9073486328125e-06) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(1.9073486328125e-06) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(1.9073486328125e-06)) + T.float32(9.9999999999999995e-07)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(256)):
                    with T.block("T_reshape_3"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(65536))
                        v_ax2 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(65536) // T.int64(256))
                        v_ax3 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256))
                        T.reads(T_group_norm[T.int64(0), ((v_ax3 // T.int64(256) + v_ax2) // T.int64(256) + v_ax1) % T.int64(256) // T.int64(8), ((v_ax3 // T.int64(256) + v_ax2) // T.int64(256) + v_ax1) % T.int64(8), (v_ax3 // T.int64(256) + v_ax2) % T.int64(256), v_ax3 % T.int64(256)])
                        T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[T.int64(0), ((v_ax3 // T.int64(256) + v_ax2) // T.int64(256) + v_ax1) % T.int64(256) // T.int64(8), ((v_ax3 // T.int64(256) + v_ax2) // T.int64(256) + v_ax1) % T.int64(8), (v_ax3 // T.int64(256) + v_ax2) % T.int64(256), v_ax3 % T.int64(256)]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(256)):
                    with T.block("compute"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(256), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(65536))
                        v_i2 = T.axis.spatial(T.int64(256), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(65536) // T.int64(256))
                        v_i3 = T.axis.spatial(T.int64(256), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(256))
                        T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                        T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                        compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(256)):
                    with T.block("T_multiply"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(65536))
                        v_ax2 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(65536) // T.int64(256))
                        v_ax3 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256))
                        T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_group_norm19_silu17(lv190: T.Buffer((T.int64(1), T.int64(256), T.int64(512), T.int64(512)), "float32"), vae_decoder_up_blocks_3_resnets_0_norm1_weight: T.Buffer((T.int64(256),), "float32"), vae_decoder_up_blocks_3_resnets_0_norm1_bias: T.Buffer((T.int64(256),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(1), T.int64(256), T.int64(512), T.int64(512)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(8), T.int64(512), T.int64(512)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(1), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(1), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(8)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(8)))
        T_group_norm = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(8), T.int64(512), T.int64(512)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(512), T.int64(512)))
        compute = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(512), T.int64(512)))
        for ax0_ax1_ax2_ax3_ax4_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_ax4_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_ax4_fused_0 in range(T.int64(1024)):
                    with T.block("T_reshape"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) // T.int64(2097152))
                        v_ax2 = T.axis.spatial(T.int64(8), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(2097152) // T.int64(262144))
                        v_ax3 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(262144) // T.int64(512))
                        v_ax4 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(512))
                        T.reads(lv190[T.int64(0), (v_ax1 * T.int64(8) + (v_ax4 // T.int64(512) + v_ax3) // T.int64(512) + v_ax2) % T.int64(256), (v_ax4 // T.int64(512) + v_ax3) % T.int64(512), v_ax4 % T.int64(512)])
                        T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv190[T.int64(0), (v_ax1 * T.int64(8) + (v_ax4 // T.int64(512) + v_ax3) // T.int64(512) + v_ax2) % T.int64(256), (v_ax4 // T.int64(512) + v_ax3) % T.int64(512), v_ax4 % T.int64(512)]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for k2, k3, k4 in T.grid(T.int64(8), T.int64(512), T.int64(512)):
                    with T.block("A_red_temp"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), ax0_ax1_fused_0 * T.int64(32) + ax0_ax1_fused_1)
                        v_k2, v_k3, v_k4 = T.axis.remap("RRR", [k2, k3, k4])
                        T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                        T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                        with T.init():
                            A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                            A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                        v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                        v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                        A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                        A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape_1"):
                    v_ax0 = T.axis.spatial(T.int64(32), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) // T.int64(8))
                    v_ax1 = T.axis.spatial(T.int64(8), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) % T.int64(8))
                    T.reads(vae_decoder_up_blocks_3_resnets_0_norm1_weight[(v_ax0 * T.int64(8) + v_ax1) % T.int64(256)])
                    T.writes(T_reshape_1[v_ax0, v_ax1])
                    T_reshape_1[v_ax0, v_ax1] = vae_decoder_up_blocks_3_resnets_0_norm1_weight[(v_ax0 * T.int64(8) + v_ax1) % T.int64(256)]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape_2"):
                    v_ax0 = T.axis.spatial(T.int64(32), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) // T.int64(8))
                    v_ax1 = T.axis.spatial(T.int64(8), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) % T.int64(8))
                    T.reads(vae_decoder_up_blocks_3_resnets_0_norm1_bias[(v_ax0 * T.int64(8) + v_ax1) % T.int64(256)])
                    T.writes(T_reshape_2[v_ax0, v_ax1])
                    T_reshape_2[v_ax0, v_ax1] = vae_decoder_up_blocks_3_resnets_0_norm1_bias[(v_ax0 * T.int64(8) + v_ax1) % T.int64(256)]
        for ax0_ax1_ax2_ax3_ax4_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_ax4_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_ax4_fused_0 in range(T.int64(1024)):
                    with T.block("T_group_norm"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) // T.int64(2097152))
                        v_ax2 = T.axis.spatial(T.int64(8), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(2097152) // T.int64(262144))
                        v_ax3 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(262144) // T.int64(512))
                        v_ax4 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(512))
                        T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                        T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(4.76837158203125e-07)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(4.76837158203125e-07) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(4.76837158203125e-07) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(4.76837158203125e-07)) + T.float32(9.9999999999999995e-07)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(1024)):
                    with T.block("T_reshape_3"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(262144))
                        v_ax2 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(262144) // T.int64(512))
                        v_ax3 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512))
                        T.reads(T_group_norm[T.int64(0), ((v_ax3 // T.int64(512) + v_ax2) // T.int64(512) + v_ax1) % T.int64(256) // T.int64(8), ((v_ax3 // T.int64(512) + v_ax2) // T.int64(512) + v_ax1) % T.int64(8), (v_ax3 // T.int64(512) + v_ax2) % T.int64(512), v_ax3 % T.int64(512)])
                        T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[T.int64(0), ((v_ax3 // T.int64(512) + v_ax2) // T.int64(512) + v_ax1) % T.int64(256) // T.int64(8), ((v_ax3 // T.int64(512) + v_ax2) // T.int64(512) + v_ax1) % T.int64(8), (v_ax3 // T.int64(512) + v_ax2) % T.int64(512), v_ax3 % T.int64(512)]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(1024)):
                    with T.block("compute"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(256), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(262144))
                        v_i2 = T.axis.spatial(T.int64(512), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(262144) // T.int64(512))
                        v_i3 = T.axis.spatial(T.int64(512), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(512))
                        T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                        T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                        compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(1024)):
                    with T.block("T_multiply"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(262144))
                        v_ax2 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(262144) // T.int64(512))
                        v_ax3 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512))
                        T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_group_norm1_silu2(lv89: T.Buffer((T.int64(1), T.int64(320), T.int64(32), T.int64(32)), "float32"), unet_down_blocks_1_resnets_0_norm1_weight: T.Buffer((T.int64(320),), "float32"), unet_down_blocks_1_resnets_0_norm1_bias: T.Buffer((T.int64(320),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(1), T.int64(320), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(10), T.int64(32), T.int64(32)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(1), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(1), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(10)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(10)))
        T_group_norm = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(10), T.int64(32), T.int64(32)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(320), T.int64(32), T.int64(32)))
        compute = T.alloc_buffer((T.int64(1), T.int64(320), T.int64(32), T.int64(32)))
        for ax0_ax1_ax2_ax3_ax4_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_ax4_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_ax4_fused_0 in range(T.int64(5)):
                    with T.block("T_reshape"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) // T.int64(10240))
                        v_ax2 = T.axis.spatial(T.int64(10), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(10240) // T.int64(1024))
                        v_ax3 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(1024) // T.int64(32))
                        v_ax4 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(32))
                        T.reads(lv89[T.int64(0), (v_ax1 * T.int64(10) + (v_ax4 // T.int64(32) + v_ax3) // T.int64(32) + v_ax2) % T.int64(320), (v_ax4 // T.int64(32) + v_ax3) % T.int64(32), v_ax4 % T.int64(32)])
                        T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv89[T.int64(0), (v_ax1 * T.int64(10) + (v_ax4 // T.int64(32) + v_ax3) // T.int64(32) + v_ax2) % T.int64(320), (v_ax4 // T.int64(32) + v_ax3) % T.int64(32), v_ax4 % T.int64(32)]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for k2, k3, k4 in T.grid(T.int64(10), T.int64(32), T.int64(32)):
                    with T.block("A_red_temp"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), ax0_ax1_fused_0 * T.int64(32) + ax0_ax1_fused_1)
                        v_k2, v_k3, v_k4 = T.axis.remap("RRR", [k2, k3, k4])
                        T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                        T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                        with T.init():
                            A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                            A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                        v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                        v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                        A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                        A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(2), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape_1"):
                    v_ax0 = T.axis.spatial(T.int64(32), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) // T.int64(10))
                    v_ax1 = T.axis.spatial(T.int64(10), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) % T.int64(10))
                    T.where(ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1 < T.int64(320))
                    T.reads(unet_down_blocks_1_resnets_0_norm1_weight[(v_ax0 * T.int64(10) + v_ax1) % T.int64(320)])
                    T.writes(T_reshape_1[v_ax0, v_ax1])
                    T_reshape_1[v_ax0, v_ax1] = unet_down_blocks_1_resnets_0_norm1_weight[(v_ax0 * T.int64(10) + v_ax1) % T.int64(320)]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(2), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape_2"):
                    v_ax0 = T.axis.spatial(T.int64(32), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) // T.int64(10))
                    v_ax1 = T.axis.spatial(T.int64(10), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) % T.int64(10))
                    T.where(ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1 < T.int64(320))
                    T.reads(unet_down_blocks_1_resnets_0_norm1_bias[(v_ax0 * T.int64(10) + v_ax1) % T.int64(320)])
                    T.writes(T_reshape_2[v_ax0, v_ax1])
                    T_reshape_2[v_ax0, v_ax1] = unet_down_blocks_1_resnets_0_norm1_bias[(v_ax0 * T.int64(10) + v_ax1) % T.int64(320)]
        for ax0_ax1_ax2_ax3_ax4_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_ax4_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_ax4_fused_0 in range(T.int64(5)):
                    with T.block("T_group_norm"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) // T.int64(10240))
                        v_ax2 = T.axis.spatial(T.int64(10), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(10240) // T.int64(1024))
                        v_ax3 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(1024) // T.int64(32))
                        v_ax4 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(32))
                        T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                        T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(9.7656250000000005e-05)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(9.7656250000000005e-05) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(9.7656250000000005e-05) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(9.7656250000000005e-05)) + T.float32(1.0000000000000001e-05)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(5)):
                    with T.block("T_reshape_3"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(320), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                        v_ax2 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(32))
                        v_ax3 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                        T.reads(T_group_norm[T.int64(0), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(320) // T.int64(10), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(10), (v_ax3 // T.int64(32) + v_ax2) % T.int64(32), v_ax3 % T.int64(32)])
                        T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[T.int64(0), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(320) // T.int64(10), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(10), (v_ax3 // T.int64(32) + v_ax2) % T.int64(32), v_ax3 % T.int64(32)]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(5)):
                    with T.block("compute"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(320), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(1024))
                        v_i2 = T.axis.spatial(T.int64(32), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(1024) // T.int64(32))
                        v_i3 = T.axis.spatial(T.int64(32), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(32))
                        T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                        T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                        compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(5)):
                    with T.block("T_multiply"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(320), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                        v_ax2 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(32))
                        v_ax3 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                        T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_group_norm20_silu18(lv195: T.Buffer((T.int64(1), T.int64(128), T.int64(512), T.int64(512)), "float32"), vae_decoder_up_blocks_3_resnets_0_norm2_weight: T.Buffer((T.int64(128),), "float32"), vae_decoder_up_blocks_3_resnets_0_norm2_bias: T.Buffer((T.int64(128),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(1), T.int64(128), T.int64(512), T.int64(512)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(4), T.int64(512), T.int64(512)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(1), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(1), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(4)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(4)))
        T_group_norm = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(4), T.int64(512), T.int64(512)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(128), T.int64(512), T.int64(512)))
        compute = T.alloc_buffer((T.int64(1), T.int64(128), T.int64(512), T.int64(512)))
        for ax0_ax1_ax2_ax3_ax4_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_ax4_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_ax4_fused_0 in range(T.int64(512)):
                    with T.block("T_reshape"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) // T.int64(1048576))
                        v_ax2 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(1048576) // T.int64(262144))
                        v_ax3 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(262144) // T.int64(512))
                        v_ax4 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(512))
                        T.reads(lv195[T.int64(0), (v_ax1 * T.int64(4) + (v_ax4 // T.int64(512) + v_ax3) // T.int64(512) + v_ax2) % T.int64(128), (v_ax4 // T.int64(512) + v_ax3) % T.int64(512), v_ax4 % T.int64(512)])
                        T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv195[T.int64(0), (v_ax1 * T.int64(4) + (v_ax4 // T.int64(512) + v_ax3) // T.int64(512) + v_ax2) % T.int64(128), (v_ax4 // T.int64(512) + v_ax3) % T.int64(512), v_ax4 % T.int64(512)]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for k2, k3, k4 in T.grid(T.int64(4), T.int64(512), T.int64(512)):
                    with T.block("A_red_temp"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), ax0_ax1_fused_0 * T.int64(32) + ax0_ax1_fused_1)
                        v_k2, v_k3, v_k4 = T.axis.remap("RRR", [k2, k3, k4])
                        T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                        T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                        with T.init():
                            A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                            A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                        v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                        v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                        A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                        A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                with T.block("T_reshape_1"):
                    v_ax0 = T.axis.spatial(T.int64(32), (ax0_ax1_fused_0 * T.int64(128) + ax0_ax1_fused_1) // T.int64(4))
                    v_ax1 = T.axis.spatial(T.int64(4), (ax0_ax1_fused_0 * T.int64(128) + ax0_ax1_fused_1) % T.int64(4))
                    T.reads(vae_decoder_up_blocks_3_resnets_0_norm2_weight[(v_ax0 * T.int64(4) + v_ax1) % T.int64(128)])
                    T.writes(T_reshape_1[v_ax0, v_ax1])
                    T_reshape_1[v_ax0, v_ax1] = vae_decoder_up_blocks_3_resnets_0_norm2_weight[(v_ax0 * T.int64(4) + v_ax1) % T.int64(128)]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                with T.block("T_reshape_2"):
                    v_ax0 = T.axis.spatial(T.int64(32), (ax0_ax1_fused_0 * T.int64(128) + ax0_ax1_fused_1) // T.int64(4))
                    v_ax1 = T.axis.spatial(T.int64(4), (ax0_ax1_fused_0 * T.int64(128) + ax0_ax1_fused_1) % T.int64(4))
                    T.reads(vae_decoder_up_blocks_3_resnets_0_norm2_bias[(v_ax0 * T.int64(4) + v_ax1) % T.int64(128)])
                    T.writes(T_reshape_2[v_ax0, v_ax1])
                    T_reshape_2[v_ax0, v_ax1] = vae_decoder_up_blocks_3_resnets_0_norm2_bias[(v_ax0 * T.int64(4) + v_ax1) % T.int64(128)]
        for ax0_ax1_ax2_ax3_ax4_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_ax4_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_ax4_fused_0 in range(T.int64(512)):
                    with T.block("T_group_norm"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) // T.int64(1048576))
                        v_ax2 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(1048576) // T.int64(262144))
                        v_ax3 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(262144) // T.int64(512))
                        v_ax4 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(512))
                        T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                        T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(9.5367431640625e-07)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(9.5367431640625e-07) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(9.5367431640625e-07) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(9.5367431640625e-07)) + T.float32(9.9999999999999995e-07)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(512)):
                    with T.block("T_reshape_3"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(128), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(262144))
                        v_ax2 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(262144) // T.int64(512))
                        v_ax3 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512))
                        T.reads(T_group_norm[T.int64(0), ((v_ax3 // T.int64(512) + v_ax2) // T.int64(512) + v_ax1) % T.int64(128) // T.int64(4), ((v_ax3 // T.int64(512) + v_ax2) // T.int64(512) + v_ax1) % T.int64(4), (v_ax3 // T.int64(512) + v_ax2) % T.int64(512), v_ax3 % T.int64(512)])
                        T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[T.int64(0), ((v_ax3 // T.int64(512) + v_ax2) // T.int64(512) + v_ax1) % T.int64(128) // T.int64(4), ((v_ax3 // T.int64(512) + v_ax2) // T.int64(512) + v_ax1) % T.int64(4), (v_ax3 // T.int64(512) + v_ax2) % T.int64(512), v_ax3 % T.int64(512)]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(512)):
                    with T.block("compute"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(128), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(262144))
                        v_i2 = T.axis.spatial(T.int64(512), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(262144) // T.int64(512))
                        v_i3 = T.axis.spatial(T.int64(512), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(512))
                        T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                        T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                        compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(512)):
                    with T.block("T_multiply"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(128), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(262144))
                        v_ax2 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(262144) // T.int64(512))
                        v_ax3 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512))
                        T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_group_norm2_silu3(lv101: T.Buffer((T.int64(1), T.int64(640), T.int64(32), T.int64(32)), "float32"), unet_down_blocks_1_resnets_0_norm2_weight: T.Buffer((T.int64(640),), "float32"), unet_down_blocks_1_resnets_0_norm2_bias: T.Buffer((T.int64(640),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(1), T.int64(640), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(20), T.int64(32), T.int64(32)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(1), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(1), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(20)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(20)))
        T_group_norm = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(20), T.int64(32), T.int64(32)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(640), T.int64(32), T.int64(32)))
        compute = T.alloc_buffer((T.int64(1), T.int64(640), T.int64(32), T.int64(32)))
        for ax0_ax1_ax2_ax3_ax4_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_ax4_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_ax4_fused_0 in range(T.int64(10)):
                    with T.block("T_reshape"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) // T.int64(20480))
                        v_ax2 = T.axis.spatial(T.int64(20), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(20480) // T.int64(1024))
                        v_ax3 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(1024) // T.int64(32))
                        v_ax4 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(32))
                        T.reads(lv101[T.int64(0), (v_ax1 * T.int64(20) + (v_ax4 // T.int64(32) + v_ax3) // T.int64(32) + v_ax2) % T.int64(640), (v_ax4 // T.int64(32) + v_ax3) % T.int64(32), v_ax4 % T.int64(32)])
                        T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv101[T.int64(0), (v_ax1 * T.int64(20) + (v_ax4 // T.int64(32) + v_ax3) // T.int64(32) + v_ax2) % T.int64(640), (v_ax4 // T.int64(32) + v_ax3) % T.int64(32), v_ax4 % T.int64(32)]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for k2, k3, k4 in T.grid(T.int64(20), T.int64(32), T.int64(32)):
                    with T.block("A_red_temp"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), ax0_ax1_fused_0 * T.int64(32) + ax0_ax1_fused_1)
                        v_k2, v_k3, v_k4 = T.axis.remap("RRR", [k2, k3, k4])
                        T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                        T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                        with T.init():
                            A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                            A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                        v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                        v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                        A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                        A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(3), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape_1"):
                    v_ax0 = T.axis.spatial(T.int64(32), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) // T.int64(20))
                    v_ax1 = T.axis.spatial(T.int64(20), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) % T.int64(20))
                    T.where(ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1 < T.int64(640))
                    T.reads(unet_down_blocks_1_resnets_0_norm2_weight[(v_ax0 * T.int64(20) + v_ax1) % T.int64(640)])
                    T.writes(T_reshape_1[v_ax0, v_ax1])
                    T_reshape_1[v_ax0, v_ax1] = unet_down_blocks_1_resnets_0_norm2_weight[(v_ax0 * T.int64(20) + v_ax1) % T.int64(640)]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(3), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape_2"):
                    v_ax0 = T.axis.spatial(T.int64(32), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) // T.int64(20))
                    v_ax1 = T.axis.spatial(T.int64(20), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) % T.int64(20))
                    T.where(ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1 < T.int64(640))
                    T.reads(unet_down_blocks_1_resnets_0_norm2_bias[(v_ax0 * T.int64(20) + v_ax1) % T.int64(640)])
                    T.writes(T_reshape_2[v_ax0, v_ax1])
                    T_reshape_2[v_ax0, v_ax1] = unet_down_blocks_1_resnets_0_norm2_bias[(v_ax0 * T.int64(20) + v_ax1) % T.int64(640)]
        for ax0_ax1_ax2_ax3_ax4_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_ax4_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_ax4_fused_0 in range(T.int64(10)):
                    with T.block("T_group_norm"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) // T.int64(20480))
                        v_ax2 = T.axis.spatial(T.int64(20), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(20480) // T.int64(1024))
                        v_ax3 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(1024) // T.int64(32))
                        v_ax4 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(32))
                        T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                        T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(4.8828125000000003e-05)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(4.8828125000000003e-05) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(4.8828125000000003e-05) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(4.8828125000000003e-05)) + T.float32(1.0000000000000001e-05)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(10)):
                    with T.block("T_reshape_3"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(640), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                        v_ax2 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(32))
                        v_ax3 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                        T.reads(T_group_norm[T.int64(0), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(640) // T.int64(20), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(20), (v_ax3 // T.int64(32) + v_ax2) % T.int64(32), v_ax3 % T.int64(32)])
                        T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[T.int64(0), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(640) // T.int64(20), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(20), (v_ax3 // T.int64(32) + v_ax2) % T.int64(32), v_ax3 % T.int64(32)]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(10)):
                    with T.block("compute"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(640), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(1024))
                        v_i2 = T.axis.spatial(T.int64(32), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(1024) // T.int64(32))
                        v_i3 = T.axis.spatial(T.int64(32), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(32))
                        T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                        T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                        compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(10)):
                    with T.block("T_multiply"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(640), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                        v_ax2 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(32))
                        v_ax3 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                        T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_group_norm4_silu4(lv425: T.Buffer((T.int64(1), T.int64(640), T.int64(16), T.int64(16)), "float32"), unet_down_blocks_2_resnets_0_norm1_weight: T.Buffer((T.int64(640),), "float32"), unet_down_blocks_2_resnets_0_norm1_bias: T.Buffer((T.int64(640),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(1), T.int64(640), T.int64(16), T.int64(16)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(20), T.int64(16), T.int64(16)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(1), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(1), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(20)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(20)))
        T_group_norm = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(20), T.int64(16), T.int64(16)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(640), T.int64(16), T.int64(16)))
        compute = T.alloc_buffer((T.int64(1), T.int64(640), T.int64(16), T.int64(16)))
        for ax0_ax1_ax2_ax3_ax4_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_ax4_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_ax4_fused_0 in range(T.int64(3)):
                    with T.block("T_reshape"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) // T.int64(5120))
                        v_ax2 = T.axis.spatial(T.int64(20), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(5120) // T.int64(256))
                        v_ax3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(256) // T.int64(16))
                        v_ax4 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(16))
                        T.where((ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_1) * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2 < T.int64(163840))
                        T.reads(lv425[T.int64(0), (v_ax1 * T.int64(20) + (v_ax4 // T.int64(16) + v_ax3) // T.int64(16) + v_ax2) % T.int64(640), (v_ax4 // T.int64(16) + v_ax3) % T.int64(16), v_ax4 % T.int64(16)])
                        T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv425[T.int64(0), (v_ax1 * T.int64(20) + (v_ax4 // T.int64(16) + v_ax3) // T.int64(16) + v_ax2) % T.int64(640), (v_ax4 // T.int64(16) + v_ax3) % T.int64(16), v_ax4 % T.int64(16)]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for k2, k3, k4 in T.grid(T.int64(20), T.int64(16), T.int64(16)):
                    with T.block("A_red_temp"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), ax0_ax1_fused_0 * T.int64(32) + ax0_ax1_fused_1)
                        v_k2, v_k3, v_k4 = T.axis.remap("RRR", [k2, k3, k4])
                        T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                        T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                        with T.init():
                            A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                            A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                        v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                        v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                        A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                        A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(3), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape_1"):
                    v_ax0 = T.axis.spatial(T.int64(32), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) // T.int64(20))
                    v_ax1 = T.axis.spatial(T.int64(20), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) % T.int64(20))
                    T.where(ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1 < T.int64(640))
                    T.reads(unet_down_blocks_2_resnets_0_norm1_weight[(v_ax0 * T.int64(20) + v_ax1) % T.int64(640)])
                    T.writes(T_reshape_1[v_ax0, v_ax1])
                    T_reshape_1[v_ax0, v_ax1] = unet_down_blocks_2_resnets_0_norm1_weight[(v_ax0 * T.int64(20) + v_ax1) % T.int64(640)]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(3), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape_2"):
                    v_ax0 = T.axis.spatial(T.int64(32), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) // T.int64(20))
                    v_ax1 = T.axis.spatial(T.int64(20), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) % T.int64(20))
                    T.where(ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1 < T.int64(640))
                    T.reads(unet_down_blocks_2_resnets_0_norm1_bias[(v_ax0 * T.int64(20) + v_ax1) % T.int64(640)])
                    T.writes(T_reshape_2[v_ax0, v_ax1])
                    T_reshape_2[v_ax0, v_ax1] = unet_down_blocks_2_resnets_0_norm1_bias[(v_ax0 * T.int64(20) + v_ax1) % T.int64(640)]
        for ax0_ax1_ax2_ax3_ax4_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_ax4_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_ax4_fused_0 in range(T.int64(3)):
                    with T.block("T_group_norm"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) // T.int64(5120))
                        v_ax2 = T.axis.spatial(T.int64(20), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(5120) // T.int64(256))
                        v_ax3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(256) // T.int64(16))
                        v_ax4 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(16))
                        T.where((ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_1) * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2 < T.int64(163840))
                        T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                        T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(0.00019531250000000001)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(0.00019531250000000001) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(0.00019531250000000001) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(0.00019531250000000001)) + T.float32(1.0000000000000001e-05)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(3)):
                    with T.block("T_reshape_3"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(640), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(256))
                        v_ax2 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256) // T.int64(16))
                        v_ax3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) * T.int64(256) + ax0_ax1_ax2_ax3_fused_2 < T.int64(163840))
                        T.reads(T_group_norm[T.int64(0), ((v_ax3 // T.int64(16) + v_ax2) // T.int64(16) + v_ax1) % T.int64(640) // T.int64(20), ((v_ax3 // T.int64(16) + v_ax2) // T.int64(16) + v_ax1) % T.int64(20), (v_ax3 // T.int64(16) + v_ax2) % T.int64(16), v_ax3 % T.int64(16)])
                        T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[T.int64(0), ((v_ax3 // T.int64(16) + v_ax2) // T.int64(16) + v_ax1) % T.int64(640) // T.int64(20), ((v_ax3 // T.int64(16) + v_ax2) // T.int64(16) + v_ax1) % T.int64(20), (v_ax3 // T.int64(16) + v_ax2) % T.int64(16), v_ax3 % T.int64(16)]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(3)):
                    with T.block("compute"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(640), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(256))
                        v_i2 = T.axis.spatial(T.int64(16), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(256) // T.int64(16))
                        v_i3 = T.axis.spatial(T.int64(16), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(16))
                        T.where((i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1) * T.int64(256) + i0_i1_i2_i3_fused_2 < T.int64(163840))
                        T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                        T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                        compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(3)):
                    with T.block("T_multiply"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(640), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(256))
                        v_ax2 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256) // T.int64(16))
                        v_ax3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) * T.int64(256) + ax0_ax1_ax2_ax3_fused_2 < T.int64(163840))
                        T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_group_norm5_silu5(lv437: T.Buffer((T.int64(1), T.int64(1280), T.int64(16), T.int64(16)), "float32"), unet_down_blocks_2_resnets_0_norm2_weight: T.Buffer((T.int64(1280),), "float32"), unet_down_blocks_2_resnets_0_norm2_bias: T.Buffer((T.int64(1280),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(1), T.int64(1280), T.int64(16), T.int64(16)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(40), T.int64(16), T.int64(16)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(1), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(1), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(40)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(40)))
        T_group_norm = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(40), T.int64(16), T.int64(16)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(1280), T.int64(16), T.int64(16)))
        compute = T.alloc_buffer((T.int64(1), T.int64(1280), T.int64(16), T.int64(16)))
        for ax0_ax1_ax2_ax3_ax4_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_ax4_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_ax4_fused_0 in range(T.int64(5)):
                    with T.block("T_reshape"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) // T.int64(10240))
                        v_ax2 = T.axis.spatial(T.int64(40), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(10240) // T.int64(256))
                        v_ax3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(256) // T.int64(16))
                        v_ax4 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(16))
                        T.reads(lv437[T.int64(0), (v_ax1 * T.int64(40) + (v_ax4 // T.int64(16) + v_ax3) // T.int64(16) + v_ax2) % T.int64(1280), (v_ax4 // T.int64(16) + v_ax3) % T.int64(16), v_ax4 % T.int64(16)])
                        T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv437[T.int64(0), (v_ax1 * T.int64(40) + (v_ax4 // T.int64(16) + v_ax3) // T.int64(16) + v_ax2) % T.int64(1280), (v_ax4 // T.int64(16) + v_ax3) % T.int64(16), v_ax4 % T.int64(16)]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for k2, k3, k4 in T.grid(T.int64(40), T.int64(16), T.int64(16)):
                    with T.block("A_red_temp"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), ax0_ax1_fused_0 * T.int64(32) + ax0_ax1_fused_1)
                        v_k2, v_k3, v_k4 = T.axis.remap("RRR", [k2, k3, k4])
                        T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                        T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                        with T.init():
                            A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                            A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                        v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                        v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                        A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                        A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(5), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape_1"):
                    v_ax0 = T.axis.spatial(T.int64(32), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) // T.int64(40))
                    v_ax1 = T.axis.spatial(T.int64(40), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) % T.int64(40))
                    T.reads(unet_down_blocks_2_resnets_0_norm2_weight[(v_ax0 * T.int64(40) + v_ax1) % T.int64(1280)])
                    T.writes(T_reshape_1[v_ax0, v_ax1])
                    T_reshape_1[v_ax0, v_ax1] = unet_down_blocks_2_resnets_0_norm2_weight[(v_ax0 * T.int64(40) + v_ax1) % T.int64(1280)]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(5), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape_2"):
                    v_ax0 = T.axis.spatial(T.int64(32), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) // T.int64(40))
                    v_ax1 = T.axis.spatial(T.int64(40), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) % T.int64(40))
                    T.reads(unet_down_blocks_2_resnets_0_norm2_bias[(v_ax0 * T.int64(40) + v_ax1) % T.int64(1280)])
                    T.writes(T_reshape_2[v_ax0, v_ax1])
                    T_reshape_2[v_ax0, v_ax1] = unet_down_blocks_2_resnets_0_norm2_bias[(v_ax0 * T.int64(40) + v_ax1) % T.int64(1280)]
        for ax0_ax1_ax2_ax3_ax4_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_ax4_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_ax4_fused_0 in range(T.int64(5)):
                    with T.block("T_group_norm"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) // T.int64(10240))
                        v_ax2 = T.axis.spatial(T.int64(40), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(10240) // T.int64(256))
                        v_ax3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(256) // T.int64(16))
                        v_ax4 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(16))
                        T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                        T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(9.7656250000000005e-05)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(9.7656250000000005e-05) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(9.7656250000000005e-05) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(9.7656250000000005e-05)) + T.float32(1.0000000000000001e-05)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(5)):
                    with T.block("T_reshape_3"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(256))
                        v_ax2 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256) // T.int64(16))
                        v_ax3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                        T.reads(T_group_norm[T.int64(0), ((v_ax3 // T.int64(16) + v_ax2) // T.int64(16) + v_ax1) % T.int64(1280) // T.int64(40), ((v_ax3 // T.int64(16) + v_ax2) // T.int64(16) + v_ax1) % T.int64(40), (v_ax3 // T.int64(16) + v_ax2) % T.int64(16), v_ax3 % T.int64(16)])
                        T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[T.int64(0), ((v_ax3 // T.int64(16) + v_ax2) // T.int64(16) + v_ax1) % T.int64(1280) // T.int64(40), ((v_ax3 // T.int64(16) + v_ax2) // T.int64(16) + v_ax1) % T.int64(40), (v_ax3 // T.int64(16) + v_ax2) % T.int64(16), v_ax3 % T.int64(16)]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(5)):
                    with T.block("compute"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1280), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(256))
                        v_i2 = T.axis.spatial(T.int64(16), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(256) // T.int64(16))
                        v_i3 = T.axis.spatial(T.int64(16), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(16))
                        T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                        T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                        compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(5)):
                    with T.block("T_multiply"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(256))
                        v_ax2 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256) // T.int64(16))
                        v_ax3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                        T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_group_norm7_silu6(lv2551: T.Buffer((T.int64(1), T.int64(2560), T.int64(16), T.int64(16)), "float32"), unet_up_blocks_0_resnets_0_norm1_weight: T.Buffer((T.int64(2560),), "float32"), unet_up_blocks_0_resnets_0_norm1_bias: T.Buffer((T.int64(2560),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(1), T.int64(2560), T.int64(16), T.int64(16)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(80), T.int64(16), T.int64(16)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(1), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(1), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(80)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(80)))
        T_group_norm = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(80), T.int64(16), T.int64(16)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(2560), T.int64(16), T.int64(16)))
        compute = T.alloc_buffer((T.int64(1), T.int64(2560), T.int64(16), T.int64(16)))
        for ax0_ax1_ax2_ax3_ax4_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_ax4_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_ax4_fused_0 in range(T.int64(10)):
                    with T.block("T_reshape"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) // T.int64(20480))
                        v_ax2 = T.axis.spatial(T.int64(80), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(20480) // T.int64(256))
                        v_ax3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(256) // T.int64(16))
                        v_ax4 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(16))
                        T.reads(lv2551[T.int64(0), (v_ax1 * T.int64(80) + (v_ax4 // T.int64(16) + v_ax3) // T.int64(16) + v_ax2) % T.int64(2560), (v_ax4 // T.int64(16) + v_ax3) % T.int64(16), v_ax4 % T.int64(16)])
                        T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv2551[T.int64(0), (v_ax1 * T.int64(80) + (v_ax4 // T.int64(16) + v_ax3) // T.int64(16) + v_ax2) % T.int64(2560), (v_ax4 // T.int64(16) + v_ax3) % T.int64(16), v_ax4 % T.int64(16)]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for k2, k3, k4 in T.grid(T.int64(80), T.int64(16), T.int64(16)):
                    with T.block("A_red_temp"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), ax0_ax1_fused_0 * T.int64(32) + ax0_ax1_fused_1)
                        v_k2, v_k3, v_k4 = T.axis.remap("RRR", [k2, k3, k4])
                        T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                        T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                        with T.init():
                            A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                            A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                        v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                        v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                        A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                        A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(10), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape_1"):
                    v_ax0 = T.axis.spatial(T.int64(32), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) // T.int64(80))
                    v_ax1 = T.axis.spatial(T.int64(80), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) % T.int64(80))
                    T.reads(unet_up_blocks_0_resnets_0_norm1_weight[(v_ax0 * T.int64(80) + v_ax1) % T.int64(2560)])
                    T.writes(T_reshape_1[v_ax0, v_ax1])
                    T_reshape_1[v_ax0, v_ax1] = unet_up_blocks_0_resnets_0_norm1_weight[(v_ax0 * T.int64(80) + v_ax1) % T.int64(2560)]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(10), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape_2"):
                    v_ax0 = T.axis.spatial(T.int64(32), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) // T.int64(80))
                    v_ax1 = T.axis.spatial(T.int64(80), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) % T.int64(80))
                    T.reads(unet_up_blocks_0_resnets_0_norm1_bias[(v_ax0 * T.int64(80) + v_ax1) % T.int64(2560)])
                    T.writes(T_reshape_2[v_ax0, v_ax1])
                    T_reshape_2[v_ax0, v_ax1] = unet_up_blocks_0_resnets_0_norm1_bias[(v_ax0 * T.int64(80) + v_ax1) % T.int64(2560)]
        for ax0_ax1_ax2_ax3_ax4_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_ax4_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_ax4_fused_0 in range(T.int64(10)):
                    with T.block("T_group_norm"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) // T.int64(20480))
                        v_ax2 = T.axis.spatial(T.int64(80), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(20480) // T.int64(256))
                        v_ax3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(256) // T.int64(16))
                        v_ax4 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(16))
                        T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                        T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(4.8828125000000003e-05)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(4.8828125000000003e-05) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(4.8828125000000003e-05) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(4.8828125000000003e-05)) + T.float32(1.0000000000000001e-05)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(10)):
                    with T.block("T_reshape_3"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(2560), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(256))
                        v_ax2 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256) // T.int64(16))
                        v_ax3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                        T.reads(T_group_norm[T.int64(0), ((v_ax3 // T.int64(16) + v_ax2) // T.int64(16) + v_ax1) % T.int64(2560) // T.int64(80), ((v_ax3 // T.int64(16) + v_ax2) // T.int64(16) + v_ax1) % T.int64(80), (v_ax3 // T.int64(16) + v_ax2) % T.int64(16), v_ax3 % T.int64(16)])
                        T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[T.int64(0), ((v_ax3 // T.int64(16) + v_ax2) // T.int64(16) + v_ax1) % T.int64(2560) // T.int64(80), ((v_ax3 // T.int64(16) + v_ax2) // T.int64(16) + v_ax1) % T.int64(80), (v_ax3 // T.int64(16) + v_ax2) % T.int64(16), v_ax3 % T.int64(16)]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(10)):
                    with T.block("compute"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(2560), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(256))
                        v_i2 = T.axis.spatial(T.int64(16), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(256) // T.int64(16))
                        v_i3 = T.axis.spatial(T.int64(16), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(16))
                        T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                        T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                        compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(10)):
                    with T.block("T_multiply"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(2560), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(256))
                        v_ax2 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256) // T.int64(16))
                        v_ax3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                        T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_group_norm8_silu7(lv3961: T.Buffer((T.int64(1), T.int64(1920), T.int64(16), T.int64(16)), "float32"), unet_up_blocks_0_resnets_2_norm1_weight: T.Buffer((T.int64(1920),), "float32"), unet_up_blocks_0_resnets_2_norm1_bias: T.Buffer((T.int64(1920),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(1), T.int64(1920), T.int64(16), T.int64(16)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(60), T.int64(16), T.int64(16)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(1), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(1), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(60)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(60)))
        T_group_norm = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(60), T.int64(16), T.int64(16)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(1920), T.int64(16), T.int64(16)))
        compute = T.alloc_buffer((T.int64(1), T.int64(1920), T.int64(16), T.int64(16)))
        for ax0_ax1_ax2_ax3_ax4_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_ax4_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_ax4_fused_0 in range(T.int64(8)):
                    with T.block("T_reshape"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) // T.int64(15360))
                        v_ax2 = T.axis.spatial(T.int64(60), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(15360) // T.int64(256))
                        v_ax3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(256) // T.int64(16))
                        v_ax4 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(16))
                        T.where((ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_1) * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2 < T.int64(491520))
                        T.reads(lv3961[T.int64(0), (v_ax1 * T.int64(60) + (v_ax4 // T.int64(16) + v_ax3) // T.int64(16) + v_ax2) % T.int64(1920), (v_ax4 // T.int64(16) + v_ax3) % T.int64(16), v_ax4 % T.int64(16)])
                        T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv3961[T.int64(0), (v_ax1 * T.int64(60) + (v_ax4 // T.int64(16) + v_ax3) // T.int64(16) + v_ax2) % T.int64(1920), (v_ax4 // T.int64(16) + v_ax3) % T.int64(16), v_ax4 % T.int64(16)]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for k2, k3, k4 in T.grid(T.int64(60), T.int64(16), T.int64(16)):
                    with T.block("A_red_temp"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), ax0_ax1_fused_0 * T.int64(32) + ax0_ax1_fused_1)
                        v_k2, v_k3, v_k4 = T.axis.remap("RRR", [k2, k3, k4])
                        T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                        T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                        with T.init():
                            A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                            A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                        v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                        v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                        A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                        A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(8), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape_1"):
                    v_ax0 = T.axis.spatial(T.int64(32), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) // T.int64(60))
                    v_ax1 = T.axis.spatial(T.int64(60), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) % T.int64(60))
                    T.where(ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1 < T.int64(1920))
                    T.reads(unet_up_blocks_0_resnets_2_norm1_weight[(v_ax0 * T.int64(60) + v_ax1) % T.int64(1920)])
                    T.writes(T_reshape_1[v_ax0, v_ax1])
                    T_reshape_1[v_ax0, v_ax1] = unet_up_blocks_0_resnets_2_norm1_weight[(v_ax0 * T.int64(60) + v_ax1) % T.int64(1920)]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(8), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape_2"):
                    v_ax0 = T.axis.spatial(T.int64(32), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) // T.int64(60))
                    v_ax1 = T.axis.spatial(T.int64(60), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) % T.int64(60))
                    T.where(ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1 < T.int64(1920))
                    T.reads(unet_up_blocks_0_resnets_2_norm1_bias[(v_ax0 * T.int64(60) + v_ax1) % T.int64(1920)])
                    T.writes(T_reshape_2[v_ax0, v_ax1])
                    T_reshape_2[v_ax0, v_ax1] = unet_up_blocks_0_resnets_2_norm1_bias[(v_ax0 * T.int64(60) + v_ax1) % T.int64(1920)]
        for ax0_ax1_ax2_ax3_ax4_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_ax4_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_ax4_fused_0 in range(T.int64(8)):
                    with T.block("T_group_norm"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) // T.int64(15360))
                        v_ax2 = T.axis.spatial(T.int64(60), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(15360) // T.int64(256))
                        v_ax3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(256) // T.int64(16))
                        v_ax4 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(16))
                        T.where((ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_1) * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2 < T.int64(491520))
                        T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                        T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(6.5104166666666666e-05)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(6.5104166666666666e-05) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(6.5104166666666666e-05) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(6.5104166666666666e-05)) + T.float32(1.0000000000000001e-05)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(8)):
                    with T.block("T_reshape_3"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1920), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(256))
                        v_ax2 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256) // T.int64(16))
                        v_ax3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) * T.int64(256) + ax0_ax1_ax2_ax3_fused_2 < T.int64(491520))
                        T.reads(T_group_norm[T.int64(0), ((v_ax3 // T.int64(16) + v_ax2) // T.int64(16) + v_ax1) % T.int64(1920) // T.int64(60), ((v_ax3 // T.int64(16) + v_ax2) // T.int64(16) + v_ax1) % T.int64(60), (v_ax3 // T.int64(16) + v_ax2) % T.int64(16), v_ax3 % T.int64(16)])
                        T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[T.int64(0), ((v_ax3 // T.int64(16) + v_ax2) // T.int64(16) + v_ax1) % T.int64(1920) // T.int64(60), ((v_ax3 // T.int64(16) + v_ax2) // T.int64(16) + v_ax1) % T.int64(60), (v_ax3 // T.int64(16) + v_ax2) % T.int64(16), v_ax3 % T.int64(16)]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(8)):
                    with T.block("compute"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1920), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(256))
                        v_i2 = T.axis.spatial(T.int64(16), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(256) // T.int64(16))
                        v_i3 = T.axis.spatial(T.int64(16), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(16))
                        T.where((i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1) * T.int64(256) + i0_i1_i2_i3_fused_2 < T.int64(491520))
                        T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                        T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                        compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(8)):
                    with T.block("T_multiply"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1920), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(256))
                        v_ax2 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256) // T.int64(16))
                        v_ax3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) * T.int64(256) + ax0_ax1_ax2_ax3_fused_2 < T.int64(491520))
                        T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_group_norm9_silu8(lv4670: T.Buffer((T.int64(1), T.int64(1920), T.int64(32), T.int64(32)), "float32"), unet_up_blocks_1_resnets_0_norm1_weight: T.Buffer((T.int64(1920),), "float32"), unet_up_blocks_1_resnets_0_norm1_bias: T.Buffer((T.int64(1920),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(1), T.int64(1920), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(60), T.int64(32), T.int64(32)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(1), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(1), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(60)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(60)))
        T_group_norm = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(60), T.int64(32), T.int64(32)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(1920), T.int64(32), T.int64(32)))
        compute = T.alloc_buffer((T.int64(1), T.int64(1920), T.int64(32), T.int64(32)))
        for ax0_ax1_ax2_ax3_ax4_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_ax4_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_ax4_fused_0 in range(T.int64(30)):
                    with T.block("T_reshape"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) // T.int64(61440))
                        v_ax2 = T.axis.spatial(T.int64(60), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(61440) // T.int64(1024))
                        v_ax3 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(1024) // T.int64(32))
                        v_ax4 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(32))
                        T.reads(lv4670[T.int64(0), (v_ax1 * T.int64(60) + (v_ax4 // T.int64(32) + v_ax3) // T.int64(32) + v_ax2) % T.int64(1920), (v_ax4 // T.int64(32) + v_ax3) % T.int64(32), v_ax4 % T.int64(32)])
                        T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv4670[T.int64(0), (v_ax1 * T.int64(60) + (v_ax4 // T.int64(32) + v_ax3) // T.int64(32) + v_ax2) % T.int64(1920), (v_ax4 // T.int64(32) + v_ax3) % T.int64(32), v_ax4 % T.int64(32)]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for k2, k3, k4 in T.grid(T.int64(60), T.int64(32), T.int64(32)):
                    with T.block("A_red_temp"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), ax0_ax1_fused_0 * T.int64(32) + ax0_ax1_fused_1)
                        v_k2, v_k3, v_k4 = T.axis.remap("RRR", [k2, k3, k4])
                        T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                        T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                        with T.init():
                            A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                            A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                        v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                        v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                        A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                        A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(8), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape_1"):
                    v_ax0 = T.axis.spatial(T.int64(32), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) // T.int64(60))
                    v_ax1 = T.axis.spatial(T.int64(60), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) % T.int64(60))
                    T.where(ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1 < T.int64(1920))
                    T.reads(unet_up_blocks_1_resnets_0_norm1_weight[(v_ax0 * T.int64(60) + v_ax1) % T.int64(1920)])
                    T.writes(T_reshape_1[v_ax0, v_ax1])
                    T_reshape_1[v_ax0, v_ax1] = unet_up_blocks_1_resnets_0_norm1_weight[(v_ax0 * T.int64(60) + v_ax1) % T.int64(1920)]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(8), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape_2"):
                    v_ax0 = T.axis.spatial(T.int64(32), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) // T.int64(60))
                    v_ax1 = T.axis.spatial(T.int64(60), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) % T.int64(60))
                    T.where(ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1 < T.int64(1920))
                    T.reads(unet_up_blocks_1_resnets_0_norm1_bias[(v_ax0 * T.int64(60) + v_ax1) % T.int64(1920)])
                    T.writes(T_reshape_2[v_ax0, v_ax1])
                    T_reshape_2[v_ax0, v_ax1] = unet_up_blocks_1_resnets_0_norm1_bias[(v_ax0 * T.int64(60) + v_ax1) % T.int64(1920)]
        for ax0_ax1_ax2_ax3_ax4_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_ax4_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_ax4_fused_0 in range(T.int64(30)):
                    with T.block("T_group_norm"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) // T.int64(61440))
                        v_ax2 = T.axis.spatial(T.int64(60), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(61440) // T.int64(1024))
                        v_ax3 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(1024) // T.int64(32))
                        v_ax4 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(32))
                        T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                        T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(1.6276041666666666e-05)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(1.6276041666666666e-05) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(1.6276041666666666e-05) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(1.6276041666666666e-05)) + T.float32(1.0000000000000001e-05)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(30)):
                    with T.block("T_reshape_3"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1920), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                        v_ax2 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(32))
                        v_ax3 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                        T.reads(T_group_norm[T.int64(0), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(1920) // T.int64(60), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(60), (v_ax3 // T.int64(32) + v_ax2) % T.int64(32), v_ax3 % T.int64(32)])
                        T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[T.int64(0), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(1920) // T.int64(60), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(60), (v_ax3 // T.int64(32) + v_ax2) % T.int64(32), v_ax3 % T.int64(32)]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(30)):
                    with T.block("compute"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1920), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(1024))
                        v_i2 = T.axis.spatial(T.int64(32), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(1024) // T.int64(32))
                        v_i3 = T.axis.spatial(T.int64(32), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(32))
                        T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                        T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                        compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(30)):
                    with T.block("T_multiply"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1920), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                        v_ax2 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(32))
                        v_ax3 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                        T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_group_norm_silu1(lv48: T.Buffer((T.int64(1), T.int64(320), T.int64(64), T.int64(64)), "float32"), unet_down_blocks_0_resnets_0_norm1_weight: T.Buffer((T.int64(320),), "float32"), unet_down_blocks_0_resnets_0_norm1_bias: T.Buffer((T.int64(320),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(1), T.int64(320), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(10), T.int64(64), T.int64(64)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(1), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(1), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(10)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(10)))
        T_group_norm = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(10), T.int64(64), T.int64(64)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(320), T.int64(64), T.int64(64)))
        compute = T.alloc_buffer((T.int64(1), T.int64(320), T.int64(64), T.int64(64)))
        for ax0_ax1_ax2_ax3_ax4_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_ax4_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_ax4_fused_0 in range(T.int64(20)):
                    with T.block("T_reshape"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) // T.int64(40960))
                        v_ax2 = T.axis.spatial(T.int64(10), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(40960) // T.int64(4096))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(4096) // T.int64(64))
                        v_ax4 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(64))
                        T.reads(lv48[T.int64(0), (v_ax1 * T.int64(10) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) % T.int64(320), (v_ax4 // T.int64(64) + v_ax3) % T.int64(64), v_ax4 % T.int64(64)])
                        T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv48[T.int64(0), (v_ax1 * T.int64(10) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) % T.int64(320), (v_ax4 // T.int64(64) + v_ax3) % T.int64(64), v_ax4 % T.int64(64)]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for k2, k3, k4 in T.grid(T.int64(10), T.int64(64), T.int64(64)):
                    with T.block("A_red_temp"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), ax0_ax1_fused_0 * T.int64(32) + ax0_ax1_fused_1)
                        v_k2, v_k3, v_k4 = T.axis.remap("RRR", [k2, k3, k4])
                        T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                        T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                        with T.init():
                            A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                            A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                        v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                        v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                        A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                        A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(2), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape_1"):
                    v_ax0 = T.axis.spatial(T.int64(32), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) // T.int64(10))
                    v_ax1 = T.axis.spatial(T.int64(10), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) % T.int64(10))
                    T.where(ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1 < T.int64(320))
                    T.reads(unet_down_blocks_0_resnets_0_norm1_weight[(v_ax0 * T.int64(10) + v_ax1) % T.int64(320)])
                    T.writes(T_reshape_1[v_ax0, v_ax1])
                    T_reshape_1[v_ax0, v_ax1] = unet_down_blocks_0_resnets_0_norm1_weight[(v_ax0 * T.int64(10) + v_ax1) % T.int64(320)]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(2), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape_2"):
                    v_ax0 = T.axis.spatial(T.int64(32), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) // T.int64(10))
                    v_ax1 = T.axis.spatial(T.int64(10), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) % T.int64(10))
                    T.where(ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1 < T.int64(320))
                    T.reads(unet_down_blocks_0_resnets_0_norm1_bias[(v_ax0 * T.int64(10) + v_ax1) % T.int64(320)])
                    T.writes(T_reshape_2[v_ax0, v_ax1])
                    T_reshape_2[v_ax0, v_ax1] = unet_down_blocks_0_resnets_0_norm1_bias[(v_ax0 * T.int64(10) + v_ax1) % T.int64(320)]
        for ax0_ax1_ax2_ax3_ax4_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_ax4_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_ax4_fused_0 in range(T.int64(20)):
                    with T.block("T_group_norm"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) // T.int64(40960))
                        v_ax2 = T.axis.spatial(T.int64(10), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(40960) // T.int64(4096))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(4096) // T.int64(64))
                        v_ax4 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(64))
                        T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                        T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(2.4414062500000001e-05)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(2.4414062500000001e-05) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(2.4414062500000001e-05) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(2.4414062500000001e-05)) + T.float32(1.0000000000000001e-05)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(20)):
                    with T.block("T_reshape_3"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(320), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(4096))
                        v_ax2 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(4096) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.reads(T_group_norm[T.int64(0), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(320) // T.int64(10), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(10), (v_ax3 // T.int64(64) + v_ax2) % T.int64(64), v_ax3 % T.int64(64)])
                        T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[T.int64(0), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(320) // T.int64(10), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(10), (v_ax3 // T.int64(64) + v_ax2) % T.int64(64), v_ax3 % T.int64(64)]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(20)):
                    with T.block("compute"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(320), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(4096))
                        v_i2 = T.axis.spatial(T.int64(64), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(4096) // T.int64(64))
                        v_i3 = T.axis.spatial(T.int64(64), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(64))
                        T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                        T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                        compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(20)):
                    with T.block("T_multiply"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(320), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(4096))
                        v_ax2 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(4096) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_matmul10_add16(lv114: T.Buffer((T.int64(1), T.int64(1024), T.int64(640)), "float32"), lv115: T.Buffer((T.int64(640), T.int64(640)), "float32"), unet_down_blocks_1_attentions_0_proj_in_bias: T.Buffer((T.int64(640),), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(1024), T.int64(640)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(1024), T.int64(640)))
        for i0_i1_i2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_fused_0, k in T.grid(T.int64(10), T.int64(640)):
                    with T.block("matmul"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1024), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) // T.int64(640))
                        v_i2 = T.axis.spatial(T.int64(640), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) % T.int64(640))
                        v_k = T.axis.reduce(T.int64(640), k)
                        T.reads(lv114[v_i0, v_i1, v_k], lv115[v_k, v_i2])
                        T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                        with T.init():
                            var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                        var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv114[v_i0, v_i1, v_k] * lv115[v_k, v_i2]
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(10)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1024), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(640))
                        v_ax2 = T.axis.spatial(T.int64(640), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(640))
                        T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], unet_down_blocks_1_attentions_0_proj_in_bias[v_ax2])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + unet_down_blocks_1_attentions_0_proj_in_bias[v_ax2]

    @T.prim_func(private=True)
    def fused_matmul10_add16_divide5_add17(lv139: T.Buffer((T.int64(1), T.int64(1024), T.int64(640)), "float32"), lv140: T.Buffer((T.int64(640), T.int64(640)), "float32"), unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_out_0_bias: T.Buffer((T.int64(640),), "float32"), lv117: T.Buffer((T.int64(1), T.int64(1024), T.int64(640)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(1024), T.int64(640)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(1024), T.int64(640)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(1024), T.int64(640)))
        var_T_divide_intermediate = T.alloc_buffer((T.int64(1), T.int64(1024), T.int64(640)))
        for i0_i1_i2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_fused_0, k in T.grid(T.int64(10), T.int64(640)):
                    with T.block("matmul"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1024), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) // T.int64(640))
                        v_i2 = T.axis.spatial(T.int64(640), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) % T.int64(640))
                        v_k = T.axis.reduce(T.int64(640), k)
                        T.reads(lv139[v_i0, v_i1, v_k], lv140[v_k, v_i2])
                        T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                        with T.init():
                            var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                        var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv139[v_i0, v_i1, v_k] * lv140[v_k, v_i2]
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(10)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1024), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(640))
                        v_ax2 = T.axis.spatial(T.int64(640), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(640))
                        T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_out_0_bias[v_ax2])
                        T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2])
                        var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_out_0_bias[v_ax2]
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(10)):
                    with T.block("T_divide"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1024), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(640))
                        v_ax2 = T.axis.spatial(T.int64(640), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(640))
                        T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2])
                        T.writes(var_T_divide_intermediate[v_ax0, v_ax1, v_ax2])
                        var_T_divide_intermediate[v_ax0, v_ax1, v_ax2] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2]
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(10)):
                    with T.block("T_add_1"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1024), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(640))
                        v_ax2 = T.axis.spatial(T.int64(640), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(640))
                        T.reads(var_T_divide_intermediate[v_ax0, v_ax1, v_ax2], lv117[v_ax0, v_ax1, v_ax2])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = var_T_divide_intermediate[v_ax0, v_ax1, v_ax2] + lv117[v_ax0, v_ax1, v_ax2]

    @T.prim_func(private=True)
    def fused_matmul11_multiply8(lv126: T.Buffer((T.int64(1), T.int64(10), T.int64(1024), T.int64(64)), "float32"), lv133: T.Buffer((T.int64(1), T.int64(10), T.int64(64), T.int64(1024)), "float32"), param_0: T.Buffer((), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(1), T.int64(10), T.int64(1024), T.int64(1024)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(10), T.int64(1024), T.int64(1024)))
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0, k in T.grid(T.int64(160), T.int64(64)):
                    with T.block("matmul"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(10), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(1048576))
                        v_i2 = T.axis.spatial(T.int64(1024), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(1048576) // T.int64(1024))
                        v_i3 = T.axis.spatial(T.int64(1024), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(1024))
                        v_k = T.axis.reduce(T.int64(64), k)
                        T.reads(lv126[v_i0, v_i1, v_i2, v_k], lv133[v_i0, v_i1, v_k, v_i3])
                        T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3])
                        with T.init():
                            var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3] = T.float32(0)
                        var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3] = var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3] + lv126[v_i0, v_i1, v_i2, v_k] * lv133[v_i0, v_i1, v_k, v_i3]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(160)):
                    with T.block("T_multiply"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(10), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1048576))
                        v_ax2 = T.axis.spatial(T.int64(1024), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1048576) // T.int64(1024))
                        v_ax3 = T.axis.spatial(T.int64(1024), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024))
                        T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], param_0[()])
                        T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * param_0[()]

    @T.prim_func(private=True)
    def fused_matmul14_multiply9(lv153: T.Buffer((T.int64(1), T.int64(10), T.int64(1024), T.int64(64)), "float32"), lv160: T.Buffer((T.int64(1), T.int64(10), T.int64(64), T.int64(77)), "float32"), param_0: T.Buffer((), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(1), T.int64(10), T.int64(1024), T.int64(77)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(10), T.int64(1024), T.int64(77)))
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0, k in T.grid(T.int64(13), T.int64(64)):
                    with T.block("matmul"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(10), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(78848))
                        v_i2 = T.axis.spatial(T.int64(1024), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(78848) // T.int64(77))
                        v_i3 = T.axis.spatial(T.int64(77), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(77))
                        v_k = T.axis.reduce(T.int64(64), k)
                        T.where((i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1) * T.int64(256) + i0_i1_i2_i3_fused_2 < T.int64(788480))
                        T.reads(lv153[v_i0, v_i1, v_i2, v_k], lv160[v_i0, v_i1, v_k, v_i3])
                        T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3])
                        with T.init():
                            var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3] = T.float32(0)
                        var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3] = var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3] + lv153[v_i0, v_i1, v_i2, v_k] * lv160[v_i0, v_i1, v_k, v_i3]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(13)):
                    with T.block("T_multiply"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(10), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(78848))
                        v_ax2 = T.axis.spatial(T.int64(1024), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(78848) // T.int64(77))
                        v_ax3 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(77))
                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) * T.int64(256) + ax0_ax1_ax2_ax3_fused_2 < T.int64(788480))
                        T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], param_0[()])
                        T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * param_0[()]

    @T.prim_func(private=True)
    def fused_matmul16_add18(lv172: T.Buffer((T.int64(1), T.int64(1024), T.int64(640)), "float32"), lv173: T.Buffer((T.int64(640), T.int64(5120)), "float32"), unet_down_blocks_1_attentions_0_transformer_blocks_0_ff_net_0_proj_bias: T.Buffer((T.int64(5120),), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(1024), T.int64(5120)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(1024), T.int64(5120)))
        for i0_i1_i2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_fused_0, k in T.grid(T.int64(80), T.int64(640)):
                    with T.block("matmul"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1024), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) // T.int64(5120))
                        v_i2 = T.axis.spatial(T.int64(5120), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) % T.int64(5120))
                        v_k = T.axis.reduce(T.int64(640), k)
                        T.reads(lv172[v_i0, v_i1, v_k], lv173[v_k, v_i2])
                        T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                        with T.init():
                            var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                        var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv172[v_i0, v_i1, v_k] * lv173[v_k, v_i2]
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(80)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1024), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(5120))
                        v_ax2 = T.axis.spatial(T.int64(5120), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(5120))
                        T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], unet_down_blocks_1_attentions_0_transformer_blocks_0_ff_net_0_proj_bias[v_ax2])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + unet_down_blocks_1_attentions_0_transformer_blocks_0_ff_net_0_proj_bias[v_ax2]

    @T.prim_func(private=True)
    def fused_matmul17_add16_add17(lv180: T.Buffer((T.int64(1), T.int64(1024), T.int64(2560)), "float32"), lv181: T.Buffer((T.int64(2560), T.int64(640)), "float32"), unet_down_blocks_1_attentions_0_transformer_blocks_0_ff_net_2_bias: T.Buffer((T.int64(640),), "float32"), lv171: T.Buffer((T.int64(1), T.int64(1024), T.int64(640)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(1024), T.int64(640)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(1024), T.int64(640)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(1024), T.int64(640)))
        for i0_i1_i2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_fused_0, k in T.grid(T.int64(10), T.int64(2560)):
                    with T.block("matmul"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1024), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) // T.int64(640))
                        v_i2 = T.axis.spatial(T.int64(640), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) % T.int64(640))
                        v_k = T.axis.reduce(T.int64(2560), k)
                        T.reads(lv180[v_i0, v_i1, v_k], lv181[v_k, v_i2])
                        T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                        with T.init():
                            var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                        var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv180[v_i0, v_i1, v_k] * lv181[v_k, v_i2]
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(10)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1024), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(640))
                        v_ax2 = T.axis.spatial(T.int64(640), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(640))
                        T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], unet_down_blocks_1_attentions_0_transformer_blocks_0_ff_net_2_bias[v_ax2])
                        T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2])
                        var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + unet_down_blocks_1_attentions_0_transformer_blocks_0_ff_net_2_bias[v_ax2]
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(10)):
                    with T.block("T_add_1"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1024), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(640))
                        v_ax2 = T.axis.spatial(T.int64(640), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(640))
                        T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2], lv171[v_ax0, v_ax1, v_ax2])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2] + lv171[v_ax0, v_ax1, v_ax2]

    @T.prim_func(private=True)
    def fused_matmul18_add22(lv450: T.Buffer((T.int64(1), T.int64(256), T.int64(1280)), "float32"), lv451: T.Buffer((T.int64(1280), T.int64(1280)), "float32"), unet_down_blocks_2_attentions_0_proj_in_bias: T.Buffer((T.int64(1280),), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(256), T.int64(1280)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(1280)))
        for i0_i1_i2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_fused_0, k in T.grid(T.int64(5), T.int64(1280)):
                    with T.block("matmul"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(256), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) // T.int64(1280))
                        v_i2 = T.axis.spatial(T.int64(1280), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) % T.int64(1280))
                        v_k = T.axis.reduce(T.int64(1280), k)
                        T.reads(lv450[v_i0, v_i1, v_k], lv451[v_k, v_i2])
                        T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                        with T.init():
                            var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                        var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv450[v_i0, v_i1, v_k] * lv451[v_k, v_i2]
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(5)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(1280))
                        v_ax2 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(1280))
                        T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], unet_down_blocks_2_attentions_0_proj_in_bias[v_ax2])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + unet_down_blocks_2_attentions_0_proj_in_bias[v_ax2]

    @T.prim_func(private=True)
    def fused_matmul18_add22_divide7_add23(lv475: T.Buffer((T.int64(1), T.int64(256), T.int64(1280)), "float32"), lv476: T.Buffer((T.int64(1280), T.int64(1280)), "float32"), unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_out_0_bias: T.Buffer((T.int64(1280),), "float32"), lv453: T.Buffer((T.int64(1), T.int64(256), T.int64(1280)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(256), T.int64(1280)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(1280)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(1280)))
        var_T_divide_intermediate = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(1280)))
        for i0_i1_i2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_fused_0, k in T.grid(T.int64(5), T.int64(1280)):
                    with T.block("matmul"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(256), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) // T.int64(1280))
                        v_i2 = T.axis.spatial(T.int64(1280), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) % T.int64(1280))
                        v_k = T.axis.reduce(T.int64(1280), k)
                        T.reads(lv475[v_i0, v_i1, v_k], lv476[v_k, v_i2])
                        T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                        with T.init():
                            var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                        var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv475[v_i0, v_i1, v_k] * lv476[v_k, v_i2]
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(5)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(1280))
                        v_ax2 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(1280))
                        T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_out_0_bias[v_ax2])
                        T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2])
                        var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_out_0_bias[v_ax2]
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(5)):
                    with T.block("T_divide"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(1280))
                        v_ax2 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(1280))
                        T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2])
                        T.writes(var_T_divide_intermediate[v_ax0, v_ax1, v_ax2])
                        var_T_divide_intermediate[v_ax0, v_ax1, v_ax2] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2]
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(5)):
                    with T.block("T_add_1"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(1280))
                        v_ax2 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(1280))
                        T.reads(var_T_divide_intermediate[v_ax0, v_ax1, v_ax2], lv453[v_ax0, v_ax1, v_ax2])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = var_T_divide_intermediate[v_ax0, v_ax1, v_ax2] + lv453[v_ax0, v_ax1, v_ax2]

    @T.prim_func(private=True)
    def fused_matmul19_multiply11(lv462: T.Buffer((T.int64(1), T.int64(20), T.int64(256), T.int64(64)), "float32"), lv469: T.Buffer((T.int64(1), T.int64(20), T.int64(64), T.int64(256)), "float32"), param_0: T.Buffer((), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(1), T.int64(20), T.int64(256), T.int64(256)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(20), T.int64(256), T.int64(256)))
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0, k in T.grid(T.int64(20), T.int64(64)):
                    with T.block("matmul"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(20), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(65536))
                        v_i2 = T.axis.spatial(T.int64(256), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(65536) // T.int64(256))
                        v_i3 = T.axis.spatial(T.int64(256), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(256))
                        v_k = T.axis.reduce(T.int64(64), k)
                        T.reads(lv462[v_i0, v_i1, v_i2, v_k], lv469[v_i0, v_i1, v_k, v_i3])
                        T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3])
                        with T.init():
                            var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3] = T.float32(0)
                        var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3] = var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3] + lv462[v_i0, v_i1, v_i2, v_k] * lv469[v_i0, v_i1, v_k, v_i3]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(20)):
                    with T.block("T_multiply"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(20), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(65536))
                        v_ax2 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(65536) // T.int64(256))
                        v_ax3 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256))
                        T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], param_0[()])
                        T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * param_0[()]

    @T.prim_func(private=True)
    def fused_matmul22_multiply12(lv489: T.Buffer((T.int64(1), T.int64(20), T.int64(256), T.int64(64)), "float32"), lv496: T.Buffer((T.int64(1), T.int64(20), T.int64(64), T.int64(77)), "float32"), param_0: T.Buffer((), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(1), T.int64(20), T.int64(256), T.int64(77)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(20), T.int64(256), T.int64(77)))
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0, k in T.grid(T.int64(7), T.int64(64)):
                    with T.block("matmul"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(20), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(19712))
                        v_i2 = T.axis.spatial(T.int64(256), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(19712) // T.int64(77))
                        v_i3 = T.axis.spatial(T.int64(77), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(77))
                        v_k = T.axis.reduce(T.int64(64), k)
                        T.where((i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1) * T.int64(256) + i0_i1_i2_i3_fused_2 < T.int64(394240))
                        T.reads(lv489[v_i0, v_i1, v_i2, v_k], lv496[v_i0, v_i1, v_k, v_i3])
                        T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3])
                        with T.init():
                            var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3] = T.float32(0)
                        var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3] = var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3] + lv489[v_i0, v_i1, v_i2, v_k] * lv496[v_i0, v_i1, v_k, v_i3]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(7)):
                    with T.block("T_multiply"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(20), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(19712))
                        v_ax2 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(19712) // T.int64(77))
                        v_ax3 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(77))
                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) * T.int64(256) + ax0_ax1_ax2_ax3_fused_2 < T.int64(394240))
                        T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], param_0[()])
                        T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * param_0[()]

    @T.prim_func(private=True)
    def fused_matmul24_add24(lv508: T.Buffer((T.int64(1), T.int64(256), T.int64(1280)), "float32"), lv509: T.Buffer((T.int64(1280), T.int64(10240)), "float32"), unet_down_blocks_2_attentions_0_transformer_blocks_0_ff_net_0_proj_bias: T.Buffer((T.int64(10240),), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(256), T.int64(10240)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(10240)))
        for i0_i1_i2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_fused_0, k in T.grid(T.int64(40), T.int64(1280)):
                    with T.block("matmul"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(256), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) // T.int64(10240))
                        v_i2 = T.axis.spatial(T.int64(10240), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) % T.int64(10240))
                        v_k = T.axis.reduce(T.int64(1280), k)
                        T.reads(lv508[v_i0, v_i1, v_k], lv509[v_k, v_i2])
                        T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                        with T.init():
                            var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                        var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv508[v_i0, v_i1, v_k] * lv509[v_k, v_i2]
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(40)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(10240))
                        v_ax2 = T.axis.spatial(T.int64(10240), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(10240))
                        T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], unet_down_blocks_2_attentions_0_transformer_blocks_0_ff_net_0_proj_bias[v_ax2])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + unet_down_blocks_2_attentions_0_transformer_blocks_0_ff_net_0_proj_bias[v_ax2]

    @T.prim_func(private=True)
    def fused_matmul25_add22_add23(lv516: T.Buffer((T.int64(1), T.int64(256), T.int64(5120)), "float32"), lv517: T.Buffer((T.int64(5120), T.int64(1280)), "float32"), unet_down_blocks_2_attentions_0_transformer_blocks_0_ff_net_2_bias: T.Buffer((T.int64(1280),), "float32"), lv507: T.Buffer((T.int64(1), T.int64(256), T.int64(1280)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(256), T.int64(1280)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(1280)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(1280)))
        for i0_i1_i2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_fused_0, k in T.grid(T.int64(5), T.int64(5120)):
                    with T.block("matmul"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(256), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) // T.int64(1280))
                        v_i2 = T.axis.spatial(T.int64(1280), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) % T.int64(1280))
                        v_k = T.axis.reduce(T.int64(5120), k)
                        T.reads(lv516[v_i0, v_i1, v_k], lv517[v_k, v_i2])
                        T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                        with T.init():
                            var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                        var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv516[v_i0, v_i1, v_k] * lv517[v_k, v_i2]
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(5)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(1280))
                        v_ax2 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(1280))
                        T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], unet_down_blocks_2_attentions_0_transformer_blocks_0_ff_net_2_bias[v_ax2])
                        T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2])
                        var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + unet_down_blocks_2_attentions_0_transformer_blocks_0_ff_net_2_bias[v_ax2]
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(5)):
                    with T.block("T_add_1"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(1280))
                        v_ax2 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(1280))
                        T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2], lv507[v_ax0, v_ax1, v_ax2])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2] + lv507[v_ax0, v_ax1, v_ax2]

    @T.prim_func(private=True)
    def fused_matmul26_add30(lv23: T.Buffer((T.int64(1), T.int64(4096), T.int64(512)), "float32"), lv24: T.Buffer((T.int64(512), T.int64(512)), "float32"), vae_decoder_mid_block_attentions_0_to_q_bias: T.Buffer((T.int64(512),), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(4096), T.int64(512)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(4096), T.int64(512)))
        for i0_i1_i2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_fused_0, k in T.grid(T.int64(32), T.int64(512)):
                    with T.block("matmul"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(4096), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) // T.int64(512))
                        v_i2 = T.axis.spatial(T.int64(512), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) % T.int64(512))
                        v_k = T.axis.reduce(T.int64(512), k)
                        T.reads(lv23[v_i0, v_i1, v_k], lv24[v_k, v_i2])
                        T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                        with T.init():
                            var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                        var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv23[v_i0, v_i1, v_k] * lv24[v_k, v_i2]
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(32)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(4096), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(512))
                        v_ax2 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(512))
                        T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], vae_decoder_mid_block_attentions_0_to_q_bias[v_ax2])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + vae_decoder_mid_block_attentions_0_to_q_bias[v_ax2]

    @T.prim_func(private=True)
    def fused_matmul27_multiply15(lv34: T.Buffer((T.int64(1), T.int64(1), T.int64(4096), T.int64(512)), "float32"), lv41: T.Buffer((T.int64(1), T.int64(1), T.int64(512), T.int64(4096)), "float32"), param_0: T.Buffer((), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(1), T.int64(1), T.int64(4096), T.int64(4096)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(4096), T.int64(4096)))
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0, k in T.grid(T.int64(256), T.int64(512)):
                    with T.block("matmul"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i2 = T.axis.spatial(T.int64(4096), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(4096))
                        v_i3 = T.axis.spatial(T.int64(4096), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(4096))
                        v_k = T.axis.reduce(T.int64(512), k)
                        T.reads(lv34[v_i0, v_i1, v_i2, v_k], lv41[v_i0, v_i1, v_k, v_i3])
                        T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3])
                        with T.init():
                            var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3] = T.float32(0)
                        var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3] = var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3] + lv34[v_i0, v_i1, v_i2, v_k] * lv41[v_i0, v_i1, v_k, v_i3]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(256)):
                    with T.block("T_multiply"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax2 = T.axis.spatial(T.int64(4096), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(4096))
                        v_ax3 = T.axis.spatial(T.int64(4096), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(4096))
                        T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], param_0[()])
                        T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * param_0[()]

    @T.prim_func(private=True)
    def fused_matmul29_add42(lv21: T.Buffer((T.int64(1), T.int64(77), T.int64(768)), "float32"), lv26: T.Buffer((T.int64(768), T.int64(768)), "float32"), self_clip_text_model_encoder_layers_0_self_attn_k_proj_bias: T.Buffer((T.int64(768),), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(77), T.int64(768)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(768)))
        for i0_i1_i2_fused_0 in T.thread_binding(T.int64(231), thread="blockIdx.x"):
            for i0_i1_i2_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for k in range(T.int64(768)):
                    with T.block("matmul"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(77), (i0_i1_i2_fused_0 * T.int64(256) + i0_i1_i2_fused_1) // T.int64(768))
                        v_i2 = T.axis.spatial(T.int64(768), (i0_i1_i2_fused_0 * T.int64(256) + i0_i1_i2_fused_1) % T.int64(768))
                        v_k = T.axis.reduce(T.int64(768), k)
                        T.reads(lv21[v_i0, v_i1, v_k], lv26[v_k, v_i2])
                        T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                        with T.init():
                            var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                        var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv21[v_i0, v_i1, v_k] * lv26[v_k, v_i2]
        for ax0_ax1_ax2_fused_0 in T.thread_binding(T.int64(231), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_add"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) // T.int64(768))
                    v_ax2 = T.axis.spatial(T.int64(768), (ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) % T.int64(768))
                    T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], self_clip_text_model_encoder_layers_0_self_attn_k_proj_bias[v_ax2])
                    T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                    var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + self_clip_text_model_encoder_layers_0_self_attn_k_proj_bias[v_ax2]

    @T.prim_func(private=True)
    def fused_matmul29_add42_add41(lv50: T.Buffer((T.int64(1), T.int64(77), T.int64(768)), "float32"), lv51: T.Buffer((T.int64(768), T.int64(768)), "float32"), self_clip_text_model_encoder_layers_0_self_attn_out_proj_bias: T.Buffer((T.int64(768),), "float32"), lv9: T.Buffer((T.int64(1), T.int64(77), T.int64(768)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(77), T.int64(768)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(768)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(768)))
        for i0_i1_i2_fused_0 in T.thread_binding(T.int64(231), thread="blockIdx.x"):
            for i0_i1_i2_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for k in range(T.int64(768)):
                    with T.block("matmul"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(77), (i0_i1_i2_fused_0 * T.int64(256) + i0_i1_i2_fused_1) // T.int64(768))
                        v_i2 = T.axis.spatial(T.int64(768), (i0_i1_i2_fused_0 * T.int64(256) + i0_i1_i2_fused_1) % T.int64(768))
                        v_k = T.axis.reduce(T.int64(768), k)
                        T.reads(lv50[v_i0, v_i1, v_k], lv51[v_k, v_i2])
                        T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                        with T.init():
                            var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                        var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv50[v_i0, v_i1, v_k] * lv51[v_k, v_i2]
        for ax0_ax1_ax2_fused_0 in T.thread_binding(T.int64(231), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_add"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) // T.int64(768))
                    v_ax2 = T.axis.spatial(T.int64(768), (ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) % T.int64(768))
                    T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], self_clip_text_model_encoder_layers_0_self_attn_out_proj_bias[v_ax2])
                    T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2])
                    var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + self_clip_text_model_encoder_layers_0_self_attn_out_proj_bias[v_ax2]
        for ax0_ax1_ax2_fused_0 in T.thread_binding(T.int64(231), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_add_1"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) // T.int64(768))
                    v_ax2 = T.axis.spatial(T.int64(768), (ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) % T.int64(768))
                    T.reads(lv9[v_ax0, v_ax1, v_ax2], var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2])
                    T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                    var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = lv9[v_ax0, v_ax1, v_ax2] + var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2]

    @T.prim_func(private=True)
    def fused_matmul29_add42_multiply17(lv21: T.Buffer((T.int64(1), T.int64(77), T.int64(768)), "float32"), lv22: T.Buffer((T.int64(768), T.int64(768)), "float32"), self_clip_text_model_encoder_layers_0_self_attn_q_proj_bias: T.Buffer((T.int64(768),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(1), T.int64(77), T.int64(768)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(768)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(768)))
        for i0_i1_i2_fused_0 in T.thread_binding(T.int64(231), thread="blockIdx.x"):
            for i0_i1_i2_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for k in range(T.int64(768)):
                    with T.block("matmul"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(77), (i0_i1_i2_fused_0 * T.int64(256) + i0_i1_i2_fused_1) // T.int64(768))
                        v_i2 = T.axis.spatial(T.int64(768), (i0_i1_i2_fused_0 * T.int64(256) + i0_i1_i2_fused_1) % T.int64(768))
                        v_k = T.axis.reduce(T.int64(768), k)
                        T.reads(lv21[v_i0, v_i1, v_k], lv22[v_k, v_i2])
                        T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                        with T.init():
                            var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                        var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv21[v_i0, v_i1, v_k] * lv22[v_k, v_i2]
        for ax0_ax1_ax2_fused_0 in T.thread_binding(T.int64(231), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_add"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) // T.int64(768))
                    v_ax2 = T.axis.spatial(T.int64(768), (ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) % T.int64(768))
                    T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], self_clip_text_model_encoder_layers_0_self_attn_q_proj_bias[v_ax2])
                    T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                    var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + self_clip_text_model_encoder_layers_0_self_attn_q_proj_bias[v_ax2]
        for ax0_ax1_ax2_fused_0 in T.thread_binding(T.int64(231), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_multiply"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) // T.int64(768))
                    v_ax2 = T.axis.spatial(T.int64(768), (ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) % T.int64(768))
                    T.reads(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                    T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2])
                    var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2] = var_T_add_intermediate[v_ax0, v_ax1, v_ax2] * T.float32(0.125)

    @T.prim_func(private=True)
    def fused_matmul32_add44_multiply18_tir_sigmoid_multiply19(lv55: T.Buffer((T.int64(1), T.int64(77), T.int64(768)), "float32"), lv56: T.Buffer((T.int64(768), T.int64(3072)), "float32"), self_clip_text_model_encoder_layers_0_mlp_fc1_bias: T.Buffer((T.int64(3072),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(1), T.int64(77), T.int64(3072)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(3072)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(3072)))
        var_T_multiply_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(3072)))
        var_compute_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(3072)))
        for i0_i1_i2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_fused_0, k in T.grid(T.int64(4), T.int64(768)):
                    with T.block("matmul"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(77), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) // T.int64(3072))
                        v_i2 = T.axis.spatial(T.int64(3072), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) % T.int64(3072))
                        v_k = T.axis.reduce(T.int64(768), k)
                        T.where((i0_i1_i2_fused_0 * T.int64(256) + i0_i1_i2_fused_1) * T.int64(256) + i0_i1_i2_fused_2 < T.int64(236544))
                        T.reads(lv55[v_i0, v_i1, v_k], lv56[v_k, v_i2])
                        T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                        with T.init():
                            var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                        var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv55[v_i0, v_i1, v_k] * lv56[v_k, v_i2]
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(4)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(3072))
                        v_ax2 = T.axis.spatial(T.int64(3072), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(3072))
                        T.where((ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) * T.int64(256) + ax0_ax1_ax2_fused_2 < T.int64(236544))
                        T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], self_clip_text_model_encoder_layers_0_mlp_fc1_bias[v_ax2])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + self_clip_text_model_encoder_layers_0_mlp_fc1_bias[v_ax2]
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(4)):
                    with T.block("T_multiply"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(3072))
                        v_ax2 = T.axis.spatial(T.int64(3072), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(3072))
                        T.where((ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) * T.int64(256) + ax0_ax1_ax2_fused_2 < T.int64(236544))
                        T.reads(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                        T.writes(var_T_multiply_intermediate_1[v_ax0, v_ax1, v_ax2])
                        var_T_multiply_intermediate_1[v_ax0, v_ax1, v_ax2] = T.float32(1.7020000219345093) * var_T_add_intermediate[v_ax0, v_ax1, v_ax2]
        for i0_i1_i2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_fused_0 in range(T.int64(4)):
                    with T.block("compute"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(77), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) // T.int64(3072))
                        v_i2 = T.axis.spatial(T.int64(3072), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) % T.int64(3072))
                        T.where((i0_i1_i2_fused_0 * T.int64(256) + i0_i1_i2_fused_1) * T.int64(256) + i0_i1_i2_fused_2 < T.int64(236544))
                        T.reads(var_T_multiply_intermediate_1[v_i0, v_i1, v_i2])
                        T.writes(var_compute_intermediate[v_i0, v_i1, v_i2])
                        var_compute_intermediate[v_i0, v_i1, v_i2] = T.sigmoid(var_T_multiply_intermediate_1[v_i0, v_i1, v_i2])
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(4)):
                    with T.block("T_multiply_1"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(3072))
                        v_ax2 = T.axis.spatial(T.int64(3072), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(3072))
                        T.where((ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) * T.int64(256) + ax0_ax1_ax2_fused_2 < T.int64(236544))
                        T.reads(var_T_add_intermediate[v_ax0, v_ax1, v_ax2], var_compute_intermediate[v_ax0, v_ax1, v_ax2])
                        T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2])
                        var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2] = var_T_add_intermediate[v_ax0, v_ax1, v_ax2] * var_compute_intermediate[v_ax0, v_ax1, v_ax2]

    @T.prim_func(private=True)
    def fused_matmul33_add42_add41(lv61: T.Buffer((T.int64(1), T.int64(77), T.int64(3072)), "float32"), lv62: T.Buffer((T.int64(3072), T.int64(768)), "float32"), self_clip_text_model_encoder_layers_0_mlp_fc2_bias: T.Buffer((T.int64(768),), "float32"), lv54: T.Buffer((T.int64(1), T.int64(77), T.int64(768)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(77), T.int64(768)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(768)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(768)))
        for i0_i1_i2_fused_0 in T.thread_binding(T.int64(231), thread="blockIdx.x"):
            for i0_i1_i2_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for k in range(T.int64(3072)):
                    with T.block("matmul"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(77), (i0_i1_i2_fused_0 * T.int64(256) + i0_i1_i2_fused_1) // T.int64(768))
                        v_i2 = T.axis.spatial(T.int64(768), (i0_i1_i2_fused_0 * T.int64(256) + i0_i1_i2_fused_1) % T.int64(768))
                        v_k = T.axis.reduce(T.int64(3072), k)
                        T.reads(lv61[v_i0, v_i1, v_k], lv62[v_k, v_i2])
                        T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                        with T.init():
                            var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                        var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv61[v_i0, v_i1, v_k] * lv62[v_k, v_i2]
        for ax0_ax1_ax2_fused_0 in T.thread_binding(T.int64(231), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_add"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) // T.int64(768))
                    v_ax2 = T.axis.spatial(T.int64(768), (ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) % T.int64(768))
                    T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], self_clip_text_model_encoder_layers_0_mlp_fc2_bias[v_ax2])
                    T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2])
                    var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + self_clip_text_model_encoder_layers_0_mlp_fc2_bias[v_ax2]
        for ax0_ax1_ax2_fused_0 in T.thread_binding(T.int64(231), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_add_1"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) // T.int64(768))
                    v_ax2 = T.axis.spatial(T.int64(768), (ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) % T.int64(768))
                    T.reads(lv54[v_ax0, v_ax1, v_ax2], var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2])
                    T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                    var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = lv54[v_ax0, v_ax1, v_ax2] + var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2]

    @T.prim_func(private=True)
    def fused_matmul3_add6_gelu(lv57: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32"), lv58: T.Buffer((T.int64(1280), T.int64(5120)), "float32"), self_clip_text_model_encoder_layers_0_mlp_fc1_bias: T.Buffer((T.int64(5120),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(1), T.int64(77), T.int64(5120)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(5120)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(5120)))
        T_multiply = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(5120)))
        compute = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(5120)))
        T_multiply_1 = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(5120)))
        T_add = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(5120)))
        for i0_i1_i2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_fused_0, k in T.grid(T.int64(7), T.int64(1280)):
                    with T.block("matmul"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(77), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) // T.int64(5120))
                        v_i2 = T.axis.spatial(T.int64(5120), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) % T.int64(5120))
                        v_k = T.axis.reduce(T.int64(1280), k)
                        T.where((i0_i1_i2_fused_0 * T.int64(256) + i0_i1_i2_fused_1) * T.int64(256) + i0_i1_i2_fused_2 < T.int64(394240))
                        T.reads(lv57[v_i0, v_i1, v_k], lv58[v_k, v_i2])
                        T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                        with T.init():
                            var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                        var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv57[v_i0, v_i1, v_k] * lv58[v_k, v_i2]
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(7)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(5120))
                        v_ax2 = T.axis.spatial(T.int64(5120), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(5120))
                        T.where((ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) * T.int64(256) + ax0_ax1_ax2_fused_2 < T.int64(394240))
                        T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], self_clip_text_model_encoder_layers_0_mlp_fc1_bias[v_ax2])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + self_clip_text_model_encoder_layers_0_mlp_fc1_bias[v_ax2]
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(7)):
                    with T.block("T_multiply"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(5120))
                        v_ax2 = T.axis.spatial(T.int64(5120), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(5120))
                        T.where((ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) * T.int64(256) + ax0_ax1_ax2_fused_2 < T.int64(394240))
                        T.reads(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                        T.writes(T_multiply[v_ax0, v_ax1, v_ax2])
                        T_multiply[v_ax0, v_ax1, v_ax2] = var_T_add_intermediate[v_ax0, v_ax1, v_ax2] * T.float32(0.70710678118654757)
        for i0_i1_i2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_fused_0 in range(T.int64(7)):
                    with T.block("compute"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(77), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) // T.int64(5120))
                        v_i2 = T.axis.spatial(T.int64(5120), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) % T.int64(5120))
                        T.where((i0_i1_i2_fused_0 * T.int64(256) + i0_i1_i2_fused_1) * T.int64(256) + i0_i1_i2_fused_2 < T.int64(394240))
                        T.reads(T_multiply[v_i0, v_i1, v_i2])
                        T.writes(compute[v_i0, v_i1, v_i2])
                        compute[v_i0, v_i1, v_i2] = T.erf(T_multiply[v_i0, v_i1, v_i2])
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(7)):
                    with T.block("T_multiply_1"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(5120))
                        v_ax2 = T.axis.spatial(T.int64(5120), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(5120))
                        T.where((ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) * T.int64(256) + ax0_ax1_ax2_fused_2 < T.int64(394240))
                        T.reads(compute[v_ax0, v_ax1, v_ax2])
                        T.writes(T_multiply_1[v_ax0, v_ax1, v_ax2])
                        T_multiply_1[v_ax0, v_ax1, v_ax2] = compute[v_ax0, v_ax1, v_ax2] * T.float32(0.5)
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(7)):
                    with T.block("T_add_1"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(5120))
                        v_ax2 = T.axis.spatial(T.int64(5120), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(5120))
                        T.where((ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) * T.int64(256) + ax0_ax1_ax2_fused_2 < T.int64(394240))
                        T.reads(T_multiply_1[v_ax0, v_ax1, v_ax2])
                        T.writes(T_add[v_ax0, v_ax1, v_ax2])
                        T_add[v_ax0, v_ax1, v_ax2] = T.float32(0.5) + T_multiply_1[v_ax0, v_ax1, v_ax2]
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(7)):
                    with T.block("T_multiply_2"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(5120))
                        v_ax2 = T.axis.spatial(T.int64(5120), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(5120))
                        T.where((ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) * T.int64(256) + ax0_ax1_ax2_fused_2 < T.int64(394240))
                        T.reads(var_T_add_intermediate[v_ax0, v_ax1, v_ax2], T_add[v_ax0, v_ax1, v_ax2])
                        T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2])
                        var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2] = var_T_add_intermediate[v_ax0, v_ax1, v_ax2] * T_add[v_ax0, v_ax1, v_ax2]

    @T.prim_func(private=True)
    def fused_matmul4_add4_add2(lv61: T.Buffer((T.int64(1), T.int64(77), T.int64(5120)), "float32"), lv62: T.Buffer((T.int64(5120), T.int64(1280)), "float32"), self_clip_text_model_encoder_layers_0_mlp_fc2_bias: T.Buffer((T.int64(1280),), "float32"), lv56: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(1280)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(1280)))
        for i0_i1_i2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_fused_0, k in T.grid(T.int64(2), T.int64(5120)):
                    with T.block("matmul"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(77), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) // T.int64(1280))
                        v_i2 = T.axis.spatial(T.int64(1280), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) % T.int64(1280))
                        v_k = T.axis.reduce(T.int64(5120), k)
                        T.where((i0_i1_i2_fused_0 * T.int64(256) + i0_i1_i2_fused_1) * T.int64(256) + i0_i1_i2_fused_2 < T.int64(98560))
                        T.reads(lv61[v_i0, v_i1, v_k], lv62[v_k, v_i2])
                        T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                        with T.init():
                            var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                        var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv61[v_i0, v_i1, v_k] * lv62[v_k, v_i2]
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(2)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(1280))
                        v_ax2 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(1280))
                        T.where((ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) * T.int64(256) + ax0_ax1_ax2_fused_2 < T.int64(98560))
                        T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], self_clip_text_model_encoder_layers_0_mlp_fc2_bias[v_ax2])
                        T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2])
                        var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + self_clip_text_model_encoder_layers_0_mlp_fc2_bias[v_ax2]
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(2)):
                    with T.block("T_add_1"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(1280))
                        v_ax2 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(1280))
                        T.where((ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) * T.int64(256) + ax0_ax1_ax2_fused_2 < T.int64(98560))
                        T.reads(lv56[v_ax0, v_ax1, v_ax2], var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = lv56[v_ax0, v_ax1, v_ax2] + var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2]

    @T.prim_func(private=True)
    def fused_matmul5_add7(lv41: T.Buffer((T.int64(1), T.int64(1280)), "float32"), lv42: T.Buffer((T.int64(1280), T.int64(1280)), "float32"), unet_add_embedding_linear_2_bias: T.Buffer((T.int64(1280),), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(1280)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(1280)))
        for i0_i1_fused_0 in T.thread_binding(T.int64(5), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for k in range(T.int64(1280)):
                    with T.block("matmul"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1280), i0_i1_fused_0 * T.int64(256) + i0_i1_fused_1)
                        v_k = T.axis.reduce(T.int64(1280), k)
                        T.reads(lv41[v_i0, v_k], lv42[v_k, v_i1])
                        T.writes(var_matmul_intermediate[v_i0, v_i1])
                        with T.init():
                            var_matmul_intermediate[v_i0, v_i1] = T.float32(0)
                        var_matmul_intermediate[v_i0, v_i1] = var_matmul_intermediate[v_i0, v_i1] + lv41[v_i0, v_k] * lv42[v_k, v_i1]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(5), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_add"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(1280), ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1)
                    T.reads(var_matmul_intermediate[v_ax0, v_ax1], unet_add_embedding_linear_2_bias[v_ax1])
                    T.writes(var_T_add_intermediate[v_ax0, v_ax1])
                    var_T_add_intermediate[v_ax0, v_ax1] = var_matmul_intermediate[v_ax0, v_ax1] + unet_add_embedding_linear_2_bias[v_ax1]

    @T.prim_func(private=True)
    def fused_matmul5_add7_add8(lv18: T.Buffer((T.int64(1), T.int64(1280)), "float32"), lv19: T.Buffer((T.int64(1280), T.int64(1280)), "float32"), unet_time_embedding_linear_2_bias: T.Buffer((T.int64(1280),), "float32"), lv44: T.Buffer((T.int64(1), T.int64(1280)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(1280)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(1280)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(1280)))
        for i0_i1_fused_0 in T.thread_binding(T.int64(5), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for k in range(T.int64(1280)):
                    with T.block("matmul"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1280), i0_i1_fused_0 * T.int64(256) + i0_i1_fused_1)
                        v_k = T.axis.reduce(T.int64(1280), k)
                        T.reads(lv18[v_i0, v_k], lv19[v_k, v_i1])
                        T.writes(var_matmul_intermediate[v_i0, v_i1])
                        with T.init():
                            var_matmul_intermediate[v_i0, v_i1] = T.float32(0)
                        var_matmul_intermediate[v_i0, v_i1] = var_matmul_intermediate[v_i0, v_i1] + lv18[v_i0, v_k] * lv19[v_k, v_i1]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(5), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_add"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(1280), ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1)
                    T.reads(var_matmul_intermediate[v_ax0, v_ax1], unet_time_embedding_linear_2_bias[v_ax1])
                    T.writes(var_T_add_intermediate_1[v_ax0, v_ax1])
                    var_T_add_intermediate_1[v_ax0, v_ax1] = var_matmul_intermediate[v_ax0, v_ax1] + unet_time_embedding_linear_2_bias[v_ax1]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(5), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_add_1"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(1280), ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1)
                    T.reads(var_T_add_intermediate_1[v_ax0, v_ax1], lv44[v_ax0, v_ax1])
                    T.writes(var_T_add_intermediate[v_ax0, v_ax1])
                    var_T_add_intermediate[v_ax0, v_ax1] = var_T_add_intermediate_1[v_ax0, v_ax1] + lv44[v_ax0, v_ax1]

    @T.prim_func(private=True)
    def fused_matmul5_add7_strided_slice(lv431: T.Buffer((T.int64(1), T.int64(1280)), "float32"), lv432: T.Buffer((T.int64(1280), T.int64(1280)), "float32"), unet_down_blocks_2_resnets_0_time_emb_proj_bias: T.Buffer((T.int64(1280),), "float32"), var_T_strided_slice_with_axes_intermediate: T.Buffer((T.int64(1), T.int64(1280)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(1280)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(1280)))
        for i0_i1_fused_0 in T.thread_binding(T.int64(5), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for k in range(T.int64(1280)):
                    with T.block("matmul"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1280), i0_i1_fused_0 * T.int64(256) + i0_i1_fused_1)
                        v_k = T.axis.reduce(T.int64(1280), k)
                        T.reads(lv431[v_i0, v_k], lv432[v_k, v_i1])
                        T.writes(var_matmul_intermediate[v_i0, v_i1])
                        with T.init():
                            var_matmul_intermediate[v_i0, v_i1] = T.float32(0)
                        var_matmul_intermediate[v_i0, v_i1] = var_matmul_intermediate[v_i0, v_i1] + lv431[v_i0, v_k] * lv432[v_k, v_i1]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(5), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_add"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(1280), ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1)
                    T.reads(var_matmul_intermediate[v_ax0, v_ax1], unet_down_blocks_2_resnets_0_time_emb_proj_bias[v_ax1])
                    T.writes(var_T_add_intermediate[v_ax0, v_ax1])
                    var_T_add_intermediate[v_ax0, v_ax1] = var_matmul_intermediate[v_ax0, v_ax1] + unet_down_blocks_2_resnets_0_time_emb_proj_bias[v_ax1]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(5), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_strided_slice_with_axes"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(1280), ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1)
                    T.reads(var_T_add_intermediate[v_ax0, v_ax1])
                    T.writes(var_T_strided_slice_with_axes_intermediate[v_ax0, v_ax1])
                    var_T_strided_slice_with_axes_intermediate[v_ax0, v_ax1] = var_T_add_intermediate[v_ax0, v_ax1]

    @T.prim_func(private=True)
    def fused_matmul6_add7_silu(lv14: T.Buffer((T.int64(1), T.int64(320)), "float32"), lv15: T.Buffer((T.int64(320), T.int64(1280)), "float32"), unet_time_embedding_linear_1_bias: T.Buffer((T.int64(1280),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(1), T.int64(1280)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(1280)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(1280)))
        compute = T.alloc_buffer((T.int64(1), T.int64(1280)))
        for i0_i1_fused_0 in T.thread_binding(T.int64(5), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for k in range(T.int64(320)):
                    with T.block("matmul"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1280), i0_i1_fused_0 * T.int64(256) + i0_i1_fused_1)
                        v_k = T.axis.reduce(T.int64(320), k)
                        T.reads(lv14[v_i0, v_k], lv15[v_k, v_i1])
                        T.writes(var_matmul_intermediate[v_i0, v_i1])
                        with T.init():
                            var_matmul_intermediate[v_i0, v_i1] = T.float32(0)
                        var_matmul_intermediate[v_i0, v_i1] = var_matmul_intermediate[v_i0, v_i1] + lv14[v_i0, v_k] * lv15[v_k, v_i1]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(5), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_add"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(1280), ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1)
                    T.reads(var_matmul_intermediate[v_ax0, v_ax1], unet_time_embedding_linear_1_bias[v_ax1])
                    T.writes(var_T_add_intermediate[v_ax0, v_ax1])
                    var_T_add_intermediate[v_ax0, v_ax1] = var_matmul_intermediate[v_ax0, v_ax1] + unet_time_embedding_linear_1_bias[v_ax1]
        for i0_i1_fused_0 in T.thread_binding(T.int64(5), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("compute"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(1280), i0_i1_fused_0 * T.int64(256) + i0_i1_fused_1)
                    T.reads(var_T_add_intermediate[v_i0, v_i1])
                    T.writes(compute[v_i0, v_i1])
                    compute[v_i0, v_i1] = T.sigmoid(var_T_add_intermediate[v_i0, v_i1])
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(5), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_multiply"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(1280), ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1)
                    T.reads(var_T_add_intermediate[v_ax0, v_ax1], compute[v_ax0, v_ax1])
                    T.writes(var_T_multiply_intermediate[v_ax0, v_ax1])
                    var_T_multiply_intermediate[v_ax0, v_ax1] = var_T_add_intermediate[v_ax0, v_ax1] * compute[v_ax0, v_ax1]

    @T.prim_func(private=True)
    def fused_matmul7_add7_silu(lv37: T.Buffer((T.int64(1), T.int64(2816)), "float32"), lv38: T.Buffer((T.int64(2816), T.int64(1280)), "float32"), unet_add_embedding_linear_1_bias: T.Buffer((T.int64(1280),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(1), T.int64(1280)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(1280)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(1280)))
        compute = T.alloc_buffer((T.int64(1), T.int64(1280)))
        for i0_i1_fused_0 in T.thread_binding(T.int64(5), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for k in range(T.int64(2816)):
                    with T.block("matmul"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1280), i0_i1_fused_0 * T.int64(256) + i0_i1_fused_1)
                        v_k = T.axis.reduce(T.int64(2816), k)
                        T.reads(lv37[v_i0, v_k], lv38[v_k, v_i1])
                        T.writes(var_matmul_intermediate[v_i0, v_i1])
                        with T.init():
                            var_matmul_intermediate[v_i0, v_i1] = T.float32(0)
                        var_matmul_intermediate[v_i0, v_i1] = var_matmul_intermediate[v_i0, v_i1] + lv37[v_i0, v_k] * lv38[v_k, v_i1]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(5), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_add"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(1280), ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1)
                    T.reads(var_matmul_intermediate[v_ax0, v_ax1], unet_add_embedding_linear_1_bias[v_ax1])
                    T.writes(var_T_add_intermediate[v_ax0, v_ax1])
                    var_T_add_intermediate[v_ax0, v_ax1] = var_matmul_intermediate[v_ax0, v_ax1] + unet_add_embedding_linear_1_bias[v_ax1]
        for i0_i1_fused_0 in T.thread_binding(T.int64(5), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("compute"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(1280), i0_i1_fused_0 * T.int64(256) + i0_i1_fused_1)
                    T.reads(var_T_add_intermediate[v_i0, v_i1])
                    T.writes(compute[v_i0, v_i1])
                    compute[v_i0, v_i1] = T.sigmoid(var_T_add_intermediate[v_i0, v_i1])
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(5), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_multiply"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(1280), ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1)
                    T.reads(var_T_add_intermediate[v_ax0, v_ax1], compute[v_ax0, v_ax1])
                    T.writes(var_T_multiply_intermediate[v_ax0, v_ax1])
                    var_T_multiply_intermediate[v_ax0, v_ax1] = var_T_add_intermediate[v_ax0, v_ax1] * compute[v_ax0, v_ax1]

    @T.prim_func(private=True)
    def fused_matmul8_add10_cast4(lv54: T.Buffer((T.int64(1), T.int64(1280)), "float32"), lv55: T.Buffer((T.int64(1280), T.int64(320)), "float32"), unet_down_blocks_0_resnets_0_time_emb_proj_bias: T.Buffer((T.int64(320),), "float32"), var_compute_intermediate: T.Buffer((T.int64(1), T.int64(320)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(320)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(320)))
        for i0_i1_fused_0 in T.thread_binding(T.int64(2), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for k in range(T.int64(1280)):
                    with T.block("matmul"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(320), i0_i1_fused_0 * T.int64(256) + i0_i1_fused_1)
                        v_k = T.axis.reduce(T.int64(1280), k)
                        T.where(i0_i1_fused_0 * T.int64(256) + i0_i1_fused_1 < T.int64(320))
                        T.reads(lv54[v_i0, v_k], lv55[v_k, v_i1])
                        T.writes(var_matmul_intermediate[v_i0, v_i1])
                        with T.init():
                            var_matmul_intermediate[v_i0, v_i1] = T.float32(0)
                        var_matmul_intermediate[v_i0, v_i1] = var_matmul_intermediate[v_i0, v_i1] + lv54[v_i0, v_k] * lv55[v_k, v_i1]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(2), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_add"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(320), ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1)
                    T.where(ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1 < T.int64(320))
                    T.reads(var_matmul_intermediate[v_ax0, v_ax1], unet_down_blocks_0_resnets_0_time_emb_proj_bias[v_ax1])
                    T.writes(var_T_add_intermediate[v_ax0, v_ax1])
                    var_T_add_intermediate[v_ax0, v_ax1] = var_matmul_intermediate[v_ax0, v_ax1] + unet_down_blocks_0_resnets_0_time_emb_proj_bias[v_ax1]
        for i0_i1_fused_0 in T.thread_binding(T.int64(2), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("compute"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(320), i0_i1_fused_0 * T.int64(256) + i0_i1_fused_1)
                    T.where(i0_i1_fused_0 * T.int64(256) + i0_i1_fused_1 < T.int64(320))
                    T.reads(var_T_add_intermediate[v_i0, v_i1])
                    T.writes(var_compute_intermediate[v_i0, v_i1])
                    var_compute_intermediate[v_i0, v_i1] = var_T_add_intermediate[v_i0, v_i1]

    @T.prim_func(private=True)
    def fused_matmul9_add14_strided_slice7(lv95: T.Buffer((T.int64(1), T.int64(1280)), "float32"), lv96: T.Buffer((T.int64(1280), T.int64(640)), "float32"), unet_down_blocks_1_resnets_0_time_emb_proj_bias: T.Buffer((T.int64(640),), "float32"), var_T_strided_slice_with_axes_intermediate: T.Buffer((T.int64(1), T.int64(640)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(640)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(640)))
        for i0_i1_fused_0 in T.thread_binding(T.int64(3), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for k in range(T.int64(1280)):
                    with T.block("matmul"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(640), i0_i1_fused_0 * T.int64(256) + i0_i1_fused_1)
                        v_k = T.axis.reduce(T.int64(1280), k)
                        T.where(i0_i1_fused_0 * T.int64(256) + i0_i1_fused_1 < T.int64(640))
                        T.reads(lv95[v_i0, v_k], lv96[v_k, v_i1])
                        T.writes(var_matmul_intermediate[v_i0, v_i1])
                        with T.init():
                            var_matmul_intermediate[v_i0, v_i1] = T.float32(0)
                        var_matmul_intermediate[v_i0, v_i1] = var_matmul_intermediate[v_i0, v_i1] + lv95[v_i0, v_k] * lv96[v_k, v_i1]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(3), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_add"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(640), ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1)
                    T.where(ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1 < T.int64(640))
                    T.reads(var_matmul_intermediate[v_ax0, v_ax1], unet_down_blocks_1_resnets_0_time_emb_proj_bias[v_ax1])
                    T.writes(var_T_add_intermediate[v_ax0, v_ax1])
                    var_T_add_intermediate[v_ax0, v_ax1] = var_matmul_intermediate[v_ax0, v_ax1] + unet_down_blocks_1_resnets_0_time_emb_proj_bias[v_ax1]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(3), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_strided_slice_with_axes"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(640), ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1)
                    T.where(ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1 < T.int64(640))
                    T.reads(var_T_add_intermediate[v_ax0, v_ax1])
                    T.writes(var_T_strided_slice_with_axes_intermediate[v_ax0, v_ax1])
                    var_T_strided_slice_with_axes_intermediate[v_ax0, v_ax1] = var_T_add_intermediate[v_ax0, v_ax1]

    @T.prim_func(private=True)
    def fused_matmul_add4(lv21: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32"), lv26: T.Buffer((T.int64(1280), T.int64(1280)), "float32"), self_clip_text_model_encoder_layers_0_self_attn_k_proj_bias: T.Buffer((T.int64(1280),), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(1280)))
        for i0_i1_i2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_fused_0, k in T.grid(T.int64(2), T.int64(1280)):
                    with T.block("matmul"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(77), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) // T.int64(1280))
                        v_i2 = T.axis.spatial(T.int64(1280), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) % T.int64(1280))
                        v_k = T.axis.reduce(T.int64(1280), k)
                        T.where((i0_i1_i2_fused_0 * T.int64(256) + i0_i1_i2_fused_1) * T.int64(256) + i0_i1_i2_fused_2 < T.int64(98560))
                        T.reads(lv21[v_i0, v_i1, v_k], lv26[v_k, v_i2])
                        T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                        with T.init():
                            var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                        var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv21[v_i0, v_i1, v_k] * lv26[v_k, v_i2]
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(2)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(1280))
                        v_ax2 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(1280))
                        T.where((ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) * T.int64(256) + ax0_ax1_ax2_fused_2 < T.int64(98560))
                        T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], self_clip_text_model_encoder_layers_0_self_attn_k_proj_bias[v_ax2])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + self_clip_text_model_encoder_layers_0_self_attn_k_proj_bias[v_ax2]

    @T.prim_func(private=True)
    def fused_matmul_add4_add2(lv52: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32"), lv53: T.Buffer((T.int64(1280), T.int64(1280)), "float32"), self_clip_text_model_encoder_layers_0_self_attn_out_proj_bias: T.Buffer((T.int64(1280),), "float32"), lv9: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(1280)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(1280)))
        for i0_i1_i2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_fused_0, k in T.grid(T.int64(2), T.int64(1280)):
                    with T.block("matmul"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(77), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) // T.int64(1280))
                        v_i2 = T.axis.spatial(T.int64(1280), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) % T.int64(1280))
                        v_k = T.axis.reduce(T.int64(1280), k)
                        T.where((i0_i1_i2_fused_0 * T.int64(256) + i0_i1_i2_fused_1) * T.int64(256) + i0_i1_i2_fused_2 < T.int64(98560))
                        T.reads(lv52[v_i0, v_i1, v_k], lv53[v_k, v_i2])
                        T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                        with T.init():
                            var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                        var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv52[v_i0, v_i1, v_k] * lv53[v_k, v_i2]
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(2)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(1280))
                        v_ax2 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(1280))
                        T.where((ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) * T.int64(256) + ax0_ax1_ax2_fused_2 < T.int64(98560))
                        T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], self_clip_text_model_encoder_layers_0_self_attn_out_proj_bias[v_ax2])
                        T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2])
                        var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + self_clip_text_model_encoder_layers_0_self_attn_out_proj_bias[v_ax2]
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(2)):
                    with T.block("T_add_1"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(1280))
                        v_ax2 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(1280))
                        T.where((ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) * T.int64(256) + ax0_ax1_ax2_fused_2 < T.int64(98560))
                        T.reads(lv9[v_ax0, v_ax1, v_ax2], var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = lv9[v_ax0, v_ax1, v_ax2] + var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2]

    @T.prim_func(private=True)
    def fused_matmul_add4_multiply3(lv21: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32"), lv22: T.Buffer((T.int64(1280), T.int64(1280)), "float32"), self_clip_text_model_encoder_layers_0_self_attn_q_proj_bias: T.Buffer((T.int64(1280),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(1280)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(1280)))
        for i0_i1_i2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_fused_0, k in T.grid(T.int64(2), T.int64(1280)):
                    with T.block("matmul"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(77), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) // T.int64(1280))
                        v_i2 = T.axis.spatial(T.int64(1280), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) % T.int64(1280))
                        v_k = T.axis.reduce(T.int64(1280), k)
                        T.where((i0_i1_i2_fused_0 * T.int64(256) + i0_i1_i2_fused_1) * T.int64(256) + i0_i1_i2_fused_2 < T.int64(98560))
                        T.reads(lv21[v_i0, v_i1, v_k], lv22[v_k, v_i2])
                        T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                        with T.init():
                            var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                        var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv21[v_i0, v_i1, v_k] * lv22[v_k, v_i2]
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(2)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(1280))
                        v_ax2 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(1280))
                        T.where((ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) * T.int64(256) + ax0_ax1_ax2_fused_2 < T.int64(98560))
                        T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], self_clip_text_model_encoder_layers_0_self_attn_q_proj_bias[v_ax2])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + self_clip_text_model_encoder_layers_0_self_attn_q_proj_bias[v_ax2]
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(2)):
                    with T.block("T_multiply"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(1280))
                        v_ax2 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(1280))
                        T.where((ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) * T.int64(256) + ax0_ax1_ax2_fused_2 < T.int64(98560))
                        T.reads(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                        T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2])
                        var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2] = var_T_add_intermediate[v_ax0, v_ax1, v_ax2] * T.float32(0.125)

    @T.prim_func(private=True)
    def fused_reshape14_strided_slice4_reshape15_cast5_multiply6_multiply7_tir_sin1_tir_cos1_concatenate2_strided_slice5_reshape16_strided_slice6_reshape16_concatenate2_reshape17_concatenate3(inp_4: T.Buffer((T.int64(1), T.int64(6)), "float32"), param_0: T.Buffer((T.int64(1), T.int64(128)), "float32"), inp_3: T.Buffer((T.int64(1), T.int64(1280)), "float32"), var_T_concat_intermediate: T.Buffer((T.int64(1), T.int64(2816)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(6),))
        var_T_strided_slice_with_axes_intermediate = T.alloc_buffer((T.int64(6),))
        var_T_reshape_intermediate_1 = T.alloc_buffer((T.int64(6), T.int64(1)))
        var_compute_intermediate = T.alloc_buffer((T.int64(6), T.int64(1)))
        var_T_multiply_intermediate = T.alloc_buffer((T.int64(6), T.int64(128)))
        var_T_multiply_intermediate_1 = T.alloc_buffer((T.int64(6), T.int64(128)))
        var_compute_intermediate_1 = T.alloc_buffer((T.int64(6), T.int64(128)))
        var_compute_intermediate_2 = T.alloc_buffer((T.int64(6), T.int64(128)))
        var_T_concat_intermediate_1 = T.alloc_buffer((T.int64(6), T.int64(256)))
        var_T_strided_slice_with_axes_intermediate_1 = T.alloc_buffer((T.int64(6), T.int64(128)))
        var_T_reshape_intermediate_2 = T.alloc_buffer((T.int64(6), T.int64(128)))
        var_T_strided_slice_with_axes_intermediate_2 = T.alloc_buffer((T.int64(6), T.int64(128)))
        var_T_reshape_intermediate_3 = T.alloc_buffer((T.int64(6), T.int64(128)))
        var_T_concat_intermediate_2 = T.alloc_buffer((T.int64(6), T.int64(256)))
        var_T_reshape_intermediate_4 = T.alloc_buffer((T.int64(1), T.int64(1536)))
        for ax0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for ax0_fused_1 in T.thread_binding(T.int64(6), thread="threadIdx.x"):
                with T.block("T_reshape"):
                    v_ax0 = T.axis.spatial(T.int64(6), ax0_fused_0 * T.int64(6) + ax0_fused_1)
                    T.reads(inp_4[T.int64(0), v_ax0 % T.int64(6)])
                    T.writes(var_T_reshape_intermediate[v_ax0])
                    var_T_reshape_intermediate[v_ax0] = inp_4[T.int64(0), v_ax0 % T.int64(6)]
        for ax0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for ax0_fused_1 in T.thread_binding(T.int64(6), thread="threadIdx.x"):
                with T.block("T_strided_slice_with_axes"):
                    v_ax0 = T.axis.spatial(T.int64(6), ax0_fused_0 * T.int64(6) + ax0_fused_1)
                    T.reads(var_T_reshape_intermediate[v_ax0])
                    T.writes(var_T_strided_slice_with_axes_intermediate[v_ax0])
                    var_T_strided_slice_with_axes_intermediate[v_ax0] = var_T_reshape_intermediate[v_ax0]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(6), thread="threadIdx.x"):
                with T.block("T_reshape_1"):
                    v_ax0 = T.axis.spatial(T.int64(6), ax0_ax1_fused_0 * T.int64(6) + ax0_ax1_fused_1)
                    v_ax1 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads(var_T_strided_slice_with_axes_intermediate[(v_ax0 + v_ax1) % T.int64(6)])
                    T.writes(var_T_reshape_intermediate_1[v_ax0, v_ax1])
                    var_T_reshape_intermediate_1[v_ax0, v_ax1] = var_T_strided_slice_with_axes_intermediate[(v_ax0 + v_ax1) % T.int64(6)]
        for i0_i1_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(6), thread="threadIdx.x"):
                with T.block("compute"):
                    v_i0 = T.axis.spatial(T.int64(6), i0_i1_fused_0 * T.int64(6) + i0_i1_fused_1)
                    v_i1 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads(var_T_reshape_intermediate_1[v_i0, v_i1])
                    T.writes(var_compute_intermediate[v_i0, v_i1])
                    var_compute_intermediate[v_i0, v_i1] = var_T_reshape_intermediate_1[v_i0, v_i1]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(3), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_multiply"):
                    v_ax0 = T.axis.spatial(T.int64(6), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) // T.int64(128))
                    v_ax1 = T.axis.spatial(T.int64(128), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) % T.int64(128))
                    T.reads(var_compute_intermediate[v_ax0, T.int64(0)], param_0[T.int64(0), v_ax1])
                    T.writes(var_T_multiply_intermediate[v_ax0, v_ax1])
                    var_T_multiply_intermediate[v_ax0, v_ax1] = var_compute_intermediate[v_ax0, T.int64(0)] * param_0[T.int64(0), v_ax1]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(3), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_multiply_1"):
                    v_ax0 = T.axis.spatial(T.int64(6), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) // T.int64(128))
                    v_ax1 = T.axis.spatial(T.int64(128), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) % T.int64(128))
                    T.reads(var_T_multiply_intermediate[v_ax0, v_ax1])
                    T.writes(var_T_multiply_intermediate_1[v_ax0, v_ax1])
                    var_T_multiply_intermediate_1[v_ax0, v_ax1] = var_T_multiply_intermediate[v_ax0, v_ax1]
        for i0_i1_fused_0 in T.thread_binding(T.int64(3), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("compute_1"):
                    v_i0 = T.axis.spatial(T.int64(6), (i0_i1_fused_0 * T.int64(256) + i0_i1_fused_1) // T.int64(128))
                    v_i1 = T.axis.spatial(T.int64(128), (i0_i1_fused_0 * T.int64(256) + i0_i1_fused_1) % T.int64(128))
                    T.reads(var_T_multiply_intermediate_1[v_i0, v_i1])
                    T.writes(var_compute_intermediate_1[v_i0, v_i1])
                    var_compute_intermediate_1[v_i0, v_i1] = T.sin(var_T_multiply_intermediate_1[v_i0, v_i1])
        for i0_i1_fused_0 in T.thread_binding(T.int64(3), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("compute_2"):
                    v_i0 = T.axis.spatial(T.int64(6), (i0_i1_fused_0 * T.int64(256) + i0_i1_fused_1) // T.int64(128))
                    v_i1 = T.axis.spatial(T.int64(128), (i0_i1_fused_0 * T.int64(256) + i0_i1_fused_1) % T.int64(128))
                    T.reads(var_T_multiply_intermediate_1[v_i0, v_i1])
                    T.writes(var_compute_intermediate_2[v_i0, v_i1])
                    var_compute_intermediate_2[v_i0, v_i1] = T.cos(var_T_multiply_intermediate_1[v_i0, v_i1])
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(6), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_concat"):
                    v_ax0 = T.axis.spatial(T.int64(6), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) // T.int64(256))
                    v_ax1 = T.axis.spatial(T.int64(256), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) % T.int64(256))
                    T.reads(var_compute_intermediate_2[v_ax0, v_ax1 - T.int64(128)], var_compute_intermediate_1[v_ax0, v_ax1])
                    T.writes(var_T_concat_intermediate_1[v_ax0, v_ax1])
                    var_T_concat_intermediate_1[v_ax0, v_ax1] = T.if_then_else(T.int64(128) <= v_ax1, var_compute_intermediate_2[v_ax0, v_ax1 - T.int64(128)], var_compute_intermediate_1[v_ax0, v_ax1])
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(3), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_strided_slice_with_axes_1"):
                    v_ax0 = T.axis.spatial(T.int64(6), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) // T.int64(128))
                    v_ax1 = T.axis.spatial(T.int64(128), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) % T.int64(128))
                    T.reads(var_T_concat_intermediate_1[v_ax0, v_ax1 + T.int64(128)])
                    T.writes(var_T_strided_slice_with_axes_intermediate_1[v_ax0, v_ax1])
                    var_T_strided_slice_with_axes_intermediate_1[v_ax0, v_ax1] = var_T_concat_intermediate_1[v_ax0, v_ax1 + T.int64(128)]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(3), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape_2"):
                    v_ax0 = T.axis.spatial(T.int64(6), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) // T.int64(128))
                    v_ax1 = T.axis.spatial(T.int64(128), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) % T.int64(128))
                    T.reads(var_T_strided_slice_with_axes_intermediate_1[(v_ax1 // T.int64(128) + v_ax0) % T.int64(6), v_ax1 % T.int64(128)])
                    T.writes(var_T_reshape_intermediate_2[v_ax0, v_ax1])
                    var_T_reshape_intermediate_2[v_ax0, v_ax1] = var_T_strided_slice_with_axes_intermediate_1[(v_ax1 // T.int64(128) + v_ax0) % T.int64(6), v_ax1 % T.int64(128)]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(3), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_strided_slice_with_axes_2"):
                    v_ax0 = T.axis.spatial(T.int64(6), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) // T.int64(128))
                    v_ax1 = T.axis.spatial(T.int64(128), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) % T.int64(128))
                    T.reads(var_T_concat_intermediate_1[v_ax0, v_ax1])
                    T.writes(var_T_strided_slice_with_axes_intermediate_2[v_ax0, v_ax1])
                    var_T_strided_slice_with_axes_intermediate_2[v_ax0, v_ax1] = var_T_concat_intermediate_1[v_ax0, v_ax1]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(3), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape_3"):
                    v_ax0 = T.axis.spatial(T.int64(6), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) // T.int64(128))
                    v_ax1 = T.axis.spatial(T.int64(128), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) % T.int64(128))
                    T.reads(var_T_strided_slice_with_axes_intermediate_2[(v_ax1 // T.int64(128) + v_ax0) % T.int64(6), v_ax1 % T.int64(128)])
                    T.writes(var_T_reshape_intermediate_3[v_ax0, v_ax1])
                    var_T_reshape_intermediate_3[v_ax0, v_ax1] = var_T_strided_slice_with_axes_intermediate_2[(v_ax1 // T.int64(128) + v_ax0) % T.int64(6), v_ax1 % T.int64(128)]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(6), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_concat_1"):
                    v_ax0 = T.axis.spatial(T.int64(6), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) // T.int64(256))
                    v_ax1 = T.axis.spatial(T.int64(256), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) % T.int64(256))
                    T.reads(var_T_reshape_intermediate_3[v_ax0, v_ax1 - T.int64(128)], var_T_reshape_intermediate_2[v_ax0, v_ax1])
                    T.writes(var_T_concat_intermediate_2[v_ax0, v_ax1])
                    var_T_concat_intermediate_2[v_ax0, v_ax1] = T.if_then_else(T.int64(128) <= v_ax1, var_T_reshape_intermediate_3[v_ax0, v_ax1 - T.int64(128)], var_T_reshape_intermediate_2[v_ax0, v_ax1])
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(6), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape_4"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(1536), ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1)
                    T.reads(var_T_concat_intermediate_2[v_ax1 % T.int64(1536) // T.int64(256), v_ax1 % T.int64(256)])
                    T.writes(var_T_reshape_intermediate_4[v_ax0, v_ax1])
                    var_T_reshape_intermediate_4[v_ax0, v_ax1] = var_T_concat_intermediate_2[v_ax1 % T.int64(1536) // T.int64(256), v_ax1 % T.int64(256)]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(11), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_concat_2"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(2816), ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1)
                    T.reads(var_T_reshape_intermediate_4[v_ax0, v_ax1 - T.int64(1280)], inp_3[v_ax0, v_ax1])
                    T.writes(var_T_concat_intermediate[v_ax0, v_ax1])
                    var_T_concat_intermediate[v_ax0, v_ax1] = T.if_then_else(T.int64(1280) <= v_ax1, var_T_reshape_intermediate_4[v_ax0, v_ax1 - T.int64(1280)], inp_3[v_ax0, v_ax1])

    @T.prim_func(private=True)
    def fused_reshape23_transpose12(lv120: T.Buffer((T.int64(1), T.int64(1024), T.int64(640)), "float32"), var_T_transpose_intermediate: T.Buffer((T.int64(1), T.int64(10), T.int64(1024), T.int64(64)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(1024), T.int64(10), T.int64(64)))
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(10)):
                    with T.block("T_reshape"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1024), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(640))
                        v_ax2 = T.axis.spatial(T.int64(10), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(640) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.reads(lv120[T.int64(0), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(640) + v_ax1) % T.int64(1024), (v_ax2 * T.int64(64) + v_ax3) % T.int64(640)])
                        T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv120[T.int64(0), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(640) + v_ax1) % T.int64(1024), (v_ax2 * T.int64(64) + v_ax3) % T.int64(640)]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(10)):
                    with T.block("T_transpose"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(10), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(65536))
                        v_ax2 = T.axis.spatial(T.int64(1024), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(65536) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3])
                        T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3]

    @T.prim_func(private=True)
    def fused_reshape23_transpose12_transpose13(lv122: T.Buffer((T.int64(1), T.int64(1024), T.int64(640)), "float32"), var_T_transpose_intermediate: T.Buffer((T.int64(1), T.int64(10), T.int64(64), T.int64(1024)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(1024), T.int64(10), T.int64(64)))
        var_T_transpose_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(10), T.int64(1024), T.int64(64)))
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(10)):
                    with T.block("T_reshape"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1024), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(640))
                        v_ax2 = T.axis.spatial(T.int64(10), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(640) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.reads(lv122[T.int64(0), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(640) + v_ax1) % T.int64(1024), (v_ax2 * T.int64(64) + v_ax3) % T.int64(640)])
                        T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv122[T.int64(0), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(640) + v_ax1) % T.int64(1024), (v_ax2 * T.int64(64) + v_ax3) % T.int64(640)]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(10)):
                    with T.block("T_transpose"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(10), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(65536))
                        v_ax2 = T.axis.spatial(T.int64(1024), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(65536) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3])
                        T.writes(var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(10)):
                    with T.block("T_transpose_1"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(10), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(65536))
                        v_ax2 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(65536) // T.int64(1024))
                        v_ax3 = T.axis.spatial(T.int64(1024), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024))
                        T.reads(var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax3, v_ax2])
                        T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax3, v_ax2]

    @T.prim_func(private=True)
    def fused_reshape25_transpose16(lv151: T.Buffer((T.int64(1), T.int64(77), T.int64(640)), "float32"), var_T_transpose_intermediate: T.Buffer((T.int64(1), T.int64(10), T.int64(77), T.int64(64)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(10), T.int64(64)))
        for ax0_ax1_ax2_ax3_fused_0 in T.thread_binding(T.int64(193), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) // T.int64(640))
                    v_ax2 = T.axis.spatial(T.int64(10), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(640) // T.int64(64))
                    v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(64))
                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 < T.int64(49280))
                    T.reads(lv151[T.int64(0), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(640) + v_ax1) % T.int64(77), (v_ax2 * T.int64(64) + v_ax3) % T.int64(640)])
                    T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                    var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv151[T.int64(0), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(640) + v_ax1) % T.int64(77), (v_ax2 * T.int64(64) + v_ax3) % T.int64(640)]
        for ax0_ax1_ax2_ax3_fused_0 in T.thread_binding(T.int64(193), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_transpose"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(10), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) // T.int64(4928))
                    v_ax2 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(4928) // T.int64(64))
                    v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(64))
                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 < T.int64(49280))
                    T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3])
                    T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                    var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3]

    @T.prim_func(private=True)
    def fused_reshape25_transpose16_transpose17(lv149: T.Buffer((T.int64(1), T.int64(77), T.int64(640)), "float32"), var_T_transpose_intermediate: T.Buffer((T.int64(1), T.int64(10), T.int64(64), T.int64(77)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(10), T.int64(64)))
        var_T_transpose_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(10), T.int64(77), T.int64(64)))
        for ax0_ax1_ax2_ax3_fused_0 in T.thread_binding(T.int64(193), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) // T.int64(640))
                    v_ax2 = T.axis.spatial(T.int64(10), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(640) // T.int64(64))
                    v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(64))
                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 < T.int64(49280))
                    T.reads(lv149[T.int64(0), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(640) + v_ax1) % T.int64(77), (v_ax2 * T.int64(64) + v_ax3) % T.int64(640)])
                    T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                    var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv149[T.int64(0), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(640) + v_ax1) % T.int64(77), (v_ax2 * T.int64(64) + v_ax3) % T.int64(640)]
        for ax0_ax1_ax2_ax3_fused_0 in T.thread_binding(T.int64(193), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_transpose"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(10), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) // T.int64(4928))
                    v_ax2 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(4928) // T.int64(64))
                    v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(64))
                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 < T.int64(49280))
                    T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3])
                    T.writes(var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                    var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3]
        for ax0_ax1_ax2_ax3_fused_0 in T.thread_binding(T.int64(193), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_transpose_1"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(10), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) // T.int64(4928))
                    v_ax2 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(4928) // T.int64(77))
                    v_ax3 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(77))
                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 < T.int64(49280))
                    T.reads(var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax3, v_ax2])
                    T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                    var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax3, v_ax2]

    @T.prim_func(private=True)
    def fused_reshape26_transpose20_add15(lv254: T.Buffer((T.int64(1), T.int64(1024), T.int64(640)), "float32"), lv111: T.Buffer((T.int64(1), T.int64(640), T.int64(32), T.int64(32)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(640), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(32), T.int64(640)))
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(1), T.int64(640), T.int64(32), T.int64(32)))
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(10)):
                    with T.block("T_reshape"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(20480))
                        v_ax2 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(20480) // T.int64(640))
                        v_ax3 = T.axis.spatial(T.int64(640), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(640))
                        T.reads(lv254[T.int64(0), (v_ax1 * T.int64(32) + v_ax3 // T.int64(640) + v_ax2) % T.int64(1024), v_ax3 % T.int64(640)])
                        T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv254[T.int64(0), (v_ax1 * T.int64(32) + v_ax3 // T.int64(640) + v_ax2) % T.int64(1024), v_ax3 % T.int64(640)]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(10)):
                    with T.block("T_transpose"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(640), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                        v_ax2 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(32))
                        v_ax3 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                        T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax3, v_ax1])
                        T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax3, v_ax1]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(10)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(640), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                        v_ax2 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(32))
                        v_ax3 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                        T.reads(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv111[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv111[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_reshape26_transpose20_add15_concatenate7(lv4835: T.Buffer((T.int64(1), T.int64(1024), T.int64(640)), "float32"), lv4692: T.Buffer((T.int64(1), T.int64(640), T.int64(32), T.int64(32)), "float32"), lv257: T.Buffer((T.int64(1), T.int64(640), T.int64(32), T.int64(32)), "float32"), var_T_concat_intermediate: T.Buffer((T.int64(1), T.int64(1280), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(32), T.int64(640)))
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(1), T.int64(640), T.int64(32), T.int64(32)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(640), T.int64(32), T.int64(32)))
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(10)):
                    with T.block("T_reshape"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(20480))
                        v_ax2 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(20480) // T.int64(640))
                        v_ax3 = T.axis.spatial(T.int64(640), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(640))
                        T.reads(lv4835[T.int64(0), (v_ax1 * T.int64(32) + v_ax3 // T.int64(640) + v_ax2) % T.int64(1024), v_ax3 % T.int64(640)])
                        T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv4835[T.int64(0), (v_ax1 * T.int64(32) + v_ax3 // T.int64(640) + v_ax2) % T.int64(1024), v_ax3 % T.int64(640)]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(10)):
                    with T.block("T_transpose"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(640), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                        v_ax2 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(32))
                        v_ax3 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                        T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax3, v_ax1])
                        T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax3, v_ax1]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(10)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(640), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                        v_ax2 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(32))
                        v_ax3 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                        T.reads(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv4692[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv4692[v_ax0, v_ax1, v_ax2, v_ax3]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(20)):
                    with T.block("T_concat"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                        v_ax2 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(32))
                        v_ax3 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                        T.reads(lv257[v_ax0, v_ax1 - T.int64(640), v_ax2, v_ax3], var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(var_T_concat_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_concat_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T.if_then_else(T.int64(640) <= v_ax1, lv257[v_ax0, v_ax1 - T.int64(640), v_ax2, v_ax3], var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])

    @T.prim_func(private=True)
    def fused_reshape26_transpose20_add15_concatenate8(lv5004: T.Buffer((T.int64(1), T.int64(1024), T.int64(640)), "float32"), lv4861: T.Buffer((T.int64(1), T.int64(640), T.int64(32), T.int64(32)), "float32"), lv89: T.Buffer((T.int64(1), T.int64(320), T.int64(32), T.int64(32)), "float32"), var_T_concat_intermediate: T.Buffer((T.int64(1), T.int64(960), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(32), T.int64(640)))
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(1), T.int64(640), T.int64(32), T.int64(32)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(640), T.int64(32), T.int64(32)))
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(10)):
                    with T.block("T_reshape"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(20480))
                        v_ax2 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(20480) // T.int64(640))
                        v_ax3 = T.axis.spatial(T.int64(640), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(640))
                        T.reads(lv5004[T.int64(0), (v_ax1 * T.int64(32) + v_ax3 // T.int64(640) + v_ax2) % T.int64(1024), v_ax3 % T.int64(640)])
                        T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv5004[T.int64(0), (v_ax1 * T.int64(32) + v_ax3 // T.int64(640) + v_ax2) % T.int64(1024), v_ax3 % T.int64(640)]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(10)):
                    with T.block("T_transpose"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(640), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                        v_ax2 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(32))
                        v_ax3 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                        T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax3, v_ax1])
                        T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax3, v_ax1]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(10)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(640), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                        v_ax2 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(32))
                        v_ax3 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                        T.reads(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv4861[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv4861[v_ax0, v_ax1, v_ax2, v_ax3]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(15)):
                    with T.block("T_concat"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(960), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                        v_ax2 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(32))
                        v_ax3 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                        T.reads(lv89[v_ax0, v_ax1 - T.int64(640), v_ax2, v_ax3], var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(var_T_concat_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_concat_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T.if_then_else(T.int64(640) <= v_ax1, lv89[v_ax0, v_ax1 - T.int64(640), v_ax2, v_ax3], var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])

    @T.prim_func(private=True)
    def fused_reshape26_transpose20_add15_resize2d1(lv5173: T.Buffer((T.int64(1), T.int64(1024), T.int64(640)), "float32"), lv5030: T.Buffer((T.int64(1), T.int64(640), T.int64(32), T.int64(32)), "float32"), var_resize_intermediate: T.Buffer((T.int64(1), T.int64(640), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(32), T.int64(640)))
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(1), T.int64(640), T.int64(32), T.int64(32)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(640), T.int64(32), T.int64(32)))
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(10)):
                    with T.block("T_reshape"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(20480))
                        v_ax2 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(20480) // T.int64(640))
                        v_ax3 = T.axis.spatial(T.int64(640), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(640))
                        T.reads(lv5173[T.int64(0), (v_ax1 * T.int64(32) + v_ax3 // T.int64(640) + v_ax2) % T.int64(1024), v_ax3 % T.int64(640)])
                        T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv5173[T.int64(0), (v_ax1 * T.int64(32) + v_ax3 // T.int64(640) + v_ax2) % T.int64(1024), v_ax3 % T.int64(640)]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(10)):
                    with T.block("T_transpose"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(640), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                        v_ax2 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(32))
                        v_ax3 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                        T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax3, v_ax1])
                        T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax3, v_ax1]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(10)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(640), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                        v_ax2 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(32))
                        v_ax3 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                        T.reads(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv5030[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv5030[v_ax0, v_ax1, v_ax2, v_ax3]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(40)):
                    with T.block("resize"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(640), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(4096))
                        v_i2 = T.axis.spatial(T.int64(64), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(4096) // T.int64(64))
                        v_i3 = T.axis.spatial(T.int64(64), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(64))
                        T.reads(var_T_add_intermediate[v_i0, v_i1, T.max(T.min(T.Div(v_i2, T.int64(2)), T.int64(31)), T.int64(0)), T.max(T.min(T.Div(v_i3, T.int64(2)), T.int64(31)), T.int64(0))])
                        T.writes(var_resize_intermediate[v_i0, v_i1, v_i2, v_i3])
                        var_resize_intermediate[v_i0, v_i1, v_i2, v_i3] = var_T_add_intermediate[v_i0, v_i1, T.max(T.min(T.Div(v_i2, T.int64(2)), T.int64(31)), T.int64(0)), T.max(T.min(T.Div(v_i3, T.int64(2)), T.int64(31)), T.int64(0))]

    @T.prim_func(private=True)
    def fused_reshape2_reshape2_add2(lv3: T.Buffer((T.int64(77), T.int64(1280)), "float32"), lv7: T.Buffer((T.int64(77), T.int64(1280)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(1280)))
        var_T_reshape_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(1280)))
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(2)):
                    with T.block("T_reshape"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(1280))
                        v_ax2 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(1280))
                        T.where((ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) * T.int64(256) + ax0_ax1_ax2_fused_2 < T.int64(98560))
                        T.reads(lv3[(v_ax2 // T.int64(1280) + v_ax1) % T.int64(77), v_ax2 % T.int64(1280)])
                        T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2])
                        var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2] = lv3[(v_ax2 // T.int64(1280) + v_ax1) % T.int64(77), v_ax2 % T.int64(1280)]
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(2)):
                    with T.block("T_reshape_1"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(1280))
                        v_ax2 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(1280))
                        T.where((ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) * T.int64(256) + ax0_ax1_ax2_fused_2 < T.int64(98560))
                        T.reads(lv7[(v_ax2 // T.int64(1280) + v_ax1) % T.int64(77), v_ax2 % T.int64(1280)])
                        T.writes(var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2])
                        var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2] = lv7[(v_ax2 // T.int64(1280) + v_ax1) % T.int64(77), v_ax2 % T.int64(1280)]
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(2)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(1280))
                        v_ax2 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(1280))
                        T.where((ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) * T.int64(256) + ax0_ax1_ax2_fused_2 < T.int64(98560))
                        T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2], var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2] + var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2]

    @T.prim_func(private=True)
    def fused_reshape30_transpose22(lv456: T.Buffer((T.int64(1), T.int64(256), T.int64(1280)), "float32"), var_T_transpose_intermediate: T.Buffer((T.int64(1), T.int64(20), T.int64(256), T.int64(64)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(20), T.int64(64)))
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(5)):
                    with T.block("T_reshape"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1280))
                        v_ax2 = T.axis.spatial(T.int64(20), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1280) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.reads(lv456[T.int64(0), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(1280) + v_ax1) % T.int64(256), (v_ax2 * T.int64(64) + v_ax3) % T.int64(1280)])
                        T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv456[T.int64(0), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(1280) + v_ax1) % T.int64(256), (v_ax2 * T.int64(64) + v_ax3) % T.int64(1280)]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(5)):
                    with T.block("T_transpose"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(20), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(16384))
                        v_ax2 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16384) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3])
                        T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3]

    @T.prim_func(private=True)
    def fused_reshape30_transpose22_transpose23(lv458: T.Buffer((T.int64(1), T.int64(256), T.int64(1280)), "float32"), var_T_transpose_intermediate: T.Buffer((T.int64(1), T.int64(20), T.int64(64), T.int64(256)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(20), T.int64(64)))
        var_T_transpose_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(20), T.int64(256), T.int64(64)))
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(5)):
                    with T.block("T_reshape"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1280))
                        v_ax2 = T.axis.spatial(T.int64(20), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1280) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.reads(lv458[T.int64(0), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(1280) + v_ax1) % T.int64(256), (v_ax2 * T.int64(64) + v_ax3) % T.int64(1280)])
                        T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv458[T.int64(0), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(1280) + v_ax1) % T.int64(256), (v_ax2 * T.int64(64) + v_ax3) % T.int64(1280)]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(5)):
                    with T.block("T_transpose"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(20), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(16384))
                        v_ax2 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16384) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3])
                        T.writes(var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(5)):
                    with T.block("T_transpose_1"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(20), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(16384))
                        v_ax2 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16384) // T.int64(256))
                        v_ax3 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256))
                        T.reads(var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax3, v_ax2])
                        T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax3, v_ax2]

    @T.prim_func(private=True)
    def fused_reshape32_transpose28_add21(lv1126: T.Buffer((T.int64(1), T.int64(256), T.int64(1280)), "float32"), lv447: T.Buffer((T.int64(1), T.int64(1280), T.int64(16), T.int64(16)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(1280), T.int64(16), T.int64(16)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(16), T.int64(1280)))
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(1), T.int64(1280), T.int64(16), T.int64(16)))
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(5)):
                    with T.block("T_reshape"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(20480))
                        v_ax2 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(20480) // T.int64(1280))
                        v_ax3 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1280))
                        T.reads(lv1126[T.int64(0), (v_ax1 * T.int64(16) + v_ax3 // T.int64(1280) + v_ax2) % T.int64(256), v_ax3 % T.int64(1280)])
                        T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv1126[T.int64(0), (v_ax1 * T.int64(16) + v_ax3 // T.int64(1280) + v_ax2) % T.int64(256), v_ax3 % T.int64(1280)]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(5)):
                    with T.block("T_transpose"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(256))
                        v_ax2 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256) // T.int64(16))
                        v_ax3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                        T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax3, v_ax1])
                        T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax3, v_ax1]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(5)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(256))
                        v_ax2 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256) // T.int64(16))
                        v_ax3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                        T.reads(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv447[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv447[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_reshape32_transpose28_add21_concatenate4(lv3252: T.Buffer((T.int64(1), T.int64(256), T.int64(1280)), "float32"), lv2573: T.Buffer((T.int64(1), T.int64(1280), T.int64(16), T.int64(16)), "float32"), lv1129: T.Buffer((T.int64(1), T.int64(1280), T.int64(16), T.int64(16)), "float32"), var_T_concat_intermediate: T.Buffer((T.int64(1), T.int64(2560), T.int64(16), T.int64(16)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(16), T.int64(1280)))
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(1), T.int64(1280), T.int64(16), T.int64(16)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(1280), T.int64(16), T.int64(16)))
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(5)):
                    with T.block("T_reshape"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(20480))
                        v_ax2 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(20480) // T.int64(1280))
                        v_ax3 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1280))
                        T.reads(lv3252[T.int64(0), (v_ax1 * T.int64(16) + v_ax3 // T.int64(1280) + v_ax2) % T.int64(256), v_ax3 % T.int64(1280)])
                        T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv3252[T.int64(0), (v_ax1 * T.int64(16) + v_ax3 // T.int64(1280) + v_ax2) % T.int64(256), v_ax3 % T.int64(1280)]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(5)):
                    with T.block("T_transpose"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(256))
                        v_ax2 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256) // T.int64(16))
                        v_ax3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                        T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax3, v_ax1])
                        T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax3, v_ax1]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(5)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(256))
                        v_ax2 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256) // T.int64(16))
                        v_ax3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                        T.reads(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv2573[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv2573[v_ax0, v_ax1, v_ax2, v_ax3]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(10)):
                    with T.block("T_concat"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(2560), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(256))
                        v_ax2 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256) // T.int64(16))
                        v_ax3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                        T.reads(lv1129[v_ax0, v_ax1 - T.int64(1280), v_ax2, v_ax3], var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(var_T_concat_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_concat_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T.if_then_else(T.int64(1280) <= v_ax1, lv1129[v_ax0, v_ax1 - T.int64(1280), v_ax2, v_ax3], var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])

    @T.prim_func(private=True)
    def fused_reshape32_transpose28_add21_concatenate5(lv3957: T.Buffer((T.int64(1), T.int64(256), T.int64(1280)), "float32"), lv3278: T.Buffer((T.int64(1), T.int64(1280), T.int64(16), T.int64(16)), "float32"), lv425: T.Buffer((T.int64(1), T.int64(640), T.int64(16), T.int64(16)), "float32"), var_T_concat_intermediate: T.Buffer((T.int64(1), T.int64(1920), T.int64(16), T.int64(16)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(16), T.int64(1280)))
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(1), T.int64(1280), T.int64(16), T.int64(16)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(1280), T.int64(16), T.int64(16)))
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(5)):
                    with T.block("T_reshape"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(20480))
                        v_ax2 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(20480) // T.int64(1280))
                        v_ax3 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1280))
                        T.reads(lv3957[T.int64(0), (v_ax1 * T.int64(16) + v_ax3 // T.int64(1280) + v_ax2) % T.int64(256), v_ax3 % T.int64(1280)])
                        T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv3957[T.int64(0), (v_ax1 * T.int64(16) + v_ax3 // T.int64(1280) + v_ax2) % T.int64(256), v_ax3 % T.int64(1280)]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(5)):
                    with T.block("T_transpose"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(256))
                        v_ax2 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256) // T.int64(16))
                        v_ax3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                        T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax3, v_ax1])
                        T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax3, v_ax1]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(5)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(256))
                        v_ax2 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256) // T.int64(16))
                        v_ax3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                        T.reads(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv3278[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv3278[v_ax0, v_ax1, v_ax2, v_ax3]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(8)):
                    with T.block("T_concat"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1920), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(256))
                        v_ax2 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256) // T.int64(16))
                        v_ax3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) * T.int64(256) + ax0_ax1_ax2_ax3_fused_2 < T.int64(491520))
                        T.reads(lv425[v_ax0, v_ax1 - T.int64(1280), v_ax2, v_ax3], var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(var_T_concat_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_concat_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T.if_then_else(T.int64(1280) <= v_ax1, lv425[v_ax0, v_ax1 - T.int64(1280), v_ax2, v_ax3], var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])

    @T.prim_func(private=True)
    def fused_reshape32_transpose28_add21_resize2d(lv4662: T.Buffer((T.int64(1), T.int64(256), T.int64(1280)), "float32"), lv3983: T.Buffer((T.int64(1), T.int64(1280), T.int64(16), T.int64(16)), "float32"), var_resize_intermediate: T.Buffer((T.int64(1), T.int64(1280), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(16), T.int64(1280)))
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(1), T.int64(1280), T.int64(16), T.int64(16)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(1280), T.int64(16), T.int64(16)))
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(5)):
                    with T.block("T_reshape"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(20480))
                        v_ax2 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(20480) // T.int64(1280))
                        v_ax3 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1280))
                        T.reads(lv4662[T.int64(0), (v_ax1 * T.int64(16) + v_ax3 // T.int64(1280) + v_ax2) % T.int64(256), v_ax3 % T.int64(1280)])
                        T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv4662[T.int64(0), (v_ax1 * T.int64(16) + v_ax3 // T.int64(1280) + v_ax2) % T.int64(256), v_ax3 % T.int64(1280)]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(5)):
                    with T.block("T_transpose"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(256))
                        v_ax2 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256) // T.int64(16))
                        v_ax3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                        T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax3, v_ax1])
                        T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax3, v_ax1]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(5)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(256))
                        v_ax2 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256) // T.int64(16))
                        v_ax3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                        T.reads(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv3983[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv3983[v_ax0, v_ax1, v_ax2, v_ax3]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(20)):
                    with T.block("resize"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1280), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(1024))
                        v_i2 = T.axis.spatial(T.int64(32), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(1024) // T.int64(32))
                        v_i3 = T.axis.spatial(T.int64(32), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(32))
                        T.reads(var_T_add_intermediate[v_i0, v_i1, T.max(T.min(T.Div(v_i2, T.int64(2)), T.int64(15)), T.int64(0)), T.max(T.min(T.Div(v_i3, T.int64(2)), T.int64(15)), T.int64(0))])
                        T.writes(var_resize_intermediate[v_i0, v_i1, v_i2, v_i3])
                        var_resize_intermediate[v_i0, v_i1, v_i2, v_i3] = var_T_add_intermediate[v_i0, v_i1, T.max(T.min(T.Div(v_i2, T.int64(2)), T.int64(15)), T.int64(0)), T.max(T.min(T.Div(v_i3, T.int64(2)), T.int64(15)), T.int64(0))]

    @T.prim_func(private=True)
    def fused_reshape35_transpose29_transpose30(lv18: T.Buffer((T.int64(1), T.int64(512), T.int64(64), T.int64(64)), "float32"), var_T_transpose_intermediate: T.Buffer((T.int64(1), T.int64(512), T.int64(4096)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(4096)))
        var_T_transpose_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(4096), T.int64(512)))
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(32)):
                    with T.block("T_reshape"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(4096))
                        v_ax2 = T.axis.spatial(T.int64(4096), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(4096))
                        T.reads(lv18[T.int64(0), (v_ax2 // T.int64(4096) + v_ax1) % T.int64(512), v_ax2 % T.int64(4096) // T.int64(64), v_ax2 % T.int64(64)])
                        T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2])
                        var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2] = lv18[T.int64(0), (v_ax2 // T.int64(4096) + v_ax1) % T.int64(512), v_ax2 % T.int64(4096) // T.int64(64), v_ax2 % T.int64(64)]
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(32)):
                    with T.block("T_transpose"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(4096), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(512))
                        v_ax2 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(512))
                        T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1])
                        T.writes(var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax2])
                        var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax2] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1]
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(32)):
                    with T.block("T_transpose_1"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(4096))
                        v_ax2 = T.axis.spatial(T.int64(4096), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(4096))
                        T.reads(var_T_transpose_intermediate_1[v_ax0, v_ax2, v_ax1])
                        T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2])
                        var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2] = var_T_transpose_intermediate_1[v_ax0, v_ax2, v_ax1]

    @T.prim_func(private=True)
    def fused_reshape36_transpose32(lv26: T.Buffer((T.int64(1), T.int64(4096), T.int64(512)), "float32"), var_T_transpose_intermediate: T.Buffer((T.int64(1), T.int64(1), T.int64(4096), T.int64(512)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(4096), T.int64(1), T.int64(512)))
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(32)):
                    with T.block("T_reshape"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(4096), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                        v_ax2 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax3 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512))
                        T.reads(lv26[T.int64(0), (v_ax3 // T.int64(512) + v_ax1 + v_ax2) % T.int64(4096), v_ax3 % T.int64(512)])
                        T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv26[T.int64(0), (v_ax3 // T.int64(512) + v_ax1 + v_ax2) % T.int64(4096), v_ax3 % T.int64(512)]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(32)):
                    with T.block("T_transpose"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax2 = T.axis.spatial(T.int64(4096), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                        v_ax3 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512))
                        T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3])
                        T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3]

    @T.prim_func(private=True)
    def fused_reshape36_transpose32_transpose33(lv29: T.Buffer((T.int64(1), T.int64(4096), T.int64(512)), "float32"), var_T_transpose_intermediate: T.Buffer((T.int64(1), T.int64(1), T.int64(512), T.int64(4096)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(4096), T.int64(1), T.int64(512)))
        var_T_transpose_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(4096), T.int64(512)))
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(32)):
                    with T.block("T_reshape"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(4096), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                        v_ax2 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax3 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512))
                        T.reads(lv29[T.int64(0), (v_ax3 // T.int64(512) + v_ax1 + v_ax2) % T.int64(4096), v_ax3 % T.int64(512)])
                        T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv29[T.int64(0), (v_ax3 // T.int64(512) + v_ax1 + v_ax2) % T.int64(4096), v_ax3 % T.int64(512)]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(32)):
                    with T.block("T_transpose"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax2 = T.axis.spatial(T.int64(4096), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                        v_ax3 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512))
                        T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3])
                        T.writes(var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(32)):
                    with T.block("T_transpose_1"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax2 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(4096))
                        v_ax3 = T.axis.spatial(T.int64(4096), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(4096))
                        T.reads(var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax3, v_ax2])
                        T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax3, v_ax2]

    @T.prim_func(private=True)
    def fused_reshape42_reshape42_add41(lv3: T.Buffer((T.int64(77), T.int64(768)), "float32"), lv7: T.Buffer((T.int64(77), T.int64(768)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(77), T.int64(768)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(768)))
        var_T_reshape_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(768)))
        for ax0_ax1_ax2_fused_0 in T.thread_binding(T.int64(231), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) // T.int64(768))
                    v_ax2 = T.axis.spatial(T.int64(768), (ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) % T.int64(768))
                    T.reads(lv3[(v_ax2 // T.int64(768) + v_ax1) % T.int64(77), v_ax2 % T.int64(768)])
                    T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2])
                    var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2] = lv3[(v_ax2 // T.int64(768) + v_ax1) % T.int64(77), v_ax2 % T.int64(768)]
        for ax0_ax1_ax2_fused_0 in T.thread_binding(T.int64(231), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape_1"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) // T.int64(768))
                    v_ax2 = T.axis.spatial(T.int64(768), (ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) % T.int64(768))
                    T.reads(lv7[(v_ax2 // T.int64(768) + v_ax1) % T.int64(77), v_ax2 % T.int64(768)])
                    T.writes(var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2])
                    var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2] = lv7[(v_ax2 // T.int64(768) + v_ax1) % T.int64(77), v_ax2 % T.int64(768)]
        for ax0_ax1_ax2_fused_0 in T.thread_binding(T.int64(231), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_add"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) // T.int64(768))
                    v_ax2 = T.axis.spatial(T.int64(768), (ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) % T.int64(768))
                    T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2], var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2])
                    T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                    var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2] + var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2]

    @T.prim_func(private=True)
    def fused_reshape43_transpose37_reshape44(lv33: T.Buffer((T.int64(1), T.int64(77), T.int64(768)), "float32"), var_T_reshape_intermediate: T.Buffer((T.int64(12), T.int64(77), T.int64(64)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(12), T.int64(64)))
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(1), T.int64(12), T.int64(77), T.int64(64)))
        for ax0_ax1_ax2_ax3_fused_0 in T.thread_binding(T.int64(231), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) // T.int64(768))
                    v_ax2 = T.axis.spatial(T.int64(12), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(768) // T.int64(64))
                    v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(64))
                    T.reads(lv33[T.int64(0), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(768) + v_ax1) % T.int64(77), (v_ax2 * T.int64(64) + v_ax3) % T.int64(768)])
                    T.writes(var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                    var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = lv33[T.int64(0), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(768) + v_ax1) % T.int64(77), (v_ax2 * T.int64(64) + v_ax3) % T.int64(768)]
        for ax0_ax1_ax2_ax3_fused_0 in T.thread_binding(T.int64(231), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_transpose"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(12), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) // T.int64(4928))
                    v_ax2 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(4928) // T.int64(64))
                    v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(64))
                    T.reads(var_T_reshape_intermediate_1[v_ax0, v_ax2, v_ax1, v_ax3])
                    T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                    var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate_1[v_ax0, v_ax2, v_ax1, v_ax3]
        for ax0_ax1_ax2_fused_0 in T.thread_binding(T.int64(231), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape_1"):
                    v_ax0 = T.axis.spatial(T.int64(12), (ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) // T.int64(4928))
                    v_ax1 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) % T.int64(4928) // T.int64(64))
                    v_ax2 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) % T.int64(64))
                    T.reads(var_T_transpose_intermediate[T.int64(0), ((v_ax2 // T.int64(64) + v_ax1) // T.int64(77) + v_ax0) % T.int64(12), (v_ax2 // T.int64(64) + v_ax1) % T.int64(77), v_ax2 % T.int64(64)])
                    T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2])
                    var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2] = var_T_transpose_intermediate[T.int64(0), ((v_ax2 // T.int64(64) + v_ax1) // T.int64(77) + v_ax0) % T.int64(12), (v_ax2 // T.int64(64) + v_ax1) % T.int64(77), v_ax2 % T.int64(64)]

    @T.prim_func(private=True)
    def fused_reshape43_transpose37_reshape44_transpose38(lv28: T.Buffer((T.int64(1), T.int64(77), T.int64(768)), "float32"), var_T_transpose_intermediate: T.Buffer((T.int64(12), T.int64(64), T.int64(77)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(12), T.int64(64)))
        var_T_transpose_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(12), T.int64(77), T.int64(64)))
        var_T_reshape_intermediate_1 = T.alloc_buffer((T.int64(12), T.int64(77), T.int64(64)))
        for ax0_ax1_ax2_ax3_fused_0 in T.thread_binding(T.int64(231), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) // T.int64(768))
                    v_ax2 = T.axis.spatial(T.int64(12), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(768) // T.int64(64))
                    v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(64))
                    T.reads(lv28[T.int64(0), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(768) + v_ax1) % T.int64(77), (v_ax2 * T.int64(64) + v_ax3) % T.int64(768)])
                    T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                    var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv28[T.int64(0), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(768) + v_ax1) % T.int64(77), (v_ax2 * T.int64(64) + v_ax3) % T.int64(768)]
        for ax0_ax1_ax2_ax3_fused_0 in T.thread_binding(T.int64(231), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_transpose"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(12), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) // T.int64(4928))
                    v_ax2 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(4928) // T.int64(64))
                    v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(64))
                    T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3])
                    T.writes(var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                    var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3]
        for ax0_ax1_ax2_fused_0 in T.thread_binding(T.int64(231), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape_1"):
                    v_ax0 = T.axis.spatial(T.int64(12), (ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) // T.int64(4928))
                    v_ax1 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) % T.int64(4928) // T.int64(64))
                    v_ax2 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) % T.int64(64))
                    T.reads(var_T_transpose_intermediate_1[T.int64(0), ((v_ax2 // T.int64(64) + v_ax1) // T.int64(77) + v_ax0) % T.int64(12), (v_ax2 // T.int64(64) + v_ax1) % T.int64(77), v_ax2 % T.int64(64)])
                    T.writes(var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2])
                    var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2] = var_T_transpose_intermediate_1[T.int64(0), ((v_ax2 // T.int64(64) + v_ax1) // T.int64(77) + v_ax0) % T.int64(12), (v_ax2 // T.int64(64) + v_ax1) % T.int64(77), v_ax2 % T.int64(64)]
        for ax0_ax1_ax2_fused_0 in T.thread_binding(T.int64(231), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_transpose_1"):
                    v_ax0 = T.axis.spatial(T.int64(12), (ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) // T.int64(4928))
                    v_ax1 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) % T.int64(4928) // T.int64(77))
                    v_ax2 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) % T.int64(77))
                    T.reads(var_T_reshape_intermediate_1[v_ax0, v_ax2, v_ax1])
                    T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2])
                    var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2] = var_T_reshape_intermediate_1[v_ax0, v_ax2, v_ax1]

    @T.prim_func(private=True)
    def fused_reshape45_add43_reshape46(lv42: T.Buffer((T.int64(12), T.int64(77), T.int64(77)), "float32"), param_0: T.Buffer((T.int64(1), T.int64(1), T.int64(77), T.int64(77)), "float32"), var_T_reshape_intermediate: T.Buffer((T.int64(12), T.int64(77), T.int64(77)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(12), T.int64(77), T.int64(77)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(12), T.int64(77), T.int64(77)))
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(2)):
                    with T.block("T_reshape"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(12), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(5929))
                        v_ax2 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(5929) // T.int64(77))
                        v_ax3 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(77))
                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) * T.int64(256) + ax0_ax1_ax2_ax3_fused_2 < T.int64(71148))
                        T.reads(lv42[((v_ax3 // T.int64(77) + v_ax2) // T.int64(77) + v_ax1) % T.int64(12), (v_ax3 // T.int64(77) + v_ax2) % T.int64(77), v_ax3 % T.int64(77)])
                        T.writes(var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = lv42[((v_ax3 // T.int64(77) + v_ax2) // T.int64(77) + v_ax1) % T.int64(12), (v_ax3 // T.int64(77) + v_ax2) % T.int64(77), v_ax3 % T.int64(77)]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(2)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(12), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(5929))
                        v_ax2 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(5929) // T.int64(77))
                        v_ax3 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(77))
                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) * T.int64(256) + ax0_ax1_ax2_ax3_fused_2 < T.int64(71148))
                        T.reads(var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3], param_0[v_ax0, T.int64(0), v_ax2, v_ax3])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] + param_0[v_ax0, T.int64(0), v_ax2, v_ax3]
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(2)):
                    with T.block("T_reshape_1"):
                        v_ax0 = T.axis.spatial(T.int64(12), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(5929))
                        v_ax1 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(5929) // T.int64(77))
                        v_ax2 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(77))
                        T.where((ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) * T.int64(256) + ax0_ax1_ax2_fused_2 < T.int64(71148))
                        T.reads(var_T_add_intermediate[T.int64(0), ((v_ax2 // T.int64(77) + v_ax1) // T.int64(77) + v_ax0) % T.int64(12), (v_ax2 // T.int64(77) + v_ax1) % T.int64(77), v_ax2 % T.int64(77)])
                        T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2])
                        var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2] = var_T_add_intermediate[T.int64(0), ((v_ax2 // T.int64(77) + v_ax1) // T.int64(77) + v_ax0) % T.int64(12), (v_ax2 // T.int64(77) + v_ax1) % T.int64(77), v_ax2 % T.int64(77)]

    @T.prim_func(private=True)
    def fused_reshape47_transpose39_reshape48(lv47: T.Buffer((T.int64(12), T.int64(77), T.int64(64)), "float32"), var_T_reshape_intermediate: T.Buffer((T.int64(1), T.int64(77), T.int64(768)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(12), T.int64(77), T.int64(64)))
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(12), T.int64(64)))
        for ax0_ax1_ax2_ax3_fused_0 in T.thread_binding(T.int64(231), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(12), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) // T.int64(4928))
                    v_ax2 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(4928) // T.int64(64))
                    v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(64))
                    T.reads(lv47[((v_ax3 // T.int64(64) + v_ax2) // T.int64(77) + v_ax1) % T.int64(12), (v_ax3 // T.int64(64) + v_ax2) % T.int64(77), v_ax3 % T.int64(64)])
                    T.writes(var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                    var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = lv47[((v_ax3 // T.int64(64) + v_ax2) // T.int64(77) + v_ax1) % T.int64(12), (v_ax3 // T.int64(64) + v_ax2) % T.int64(77), v_ax3 % T.int64(64)]
        for ax0_ax1_ax2_ax3_fused_0 in T.thread_binding(T.int64(231), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_transpose"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) // T.int64(768))
                    v_ax2 = T.axis.spatial(T.int64(12), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(768) // T.int64(64))
                    v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(64))
                    T.reads(var_T_reshape_intermediate_1[v_ax0, v_ax2, v_ax1, v_ax3])
                    T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                    var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate_1[v_ax0, v_ax2, v_ax1, v_ax3]
        for ax0_ax1_ax2_fused_0 in T.thread_binding(T.int64(231), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape_1"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) // T.int64(768))
                    v_ax2 = T.axis.spatial(T.int64(768), (ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) % T.int64(768))
                    T.reads(var_T_transpose_intermediate[T.int64(0), (v_ax2 // T.int64(768) + v_ax1) % T.int64(77), v_ax2 % T.int64(768) // T.int64(64), v_ax2 % T.int64(64)])
                    T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2])
                    var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2] = var_T_transpose_intermediate[T.int64(0), (v_ax2 // T.int64(768) + v_ax1) % T.int64(77), v_ax2 % T.int64(768) // T.int64(64), v_ax2 % T.int64(64)]

    @T.prim_func(private=True)
    def fused_reshape5_transpose1(lv487: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32"), var_T_transpose_intermediate: T.Buffer((T.int64(1), T.int64(20), T.int64(77), T.int64(64)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(20), T.int64(64)))
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(2)):
                    with T.block("T_reshape"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1280))
                        v_ax2 = T.axis.spatial(T.int64(20), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1280) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) * T.int64(256) + ax0_ax1_ax2_ax3_fused_2 < T.int64(98560))
                        T.reads(lv487[T.int64(0), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(1280) + v_ax1) % T.int64(77), (v_ax2 * T.int64(64) + v_ax3) % T.int64(1280)])
                        T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv487[T.int64(0), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(1280) + v_ax1) % T.int64(77), (v_ax2 * T.int64(64) + v_ax3) % T.int64(1280)]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(2)):
                    with T.block("T_transpose"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(20), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(4928))
                        v_ax2 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(4928) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) * T.int64(256) + ax0_ax1_ax2_ax3_fused_2 < T.int64(98560))
                        T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3])
                        T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3]

    @T.prim_func(private=True)
    def fused_reshape5_transpose1_reshape6(lv33: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32"), var_T_reshape_intermediate: T.Buffer((T.int64(20), T.int64(77), T.int64(64)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(20), T.int64(64)))
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(1), T.int64(20), T.int64(77), T.int64(64)))
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(2)):
                    with T.block("T_reshape"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1280))
                        v_ax2 = T.axis.spatial(T.int64(20), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1280) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) * T.int64(256) + ax0_ax1_ax2_ax3_fused_2 < T.int64(98560))
                        T.reads(lv33[T.int64(0), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(1280) + v_ax1) % T.int64(77), (v_ax2 * T.int64(64) + v_ax3) % T.int64(1280)])
                        T.writes(var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = lv33[T.int64(0), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(1280) + v_ax1) % T.int64(77), (v_ax2 * T.int64(64) + v_ax3) % T.int64(1280)]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(2)):
                    with T.block("T_transpose"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(20), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(4928))
                        v_ax2 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(4928) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) * T.int64(256) + ax0_ax1_ax2_ax3_fused_2 < T.int64(98560))
                        T.reads(var_T_reshape_intermediate_1[v_ax0, v_ax2, v_ax1, v_ax3])
                        T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate_1[v_ax0, v_ax2, v_ax1, v_ax3]
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(2)):
                    with T.block("T_reshape_1"):
                        v_ax0 = T.axis.spatial(T.int64(20), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(4928))
                        v_ax1 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(4928) // T.int64(64))
                        v_ax2 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(64))
                        T.where((ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) * T.int64(256) + ax0_ax1_ax2_fused_2 < T.int64(98560))
                        T.reads(var_T_transpose_intermediate[T.int64(0), ((v_ax2 // T.int64(64) + v_ax1) // T.int64(77) + v_ax0) % T.int64(20), (v_ax2 // T.int64(64) + v_ax1) % T.int64(77), v_ax2 % T.int64(64)])
                        T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2])
                        var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2] = var_T_transpose_intermediate[T.int64(0), ((v_ax2 // T.int64(64) + v_ax1) // T.int64(77) + v_ax0) % T.int64(20), (v_ax2 // T.int64(64) + v_ax1) % T.int64(77), v_ax2 % T.int64(64)]

    @T.prim_func(private=True)
    def fused_reshape5_transpose1_reshape6_transpose2(lv28: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32"), var_T_transpose_intermediate: T.Buffer((T.int64(20), T.int64(64), T.int64(77)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(20), T.int64(64)))
        var_T_transpose_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(20), T.int64(77), T.int64(64)))
        var_T_reshape_intermediate_1 = T.alloc_buffer((T.int64(20), T.int64(77), T.int64(64)))
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(2)):
                    with T.block("T_reshape"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1280))
                        v_ax2 = T.axis.spatial(T.int64(20), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1280) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) * T.int64(256) + ax0_ax1_ax2_ax3_fused_2 < T.int64(98560))
                        T.reads(lv28[T.int64(0), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(1280) + v_ax1) % T.int64(77), (v_ax2 * T.int64(64) + v_ax3) % T.int64(1280)])
                        T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv28[T.int64(0), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(1280) + v_ax1) % T.int64(77), (v_ax2 * T.int64(64) + v_ax3) % T.int64(1280)]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(2)):
                    with T.block("T_transpose"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(20), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(4928))
                        v_ax2 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(4928) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) * T.int64(256) + ax0_ax1_ax2_ax3_fused_2 < T.int64(98560))
                        T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3])
                        T.writes(var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3]
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(2)):
                    with T.block("T_reshape_1"):
                        v_ax0 = T.axis.spatial(T.int64(20), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(4928))
                        v_ax1 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(4928) // T.int64(64))
                        v_ax2 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(64))
                        T.where((ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) * T.int64(256) + ax0_ax1_ax2_fused_2 < T.int64(98560))
                        T.reads(var_T_transpose_intermediate_1[T.int64(0), ((v_ax2 // T.int64(64) + v_ax1) // T.int64(77) + v_ax0) % T.int64(20), (v_ax2 // T.int64(64) + v_ax1) % T.int64(77), v_ax2 % T.int64(64)])
                        T.writes(var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2])
                        var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2] = var_T_transpose_intermediate_1[T.int64(0), ((v_ax2 // T.int64(64) + v_ax1) // T.int64(77) + v_ax0) % T.int64(20), (v_ax2 // T.int64(64) + v_ax1) % T.int64(77), v_ax2 % T.int64(64)]
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(2)):
                    with T.block("T_transpose_1"):
                        v_ax0 = T.axis.spatial(T.int64(20), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(4928))
                        v_ax1 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(4928) // T.int64(77))
                        v_ax2 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(77))
                        T.where((ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) * T.int64(256) + ax0_ax1_ax2_fused_2 < T.int64(98560))
                        T.reads(var_T_reshape_intermediate_1[v_ax0, v_ax2, v_ax1])
                        T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2])
                        var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2] = var_T_reshape_intermediate_1[v_ax0, v_ax2, v_ax1]

    @T.prim_func(private=True)
    def fused_reshape5_transpose1_transpose26(lv485: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32"), var_T_transpose_intermediate: T.Buffer((T.int64(1), T.int64(20), T.int64(64), T.int64(77)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(20), T.int64(64)))
        var_T_transpose_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(20), T.int64(77), T.int64(64)))
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(2)):
                    with T.block("T_reshape"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1280))
                        v_ax2 = T.axis.spatial(T.int64(20), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1280) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) * T.int64(256) + ax0_ax1_ax2_ax3_fused_2 < T.int64(98560))
                        T.reads(lv485[T.int64(0), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(1280) + v_ax1) % T.int64(77), (v_ax2 * T.int64(64) + v_ax3) % T.int64(1280)])
                        T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv485[T.int64(0), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(1280) + v_ax1) % T.int64(77), (v_ax2 * T.int64(64) + v_ax3) % T.int64(1280)]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(2)):
                    with T.block("T_transpose"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(20), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(4928))
                        v_ax2 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(4928) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) * T.int64(256) + ax0_ax1_ax2_ax3_fused_2 < T.int64(98560))
                        T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3])
                        T.writes(var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(2)):
                    with T.block("T_transpose_1"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(20), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(4928))
                        v_ax2 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(4928) // T.int64(77))
                        v_ax3 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(77))
                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) * T.int64(256) + ax0_ax1_ax2_ax3_fused_2 < T.int64(98560))
                        T.reads(var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax3, v_ax2])
                        T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax3, v_ax2]

    @T.prim_func(private=True)
    def fused_reshape7_add5_reshape8(lv42: T.Buffer((T.int64(20), T.int64(77), T.int64(77)), "float32"), param_0: T.Buffer((T.int64(1), T.int64(1), T.int64(77), T.int64(77)), "float32"), var_T_reshape_intermediate: T.Buffer((T.int64(20), T.int64(77), T.int64(77)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(20), T.int64(77), T.int64(77)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(20), T.int64(77), T.int64(77)))
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(2)):
                    with T.block("T_reshape"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(20), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(5929))
                        v_ax2 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(5929) // T.int64(77))
                        v_ax3 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(77))
                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) * T.int64(256) + ax0_ax1_ax2_ax3_fused_2 < T.int64(118580))
                        T.reads(lv42[((v_ax3 // T.int64(77) + v_ax2) // T.int64(77) + v_ax1) % T.int64(20), (v_ax3 // T.int64(77) + v_ax2) % T.int64(77), v_ax3 % T.int64(77)])
                        T.writes(var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = lv42[((v_ax3 // T.int64(77) + v_ax2) // T.int64(77) + v_ax1) % T.int64(20), (v_ax3 // T.int64(77) + v_ax2) % T.int64(77), v_ax3 % T.int64(77)]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(2)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(20), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(5929))
                        v_ax2 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(5929) // T.int64(77))
                        v_ax3 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(77))
                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) * T.int64(256) + ax0_ax1_ax2_ax3_fused_2 < T.int64(118580))
                        T.reads(var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3], param_0[v_ax0, T.int64(0), v_ax2, v_ax3])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] + param_0[v_ax0, T.int64(0), v_ax2, v_ax3]
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(2)):
                    with T.block("T_reshape_1"):
                        v_ax0 = T.axis.spatial(T.int64(20), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(5929))
                        v_ax1 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(5929) // T.int64(77))
                        v_ax2 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(77))
                        T.where((ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) * T.int64(256) + ax0_ax1_ax2_fused_2 < T.int64(118580))
                        T.reads(var_T_add_intermediate[T.int64(0), ((v_ax2 // T.int64(77) + v_ax1) // T.int64(77) + v_ax0) % T.int64(20), (v_ax2 // T.int64(77) + v_ax1) % T.int64(77), v_ax2 % T.int64(77)])
                        T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2])
                        var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2] = var_T_add_intermediate[T.int64(0), ((v_ax2 // T.int64(77) + v_ax1) // T.int64(77) + v_ax0) % T.int64(20), (v_ax2 // T.int64(77) + v_ax1) % T.int64(77), v_ax2 % T.int64(77)]

    @T.prim_func(private=True)
    def fused_reshape7_reshape8(lv46: T.Buffer((T.int64(20), T.int64(77), T.int64(77)), "float32"), var_T_reshape_intermediate: T.Buffer((T.int64(20), T.int64(77), T.int64(77)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(20), T.int64(77), T.int64(77)))
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(2)):
                    with T.block("T_reshape"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(20), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(5929))
                        v_ax2 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(5929) // T.int64(77))
                        v_ax3 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(77))
                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) * T.int64(256) + ax0_ax1_ax2_ax3_fused_2 < T.int64(118580))
                        T.reads(lv46[((v_ax3 // T.int64(77) + v_ax2) // T.int64(77) + v_ax1) % T.int64(20), (v_ax3 // T.int64(77) + v_ax2) % T.int64(77), v_ax3 % T.int64(77)])
                        T.writes(var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = lv46[((v_ax3 // T.int64(77) + v_ax2) // T.int64(77) + v_ax1) % T.int64(20), (v_ax3 // T.int64(77) + v_ax2) % T.int64(77), v_ax3 % T.int64(77)]
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(2)):
                    with T.block("T_reshape_1"):
                        v_ax0 = T.axis.spatial(T.int64(20), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(5929))
                        v_ax1 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(5929) // T.int64(77))
                        v_ax2 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(77))
                        T.where((ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) * T.int64(256) + ax0_ax1_ax2_fused_2 < T.int64(118580))
                        T.reads(var_T_reshape_intermediate_1[T.int64(0), ((v_ax2 // T.int64(77) + v_ax1) // T.int64(77) + v_ax0) % T.int64(20), (v_ax2 // T.int64(77) + v_ax1) % T.int64(77), v_ax2 % T.int64(77)])
                        T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2])
                        var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2] = var_T_reshape_intermediate_1[T.int64(0), ((v_ax2 // T.int64(77) + v_ax1) // T.int64(77) + v_ax0) % T.int64(20), (v_ax2 // T.int64(77) + v_ax1) % T.int64(77), v_ax2 % T.int64(77)]

    @T.prim_func(private=True)
    def fused_reshape9_transpose3_reshape10(lv49: T.Buffer((T.int64(20), T.int64(77), T.int64(64)), "float32"), var_T_reshape_intermediate: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(20), T.int64(77), T.int64(64)))
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(20), T.int64(64)))
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(2)):
                    with T.block("T_reshape"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(20), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(4928))
                        v_ax2 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(4928) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) * T.int64(256) + ax0_ax1_ax2_ax3_fused_2 < T.int64(98560))
                        T.reads(lv49[((v_ax3 // T.int64(64) + v_ax2) // T.int64(77) + v_ax1) % T.int64(20), (v_ax3 // T.int64(64) + v_ax2) % T.int64(77), v_ax3 % T.int64(64)])
                        T.writes(var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = lv49[((v_ax3 // T.int64(64) + v_ax2) // T.int64(77) + v_ax1) % T.int64(20), (v_ax3 // T.int64(64) + v_ax2) % T.int64(77), v_ax3 % T.int64(64)]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(2)):
                    with T.block("T_transpose"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1280))
                        v_ax2 = T.axis.spatial(T.int64(20), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1280) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) * T.int64(256) + ax0_ax1_ax2_ax3_fused_2 < T.int64(98560))
                        T.reads(var_T_reshape_intermediate_1[v_ax0, v_ax2, v_ax1, v_ax3])
                        T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate_1[v_ax0, v_ax2, v_ax1, v_ax3]
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(2)):
                    with T.block("T_reshape_1"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(1280))
                        v_ax2 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(1280))
                        T.where((ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) * T.int64(256) + ax0_ax1_ax2_fused_2 < T.int64(98560))
                        T.reads(var_T_transpose_intermediate[T.int64(0), (v_ax2 // T.int64(1280) + v_ax1) % T.int64(77), v_ax2 % T.int64(1280) // T.int64(64), v_ax2 % T.int64(64)])
                        T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2])
                        var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2] = var_T_transpose_intermediate[T.int64(0), (v_ax2 // T.int64(1280) + v_ax1) % T.int64(77), v_ax2 % T.int64(1280) // T.int64(64), v_ax2 % T.int64(64)]

    @T.prim_func(private=True)
    def fused_reshape_cast_reshape1(inp_0: T.Buffer((T.int64(1), T.int64(77)), "int32"), var_T_reshape_intermediate: T.Buffer((T.int64(77),), "int32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(77)), "int32")
        var_compute_intermediate = T.alloc_buffer((T.int64(1), T.int64(77)), "int32")
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(77), thread="threadIdx.x"):
                with T.block("T_reshape"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(77), ax0_ax1_fused_0 * T.int64(77) + ax0_ax1_fused_1)
                    T.reads(inp_0[T.int64(0), v_ax1 % T.int64(77)])
                    T.writes(var_T_reshape_intermediate_1[v_ax0, v_ax1])
                    var_T_reshape_intermediate_1[v_ax0, v_ax1] = inp_0[T.int64(0), v_ax1 % T.int64(77)]
        for i0_i1_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(77), thread="threadIdx.x"):
                with T.block("compute"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(77), i0_i1_fused_0 * T.int64(77) + i0_i1_fused_1)
                    T.reads(var_T_reshape_intermediate_1[v_i0, v_i1])
                    T.writes(var_compute_intermediate[v_i0, v_i1])
                    var_compute_intermediate[v_i0, v_i1] = var_T_reshape_intermediate_1[v_i0, v_i1]
        for ax0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for ax0_fused_1 in T.thread_binding(T.int64(77), thread="threadIdx.x"):
                with T.block("T_reshape_1"):
                    v_ax0 = T.axis.spatial(T.int64(77), ax0_fused_0 * T.int64(77) + ax0_fused_1)
                    T.reads(var_compute_intermediate[T.int64(0), v_ax0 % T.int64(77)])
                    T.writes(var_T_reshape_intermediate[v_ax0])
                    var_T_reshape_intermediate[v_ax0] = var_compute_intermediate[T.int64(0), v_ax0 % T.int64(77)]

    @T.prim_func(private=True)
    def fused_split1_gelu2_multiply13(lv511: T.Buffer((T.int64(1), T.int64(256), T.int64(10240)), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(1), T.int64(256), T.int64(5120)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_split_sections_intermediate = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(5120)))
        var_T_split_sections_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(5120)))
        T_multiply = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(5120)))
        compute = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(5120)))
        T_multiply_1 = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(5120)))
        T_add = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(5120)))
        var_T_multiply_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(5120)))
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(20)):
                    with T.block("T_split_sections"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(5120))
                        v_ax2 = T.axis.spatial(T.int64(5120), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(5120))
                        T.reads(lv511[v_ax0, v_ax1, v_ax2])
                        T.writes(var_T_split_sections_intermediate[v_ax0, v_ax1, v_ax2])
                        var_T_split_sections_intermediate[v_ax0, v_ax1, v_ax2] = lv511[v_ax0, v_ax1, v_ax2]
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(20)):
                    with T.block("T_split_sections_1"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(5120))
                        v_ax2 = T.axis.spatial(T.int64(5120), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(5120))
                        T.reads(lv511[v_ax0, v_ax1, v_ax2 + T.int64(5120)])
                        T.writes(var_T_split_sections_intermediate_1[v_ax0, v_ax1, v_ax2])
                        var_T_split_sections_intermediate_1[v_ax0, v_ax1, v_ax2] = lv511[v_ax0, v_ax1, v_ax2 + T.int64(5120)]
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(20)):
                    with T.block("T_multiply"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(5120))
                        v_ax2 = T.axis.spatial(T.int64(5120), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(5120))
                        T.reads(var_T_split_sections_intermediate_1[v_ax0, v_ax1, v_ax2])
                        T.writes(T_multiply[v_ax0, v_ax1, v_ax2])
                        T_multiply[v_ax0, v_ax1, v_ax2] = var_T_split_sections_intermediate_1[v_ax0, v_ax1, v_ax2] * T.float32(0.70710678118654757)
        for i0_i1_i2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_fused_0 in range(T.int64(20)):
                    with T.block("compute"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(256), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) // T.int64(5120))
                        v_i2 = T.axis.spatial(T.int64(5120), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) % T.int64(5120))
                        T.reads(T_multiply[v_i0, v_i1, v_i2])
                        T.writes(compute[v_i0, v_i1, v_i2])
                        compute[v_i0, v_i1, v_i2] = T.erf(T_multiply[v_i0, v_i1, v_i2])
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(20)):
                    with T.block("T_multiply_1"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(5120))
                        v_ax2 = T.axis.spatial(T.int64(5120), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(5120))
                        T.reads(compute[v_ax0, v_ax1, v_ax2])
                        T.writes(T_multiply_1[v_ax0, v_ax1, v_ax2])
                        T_multiply_1[v_ax0, v_ax1, v_ax2] = compute[v_ax0, v_ax1, v_ax2] * T.float32(0.5)
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(20)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(5120))
                        v_ax2 = T.axis.spatial(T.int64(5120), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(5120))
                        T.reads(T_multiply_1[v_ax0, v_ax1, v_ax2])
                        T.writes(T_add[v_ax0, v_ax1, v_ax2])
                        T_add[v_ax0, v_ax1, v_ax2] = T.float32(0.5) + T_multiply_1[v_ax0, v_ax1, v_ax2]
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(20)):
                    with T.block("T_multiply_2"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(5120))
                        v_ax2 = T.axis.spatial(T.int64(5120), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(5120))
                        T.reads(var_T_split_sections_intermediate_1[v_ax0, v_ax1, v_ax2], T_add[v_ax0, v_ax1, v_ax2])
                        T.writes(var_T_multiply_intermediate_1[v_ax0, v_ax1, v_ax2])
                        var_T_multiply_intermediate_1[v_ax0, v_ax1, v_ax2] = var_T_split_sections_intermediate_1[v_ax0, v_ax1, v_ax2] * T_add[v_ax0, v_ax1, v_ax2]
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(20)):
                    with T.block("T_multiply_3"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(5120))
                        v_ax2 = T.axis.spatial(T.int64(5120), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(5120))
                        T.reads(var_T_split_sections_intermediate[v_ax0, v_ax1, v_ax2], var_T_multiply_intermediate_1[v_ax0, v_ax1, v_ax2])
                        T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2])
                        var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2] = var_T_split_sections_intermediate[v_ax0, v_ax1, v_ax2] * var_T_multiply_intermediate_1[v_ax0, v_ax1, v_ax2]

    @T.prim_func(private=True)
    def fused_split_gelu1_multiply10(lv175: T.Buffer((T.int64(1), T.int64(1024), T.int64(5120)), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(1), T.int64(1024), T.int64(2560)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_split_sections_intermediate = T.alloc_buffer((T.int64(1), T.int64(1024), T.int64(2560)))
        var_T_split_sections_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(1024), T.int64(2560)))
        T_multiply = T.alloc_buffer((T.int64(1), T.int64(1024), T.int64(2560)))
        compute = T.alloc_buffer((T.int64(1), T.int64(1024), T.int64(2560)))
        T_multiply_1 = T.alloc_buffer((T.int64(1), T.int64(1024), T.int64(2560)))
        T_add = T.alloc_buffer((T.int64(1), T.int64(1024), T.int64(2560)))
        var_T_multiply_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(1024), T.int64(2560)))
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(40)):
                    with T.block("T_split_sections"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1024), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(2560))
                        v_ax2 = T.axis.spatial(T.int64(2560), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(2560))
                        T.reads(lv175[v_ax0, v_ax1, v_ax2])
                        T.writes(var_T_split_sections_intermediate[v_ax0, v_ax1, v_ax2])
                        var_T_split_sections_intermediate[v_ax0, v_ax1, v_ax2] = lv175[v_ax0, v_ax1, v_ax2]
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(40)):
                    with T.block("T_split_sections_1"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1024), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(2560))
                        v_ax2 = T.axis.spatial(T.int64(2560), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(2560))
                        T.reads(lv175[v_ax0, v_ax1, v_ax2 + T.int64(2560)])
                        T.writes(var_T_split_sections_intermediate_1[v_ax0, v_ax1, v_ax2])
                        var_T_split_sections_intermediate_1[v_ax0, v_ax1, v_ax2] = lv175[v_ax0, v_ax1, v_ax2 + T.int64(2560)]
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(40)):
                    with T.block("T_multiply"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1024), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(2560))
                        v_ax2 = T.axis.spatial(T.int64(2560), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(2560))
                        T.reads(var_T_split_sections_intermediate_1[v_ax0, v_ax1, v_ax2])
                        T.writes(T_multiply[v_ax0, v_ax1, v_ax2])
                        T_multiply[v_ax0, v_ax1, v_ax2] = var_T_split_sections_intermediate_1[v_ax0, v_ax1, v_ax2] * T.float32(0.70710678118654757)
        for i0_i1_i2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_fused_0 in range(T.int64(40)):
                    with T.block("compute"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1024), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) // T.int64(2560))
                        v_i2 = T.axis.spatial(T.int64(2560), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) % T.int64(2560))
                        T.reads(T_multiply[v_i0, v_i1, v_i2])
                        T.writes(compute[v_i0, v_i1, v_i2])
                        compute[v_i0, v_i1, v_i2] = T.erf(T_multiply[v_i0, v_i1, v_i2])
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(40)):
                    with T.block("T_multiply_1"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1024), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(2560))
                        v_ax2 = T.axis.spatial(T.int64(2560), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(2560))
                        T.reads(compute[v_ax0, v_ax1, v_ax2])
                        T.writes(T_multiply_1[v_ax0, v_ax1, v_ax2])
                        T_multiply_1[v_ax0, v_ax1, v_ax2] = compute[v_ax0, v_ax1, v_ax2] * T.float32(0.5)
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(40)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1024), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(2560))
                        v_ax2 = T.axis.spatial(T.int64(2560), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(2560))
                        T.reads(T_multiply_1[v_ax0, v_ax1, v_ax2])
                        T.writes(T_add[v_ax0, v_ax1, v_ax2])
                        T_add[v_ax0, v_ax1, v_ax2] = T.float32(0.5) + T_multiply_1[v_ax0, v_ax1, v_ax2]
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(40)):
                    with T.block("T_multiply_2"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1024), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(2560))
                        v_ax2 = T.axis.spatial(T.int64(2560), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(2560))
                        T.reads(var_T_split_sections_intermediate_1[v_ax0, v_ax1, v_ax2], T_add[v_ax0, v_ax1, v_ax2])
                        T.writes(var_T_multiply_intermediate_1[v_ax0, v_ax1, v_ax2])
                        var_T_multiply_intermediate_1[v_ax0, v_ax1, v_ax2] = var_T_split_sections_intermediate_1[v_ax0, v_ax1, v_ax2] * T_add[v_ax0, v_ax1, v_ax2]
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(40)):
                    with T.block("T_multiply_3"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1024), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(2560))
                        v_ax2 = T.axis.spatial(T.int64(2560), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(2560))
                        T.reads(var_T_split_sections_intermediate[v_ax0, v_ax1, v_ax2], var_T_multiply_intermediate_1[v_ax0, v_ax1, v_ax2])
                        T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2])
                        var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2] = var_T_split_sections_intermediate[v_ax0, v_ax1, v_ax2] * var_T_multiply_intermediate_1[v_ax0, v_ax1, v_ax2]

    @T.prim_func(private=True)
    def fused_strided_slice_reshape11(lv1465: T.Buffer((T.int64(1), T.int64(1280)), "float32"), var_T_reshape_intermediate: T.Buffer((T.int64(1), T.int64(1280)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_strided_slice_with_axes_intermediate = T.alloc_buffer((T.int64(1), T.int64(1280)))
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(5), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_strided_slice_with_axes"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(1280), ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1)
                    T.reads(lv1465[v_ax0, v_ax1])
                    T.writes(var_T_strided_slice_with_axes_intermediate[v_ax0, v_ax1])
                    var_T_strided_slice_with_axes_intermediate[v_ax0, v_ax1] = lv1465[v_ax0, v_ax1]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(5), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(1280), ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1)
                    T.reads(var_T_strided_slice_with_axes_intermediate[T.int64(0), v_ax1 % T.int64(1280)])
                    T.writes(var_T_reshape_intermediate[v_ax0, v_ax1])
                    var_T_reshape_intermediate[v_ax0, v_ax1] = var_T_strided_slice_with_axes_intermediate[T.int64(0), v_ax1 % T.int64(1280)]

    @T.prim_func(private=True)
    def fused_transpose10_reshape22(lv112: T.Buffer((T.int64(1), T.int64(640), T.int64(32), T.int64(32)), "float32"), var_T_reshape_intermediate: T.Buffer((T.int64(1), T.int64(1024), T.int64(640)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(32), T.int64(640)))
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(10)):
                    with T.block("T_transpose"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(20480))
                        v_ax2 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(20480) // T.int64(640))
                        v_ax3 = T.axis.spatial(T.int64(640), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(640))
                        T.reads(lv112[v_ax0, v_ax3, v_ax1, v_ax2])
                        T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv112[v_ax0, v_ax3, v_ax1, v_ax2]
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(10)):
                    with T.block("T_reshape"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1024), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(640))
                        v_ax2 = T.axis.spatial(T.int64(640), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(640))
                        T.reads(var_T_transpose_intermediate[T.int64(0), (v_ax2 // T.int64(640) + v_ax1) % T.int64(1024) // T.int64(32), (v_ax2 // T.int64(640) + v_ax1) % T.int64(32), v_ax2 % T.int64(640)])
                        T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2])
                        var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2] = var_T_transpose_intermediate[T.int64(0), (v_ax2 // T.int64(640) + v_ax1) % T.int64(1024) // T.int64(32), (v_ax2 // T.int64(640) + v_ax1) % T.int64(32), v_ax2 % T.int64(640)]

    @T.prim_func(private=True)
    def fused_transpose14_reshape24(lv137: T.Buffer((T.int64(1), T.int64(10), T.int64(1024), T.int64(64)), "float32"), var_T_reshape_intermediate: T.Buffer((T.int64(1), T.int64(1024), T.int64(640)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(1), T.int64(1024), T.int64(10), T.int64(64)))
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(10)):
                    with T.block("T_transpose"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1024), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(640))
                        v_ax2 = T.axis.spatial(T.int64(10), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(640) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.reads(lv137[v_ax0, v_ax2, v_ax1, v_ax3])
                        T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv137[v_ax0, v_ax2, v_ax1, v_ax3]
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(10)):
                    with T.block("T_reshape"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1024), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(640))
                        v_ax2 = T.axis.spatial(T.int64(640), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(640))
                        T.reads(var_T_transpose_intermediate[T.int64(0), (v_ax2 // T.int64(640) + v_ax1) % T.int64(1024), v_ax2 % T.int64(640) // T.int64(64), v_ax2 % T.int64(64)])
                        T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2])
                        var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2] = var_T_transpose_intermediate[T.int64(0), (v_ax2 // T.int64(640) + v_ax1) % T.int64(1024), v_ax2 % T.int64(640) // T.int64(64), v_ax2 % T.int64(64)]

    @T.prim_func(private=True)
    def fused_transpose21_reshape29(lv448: T.Buffer((T.int64(1), T.int64(1280), T.int64(16), T.int64(16)), "float32"), var_T_reshape_intermediate: T.Buffer((T.int64(1), T.int64(256), T.int64(1280)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(16), T.int64(1280)))
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(5)):
                    with T.block("T_transpose"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(20480))
                        v_ax2 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(20480) // T.int64(1280))
                        v_ax3 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1280))
                        T.reads(lv448[v_ax0, v_ax3, v_ax1, v_ax2])
                        T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv448[v_ax0, v_ax3, v_ax1, v_ax2]
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(5)):
                    with T.block("T_reshape"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(1280))
                        v_ax2 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(1280))
                        T.reads(var_T_transpose_intermediate[T.int64(0), (v_ax2 // T.int64(1280) + v_ax1) % T.int64(256) // T.int64(16), (v_ax2 // T.int64(1280) + v_ax1) % T.int64(16), v_ax2 % T.int64(1280)])
                        T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2])
                        var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2] = var_T_transpose_intermediate[T.int64(0), (v_ax2 // T.int64(1280) + v_ax1) % T.int64(256) // T.int64(16), (v_ax2 // T.int64(1280) + v_ax1) % T.int64(16), v_ax2 % T.int64(1280)]

    @T.prim_func(private=True)
    def fused_transpose24_reshape31(lv473: T.Buffer((T.int64(1), T.int64(20), T.int64(256), T.int64(64)), "float32"), var_T_reshape_intermediate: T.Buffer((T.int64(1), T.int64(256), T.int64(1280)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(20), T.int64(64)))
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(5)):
                    with T.block("T_transpose"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1280))
                        v_ax2 = T.axis.spatial(T.int64(20), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1280) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.reads(lv473[v_ax0, v_ax2, v_ax1, v_ax3])
                        T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv473[v_ax0, v_ax2, v_ax1, v_ax3]
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(5)):
                    with T.block("T_reshape"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(1280))
                        v_ax2 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(1280))
                        T.reads(var_T_transpose_intermediate[T.int64(0), (v_ax2 // T.int64(1280) + v_ax1) % T.int64(256), v_ax2 % T.int64(1280) // T.int64(64), v_ax2 % T.int64(64)])
                        T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2])
                        var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2] = var_T_transpose_intermediate[T.int64(0), (v_ax2 // T.int64(1280) + v_ax1) % T.int64(256), v_ax2 % T.int64(1280) // T.int64(64), v_ax2 % T.int64(64)]

    @T.prim_func(private=True)
    def fused_transpose30_reshape38_add29_divide8(lv50: T.Buffer((T.int64(1), T.int64(4096), T.int64(512)), "float32"), lv18: T.Buffer((T.int64(1), T.int64(512), T.int64(64), T.int64(64)), "float32"), var_T_divide_intermediate: T.Buffer((T.int64(1), T.int64(512), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(4096)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(64), T.int64(64)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(64), T.int64(64)))
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(32)):
                    with T.block("T_transpose"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(4096))
                        v_ax2 = T.axis.spatial(T.int64(4096), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(4096))
                        T.reads(lv50[v_ax0, v_ax2, v_ax1])
                        T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2])
                        var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2] = lv50[v_ax0, v_ax2, v_ax1]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(32)):
                    with T.block("T_reshape"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(4096))
                        v_ax2 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(4096) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.reads(var_T_transpose_intermediate[T.int64(0), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(4096) + v_ax1) % T.int64(512), (v_ax2 * T.int64(64) + v_ax3) % T.int64(4096)])
                        T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_transpose_intermediate[T.int64(0), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(4096) + v_ax1) % T.int64(512), (v_ax2 * T.int64(64) + v_ax3) % T.int64(4096)]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(32)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(4096))
                        v_ax2 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(4096) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv18[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv18[v_ax0, v_ax1, v_ax2, v_ax3]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(32)):
                    with T.block("T_divide"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(4096))
                        v_ax2 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(4096) // T.int64(64))
                        v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                        T.reads(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_transpose34_reshape37(lv45: T.Buffer((T.int64(1), T.int64(1), T.int64(4096), T.int64(512)), "float32"), var_T_reshape_intermediate: T.Buffer((T.int64(1), T.int64(4096), T.int64(512)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(1), T.int64(4096), T.int64(1), T.int64(512)))
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(32)):
                    with T.block("T_transpose"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(4096), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                        v_ax2 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax3 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512))
                        T.reads(lv45[v_ax0, v_ax2, v_ax1, v_ax3])
                        T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv45[v_ax0, v_ax2, v_ax1, v_ax3]
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(32)):
                    with T.block("T_reshape"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(4096), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(512))
                        v_ax2 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(512))
                        T.reads(var_T_transpose_intermediate[T.int64(0), (v_ax2 // T.int64(512) + v_ax1) % T.int64(4096), T.int64(0), v_ax2 % T.int64(512)])
                        T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2])
                        var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2] = var_T_transpose_intermediate[T.int64(0), (v_ax2 // T.int64(512) + v_ax1) % T.int64(4096), T.int64(0), v_ax2 % T.int64(512)]

    @T.prim_func(private=True)
    def fused_transpose35_multiply16_tir_round(lv237: T.Buffer((T.int64(1), T.int64(3), T.int64(512), T.int64(512)), "float32"), var_compute_intermediate: T.Buffer((T.int64(1), T.int64(512), T.int64(512), T.int64(3)), "float32")):
        T.func_attr({"tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(512), T.int64(3)))
        var_T_multiply_intermediate = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(512), T.int64(3)))
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(12)):
                    with T.block("T_transpose"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1536))
                        v_ax2 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1536) // T.int64(3))
                        v_ax3 = T.axis.spatial(T.int64(3), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(3))
                        T.reads(lv237[v_ax0, v_ax3, v_ax1, v_ax2])
                        T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv237[v_ax0, v_ax3, v_ax1, v_ax2]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(12)):
                    with T.block("T_multiply"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1536))
                        v_ax2 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1536) // T.int64(3))
                        v_ax3 = T.axis.spatial(T.int64(3), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(3))
                        T.reads(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                        var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * T.float32(255)
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(12)):
                    with T.block("compute"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(512), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(1536))
                        v_i2 = T.axis.spatial(T.int64(512), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(1536) // T.int64(3))
                        v_i3 = T.axis.spatial(T.int64(3), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(3))
                        T.reads(var_T_multiply_intermediate[v_i0, v_i1, v_i2, v_i3])
                        T.writes(var_compute_intermediate[v_i0, v_i1, v_i2, v_i3])
                        var_compute_intermediate[v_i0, v_i1, v_i2, v_i3] = T.round(var_T_multiply_intermediate[v_i0, v_i1, v_i2, v_i3])

    @T.prim_func(private=True)
    def group_norm15(A: T.Buffer((T.int64(1), T.int64(512), T.int64(4096)), "float32"), B: T.Buffer((T.int64(512),), "float32"), C: T.Buffer((T.int64(512),), "float32"), T_reshape: T.Buffer((T.int64(1), T.int64(512), T.int64(4096)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape_1 = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(16), T.int64(4096)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(1), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(1), T.int64(32)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(16)))
        T_reshape_3 = T.alloc_buffer((T.int64(32), T.int64(16)))
        T_group_norm = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(16), T.int64(4096)))
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(32)):
                    with T.block("T_reshape"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(65536))
                        v_ax2 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(65536) // T.int64(4096))
                        v_ax3 = T.axis.spatial(T.int64(4096), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(4096))
                        T.reads(A[T.int64(0), (v_ax1 * T.int64(16) + v_ax3 // T.int64(4096) + v_ax2) % T.int64(512), v_ax3 % T.int64(4096)])
                        T.writes(T_reshape_1[v_ax0, v_ax1, v_ax2, v_ax3])
                        T_reshape_1[v_ax0, v_ax1, v_ax2, v_ax3] = A[T.int64(0), (v_ax1 * T.int64(16) + v_ax3 // T.int64(4096) + v_ax2) % T.int64(512), v_ax3 % T.int64(4096)]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for k2, k3 in T.grid(T.int64(16), T.int64(4096)):
                    with T.block("A_red_temp"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), ax0_ax1_fused_0 * T.int64(32) + ax0_ax1_fused_1)
                        v_k2, v_k3 = T.axis.remap("RR", [k2, k3])
                        T.reads(T_reshape_1[v_ax0, v_ax1, v_k2, v_k3])
                        T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                        with T.init():
                            A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                            A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                        v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape_1[v_ax0, v_ax1, v_k2, v_k3]
                        v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape_1[v_ax0, v_ax1, v_k2, v_k3] * T_reshape_1[v_ax0, v_ax1, v_k2, v_k3]
                        A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                        A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(2), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape_1"):
                    v_ax0 = T.axis.spatial(T.int64(32), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) // T.int64(16))
                    v_ax1 = T.axis.spatial(T.int64(16), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) % T.int64(16))
                    T.reads(B[(v_ax0 * T.int64(16) + v_ax1) % T.int64(512)])
                    T.writes(T_reshape_2[v_ax0, v_ax1])
                    T_reshape_2[v_ax0, v_ax1] = B[(v_ax0 * T.int64(16) + v_ax1) % T.int64(512)]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(2), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape_2"):
                    v_ax0 = T.axis.spatial(T.int64(32), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) // T.int64(16))
                    v_ax1 = T.axis.spatial(T.int64(16), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) % T.int64(16))
                    T.reads(C[(v_ax0 * T.int64(16) + v_ax1) % T.int64(512)])
                    T.writes(T_reshape_3[v_ax0, v_ax1])
                    T_reshape_3[v_ax0, v_ax1] = C[(v_ax0 * T.int64(16) + v_ax1) % T.int64(512)]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(32)):
                    with T.block("T_group_norm"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(65536))
                        v_ax2 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(65536) // T.int64(4096))
                        v_ax3 = T.axis.spatial(T.int64(4096), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(4096))
                        T.reads(T_reshape_1[v_ax0, v_ax1, v_ax2, v_ax3], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_2[v_ax1, v_ax2], T_reshape_3[v_ax1, v_ax2])
                        T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3])
                        T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3] = (T_reshape_1[v_ax0, v_ax1, v_ax2, v_ax3] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(1.52587890625e-05)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(1.52587890625e-05) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(1.52587890625e-05) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(1.52587890625e-05)) + T.float32(9.9999999999999995e-07)) * T_reshape_2[v_ax1, v_ax2] + T_reshape_3[v_ax1, v_ax2]
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(32)):
                    with T.block("T_reshape_3"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(4096))
                        v_ax2 = T.axis.spatial(T.int64(4096), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(4096))
                        T.reads(T_group_norm[T.int64(0), (v_ax2 // T.int64(4096) + v_ax1) % T.int64(512) // T.int64(16), (v_ax2 // T.int64(4096) + v_ax1) % T.int64(16), v_ax2 % T.int64(4096)])
                        T.writes(T_reshape[v_ax0, v_ax1, v_ax2])
                        T_reshape[v_ax0, v_ax1, v_ax2] = T_group_norm[T.int64(0), (v_ax2 // T.int64(4096) + v_ax1) % T.int64(512) // T.int64(16), (v_ax2 // T.int64(4096) + v_ax1) % T.int64(16), v_ax2 % T.int64(4096)]

    @T.prim_func(private=True)
    def group_norm3(A: T.Buffer((T.int64(1), T.int64(640), T.int64(32), T.int64(32)), "float32"), B: T.Buffer((T.int64(640),), "float32"), C: T.Buffer((T.int64(640),), "float32"), T_reshape: T.Buffer((T.int64(1), T.int64(640), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape_1 = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(20), T.int64(32), T.int64(32)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(1), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(1), T.int64(32)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(20)))
        T_reshape_3 = T.alloc_buffer((T.int64(32), T.int64(20)))
        T_group_norm = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(20), T.int64(32), T.int64(32)))
        for ax0_ax1_ax2_ax3_ax4_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_ax4_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_ax4_fused_0 in range(T.int64(10)):
                    with T.block("T_reshape"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) // T.int64(20480))
                        v_ax2 = T.axis.spatial(T.int64(20), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(20480) // T.int64(1024))
                        v_ax3 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(1024) // T.int64(32))
                        v_ax4 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(32))
                        T.reads(A[T.int64(0), (v_ax1 * T.int64(20) + (v_ax4 // T.int64(32) + v_ax3) // T.int64(32) + v_ax2) % T.int64(640), (v_ax4 // T.int64(32) + v_ax3) % T.int64(32), v_ax4 % T.int64(32)])
                        T.writes(T_reshape_1[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_reshape_1[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = A[T.int64(0), (v_ax1 * T.int64(20) + (v_ax4 // T.int64(32) + v_ax3) // T.int64(32) + v_ax2) % T.int64(640), (v_ax4 // T.int64(32) + v_ax3) % T.int64(32), v_ax4 % T.int64(32)]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for k2, k3, k4 in T.grid(T.int64(20), T.int64(32), T.int64(32)):
                    with T.block("A_red_temp"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), ax0_ax1_fused_0 * T.int64(32) + ax0_ax1_fused_1)
                        v_k2, v_k3, v_k4 = T.axis.remap("RRR", [k2, k3, k4])
                        T.reads(T_reshape_1[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                        T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                        with T.init():
                            A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                            A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                        v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape_1[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                        v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape_1[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape_1[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                        A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                        A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(3), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape_1"):
                    v_ax0 = T.axis.spatial(T.int64(32), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) // T.int64(20))
                    v_ax1 = T.axis.spatial(T.int64(20), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) % T.int64(20))
                    T.where(ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1 < T.int64(640))
                    T.reads(B[(v_ax0 * T.int64(20) + v_ax1) % T.int64(640)])
                    T.writes(T_reshape_2[v_ax0, v_ax1])
                    T_reshape_2[v_ax0, v_ax1] = B[(v_ax0 * T.int64(20) + v_ax1) % T.int64(640)]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(3), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape_2"):
                    v_ax0 = T.axis.spatial(T.int64(32), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) // T.int64(20))
                    v_ax1 = T.axis.spatial(T.int64(20), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) % T.int64(20))
                    T.where(ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1 < T.int64(640))
                    T.reads(C[(v_ax0 * T.int64(20) + v_ax1) % T.int64(640)])
                    T.writes(T_reshape_3[v_ax0, v_ax1])
                    T_reshape_3[v_ax0, v_ax1] = C[(v_ax0 * T.int64(20) + v_ax1) % T.int64(640)]
        for ax0_ax1_ax2_ax3_ax4_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_ax4_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_ax4_fused_0 in range(T.int64(10)):
                    with T.block("T_group_norm"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) // T.int64(20480))
                        v_ax2 = T.axis.spatial(T.int64(20), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(20480) // T.int64(1024))
                        v_ax3 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(1024) // T.int64(32))
                        v_ax4 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(32))
                        T.reads(T_reshape_1[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_2[v_ax1, v_ax2], T_reshape_3[v_ax1, v_ax2])
                        T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape_1[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(4.8828125000000003e-05)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(4.8828125000000003e-05) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(4.8828125000000003e-05) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(4.8828125000000003e-05)) + T.float32(9.9999999999999995e-07)) * T_reshape_2[v_ax1, v_ax2] + T_reshape_3[v_ax1, v_ax2]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(10)):
                    with T.block("T_reshape_3"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(640), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                        v_ax2 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(32))
                        v_ax3 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                        T.reads(T_group_norm[T.int64(0), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(640) // T.int64(20), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(20), (v_ax3 // T.int64(32) + v_ax2) % T.int64(32), v_ax3 % T.int64(32)])
                        T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3])
                        T_reshape[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[T.int64(0), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(640) // T.int64(20), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(20), (v_ax3 // T.int64(32) + v_ax2) % T.int64(32), v_ax3 % T.int64(32)]

    @T.prim_func(private=True)
    def group_norm6(A: T.Buffer((T.int64(1), T.int64(1280), T.int64(16), T.int64(16)), "float32"), B: T.Buffer((T.int64(1280),), "float32"), C: T.Buffer((T.int64(1280),), "float32"), T_reshape: T.Buffer((T.int64(1), T.int64(1280), T.int64(16), T.int64(16)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape_1 = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(40), T.int64(16), T.int64(16)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(1), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(1), T.int64(32)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(40)))
        T_reshape_3 = T.alloc_buffer((T.int64(32), T.int64(40)))
        T_group_norm = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(40), T.int64(16), T.int64(16)))
        for ax0_ax1_ax2_ax3_ax4_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_ax4_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_ax4_fused_0 in range(T.int64(5)):
                    with T.block("T_reshape"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) // T.int64(10240))
                        v_ax2 = T.axis.spatial(T.int64(40), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(10240) // T.int64(256))
                        v_ax3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(256) // T.int64(16))
                        v_ax4 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(16))
                        T.reads(A[T.int64(0), (v_ax1 * T.int64(40) + (v_ax4 // T.int64(16) + v_ax3) // T.int64(16) + v_ax2) % T.int64(1280), (v_ax4 // T.int64(16) + v_ax3) % T.int64(16), v_ax4 % T.int64(16)])
                        T.writes(T_reshape_1[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_reshape_1[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = A[T.int64(0), (v_ax1 * T.int64(40) + (v_ax4 // T.int64(16) + v_ax3) // T.int64(16) + v_ax2) % T.int64(1280), (v_ax4 // T.int64(16) + v_ax3) % T.int64(16), v_ax4 % T.int64(16)]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for k2, k3, k4 in T.grid(T.int64(40), T.int64(16), T.int64(16)):
                    with T.block("A_red_temp"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), ax0_ax1_fused_0 * T.int64(32) + ax0_ax1_fused_1)
                        v_k2, v_k3, v_k4 = T.axis.remap("RRR", [k2, k3, k4])
                        T.reads(T_reshape_1[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                        T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                        with T.init():
                            A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                            A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                        v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape_1[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                        v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape_1[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape_1[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                        A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                        A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(5), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape_1"):
                    v_ax0 = T.axis.spatial(T.int64(32), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) // T.int64(40))
                    v_ax1 = T.axis.spatial(T.int64(40), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) % T.int64(40))
                    T.reads(B[(v_ax0 * T.int64(40) + v_ax1) % T.int64(1280)])
                    T.writes(T_reshape_2[v_ax0, v_ax1])
                    T_reshape_2[v_ax0, v_ax1] = B[(v_ax0 * T.int64(40) + v_ax1) % T.int64(1280)]
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(5), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape_2"):
                    v_ax0 = T.axis.spatial(T.int64(32), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) // T.int64(40))
                    v_ax1 = T.axis.spatial(T.int64(40), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) % T.int64(40))
                    T.reads(C[(v_ax0 * T.int64(40) + v_ax1) % T.int64(1280)])
                    T.writes(T_reshape_3[v_ax0, v_ax1])
                    T_reshape_3[v_ax0, v_ax1] = C[(v_ax0 * T.int64(40) + v_ax1) % T.int64(1280)]
        for ax0_ax1_ax2_ax3_ax4_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_ax4_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_ax4_fused_0 in range(T.int64(5)):
                    with T.block("T_group_norm"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) // T.int64(10240))
                        v_ax2 = T.axis.spatial(T.int64(40), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(10240) // T.int64(256))
                        v_ax3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(256) // T.int64(16))
                        v_ax4 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_ax4_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_ax4_fused_2) % T.int64(16))
                        T.reads(T_reshape_1[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_2[v_ax1, v_ax2], T_reshape_3[v_ax1, v_ax2])
                        T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape_1[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(9.7656250000000005e-05)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(9.7656250000000005e-05) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(9.7656250000000005e-05) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(9.7656250000000005e-05)) + T.float32(9.9999999999999995e-07)) * T_reshape_2[v_ax1, v_ax2] + T_reshape_3[v_ax1, v_ax2]
        for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(5)):
                    with T.block("T_reshape_3"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) // T.int64(256))
                        v_ax2 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256) // T.int64(16))
                        v_ax3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(65536) + ax0_ax1_ax2_ax3_fused_1 * T.int64(256) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                        T.reads(T_group_norm[T.int64(0), ((v_ax3 // T.int64(16) + v_ax2) // T.int64(16) + v_ax1) % T.int64(1280) // T.int64(40), ((v_ax3 // T.int64(16) + v_ax2) // T.int64(16) + v_ax1) % T.int64(40), (v_ax3 // T.int64(16) + v_ax2) % T.int64(16), v_ax3 % T.int64(16)])
                        T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3])
                        T_reshape[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[T.int64(0), ((v_ax3 // T.int64(16) + v_ax2) // T.int64(16) + v_ax1) % T.int64(1280) // T.int64(40), ((v_ax3 // T.int64(16) + v_ax2) // T.int64(16) + v_ax1) % T.int64(40), (v_ax3 // T.int64(16) + v_ax2) % T.int64(16), v_ax3 % T.int64(16)]

    @T.prim_func(private=True)
    def layer_norm(A: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32"), B: T.Buffer((T.int64(1280),), "float32"), C: T.Buffer((T.int64(1280),), "float32"), T_layer_norm: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        A_red_temp_v0 = T.alloc_buffer((T.int64(1), T.int64(77)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(1), T.int64(77)))
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(77), thread="threadIdx.x"):
                for k2 in range(T.int64(1280)):
                    with T.block("A_red_temp"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(77), ax0_ax1_fused_0 * T.int64(77) + ax0_ax1_fused_1)
                        v_k2 = T.axis.reduce(T.int64(1280), k2)
                        T.reads(A[v_ax0, v_ax1, v_k2])
                        T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                        with T.init():
                            A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                            A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                        v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + A[v_ax0, v_ax1, v_k2]
                        v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + A[v_ax0, v_ax1, v_k2] * A[v_ax0, v_ax1, v_k2]
                        A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                        A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(2)):
                    with T.block("T_layer_norm"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(1280))
                        v_ax2 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(1280))
                        T.where((ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) * T.int64(256) + ax0_ax1_ax2_fused_2 < T.int64(98560))
                        T.reads(A[v_ax0, v_ax1, v_ax2], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], B[v_ax2], C[v_ax2])
                        T.writes(T_layer_norm[v_ax0, v_ax1, v_ax2])
                        T_layer_norm[v_ax0, v_ax1, v_ax2] = (A[v_ax0, v_ax1, v_ax2] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(0.00078125000000000004)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(0.00078125000000000004) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(0.00078125000000000004) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(0.00078125000000000004)) + T.float32(1.0000000000000001e-05)) * B[v_ax2] + C[v_ax2]

    @T.prim_func(private=True)
    def layer_norm1(A: T.Buffer((T.int64(1), T.int64(1024), T.int64(640)), "float32"), B: T.Buffer((T.int64(640),), "float32"), C: T.Buffer((T.int64(640),), "float32"), T_layer_norm: T.Buffer((T.int64(1), T.int64(1024), T.int64(640)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        A_red_temp_v0 = T.alloc_buffer((T.int64(1), T.int64(1024)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(1), T.int64(1024)))
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(4), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for k2 in range(T.int64(640)):
                    with T.block("A_red_temp"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1024), ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1)
                        v_k2 = T.axis.reduce(T.int64(640), k2)
                        T.reads(A[v_ax0, v_ax1, v_k2])
                        T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                        with T.init():
                            A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                            A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                        v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + A[v_ax0, v_ax1, v_k2]
                        v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + A[v_ax0, v_ax1, v_k2] * A[v_ax0, v_ax1, v_k2]
                        A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                        A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(10)):
                    with T.block("T_layer_norm"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(1024), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(640))
                        v_ax2 = T.axis.spatial(T.int64(640), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(640))
                        T.reads(A[v_ax0, v_ax1, v_ax2], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], B[v_ax2], C[v_ax2])
                        T.writes(T_layer_norm[v_ax0, v_ax1, v_ax2])
                        T_layer_norm[v_ax0, v_ax1, v_ax2] = (A[v_ax0, v_ax1, v_ax2] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(0.0015625000000000001)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(0.0015625000000000001) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(0.0015625000000000001) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(0.0015625000000000001)) + T.float32(1.0000000000000001e-05)) * B[v_ax2] + C[v_ax2]

    @T.prim_func(private=True)
    def layer_norm2(A: T.Buffer((T.int64(1), T.int64(256), T.int64(1280)), "float32"), B: T.Buffer((T.int64(1280),), "float32"), C: T.Buffer((T.int64(1280),), "float32"), T_layer_norm: T.Buffer((T.int64(1), T.int64(256), T.int64(1280)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        A_red_temp_v0 = T.alloc_buffer((T.int64(1), T.int64(256)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(1), T.int64(256)))
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for k2 in range(T.int64(1280)):
                    with T.block("A_red_temp"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(256), ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1)
                        v_k2 = T.axis.reduce(T.int64(1280), k2)
                        T.reads(A[v_ax0, v_ax1, v_k2])
                        T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                        with T.init():
                            A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                            A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                        v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + A[v_ax0, v_ax1, v_k2]
                        v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + A[v_ax0, v_ax1, v_k2] * A[v_ax0, v_ax1, v_k2]
                        A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                        A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(5)):
                    with T.block("T_layer_norm"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(256), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(1280))
                        v_ax2 = T.axis.spatial(T.int64(1280), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(1280))
                        T.reads(A[v_ax0, v_ax1, v_ax2], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], B[v_ax2], C[v_ax2])
                        T.writes(T_layer_norm[v_ax0, v_ax1, v_ax2])
                        T_layer_norm[v_ax0, v_ax1, v_ax2] = (A[v_ax0, v_ax1, v_ax2] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(0.00078125000000000004)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(0.00078125000000000004) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(0.00078125000000000004) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(0.00078125000000000004)) + T.float32(1.0000000000000001e-05)) * B[v_ax2] + C[v_ax2]

    @T.prim_func(private=True)
    def layer_norm3(A: T.Buffer((T.int64(1), T.int64(77), T.int64(768)), "float32"), B: T.Buffer((T.int64(768),), "float32"), C: T.Buffer((T.int64(768),), "float32"), T_layer_norm: T.Buffer((T.int64(1), T.int64(77), T.int64(768)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        A_red_temp_v0 = T.alloc_buffer((T.int64(1), T.int64(77)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(1), T.int64(77)))
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(77), thread="threadIdx.x"):
                for k2 in range(T.int64(768)):
                    with T.block("A_red_temp"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(77), ax0_ax1_fused_0 * T.int64(77) + ax0_ax1_fused_1)
                        v_k2 = T.axis.reduce(T.int64(768), k2)
                        T.reads(A[v_ax0, v_ax1, v_k2])
                        T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                        with T.init():
                            A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                            A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                        v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + A[v_ax0, v_ax1, v_k2]
                        v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + A[v_ax0, v_ax1, v_k2] * A[v_ax0, v_ax1, v_k2]
                        A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                        A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0_ax1_ax2_fused_0 in T.thread_binding(T.int64(231), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_layer_norm"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(77), (ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) // T.int64(768))
                    v_ax2 = T.axis.spatial(T.int64(768), (ax0_ax1_ax2_fused_0 * T.int64(256) + ax0_ax1_ax2_fused_1) % T.int64(768))
                    T.reads(A[v_ax0, v_ax1, v_ax2], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], B[v_ax2], C[v_ax2])
                    T.writes(T_layer_norm[v_ax0, v_ax1, v_ax2])
                    T_layer_norm[v_ax0, v_ax1, v_ax2] = (A[v_ax0, v_ax1, v_ax2] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(0.0013020833333333333)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(0.0013020833333333333) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(0.0013020833333333333) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(0.0013020833333333333)) + T.float32(1.0000000000000001e-05)) * B[v_ax2] + C[v_ax2]

    @T.prim_func(private=True)
    def matmul1(A: T.Buffer((T.int64(20), T.int64(77), T.int64(64)), "float32"), B: T.Buffer((T.int64(20), T.int64(64), T.int64(77)), "float32"), matmul: T.Buffer((T.int64(20), T.int64(77), T.int64(77)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0_i1_i2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_fused_0, k in T.grid(T.int64(2), T.int64(64)):
                    with T.block("matmul"):
                        v_i0 = T.axis.spatial(T.int64(20), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) // T.int64(5929))
                        v_i1 = T.axis.spatial(T.int64(77), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) % T.int64(5929) // T.int64(77))
                        v_i2 = T.axis.spatial(T.int64(77), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) % T.int64(77))
                        v_k = T.axis.reduce(T.int64(64), k)
                        T.where((i0_i1_i2_fused_0 * T.int64(256) + i0_i1_i2_fused_1) * T.int64(256) + i0_i1_i2_fused_2 < T.int64(118580))
                        T.reads(A[v_i0, v_i1, v_k], B[v_i0, v_k, v_i2])
                        T.writes(matmul[v_i0, v_i1, v_i2])
                        with T.init():
                            matmul[v_i0, v_i1, v_i2] = T.float32(0)
                        matmul[v_i0, v_i1, v_i2] = matmul[v_i0, v_i1, v_i2] + A[v_i0, v_i1, v_k] * B[v_i0, v_k, v_i2]

    @T.prim_func(private=True)
    def matmul10(A: T.Buffer((T.int64(1), T.int64(1024), T.int64(640)), "float32"), B: T.Buffer((T.int64(640), T.int64(640)), "float32"), matmul: T.Buffer((T.int64(1), T.int64(1024), T.int64(640)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0_i1_i2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_fused_0, k in T.grid(T.int64(10), T.int64(640)):
                    with T.block("matmul"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1024), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) // T.int64(640))
                        v_i2 = T.axis.spatial(T.int64(640), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) % T.int64(640))
                        v_k = T.axis.reduce(T.int64(640), k)
                        T.reads(A[v_i0, v_i1, v_k], B[v_k, v_i2])
                        T.writes(matmul[v_i0, v_i1, v_i2])
                        with T.init():
                            matmul[v_i0, v_i1, v_i2] = T.float32(0)
                        matmul[v_i0, v_i1, v_i2] = matmul[v_i0, v_i1, v_i2] + A[v_i0, v_i1, v_k] * B[v_k, v_i2]

    @T.prim_func(private=True)
    def matmul12(A: T.Buffer((T.int64(1), T.int64(10), T.int64(1024), T.int64(1024)), "float32"), B: T.Buffer((T.int64(1), T.int64(10), T.int64(1024), T.int64(64)), "float32"), matmul: T.Buffer((T.int64(1), T.int64(10), T.int64(1024), T.int64(64)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0, k in T.grid(T.int64(10), T.int64(1024)):
                    with T.block("matmul"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(10), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(65536))
                        v_i2 = T.axis.spatial(T.int64(1024), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(65536) // T.int64(64))
                        v_i3 = T.axis.spatial(T.int64(64), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(64))
                        v_k = T.axis.reduce(T.int64(1024), k)
                        T.reads(A[v_i0, v_i1, v_i2, v_k], B[v_i0, v_i1, v_k, v_i3])
                        T.writes(matmul[v_i0, v_i1, v_i2, v_i3])
                        with T.init():
                            matmul[v_i0, v_i1, v_i2, v_i3] = T.float32(0)
                        matmul[v_i0, v_i1, v_i2, v_i3] = matmul[v_i0, v_i1, v_i2, v_i3] + A[v_i0, v_i1, v_i2, v_k] * B[v_i0, v_i1, v_k, v_i3]

    @T.prim_func(private=True)
    def matmul13(A: T.Buffer((T.int64(1), T.int64(77), T.int64(2048)), "float32"), B: T.Buffer((T.int64(2048), T.int64(640)), "float32"), matmul: T.Buffer((T.int64(1), T.int64(77), T.int64(640)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0_i1_i2_fused_0 in T.thread_binding(T.int64(193), thread="blockIdx.x"):
            for i0_i1_i2_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for k in range(T.int64(2048)):
                    with T.block("matmul"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(77), (i0_i1_i2_fused_0 * T.int64(256) + i0_i1_i2_fused_1) // T.int64(640))
                        v_i2 = T.axis.spatial(T.int64(640), (i0_i1_i2_fused_0 * T.int64(256) + i0_i1_i2_fused_1) % T.int64(640))
                        v_k = T.axis.reduce(T.int64(2048), k)
                        T.where(i0_i1_i2_fused_0 * T.int64(256) + i0_i1_i2_fused_1 < T.int64(49280))
                        T.reads(A[v_i0, v_i1, v_k], B[v_k, v_i2])
                        T.writes(matmul[v_i0, v_i1, v_i2])
                        with T.init():
                            matmul[v_i0, v_i1, v_i2] = T.float32(0)
                        matmul[v_i0, v_i1, v_i2] = matmul[v_i0, v_i1, v_i2] + A[v_i0, v_i1, v_k] * B[v_k, v_i2]

    @T.prim_func(private=True)
    def matmul15(A: T.Buffer((T.int64(1), T.int64(10), T.int64(1024), T.int64(77)), "float32"), B: T.Buffer((T.int64(1), T.int64(10), T.int64(77), T.int64(64)), "float32"), matmul: T.Buffer((T.int64(1), T.int64(10), T.int64(1024), T.int64(64)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0, k in T.grid(T.int64(10), T.int64(77)):
                    with T.block("matmul"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(10), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(65536))
                        v_i2 = T.axis.spatial(T.int64(1024), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(65536) // T.int64(64))
                        v_i3 = T.axis.spatial(T.int64(64), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(64))
                        v_k = T.axis.reduce(T.int64(77), k)
                        T.reads(A[v_i0, v_i1, v_i2, v_k], B[v_i0, v_i1, v_k, v_i3])
                        T.writes(matmul[v_i0, v_i1, v_i2, v_i3])
                        with T.init():
                            matmul[v_i0, v_i1, v_i2, v_i3] = T.float32(0)
                        matmul[v_i0, v_i1, v_i2, v_i3] = matmul[v_i0, v_i1, v_i2, v_i3] + A[v_i0, v_i1, v_i2, v_k] * B[v_i0, v_i1, v_k, v_i3]

    @T.prim_func(private=True)
    def matmul18(A: T.Buffer((T.int64(1), T.int64(256), T.int64(1280)), "float32"), B: T.Buffer((T.int64(1280), T.int64(1280)), "float32"), matmul: T.Buffer((T.int64(1), T.int64(256), T.int64(1280)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0_i1_i2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_fused_0, k in T.grid(T.int64(5), T.int64(1280)):
                    with T.block("matmul"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(256), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) // T.int64(1280))
                        v_i2 = T.axis.spatial(T.int64(1280), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) % T.int64(1280))
                        v_k = T.axis.reduce(T.int64(1280), k)
                        T.reads(A[v_i0, v_i1, v_k], B[v_k, v_i2])
                        T.writes(matmul[v_i0, v_i1, v_i2])
                        with T.init():
                            matmul[v_i0, v_i1, v_i2] = T.float32(0)
                        matmul[v_i0, v_i1, v_i2] = matmul[v_i0, v_i1, v_i2] + A[v_i0, v_i1, v_k] * B[v_k, v_i2]

    @T.prim_func(private=True)
    def matmul2(A: T.Buffer((T.int64(20), T.int64(77), T.int64(77)), "float32"), B: T.Buffer((T.int64(20), T.int64(77), T.int64(64)), "float32"), matmul: T.Buffer((T.int64(20), T.int64(77), T.int64(64)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0_i1_i2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_fused_0, k in T.grid(T.int64(2), T.int64(77)):
                    with T.block("matmul"):
                        v_i0 = T.axis.spatial(T.int64(20), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) // T.int64(4928))
                        v_i1 = T.axis.spatial(T.int64(77), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) % T.int64(4928) // T.int64(64))
                        v_i2 = T.axis.spatial(T.int64(64), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) % T.int64(64))
                        v_k = T.axis.reduce(T.int64(77), k)
                        T.where((i0_i1_i2_fused_0 * T.int64(256) + i0_i1_i2_fused_1) * T.int64(256) + i0_i1_i2_fused_2 < T.int64(98560))
                        T.reads(A[v_i0, v_i1, v_k], B[v_i0, v_k, v_i2])
                        T.writes(matmul[v_i0, v_i1, v_i2])
                        with T.init():
                            matmul[v_i0, v_i1, v_i2] = T.float32(0)
                        matmul[v_i0, v_i1, v_i2] = matmul[v_i0, v_i1, v_i2] + A[v_i0, v_i1, v_k] * B[v_i0, v_k, v_i2]

    @T.prim_func(private=True)
    def matmul20(A: T.Buffer((T.int64(1), T.int64(20), T.int64(256), T.int64(256)), "float32"), B: T.Buffer((T.int64(1), T.int64(20), T.int64(256), T.int64(64)), "float32"), matmul: T.Buffer((T.int64(1), T.int64(20), T.int64(256), T.int64(64)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0, k in T.grid(T.int64(5), T.int64(256)):
                    with T.block("matmul"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(20), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(16384))
                        v_i2 = T.axis.spatial(T.int64(256), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(16384) // T.int64(64))
                        v_i3 = T.axis.spatial(T.int64(64), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(64))
                        v_k = T.axis.reduce(T.int64(256), k)
                        T.reads(A[v_i0, v_i1, v_i2, v_k], B[v_i0, v_i1, v_k, v_i3])
                        T.writes(matmul[v_i0, v_i1, v_i2, v_i3])
                        with T.init():
                            matmul[v_i0, v_i1, v_i2, v_i3] = T.float32(0)
                        matmul[v_i0, v_i1, v_i2, v_i3] = matmul[v_i0, v_i1, v_i2, v_i3] + A[v_i0, v_i1, v_i2, v_k] * B[v_i0, v_i1, v_k, v_i3]

    @T.prim_func(private=True)
    def matmul21(A: T.Buffer((T.int64(1), T.int64(77), T.int64(2048)), "float32"), B: T.Buffer((T.int64(2048), T.int64(1280)), "float32"), matmul: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0_i1_i2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_fused_0, k in T.grid(T.int64(2), T.int64(2048)):
                    with T.block("matmul"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(77), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) // T.int64(1280))
                        v_i2 = T.axis.spatial(T.int64(1280), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) % T.int64(1280))
                        v_k = T.axis.reduce(T.int64(2048), k)
                        T.where((i0_i1_i2_fused_0 * T.int64(256) + i0_i1_i2_fused_1) * T.int64(256) + i0_i1_i2_fused_2 < T.int64(98560))
                        T.reads(A[v_i0, v_i1, v_k], B[v_k, v_i2])
                        T.writes(matmul[v_i0, v_i1, v_i2])
                        with T.init():
                            matmul[v_i0, v_i1, v_i2] = T.float32(0)
                        matmul[v_i0, v_i1, v_i2] = matmul[v_i0, v_i1, v_i2] + A[v_i0, v_i1, v_k] * B[v_k, v_i2]

    @T.prim_func(private=True)
    def matmul23(A: T.Buffer((T.int64(1), T.int64(20), T.int64(256), T.int64(77)), "float32"), B: T.Buffer((T.int64(1), T.int64(20), T.int64(77), T.int64(64)), "float32"), matmul: T.Buffer((T.int64(1), T.int64(20), T.int64(256), T.int64(64)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0, k in T.grid(T.int64(5), T.int64(77)):
                    with T.block("matmul"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(20), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(16384))
                        v_i2 = T.axis.spatial(T.int64(256), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(16384) // T.int64(64))
                        v_i3 = T.axis.spatial(T.int64(64), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(64))
                        v_k = T.axis.reduce(T.int64(77), k)
                        T.reads(A[v_i0, v_i1, v_i2, v_k], B[v_i0, v_i1, v_k, v_i3])
                        T.writes(matmul[v_i0, v_i1, v_i2, v_i3])
                        with T.init():
                            matmul[v_i0, v_i1, v_i2, v_i3] = T.float32(0)
                        matmul[v_i0, v_i1, v_i2, v_i3] = matmul[v_i0, v_i1, v_i2, v_i3] + A[v_i0, v_i1, v_i2, v_k] * B[v_i0, v_i1, v_k, v_i3]

    @T.prim_func(private=True)
    def matmul28(A: T.Buffer((T.int64(1), T.int64(1), T.int64(4096), T.int64(4096)), "float32"), B: T.Buffer((T.int64(1), T.int64(1), T.int64(4096), T.int64(512)), "float32"), matmul: T.Buffer((T.int64(1), T.int64(1), T.int64(4096), T.int64(512)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0, k in T.grid(T.int64(32), T.int64(4096)):
                    with T.block("matmul"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i2 = T.axis.spatial(T.int64(4096), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(512))
                        v_i3 = T.axis.spatial(T.int64(512), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(512))
                        v_k = T.axis.reduce(T.int64(4096), k)
                        T.reads(A[v_i0, v_i1, v_i2, v_k], B[v_i0, v_i1, v_k, v_i3])
                        T.writes(matmul[v_i0, v_i1, v_i2, v_i3])
                        with T.init():
                            matmul[v_i0, v_i1, v_i2, v_i3] = T.float32(0)
                        matmul[v_i0, v_i1, v_i2, v_i3] = matmul[v_i0, v_i1, v_i2, v_i3] + A[v_i0, v_i1, v_i2, v_k] * B[v_i0, v_i1, v_k, v_i3]

    @T.prim_func(private=True)
    def matmul30(A: T.Buffer((T.int64(12), T.int64(77), T.int64(64)), "float32"), B: T.Buffer((T.int64(12), T.int64(64), T.int64(77)), "float32"), matmul: T.Buffer((T.int64(12), T.int64(77), T.int64(77)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0_i1_i2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_fused_0, k in T.grid(T.int64(2), T.int64(64)):
                    with T.block("matmul"):
                        v_i0 = T.axis.spatial(T.int64(12), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) // T.int64(5929))
                        v_i1 = T.axis.spatial(T.int64(77), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) % T.int64(5929) // T.int64(77))
                        v_i2 = T.axis.spatial(T.int64(77), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) % T.int64(77))
                        v_k = T.axis.reduce(T.int64(64), k)
                        T.where((i0_i1_i2_fused_0 * T.int64(256) + i0_i1_i2_fused_1) * T.int64(256) + i0_i1_i2_fused_2 < T.int64(71148))
                        T.reads(A[v_i0, v_i1, v_k], B[v_i0, v_k, v_i2])
                        T.writes(matmul[v_i0, v_i1, v_i2])
                        with T.init():
                            matmul[v_i0, v_i1, v_i2] = T.float32(0)
                        matmul[v_i0, v_i1, v_i2] = matmul[v_i0, v_i1, v_i2] + A[v_i0, v_i1, v_k] * B[v_i0, v_k, v_i2]

    @T.prim_func(private=True)
    def matmul31(A: T.Buffer((T.int64(12), T.int64(77), T.int64(77)), "float32"), B: T.Buffer((T.int64(12), T.int64(77), T.int64(64)), "float32"), matmul: T.Buffer((T.int64(12), T.int64(77), T.int64(64)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0_i1_i2_fused_0 in T.thread_binding(T.int64(231), thread="blockIdx.x"):
            for i0_i1_i2_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for k in range(T.int64(77)):
                    with T.block("matmul"):
                        v_i0 = T.axis.spatial(T.int64(12), (i0_i1_i2_fused_0 * T.int64(256) + i0_i1_i2_fused_1) // T.int64(4928))
                        v_i1 = T.axis.spatial(T.int64(77), (i0_i1_i2_fused_0 * T.int64(256) + i0_i1_i2_fused_1) % T.int64(4928) // T.int64(64))
                        v_i2 = T.axis.spatial(T.int64(64), (i0_i1_i2_fused_0 * T.int64(256) + i0_i1_i2_fused_1) % T.int64(64))
                        v_k = T.axis.reduce(T.int64(77), k)
                        T.reads(A[v_i0, v_i1, v_k], B[v_i0, v_k, v_i2])
                        T.writes(matmul[v_i0, v_i1, v_i2])
                        with T.init():
                            matmul[v_i0, v_i1, v_i2] = T.float32(0)
                        matmul[v_i0, v_i1, v_i2] = matmul[v_i0, v_i1, v_i2] + A[v_i0, v_i1, v_k] * B[v_i0, v_k, v_i2]

    @T.prim_func(private=True)
    def matmul5(A: T.Buffer((T.int64(1), T.int64(1280)), "float32"), B: T.Buffer((T.int64(1280), T.int64(1280)), "float32"), matmul: T.Buffer((T.int64(1), T.int64(1280)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0_i1_fused_0 in T.thread_binding(T.int64(5), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for k in range(T.int64(1280)):
                    with T.block("matmul"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1280), i0_i1_fused_0 * T.int64(256) + i0_i1_fused_1)
                        v_k = T.axis.reduce(T.int64(1280), k)
                        T.reads(A[v_i0, v_k], B[v_k, v_i1])
                        T.writes(matmul[v_i0, v_i1])
                        with T.init():
                            matmul[v_i0, v_i1] = T.float32(0)
                        matmul[v_i0, v_i1] = matmul[v_i0, v_i1] + A[v_i0, v_k] * B[v_k, v_i1]

    @T.prim_func(private=True)
    def multiply(A: T.Buffer((), "float32"), B: T.Buffer((T.int64(1), T.int64(4), T.int64(64), T.int64(64)), "float32"), T_multiply: T.Buffer((T.int64(1), T.int64(4), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"op_pattern": 0, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0_ax1_ax2_ax3_fused_0 in T.thread_binding(T.int64(64), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_multiply"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) // T.int64(4096))
                    v_ax2 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(4096) // T.int64(64))
                    v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(64))
                    T.reads(A[()], B[v_ax0, v_ax1, v_ax2, v_ax3])
                    T.writes(T_multiply[v_ax0, v_ax1, v_ax2, v_ax3])
                    T_multiply[v_ax0, v_ax1, v_ax2, v_ax3] = A[()] * B[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def multiply1(A: T.Buffer((), "float32"), B: T.Buffer((), "float32"), T_multiply: T.Buffer((), "float32")):
        T.func_attr({"op_pattern": 0, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for u_fused_0 in T.thread_binding(1, thread="blockIdx.x"):
            for u_fused_1 in T.thread_binding(1, thread="threadIdx.x"):
                with T.block("T_multiply"):
                    vi = T.axis.spatial(1, T.int64(0))
                    T.reads(A[()], B[()])
                    T.writes(T_multiply[()])
                    T_multiply[()] = A[()] * B[()]

    @T.prim_func(private=True)
    def multiply14(A: T.Buffer((T.int64(1), T.int64(4), T.int64(64), T.int64(64)), "float32"), T_multiply: T.Buffer((T.int64(1), T.int64(4), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"op_pattern": 0, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0_ax1_ax2_ax3_fused_0 in T.thread_binding(T.int64(64), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_multiply"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) // T.int64(4096))
                    v_ax2 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(4096) // T.int64(64))
                    v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(64))
                    T.reads(A[v_ax0, v_ax1, v_ax2, v_ax3])
                    T.writes(T_multiply[v_ax0, v_ax1, v_ax2, v_ax3])
                    T_multiply[v_ax0, v_ax1, v_ax2, v_ax3] = T.float32(7.6775431632995605) * A[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def multiply2(A: T.Buffer((T.int64(1), T.int64(4), T.int64(64), T.int64(64)), "float32"), B: T.Buffer((), "float32"), T_multiply: T.Buffer((T.int64(1), T.int64(4), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"op_pattern": 0, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0_ax1_ax2_ax3_fused_0 in T.thread_binding(T.int64(64), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_multiply"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) // T.int64(4096))
                    v_ax2 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(4096) // T.int64(64))
                    v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(64))
                    T.reads(A[v_ax0, v_ax1, v_ax2, v_ax3], B[()])
                    T.writes(T_multiply[v_ax0, v_ax1, v_ax2, v_ax3])
                    T_multiply[v_ax0, v_ax1, v_ax2, v_ax3] = A[v_ax0, v_ax1, v_ax2, v_ax3] * B[()]

    @T.prim_func(private=True)
    def power(A: T.Buffer((), "float32"), T_power: T.Buffer((), "float32")):
        T.func_attr({"op_pattern": 0, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for u_fused_0 in T.thread_binding(1, thread="blockIdx.x"):
            for u_fused_1 in T.thread_binding(1, thread="threadIdx.x"):
                with T.block("T_power"):
                    vi = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads(A[()])
                    T.writes(T_power[()])
                    T_power[()] = T.pow(A[()], T.float32(2))

    @T.prim_func(private=True)
    def power1(A: T.Buffer((), "float32"), T_power: T.Buffer((), "float32")):
        T.func_attr({"op_pattern": 0, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for u_fused_0 in T.thread_binding(1, thread="blockIdx.x"):
            for u_fused_1 in T.thread_binding(1, thread="threadIdx.x"):
                with T.block("T_power"):
                    vi = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads(A[()])
                    T.writes(T_power[()])
                    T_power[()] = T.pow(A[()], T.float32(0.5))

    @T.prim_func(private=True)
    def reshape(A: T.Buffer((T.int64(1), T.int64(77)), "int32"), T_reshape: T.Buffer((T.int64(1), T.int64(77)), "int32")):
        T.func_attr({"op_pattern": 2, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(77), thread="threadIdx.x"):
                with T.block("T_reshape"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(77), ax0_ax1_fused_0 * T.int64(77) + ax0_ax1_fused_1)
                    T.reads(A[T.int64(0), v_ax1 % T.int64(77)])
                    T.writes(T_reshape[v_ax0, v_ax1])
                    T_reshape[v_ax0, v_ax1] = A[T.int64(0), v_ax1 % T.int64(77)]

    @T.prim_func(private=True)
    def reshape19(A: T.Buffer((T.int64(1), T.int64(320)), "float32"), T_reshape: T.Buffer((T.int64(1), T.int64(320), T.int64(1), T.int64(1)), "float32")):
        T.func_attr({"op_pattern": 2, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0_ax1_ax2_ax3_fused_0 in T.thread_binding(T.int64(2), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(320), ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1)
                    v_ax2 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax3 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 < T.int64(320))
                    T.reads(A[T.int64(0), (v_ax1 + v_ax2 + v_ax3) % T.int64(320)])
                    T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3])
                    T_reshape[v_ax0, v_ax1, v_ax2, v_ax3] = A[T.int64(0), (v_ax1 + v_ax2 + v_ax3) % T.int64(320)]

    @T.prim_func(private=True)
    def reshape21(A: T.Buffer((T.int64(1), T.int64(640)), "float32"), T_reshape: T.Buffer((T.int64(1), T.int64(640), T.int64(1), T.int64(1)), "float32")):
        T.func_attr({"op_pattern": 2, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0_ax1_ax2_ax3_fused_0 in T.thread_binding(T.int64(3), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(640), ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1)
                    v_ax2 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax3 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 < T.int64(640))
                    T.reads(A[T.int64(0), (v_ax1 + v_ax2 + v_ax3) % T.int64(640)])
                    T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3])
                    T_reshape[v_ax0, v_ax1, v_ax2, v_ax3] = A[T.int64(0), (v_ax1 + v_ax2 + v_ax3) % T.int64(640)]

    @T.prim_func(private=True)
    def reshape28(A: T.Buffer((T.int64(1), T.int64(1280)), "float32"), T_reshape: T.Buffer((T.int64(1), T.int64(1280), T.int64(1), T.int64(1)), "float32")):
        T.func_attr({"op_pattern": 2, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0_ax1_ax2_ax3_fused_0 in T.thread_binding(T.int64(5), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_reshape"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(1280), ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1)
                    v_ax2 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax3 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads(A[T.int64(0), (v_ax1 + v_ax2 + v_ax3) % T.int64(1280)])
                    T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3])
                    T_reshape[v_ax0, v_ax1, v_ax2, v_ax3] = A[T.int64(0), (v_ax1 + v_ax2 + v_ax3) % T.int64(1280)]

    @T.prim_func(private=True)
    def resize2d2(A: T.Buffer((T.int64(1), T.int64(512), T.int64(64), T.int64(64)), "float32"), resize: T.Buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"op_pattern": 2, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(128)):
                    with T.block("resize"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(512), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(16384))
                        v_i2 = T.axis.spatial(T.int64(128), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(16384) // T.int64(128))
                        v_i3 = T.axis.spatial(T.int64(128), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(128))
                        T.reads(A[v_i0, v_i1, T.max(T.min(T.Div(v_i2, T.int64(2)), T.int64(63)), T.int64(0)), T.max(T.min(T.Div(v_i3, T.int64(2)), T.int64(63)), T.int64(0))])
                        T.writes(resize[v_i0, v_i1, v_i2, v_i3])
                        resize[v_i0, v_i1, v_i2, v_i3] = A[v_i0, v_i1, T.max(T.min(T.Div(v_i2, T.int64(2)), T.int64(63)), T.int64(0)), T.max(T.min(T.Div(v_i3, T.int64(2)), T.int64(63)), T.int64(0))]

    @T.prim_func(private=True)
    def resize2d3(A: T.Buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)), "float32"), resize: T.Buffer((T.int64(1), T.int64(512), T.int64(256), T.int64(256)), "float32")):
        T.func_attr({"op_pattern": 2, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(512)):
                    with T.block("resize"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(512), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(65536))
                        v_i2 = T.axis.spatial(T.int64(256), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(65536) // T.int64(256))
                        v_i3 = T.axis.spatial(T.int64(256), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(256))
                        T.reads(A[v_i0, v_i1, T.max(T.min(T.Div(v_i2, T.int64(2)), T.int64(127)), T.int64(0)), T.max(T.min(T.Div(v_i3, T.int64(2)), T.int64(127)), T.int64(0))])
                        T.writes(resize[v_i0, v_i1, v_i2, v_i3])
                        resize[v_i0, v_i1, v_i2, v_i3] = A[v_i0, v_i1, T.max(T.min(T.Div(v_i2, T.int64(2)), T.int64(127)), T.int64(0)), T.max(T.min(T.Div(v_i3, T.int64(2)), T.int64(127)), T.int64(0))]

    @T.prim_func(private=True)
    def resize2d4(A: T.Buffer((T.int64(1), T.int64(256), T.int64(256), T.int64(256)), "float32"), resize: T.Buffer((T.int64(1), T.int64(256), T.int64(512), T.int64(512)), "float32")):
        T.func_attr({"op_pattern": 2, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(1024)):
                    with T.block("resize"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(256), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(262144))
                        v_i2 = T.axis.spatial(T.int64(512), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(262144) // T.int64(512))
                        v_i3 = T.axis.spatial(T.int64(512), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(512))
                        T.reads(A[v_i0, v_i1, T.max(T.min(T.Div(v_i2, T.int64(2)), T.int64(255)), T.int64(0)), T.max(T.min(T.Div(v_i3, T.int64(2)), T.int64(255)), T.int64(0))])
                        T.writes(resize[v_i0, v_i1, v_i2, v_i3])
                        resize[v_i0, v_i1, v_i2, v_i3] = A[v_i0, v_i1, T.max(T.min(T.Div(v_i2, T.int64(2)), T.int64(255)), T.int64(0)), T.max(T.min(T.Div(v_i3, T.int64(2)), T.int64(255)), T.int64(0))]

    @T.prim_func(private=True)
    def silu(A: T.Buffer((T.int64(1), T.int64(1280)), "float32"), T_multiply: T.Buffer((T.int64(1), T.int64(1280)), "float32")):
        T.func_attr({"op_pattern": 0, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        compute = T.alloc_buffer((T.int64(1), T.int64(1280)))
        for i0_i1_fused_0 in T.thread_binding(T.int64(5), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("compute"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(1280), i0_i1_fused_0 * T.int64(256) + i0_i1_fused_1)
                    T.reads(A[v_i0, v_i1])
                    T.writes(compute[v_i0, v_i1])
                    compute[v_i0, v_i1] = T.sigmoid(A[v_i0, v_i1])
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(5), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_multiply"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(1280), ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1)
                    T.reads(A[v_ax0, v_ax1], compute[v_ax0, v_ax1])
                    T.writes(T_multiply[v_ax0, v_ax1])
                    T_multiply[v_ax0, v_ax1] = A[v_ax0, v_ax1] * compute[v_ax0, v_ax1]

    @T.prim_func(private=True)
    def softmax(A: T.Buffer((T.int64(20), T.int64(77), T.int64(77)), "float32"), T_softmax_norm: T.Buffer((T.int64(20), T.int64(77), T.int64(77)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(20), T.int64(77)))
        T_softmax_exp = T.alloc_buffer((T.int64(20), T.int64(77), T.int64(77)))
        T_softmax_expsum = T.alloc_buffer((T.int64(20), T.int64(77)))
        for i0_i1_fused_0 in T.thread_binding(T.int64(7), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for k in range(T.int64(77)):
                    with T.block("T_softmax_maxelem"):
                        v_i0 = T.axis.spatial(T.int64(20), (i0_i1_fused_0 * T.int64(256) + i0_i1_fused_1) // T.int64(77))
                        v_i1 = T.axis.spatial(T.int64(77), (i0_i1_fused_0 * T.int64(256) + i0_i1_fused_1) % T.int64(77))
                        v_k = T.axis.reduce(T.int64(77), k)
                        T.where(i0_i1_fused_0 * T.int64(256) + i0_i1_fused_1 < T.int64(1540))
                        T.reads(A[v_i0, v_i1, v_k])
                        T.writes(T_softmax_maxelem[v_i0, v_i1])
                        with T.init():
                            T_softmax_maxelem[v_i0, v_i1] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem[v_i0, v_i1] = T.max(T_softmax_maxelem[v_i0, v_i1], A[v_i0, v_i1, v_k])
        for i0_i1_i2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_fused_0 in range(T.int64(2)):
                    with T.block("T_softmax_exp"):
                        v_i0 = T.axis.spatial(T.int64(20), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) // T.int64(5929))
                        v_i1 = T.axis.spatial(T.int64(77), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) % T.int64(5929) // T.int64(77))
                        v_i2 = T.axis.spatial(T.int64(77), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) % T.int64(77))
                        T.where((i0_i1_i2_fused_0 * T.int64(256) + i0_i1_i2_fused_1) * T.int64(256) + i0_i1_i2_fused_2 < T.int64(118580))
                        T.reads(A[v_i0, v_i1, v_i2], T_softmax_maxelem[v_i0, v_i1])
                        T.writes(T_softmax_exp[v_i0, v_i1, v_i2])
                        T_softmax_exp[v_i0, v_i1, v_i2] = T.exp(A[v_i0, v_i1, v_i2] - T_softmax_maxelem[v_i0, v_i1])
        for i0_i1_fused_0 in T.thread_binding(T.int64(7), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for k in range(T.int64(77)):
                    with T.block("T_softmax_expsum"):
                        v_i0 = T.axis.spatial(T.int64(20), (i0_i1_fused_0 * T.int64(256) + i0_i1_fused_1) // T.int64(77))
                        v_i1 = T.axis.spatial(T.int64(77), (i0_i1_fused_0 * T.int64(256) + i0_i1_fused_1) % T.int64(77))
                        v_k = T.axis.reduce(T.int64(77), k)
                        T.where(i0_i1_fused_0 * T.int64(256) + i0_i1_fused_1 < T.int64(1540))
                        T.reads(T_softmax_exp[v_i0, v_i1, v_k])
                        T.writes(T_softmax_expsum[v_i0, v_i1])
                        with T.init():
                            T_softmax_expsum[v_i0, v_i1] = T.float32(0)
                        T_softmax_expsum[v_i0, v_i1] = T_softmax_expsum[v_i0, v_i1] + T_softmax_exp[v_i0, v_i1, v_k]
        for i0_i1_i2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_fused_0 in range(T.int64(2)):
                    with T.block("T_softmax_norm"):
                        v_i0 = T.axis.spatial(T.int64(20), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) // T.int64(5929))
                        v_i1 = T.axis.spatial(T.int64(77), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) % T.int64(5929) // T.int64(77))
                        v_i2 = T.axis.spatial(T.int64(77), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) % T.int64(77))
                        T.where((i0_i1_i2_fused_0 * T.int64(256) + i0_i1_i2_fused_1) * T.int64(256) + i0_i1_i2_fused_2 < T.int64(118580))
                        T.reads(T_softmax_exp[v_i0, v_i1, v_i2], T_softmax_expsum[v_i0, v_i1])
                        T.writes(T_softmax_norm[v_i0, v_i1, v_i2])
                        T.block_attr({"axis": 2})
                        T_softmax_norm[v_i0, v_i1, v_i2] = T_softmax_exp[v_i0, v_i1, v_i2] / T_softmax_expsum[v_i0, v_i1]

    @T.prim_func(private=True)
    def softmax1(A: T.Buffer((T.int64(1), T.int64(10), T.int64(1024), T.int64(1024)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(10), T.int64(1024), T.int64(1024)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1), T.int64(10), T.int64(1024)))
        T_softmax_exp = T.alloc_buffer((T.int64(1), T.int64(10), T.int64(1024), T.int64(1024)))
        T_softmax_expsum = T.alloc_buffer((T.int64(1), T.int64(10), T.int64(1024)))
        for i0_i1_i2_fused_0 in T.thread_binding(T.int64(40), thread="blockIdx.x"):
            for i0_i1_i2_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for k in range(T.int64(1024)):
                    with T.block("T_softmax_maxelem"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(10), (i0_i1_i2_fused_0 * T.int64(256) + i0_i1_i2_fused_1) // T.int64(1024))
                        v_i2 = T.axis.spatial(T.int64(1024), (i0_i1_i2_fused_0 * T.int64(256) + i0_i1_i2_fused_1) % T.int64(1024))
                        v_k = T.axis.reduce(T.int64(1024), k)
                        T.reads(A[v_i0, v_i1, v_i2, v_k])
                        T.writes(T_softmax_maxelem[v_i0, v_i1, v_i2])
                        with T.init():
                            T_softmax_maxelem[v_i0, v_i1, v_i2] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem[v_i0, v_i1, v_i2] = T.max(T_softmax_maxelem[v_i0, v_i1, v_i2], A[v_i0, v_i1, v_i2, v_k])
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(160)):
                    with T.block("T_softmax_exp"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(10), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(1048576))
                        v_i2 = T.axis.spatial(T.int64(1024), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(1048576) // T.int64(1024))
                        v_i3 = T.axis.spatial(T.int64(1024), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(1024))
                        T.reads(A[v_i0, v_i1, v_i2, v_i3], T_softmax_maxelem[v_i0, v_i1, v_i2])
                        T.writes(T_softmax_exp[v_i0, v_i1, v_i2, v_i3])
                        T_softmax_exp[v_i0, v_i1, v_i2, v_i3] = T.exp(A[v_i0, v_i1, v_i2, v_i3] - T_softmax_maxelem[v_i0, v_i1, v_i2])
        for i0_i1_i2_fused_0 in T.thread_binding(T.int64(40), thread="blockIdx.x"):
            for i0_i1_i2_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for k in range(T.int64(1024)):
                    with T.block("T_softmax_expsum"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(10), (i0_i1_i2_fused_0 * T.int64(256) + i0_i1_i2_fused_1) // T.int64(1024))
                        v_i2 = T.axis.spatial(T.int64(1024), (i0_i1_i2_fused_0 * T.int64(256) + i0_i1_i2_fused_1) % T.int64(1024))
                        v_k = T.axis.reduce(T.int64(1024), k)
                        T.reads(T_softmax_exp[v_i0, v_i1, v_i2, v_k])
                        T.writes(T_softmax_expsum[v_i0, v_i1, v_i2])
                        with T.init():
                            T_softmax_expsum[v_i0, v_i1, v_i2] = T.float32(0)
                        T_softmax_expsum[v_i0, v_i1, v_i2] = T_softmax_expsum[v_i0, v_i1, v_i2] + T_softmax_exp[v_i0, v_i1, v_i2, v_k]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(160)):
                    with T.block("T_softmax_norm"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(10), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(1048576))
                        v_i2 = T.axis.spatial(T.int64(1024), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(1048576) // T.int64(1024))
                        v_i3 = T.axis.spatial(T.int64(1024), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(1024))
                        T.reads(T_softmax_exp[v_i0, v_i1, v_i2, v_i3], T_softmax_expsum[v_i0, v_i1, v_i2])
                        T.writes(T_softmax_norm[v_i0, v_i1, v_i2, v_i3])
                        T.block_attr({"axis": 3})
                        T_softmax_norm[v_i0, v_i1, v_i2, v_i3] = T_softmax_exp[v_i0, v_i1, v_i2, v_i3] / T_softmax_expsum[v_i0, v_i1, v_i2]

    @T.prim_func(private=True)
    def softmax2(A: T.Buffer((T.int64(1), T.int64(10), T.int64(1024), T.int64(77)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(10), T.int64(1024), T.int64(77)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1), T.int64(10), T.int64(1024)))
        T_softmax_exp = T.alloc_buffer((T.int64(1), T.int64(10), T.int64(1024), T.int64(77)))
        T_softmax_expsum = T.alloc_buffer((T.int64(1), T.int64(10), T.int64(1024)))
        for i0_i1_i2_fused_0 in T.thread_binding(T.int64(40), thread="blockIdx.x"):
            for i0_i1_i2_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for k in range(T.int64(77)):
                    with T.block("T_softmax_maxelem"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(10), (i0_i1_i2_fused_0 * T.int64(256) + i0_i1_i2_fused_1) // T.int64(1024))
                        v_i2 = T.axis.spatial(T.int64(1024), (i0_i1_i2_fused_0 * T.int64(256) + i0_i1_i2_fused_1) % T.int64(1024))
                        v_k = T.axis.reduce(T.int64(77), k)
                        T.reads(A[v_i0, v_i1, v_i2, v_k])
                        T.writes(T_softmax_maxelem[v_i0, v_i1, v_i2])
                        with T.init():
                            T_softmax_maxelem[v_i0, v_i1, v_i2] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem[v_i0, v_i1, v_i2] = T.max(T_softmax_maxelem[v_i0, v_i1, v_i2], A[v_i0, v_i1, v_i2, v_k])
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(13)):
                    with T.block("T_softmax_exp"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(10), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(78848))
                        v_i2 = T.axis.spatial(T.int64(1024), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(78848) // T.int64(77))
                        v_i3 = T.axis.spatial(T.int64(77), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(77))
                        T.where((i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1) * T.int64(256) + i0_i1_i2_i3_fused_2 < T.int64(788480))
                        T.reads(A[v_i0, v_i1, v_i2, v_i3], T_softmax_maxelem[v_i0, v_i1, v_i2])
                        T.writes(T_softmax_exp[v_i0, v_i1, v_i2, v_i3])
                        T_softmax_exp[v_i0, v_i1, v_i2, v_i3] = T.exp(A[v_i0, v_i1, v_i2, v_i3] - T_softmax_maxelem[v_i0, v_i1, v_i2])
        for i0_i1_i2_fused_0 in T.thread_binding(T.int64(40), thread="blockIdx.x"):
            for i0_i1_i2_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for k in range(T.int64(77)):
                    with T.block("T_softmax_expsum"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(10), (i0_i1_i2_fused_0 * T.int64(256) + i0_i1_i2_fused_1) // T.int64(1024))
                        v_i2 = T.axis.spatial(T.int64(1024), (i0_i1_i2_fused_0 * T.int64(256) + i0_i1_i2_fused_1) % T.int64(1024))
                        v_k = T.axis.reduce(T.int64(77), k)
                        T.reads(T_softmax_exp[v_i0, v_i1, v_i2, v_k])
                        T.writes(T_softmax_expsum[v_i0, v_i1, v_i2])
                        with T.init():
                            T_softmax_expsum[v_i0, v_i1, v_i2] = T.float32(0)
                        T_softmax_expsum[v_i0, v_i1, v_i2] = T_softmax_expsum[v_i0, v_i1, v_i2] + T_softmax_exp[v_i0, v_i1, v_i2, v_k]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(13)):
                    with T.block("T_softmax_norm"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(10), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(78848))
                        v_i2 = T.axis.spatial(T.int64(1024), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(78848) // T.int64(77))
                        v_i3 = T.axis.spatial(T.int64(77), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(77))
                        T.where((i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1) * T.int64(256) + i0_i1_i2_i3_fused_2 < T.int64(788480))
                        T.reads(T_softmax_exp[v_i0, v_i1, v_i2, v_i3], T_softmax_expsum[v_i0, v_i1, v_i2])
                        T.writes(T_softmax_norm[v_i0, v_i1, v_i2, v_i3])
                        T.block_attr({"axis": 3})
                        T_softmax_norm[v_i0, v_i1, v_i2, v_i3] = T_softmax_exp[v_i0, v_i1, v_i2, v_i3] / T_softmax_expsum[v_i0, v_i1, v_i2]

    @T.prim_func(private=True)
    def softmax3(A: T.Buffer((T.int64(1), T.int64(20), T.int64(256), T.int64(256)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(20), T.int64(256), T.int64(256)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1), T.int64(20), T.int64(256)))
        T_softmax_exp = T.alloc_buffer((T.int64(1), T.int64(20), T.int64(256), T.int64(256)))
        T_softmax_expsum = T.alloc_buffer((T.int64(1), T.int64(20), T.int64(256)))
        for i0_i1_i2_fused_0 in T.thread_binding(T.int64(20), thread="blockIdx.x"):
            for i0_i1_i2_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for k in range(T.int64(256)):
                    with T.block("T_softmax_maxelem"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(20), (i0_i1_i2_fused_0 * T.int64(256) + i0_i1_i2_fused_1) // T.int64(256))
                        v_i2 = T.axis.spatial(T.int64(256), (i0_i1_i2_fused_0 * T.int64(256) + i0_i1_i2_fused_1) % T.int64(256))
                        v_k = T.axis.reduce(T.int64(256), k)
                        T.reads(A[v_i0, v_i1, v_i2, v_k])
                        T.writes(T_softmax_maxelem[v_i0, v_i1, v_i2])
                        with T.init():
                            T_softmax_maxelem[v_i0, v_i1, v_i2] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem[v_i0, v_i1, v_i2] = T.max(T_softmax_maxelem[v_i0, v_i1, v_i2], A[v_i0, v_i1, v_i2, v_k])
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(20)):
                    with T.block("T_softmax_exp"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(20), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(65536))
                        v_i2 = T.axis.spatial(T.int64(256), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(65536) // T.int64(256))
                        v_i3 = T.axis.spatial(T.int64(256), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(256))
                        T.reads(A[v_i0, v_i1, v_i2, v_i3], T_softmax_maxelem[v_i0, v_i1, v_i2])
                        T.writes(T_softmax_exp[v_i0, v_i1, v_i2, v_i3])
                        T_softmax_exp[v_i0, v_i1, v_i2, v_i3] = T.exp(A[v_i0, v_i1, v_i2, v_i3] - T_softmax_maxelem[v_i0, v_i1, v_i2])
        for i0_i1_i2_fused_0 in T.thread_binding(T.int64(20), thread="blockIdx.x"):
            for i0_i1_i2_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for k in range(T.int64(256)):
                    with T.block("T_softmax_expsum"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(20), (i0_i1_i2_fused_0 * T.int64(256) + i0_i1_i2_fused_1) // T.int64(256))
                        v_i2 = T.axis.spatial(T.int64(256), (i0_i1_i2_fused_0 * T.int64(256) + i0_i1_i2_fused_1) % T.int64(256))
                        v_k = T.axis.reduce(T.int64(256), k)
                        T.reads(T_softmax_exp[v_i0, v_i1, v_i2, v_k])
                        T.writes(T_softmax_expsum[v_i0, v_i1, v_i2])
                        with T.init():
                            T_softmax_expsum[v_i0, v_i1, v_i2] = T.float32(0)
                        T_softmax_expsum[v_i0, v_i1, v_i2] = T_softmax_expsum[v_i0, v_i1, v_i2] + T_softmax_exp[v_i0, v_i1, v_i2, v_k]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(20)):
                    with T.block("T_softmax_norm"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(20), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(65536))
                        v_i2 = T.axis.spatial(T.int64(256), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(65536) // T.int64(256))
                        v_i3 = T.axis.spatial(T.int64(256), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(256))
                        T.reads(T_softmax_exp[v_i0, v_i1, v_i2, v_i3], T_softmax_expsum[v_i0, v_i1, v_i2])
                        T.writes(T_softmax_norm[v_i0, v_i1, v_i2, v_i3])
                        T.block_attr({"axis": 3})
                        T_softmax_norm[v_i0, v_i1, v_i2, v_i3] = T_softmax_exp[v_i0, v_i1, v_i2, v_i3] / T_softmax_expsum[v_i0, v_i1, v_i2]

    @T.prim_func(private=True)
    def softmax4(A: T.Buffer((T.int64(1), T.int64(20), T.int64(256), T.int64(77)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(20), T.int64(256), T.int64(77)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1), T.int64(20), T.int64(256)))
        T_softmax_exp = T.alloc_buffer((T.int64(1), T.int64(20), T.int64(256), T.int64(77)))
        T_softmax_expsum = T.alloc_buffer((T.int64(1), T.int64(20), T.int64(256)))
        for i0_i1_i2_fused_0 in T.thread_binding(T.int64(20), thread="blockIdx.x"):
            for i0_i1_i2_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for k in range(T.int64(77)):
                    with T.block("T_softmax_maxelem"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(20), (i0_i1_i2_fused_0 * T.int64(256) + i0_i1_i2_fused_1) // T.int64(256))
                        v_i2 = T.axis.spatial(T.int64(256), (i0_i1_i2_fused_0 * T.int64(256) + i0_i1_i2_fused_1) % T.int64(256))
                        v_k = T.axis.reduce(T.int64(77), k)
                        T.reads(A[v_i0, v_i1, v_i2, v_k])
                        T.writes(T_softmax_maxelem[v_i0, v_i1, v_i2])
                        with T.init():
                            T_softmax_maxelem[v_i0, v_i1, v_i2] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem[v_i0, v_i1, v_i2] = T.max(T_softmax_maxelem[v_i0, v_i1, v_i2], A[v_i0, v_i1, v_i2, v_k])
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(7)):
                    with T.block("T_softmax_exp"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(20), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(19712))
                        v_i2 = T.axis.spatial(T.int64(256), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(19712) // T.int64(77))
                        v_i3 = T.axis.spatial(T.int64(77), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(77))
                        T.where((i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1) * T.int64(256) + i0_i1_i2_i3_fused_2 < T.int64(394240))
                        T.reads(A[v_i0, v_i1, v_i2, v_i3], T_softmax_maxelem[v_i0, v_i1, v_i2])
                        T.writes(T_softmax_exp[v_i0, v_i1, v_i2, v_i3])
                        T_softmax_exp[v_i0, v_i1, v_i2, v_i3] = T.exp(A[v_i0, v_i1, v_i2, v_i3] - T_softmax_maxelem[v_i0, v_i1, v_i2])
        for i0_i1_i2_fused_0 in T.thread_binding(T.int64(20), thread="blockIdx.x"):
            for i0_i1_i2_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for k in range(T.int64(77)):
                    with T.block("T_softmax_expsum"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(20), (i0_i1_i2_fused_0 * T.int64(256) + i0_i1_i2_fused_1) // T.int64(256))
                        v_i2 = T.axis.spatial(T.int64(256), (i0_i1_i2_fused_0 * T.int64(256) + i0_i1_i2_fused_1) % T.int64(256))
                        v_k = T.axis.reduce(T.int64(77), k)
                        T.reads(T_softmax_exp[v_i0, v_i1, v_i2, v_k])
                        T.writes(T_softmax_expsum[v_i0, v_i1, v_i2])
                        with T.init():
                            T_softmax_expsum[v_i0, v_i1, v_i2] = T.float32(0)
                        T_softmax_expsum[v_i0, v_i1, v_i2] = T_softmax_expsum[v_i0, v_i1, v_i2] + T_softmax_exp[v_i0, v_i1, v_i2, v_k]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(7)):
                    with T.block("T_softmax_norm"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(20), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(19712))
                        v_i2 = T.axis.spatial(T.int64(256), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(19712) // T.int64(77))
                        v_i3 = T.axis.spatial(T.int64(77), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(77))
                        T.where((i0_i1_i2_i3_fused_0 * T.int64(256) + i0_i1_i2_i3_fused_1) * T.int64(256) + i0_i1_i2_i3_fused_2 < T.int64(394240))
                        T.reads(T_softmax_exp[v_i0, v_i1, v_i2, v_i3], T_softmax_expsum[v_i0, v_i1, v_i2])
                        T.writes(T_softmax_norm[v_i0, v_i1, v_i2, v_i3])
                        T.block_attr({"axis": 3})
                        T_softmax_norm[v_i0, v_i1, v_i2, v_i3] = T_softmax_exp[v_i0, v_i1, v_i2, v_i3] / T_softmax_expsum[v_i0, v_i1, v_i2]

    @T.prim_func(private=True)
    def softmax5(A: T.Buffer((T.int64(1), T.int64(1), T.int64(4096), T.int64(4096)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1), T.int64(4096), T.int64(4096)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(4096)))
        T_softmax_exp = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(4096), T.int64(4096)))
        T_softmax_expsum = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(4096)))
        for i0_i1_i2_fused_0 in T.thread_binding(T.int64(16), thread="blockIdx.x"):
            for i0_i1_i2_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for k in range(T.int64(4096)):
                    with T.block("T_softmax_maxelem"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i2 = T.axis.spatial(T.int64(4096), i0_i1_i2_fused_0 * T.int64(256) + i0_i1_i2_fused_1)
                        v_k = T.axis.reduce(T.int64(4096), k)
                        T.reads(A[v_i0, v_i1, v_i2, v_k])
                        T.writes(T_softmax_maxelem[v_i0, v_i1, v_i2])
                        with T.init():
                            T_softmax_maxelem[v_i0, v_i1, v_i2] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem[v_i0, v_i1, v_i2] = T.max(T_softmax_maxelem[v_i0, v_i1, v_i2], A[v_i0, v_i1, v_i2, v_k])
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(256)):
                    with T.block("T_softmax_exp"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i2 = T.axis.spatial(T.int64(4096), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(4096))
                        v_i3 = T.axis.spatial(T.int64(4096), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(4096))
                        T.reads(A[v_i0, v_i1, v_i2, v_i3], T_softmax_maxelem[v_i0, v_i1, v_i2])
                        T.writes(T_softmax_exp[v_i0, v_i1, v_i2, v_i3])
                        T_softmax_exp[v_i0, v_i1, v_i2, v_i3] = T.exp(A[v_i0, v_i1, v_i2, v_i3] - T_softmax_maxelem[v_i0, v_i1, v_i2])
        for i0_i1_i2_fused_0 in T.thread_binding(T.int64(16), thread="blockIdx.x"):
            for i0_i1_i2_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for k in range(T.int64(4096)):
                    with T.block("T_softmax_expsum"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i2 = T.axis.spatial(T.int64(4096), i0_i1_i2_fused_0 * T.int64(256) + i0_i1_i2_fused_1)
                        v_k = T.axis.reduce(T.int64(4096), k)
                        T.reads(T_softmax_exp[v_i0, v_i1, v_i2, v_k])
                        T.writes(T_softmax_expsum[v_i0, v_i1, v_i2])
                        with T.init():
                            T_softmax_expsum[v_i0, v_i1, v_i2] = T.float32(0)
                        T_softmax_expsum[v_i0, v_i1, v_i2] = T_softmax_expsum[v_i0, v_i1, v_i2] + T_softmax_exp[v_i0, v_i1, v_i2, v_k]
        for i0_i1_i2_i3_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_i3_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_i3_fused_0 in range(T.int64(256)):
                    with T.block("T_softmax_norm"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i2 = T.axis.spatial(T.int64(4096), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) // T.int64(4096))
                        v_i3 = T.axis.spatial(T.int64(4096), (i0_i1_i2_i3_fused_0 * T.int64(65536) + i0_i1_i2_i3_fused_1 * T.int64(256) + i0_i1_i2_i3_fused_2) % T.int64(4096))
                        T.reads(T_softmax_exp[v_i0, v_i1, v_i2, v_i3], T_softmax_expsum[v_i0, v_i1, v_i2])
                        T.writes(T_softmax_norm[v_i0, v_i1, v_i2, v_i3])
                        T.block_attr({"axis": 3})
                        T_softmax_norm[v_i0, v_i1, v_i2, v_i3] = T_softmax_exp[v_i0, v_i1, v_i2, v_i3] / T_softmax_expsum[v_i0, v_i1, v_i2]

    @T.prim_func(private=True)
    def softmax6(A: T.Buffer((T.int64(12), T.int64(77), T.int64(77)), "float32"), T_softmax_norm: T.Buffer((T.int64(12), T.int64(77), T.int64(77)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(12), T.int64(77)))
        T_softmax_exp = T.alloc_buffer((T.int64(12), T.int64(77), T.int64(77)))
        T_softmax_expsum = T.alloc_buffer((T.int64(12), T.int64(77)))
        for i0_i1_fused_0 in T.thread_binding(T.int64(4), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for k in range(T.int64(77)):
                    with T.block("T_softmax_maxelem"):
                        v_i0 = T.axis.spatial(T.int64(12), (i0_i1_fused_0 * T.int64(256) + i0_i1_fused_1) // T.int64(77))
                        v_i1 = T.axis.spatial(T.int64(77), (i0_i1_fused_0 * T.int64(256) + i0_i1_fused_1) % T.int64(77))
                        v_k = T.axis.reduce(T.int64(77), k)
                        T.where(i0_i1_fused_0 * T.int64(256) + i0_i1_fused_1 < T.int64(924))
                        T.reads(A[v_i0, v_i1, v_k])
                        T.writes(T_softmax_maxelem[v_i0, v_i1])
                        with T.init():
                            T_softmax_maxelem[v_i0, v_i1] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem[v_i0, v_i1] = T.max(T_softmax_maxelem[v_i0, v_i1], A[v_i0, v_i1, v_k])
        for i0_i1_i2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_fused_0 in range(T.int64(2)):
                    with T.block("T_softmax_exp"):
                        v_i0 = T.axis.spatial(T.int64(12), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) // T.int64(5929))
                        v_i1 = T.axis.spatial(T.int64(77), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) % T.int64(5929) // T.int64(77))
                        v_i2 = T.axis.spatial(T.int64(77), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) % T.int64(77))
                        T.where((i0_i1_i2_fused_0 * T.int64(256) + i0_i1_i2_fused_1) * T.int64(256) + i0_i1_i2_fused_2 < T.int64(71148))
                        T.reads(A[v_i0, v_i1, v_i2], T_softmax_maxelem[v_i0, v_i1])
                        T.writes(T_softmax_exp[v_i0, v_i1, v_i2])
                        T_softmax_exp[v_i0, v_i1, v_i2] = T.exp(A[v_i0, v_i1, v_i2] - T_softmax_maxelem[v_i0, v_i1])
        for i0_i1_fused_0 in T.thread_binding(T.int64(4), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for k in range(T.int64(77)):
                    with T.block("T_softmax_expsum"):
                        v_i0 = T.axis.spatial(T.int64(12), (i0_i1_fused_0 * T.int64(256) + i0_i1_fused_1) // T.int64(77))
                        v_i1 = T.axis.spatial(T.int64(77), (i0_i1_fused_0 * T.int64(256) + i0_i1_fused_1) % T.int64(77))
                        v_k = T.axis.reduce(T.int64(77), k)
                        T.where(i0_i1_fused_0 * T.int64(256) + i0_i1_fused_1 < T.int64(924))
                        T.reads(T_softmax_exp[v_i0, v_i1, v_k])
                        T.writes(T_softmax_expsum[v_i0, v_i1])
                        with T.init():
                            T_softmax_expsum[v_i0, v_i1] = T.float32(0)
                        T_softmax_expsum[v_i0, v_i1] = T_softmax_expsum[v_i0, v_i1] + T_softmax_exp[v_i0, v_i1, v_k]
        for i0_i1_i2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for i0_i1_i2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for i0_i1_i2_fused_0 in range(T.int64(2)):
                    with T.block("T_softmax_norm"):
                        v_i0 = T.axis.spatial(T.int64(12), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) // T.int64(5929))
                        v_i1 = T.axis.spatial(T.int64(77), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) % T.int64(5929) // T.int64(77))
                        v_i2 = T.axis.spatial(T.int64(77), (i0_i1_i2_fused_0 * T.int64(65536) + i0_i1_i2_fused_1 * T.int64(256) + i0_i1_i2_fused_2) % T.int64(77))
                        T.where((i0_i1_i2_fused_0 * T.int64(256) + i0_i1_i2_fused_1) * T.int64(256) + i0_i1_i2_fused_2 < T.int64(71148))
                        T.reads(T_softmax_exp[v_i0, v_i1, v_i2], T_softmax_expsum[v_i0, v_i1])
                        T.writes(T_softmax_norm[v_i0, v_i1, v_i2])
                        T.block_attr({"axis": 2})
                        T_softmax_norm[v_i0, v_i1, v_i2] = T_softmax_exp[v_i0, v_i1, v_i2] / T_softmax_expsum[v_i0, v_i1]

    @T.prim_func(private=True)
    def squeeze(A: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32"), T_squeeze: T.Buffer((T.int64(77), T.int64(1280)), "float32")):
        T.func_attr({"op_pattern": 1, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_fused_0 in range(T.int64(2)):
                    with T.block("T_squeeze"):
                        v_ax0 = T.axis.spatial(T.int64(77), (ax0_ax1_fused_0 * T.int64(65536) + ax0_ax1_fused_1 * T.int64(256) + ax0_ax1_fused_2) // T.int64(1280))
                        v_ax1 = T.axis.spatial(T.int64(1280), (ax0_ax1_fused_0 * T.int64(65536) + ax0_ax1_fused_1 * T.int64(256) + ax0_ax1_fused_2) % T.int64(1280))
                        T.where((ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) * T.int64(256) + ax0_ax1_fused_2 < T.int64(98560))
                        T.reads(A[T.int64(0), v_ax0, v_ax1])
                        T.writes(T_squeeze[v_ax0, v_ax1])
                        T_squeeze[v_ax0, v_ax1] = A[T.int64(0), v_ax0, v_ax1]

    @T.prim_func(private=True)
    def subtract(A: T.Buffer((T.int64(1), T.int64(4), T.int64(64), T.int64(64)), "float32"), B: T.Buffer((T.int64(1), T.int64(4), T.int64(64), T.int64(64)), "float32"), T_subtract: T.Buffer((T.int64(1), T.int64(4), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"op_pattern": 0, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0_ax1_ax2_ax3_fused_0 in T.thread_binding(T.int64(64), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_subtract"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) // T.int64(4096))
                    v_ax2 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(4096) // T.int64(64))
                    v_ax3 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(64))
                    T.reads(A[v_ax0, v_ax1, v_ax2, v_ax3], B[v_ax0, v_ax1, v_ax2, v_ax3])
                    T.writes(T_subtract[v_ax0, v_ax1, v_ax2, v_ax3])
                    T_subtract[v_ax0, v_ax1, v_ax2, v_ax3] = A[v_ax0, v_ax1, v_ax2, v_ax3] - B[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def subtract1(A: T.Buffer((), "float32"), B: T.Buffer((), "float32"), T_subtract: T.Buffer((), "float32")):
        T.func_attr({"op_pattern": 0, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for u_fused_0 in T.thread_binding(1, thread="blockIdx.x"):
            for u_fused_1 in T.thread_binding(1, thread="threadIdx.x"):
                with T.block("T_subtract"):
                    vi = T.axis.spatial(1, T.int64(0))
                    T.reads(A[()], B[()])
                    T.writes(T_subtract[()])
                    T_subtract[()] = A[()] - B[()]

    @T.prim_func(private=True)
    def take(A: T.Buffer((T.int64(49408), T.int64(1280)), "float32"), B: T.Buffer((T.int64(77),), "int32"), T_take: T.Buffer((T.int64(77), T.int64(1280)), "float32")):
        T.func_attr({"op_pattern": 8, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_fused_0 in range(T.int64(2)):
                    with T.block("T_take"):
                        v_ax0 = T.axis.spatial(T.int64(77), (ax0_ax1_fused_0 * T.int64(65536) + ax0_ax1_fused_1 * T.int64(256) + ax0_ax1_fused_2) // T.int64(1280))
                        v_ax1 = T.axis.spatial(T.int64(1280), (ax0_ax1_fused_0 * T.int64(65536) + ax0_ax1_fused_1 * T.int64(256) + ax0_ax1_fused_2) % T.int64(1280))
                        T.where((ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) * T.int64(256) + ax0_ax1_fused_2 < T.int64(98560))
                        T.reads(A[B[v_ax0], v_ax1], B[v_ax0])
                        T.writes(T_take[v_ax0, v_ax1])
                        T_take[v_ax0, v_ax1] = A[B[v_ax0], v_ax1]

    @T.prim_func(private=True)
    def take2(A: T.Buffer((T.int64(77), T.int64(1280)), "float32"), B: T.Buffer((T.int64(1),), "int64"), T_take: T.Buffer((T.int64(1), T.int64(1280)), "float32")):
        T.func_attr({"op_pattern": 8, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(5), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_take"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(1280), ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1)
                    T.reads(A[B[v_ax0], v_ax1], B[v_ax0])
                    T.writes(T_take[v_ax0, v_ax1])
                    T_take[v_ax0, v_ax1] = A[B[v_ax0], v_ax1]

    @T.prim_func(private=True)
    def take3(A: T.Buffer((T.int64(49408), T.int64(768)), "float32"), B: T.Buffer((T.int64(77),), "int32"), T_take: T.Buffer((T.int64(77), T.int64(768)), "float32")):
        T.func_attr({"op_pattern": 8, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0_ax1_fused_0 in T.thread_binding(T.int64(231), thread="blockIdx.x"):
            for ax0_ax1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_take"):
                    v_ax0 = T.axis.spatial(T.int64(77), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) // T.int64(768))
                    v_ax1 = T.axis.spatial(T.int64(768), (ax0_ax1_fused_0 * T.int64(256) + ax0_ax1_fused_1) % T.int64(768))
                    T.reads(A[B[v_ax0], v_ax1], B[v_ax0])
                    T.writes(T_take[v_ax0, v_ax1])
                    T_take[v_ax0, v_ax1] = A[B[v_ax0], v_ax1]

    @T.prim_func(private=True)
    def tir_image_to_rgba(A: T.Buffer((T.int64(1), T.int64(512), T.int64(512), T.int64(3)), "float32"), image_to_rgba: T.Buffer((T.int64(512), T.int64(512)), "uint32")):
        T.func_attr({"op_pattern": 2, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for y_x_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for y_x_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for y_x_fused_0 in range(T.int64(4)):
                    with T.block("image_to_rgba"):
                        v_y = T.axis.spatial(T.int64(512), (y_x_fused_0 * T.int64(65536) + y_x_fused_1 * T.int64(256) + y_x_fused_2) // T.int64(512))
                        v_x = T.axis.spatial(T.int64(512), (y_x_fused_0 * T.int64(65536) + y_x_fused_1 * T.int64(256) + y_x_fused_2) % T.int64(512))
                        T.reads(A[T.int64(0), v_y, v_x, T.int64(0):T.int64(3)])
                        T.writes(image_to_rgba[v_y, v_x])
                        image_to_rgba[v_y, v_x] = T.bitwise_or(T.bitwise_or(T.bitwise_or(T.Cast("uint32", A[T.int64(0), v_y, v_x, T.int64(0)]), T.shift_left(T.Cast("uint32", A[T.int64(0), v_y, v_x, T.int64(1)]), T.uint32(8))), T.shift_left(T.Cast("uint32", A[T.int64(0), v_y, v_x, T.int64(2)]), T.uint32(16))), T.uint32(4278190080))

    @T.prim_func(private=True)
    def transpose29(A: T.Buffer((T.int64(1), T.int64(512), T.int64(4096)), "float32"), T_transpose: T.Buffer((T.int64(1), T.int64(4096), T.int64(512)), "float32")):
        T.func_attr({"op_pattern": 2, "tir.is_scheduled": T.bool(True), "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ax0_ax1_ax2_fused_2 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0_ax1_ax2_fused_0 in range(T.int64(32)):
                    with T.block("T_transpose"):
                        v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_ax1 = T.axis.spatial(T.int64(4096), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) // T.int64(512))
                        v_ax2 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_fused_0 * T.int64(65536) + ax0_ax1_ax2_fused_1 * T.int64(256) + ax0_ax1_ax2_fused_2) % T.int64(512))
                        T.reads(A[v_ax0, v_ax2, v_ax1])
                        T.writes(T_transpose[v_ax0, v_ax1, v_ax2])
                        T_transpose[v_ax0, v_ax1, v_ax2] = A[v_ax0, v_ax2, v_ax1]

    @R.function
    def cat_latents(latents: R.Tensor((1, 4, 64, 64), dtype="float32")) -> R.Tensor((2, 4, 64, 64), dtype="float32"):
        cls = Module
        gv = R.call_tir(cls.concatenate12, (latents, latents), out_sinfo=R.Tensor((2, 4, 64, 64), dtype="float32"))
        return gv

    @R.function
    def clip(inp_0: R.Tensor((1, 77), dtype="int32"), model_params: R.Tuple(R.Tensor((49408, 768), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((3072,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((3072,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((3072,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((3072,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((3072,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((3072,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((3072,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((3072,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((3072,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((3072,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((3072,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((3072,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((77, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 3072), dtype="float32"), R.Tensor((3072, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 3072), dtype="float32"), R.Tensor((3072, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 3072), dtype="float32"), R.Tensor((3072, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 3072), dtype="float32"), R.Tensor((3072, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 3072), dtype="float32"), R.Tensor((3072, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 3072), dtype="float32"), R.Tensor((3072, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 3072), dtype="float32"), R.Tensor((3072, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 3072), dtype="float32"), R.Tensor((3072, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 3072), dtype="float32"), R.Tensor((3072, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 3072), dtype="float32"), R.Tensor((3072, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 3072), dtype="float32"), R.Tensor((3072, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 3072), dtype="float32"), R.Tensor((3072, 768), dtype="float32"))) -> R.Tuple(R.Tensor((1, 77, 768), dtype="float32"), R.Tensor((1, 77, 768), dtype="float32")):
        R.func_attr({"global_symbol": "subgraph_0", "num_input": 1})
        cls = Module
        with R.dataflow():
            lv1667 = R.call_tir(cls.fused_reshape_cast_reshape1, (inp_0,), out_sinfo=R.Tensor((77,), dtype="int32"))
            lv140: R.Tensor((49408, 768), dtype="float32") = model_params[0]
            lv3 = R.call_tir(cls.take3, (lv140, lv1667), out_sinfo=R.Tensor((77, 768), dtype="float32"))
            lv141: R.Tensor((77, 768), dtype="float32") = model_params[123]
            lv1668 = R.call_tir(cls.fused_reshape42_reshape42_add41, (lv3, lv141), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv142: R.Tensor((768,), dtype="float32") = model_params[2]
            lv143: R.Tensor((768,), dtype="float32") = model_params[1]
            lv21 = R.call_tir(cls.layer_norm3, (lv1668, lv142, lv143), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv144: R.Tensor((768, 768), dtype="float32") = model_params[124]
            lv145: R.Tensor((768,), dtype="float32") = model_params[9]
            lv1669 = R.call_tir(cls.fused_matmul29_add42_multiply17, (lv21, lv144, lv145), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv146: R.Tensor((768, 768), dtype="float32") = model_params[125]
            lv147: R.Tensor((768,), dtype="float32") = model_params[7]
            lv1670 = R.call_tir(cls.fused_matmul29_add42, (lv21, lv146, lv147), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv1671 = R.call_tir(cls.fused_reshape43_transpose37_reshape44_transpose38, (lv1670,), out_sinfo=R.Tensor((12, 64, 77), dtype="float32"))
            lv148: R.Tensor((768, 768), dtype="float32") = model_params[126]
            lv149: R.Tensor((768,), dtype="float32") = model_params[10]
            lv1672 = R.call_tir(cls.fused_matmul29_add42, (lv21, lv148, lv149), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv1673 = R.call_tir(cls.fused_reshape43_transpose37_reshape44, (lv1672,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv1674 = R.call_tir(cls.fused_reshape43_transpose37_reshape44, (lv1669,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv42 = R.call_tir(cls.matmul30, (lv1674, lv1671), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv1675 = R.call_tir(cls.fused_reshape45_add43_reshape46, (lv42, metadata["relax.expr.Constant"][0]), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv46 = R.call_tir(cls.softmax6, (lv1675,), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv47 = R.call_tir(cls.matmul31, (lv46, lv1673), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv1676 = R.call_tir(cls.fused_reshape47_transpose39_reshape48, (lv47,), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv150: R.Tensor((768, 768), dtype="float32") = model_params[127]
            lv151: R.Tensor((768,), dtype="float32") = model_params[8]
            lv1677 = R.call_tir(cls.fused_matmul29_add42_add41, (lv1676, lv150, lv151, lv1668), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv152: R.Tensor((768,), dtype="float32") = model_params[4]
            lv153: R.Tensor((768,), dtype="float32") = model_params[3]
            lv55 = R.call_tir(cls.layer_norm3, (lv1677, lv152, lv153), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv154: R.Tensor((768, 3072), dtype="float32") = model_params[128]
            lv155: R.Tensor((3072,), dtype="float32") = model_params[5]
            lv1678 = R.call_tir(cls.fused_matmul32_add44_multiply18_tir_sigmoid_multiply19, (lv55, lv154, lv155), out_sinfo=R.Tensor((1, 77, 3072), dtype="float32"))
            lv156: R.Tensor((3072, 768), dtype="float32") = model_params[129]
            lv157: R.Tensor((768,), dtype="float32") = model_params[6]
            lv1679 = R.call_tir(cls.fused_matmul33_add42_add41, (lv1678, lv156, lv157, lv1677), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv158: R.Tensor((768,), dtype="float32") = model_params[32]
            lv159: R.Tensor((768,), dtype="float32") = model_params[31]
            lv66 = R.call_tir(cls.layer_norm3, (lv1679, lv158, lv159), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv160: R.Tensor((768, 768), dtype="float32") = model_params[130]
            lv161: R.Tensor((768,), dtype="float32") = model_params[39]
            lv1680 = R.call_tir(cls.fused_matmul29_add42_multiply17, (lv66, lv160, lv161), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv162: R.Tensor((768, 768), dtype="float32") = model_params[131]
            lv163: R.Tensor((768,), dtype="float32") = model_params[37]
            lv1681 = R.call_tir(cls.fused_matmul29_add42, (lv66, lv162, lv163), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv1682 = R.call_tir(cls.fused_reshape43_transpose37_reshape44_transpose38, (lv1681,), out_sinfo=R.Tensor((12, 64, 77), dtype="float32"))
            lv164: R.Tensor((768, 768), dtype="float32") = model_params[132]
            lv165: R.Tensor((768,), dtype="float32") = model_params[40]
            lv1683 = R.call_tir(cls.fused_matmul29_add42, (lv66, lv164, lv165), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv1684 = R.call_tir(cls.fused_reshape43_transpose37_reshape44, (lv1683,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv1685 = R.call_tir(cls.fused_reshape43_transpose37_reshape44, (lv1680,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv87 = R.call_tir(cls.matmul30, (lv1685, lv1682), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv1686 = R.call_tir(cls.fused_reshape45_add43_reshape46, (lv87, metadata["relax.expr.Constant"][0]), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv91 = R.call_tir(cls.softmax6, (lv1686,), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv92 = R.call_tir(cls.matmul31, (lv91, lv1684), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv1687 = R.call_tir(cls.fused_reshape47_transpose39_reshape48, (lv92,), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv166: R.Tensor((768, 768), dtype="float32") = model_params[133]
            lv167: R.Tensor((768,), dtype="float32") = model_params[38]
            lv1688 = R.call_tir(cls.fused_matmul29_add42_add41, (lv1687, lv166, lv167, lv1679), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv168: R.Tensor((768,), dtype="float32") = model_params[34]
            lv169: R.Tensor((768,), dtype="float32") = model_params[33]
            lv100 = R.call_tir(cls.layer_norm3, (lv1688, lv168, lv169), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv170: R.Tensor((768, 3072), dtype="float32") = model_params[134]
            lv171: R.Tensor((3072,), dtype="float32") = model_params[35]
            lv1689 = R.call_tir(cls.fused_matmul32_add44_multiply18_tir_sigmoid_multiply19, (lv100, lv170, lv171), out_sinfo=R.Tensor((1, 77, 3072), dtype="float32"))
            lv172: R.Tensor((3072, 768), dtype="float32") = model_params[135]
            lv173: R.Tensor((768,), dtype="float32") = model_params[36]
            lv1690 = R.call_tir(cls.fused_matmul33_add42_add41, (lv1689, lv172, lv173, lv1688), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv174: R.Tensor((768,), dtype="float32") = model_params[42]
            lv175: R.Tensor((768,), dtype="float32") = model_params[41]
            lv111 = R.call_tir(cls.layer_norm3, (lv1690, lv174, lv175), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv176: R.Tensor((768, 768), dtype="float32") = model_params[136]
            lv177: R.Tensor((768,), dtype="float32") = model_params[49]
            lv1691 = R.call_tir(cls.fused_matmul29_add42_multiply17, (lv111, lv176, lv177), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv178: R.Tensor((768, 768), dtype="float32") = model_params[137]
            lv179: R.Tensor((768,), dtype="float32") = model_params[47]
            lv1692 = R.call_tir(cls.fused_matmul29_add42, (lv111, lv178, lv179), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv1693 = R.call_tir(cls.fused_reshape43_transpose37_reshape44_transpose38, (lv1692,), out_sinfo=R.Tensor((12, 64, 77), dtype="float32"))
            lv180: R.Tensor((768, 768), dtype="float32") = model_params[138]
            lv181: R.Tensor((768,), dtype="float32") = model_params[50]
            lv1694 = R.call_tir(cls.fused_matmul29_add42, (lv111, lv180, lv181), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv1695 = R.call_tir(cls.fused_reshape43_transpose37_reshape44, (lv1694,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv1696 = R.call_tir(cls.fused_reshape43_transpose37_reshape44, (lv1691,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv132 = R.call_tir(cls.matmul30, (lv1696, lv1693), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv1697 = R.call_tir(cls.fused_reshape45_add43_reshape46, (lv132, metadata["relax.expr.Constant"][0]), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv136 = R.call_tir(cls.softmax6, (lv1697,), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv137 = R.call_tir(cls.matmul31, (lv136, lv1695), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv1698 = R.call_tir(cls.fused_reshape47_transpose39_reshape48, (lv137,), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv182: R.Tensor((768, 768), dtype="float32") = model_params[139]
            lv183: R.Tensor((768,), dtype="float32") = model_params[48]
            lv1699 = R.call_tir(cls.fused_matmul29_add42_add41, (lv1698, lv182, lv183, lv1690), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv184: R.Tensor((768,), dtype="float32") = model_params[44]
            lv185: R.Tensor((768,), dtype="float32") = model_params[43]
            lv145_1 = R.call_tir(cls.layer_norm3, (lv1699, lv184, lv185), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv186: R.Tensor((768, 3072), dtype="float32") = model_params[140]
            lv187: R.Tensor((3072,), dtype="float32") = model_params[45]
            lv1700 = R.call_tir(cls.fused_matmul32_add44_multiply18_tir_sigmoid_multiply19, (lv145_1, lv186, lv187), out_sinfo=R.Tensor((1, 77, 3072), dtype="float32"))
            lv188: R.Tensor((3072, 768), dtype="float32") = model_params[141]
            lv189: R.Tensor((768,), dtype="float32") = model_params[46]
            lv1701 = R.call_tir(cls.fused_matmul33_add42_add41, (lv1700, lv188, lv189, lv1699), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv190: R.Tensor((768,), dtype="float32") = model_params[52]
            lv191: R.Tensor((768,), dtype="float32") = model_params[51]
            lv156_1 = R.call_tir(cls.layer_norm3, (lv1701, lv190, lv191), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv192: R.Tensor((768, 768), dtype="float32") = model_params[142]
            lv193: R.Tensor((768,), dtype="float32") = model_params[59]
            lv1702 = R.call_tir(cls.fused_matmul29_add42_multiply17, (lv156_1, lv192, lv193), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv194: R.Tensor((768, 768), dtype="float32") = model_params[143]
            lv195: R.Tensor((768,), dtype="float32") = model_params[57]
            lv1703 = R.call_tir(cls.fused_matmul29_add42, (lv156_1, lv194, lv195), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv1704 = R.call_tir(cls.fused_reshape43_transpose37_reshape44_transpose38, (lv1703,), out_sinfo=R.Tensor((12, 64, 77), dtype="float32"))
            lv196: R.Tensor((768, 768), dtype="float32") = model_params[144]
            lv197: R.Tensor((768,), dtype="float32") = model_params[60]
            lv1705 = R.call_tir(cls.fused_matmul29_add42, (lv156_1, lv196, lv197), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv1706 = R.call_tir(cls.fused_reshape43_transpose37_reshape44, (lv1705,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv1707 = R.call_tir(cls.fused_reshape43_transpose37_reshape44, (lv1702,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv177_1 = R.call_tir(cls.matmul30, (lv1707, lv1704), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv1708 = R.call_tir(cls.fused_reshape45_add43_reshape46, (lv177_1, metadata["relax.expr.Constant"][0]), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv181_1 = R.call_tir(cls.softmax6, (lv1708,), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv182_1 = R.call_tir(cls.matmul31, (lv181_1, lv1706), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv1709 = R.call_tir(cls.fused_reshape47_transpose39_reshape48, (lv182_1,), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv198: R.Tensor((768, 768), dtype="float32") = model_params[145]
            lv199: R.Tensor((768,), dtype="float32") = model_params[58]
            lv1710 = R.call_tir(cls.fused_matmul29_add42_add41, (lv1709, lv198, lv199, lv1701), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv200: R.Tensor((768,), dtype="float32") = model_params[54]
            lv201: R.Tensor((768,), dtype="float32") = model_params[53]
            lv190_1 = R.call_tir(cls.layer_norm3, (lv1710, lv200, lv201), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv202: R.Tensor((768, 3072), dtype="float32") = model_params[146]
            lv203: R.Tensor((3072,), dtype="float32") = model_params[55]
            lv1711 = R.call_tir(cls.fused_matmul32_add44_multiply18_tir_sigmoid_multiply19, (lv190_1, lv202, lv203), out_sinfo=R.Tensor((1, 77, 3072), dtype="float32"))
            lv204: R.Tensor((3072, 768), dtype="float32") = model_params[147]
            lv205: R.Tensor((768,), dtype="float32") = model_params[56]
            lv1712 = R.call_tir(cls.fused_matmul33_add42_add41, (lv1711, lv204, lv205, lv1710), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv206: R.Tensor((768,), dtype="float32") = model_params[62]
            lv207: R.Tensor((768,), dtype="float32") = model_params[61]
            lv201_1 = R.call_tir(cls.layer_norm3, (lv1712, lv206, lv207), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv208: R.Tensor((768, 768), dtype="float32") = model_params[148]
            lv209: R.Tensor((768,), dtype="float32") = model_params[69]
            lv1713 = R.call_tir(cls.fused_matmul29_add42_multiply17, (lv201_1, lv208, lv209), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv210: R.Tensor((768, 768), dtype="float32") = model_params[149]
            lv211: R.Tensor((768,), dtype="float32") = model_params[67]
            lv1714 = R.call_tir(cls.fused_matmul29_add42, (lv201_1, lv210, lv211), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv1715 = R.call_tir(cls.fused_reshape43_transpose37_reshape44_transpose38, (lv1714,), out_sinfo=R.Tensor((12, 64, 77), dtype="float32"))
            lv212: R.Tensor((768, 768), dtype="float32") = model_params[150]
            lv213: R.Tensor((768,), dtype="float32") = model_params[70]
            lv1716 = R.call_tir(cls.fused_matmul29_add42, (lv201_1, lv212, lv213), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv1717 = R.call_tir(cls.fused_reshape43_transpose37_reshape44, (lv1716,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv1718 = R.call_tir(cls.fused_reshape43_transpose37_reshape44, (lv1713,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv222 = R.call_tir(cls.matmul30, (lv1718, lv1715), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv1719 = R.call_tir(cls.fused_reshape45_add43_reshape46, (lv222, metadata["relax.expr.Constant"][0]), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv226 = R.call_tir(cls.softmax6, (lv1719,), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv227 = R.call_tir(cls.matmul31, (lv226, lv1717), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv1720 = R.call_tir(cls.fused_reshape47_transpose39_reshape48, (lv227,), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv214: R.Tensor((768, 768), dtype="float32") = model_params[151]
            lv215: R.Tensor((768,), dtype="float32") = model_params[68]
            lv1721 = R.call_tir(cls.fused_matmul29_add42_add41, (lv1720, lv214, lv215, lv1712), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv216: R.Tensor((768,), dtype="float32") = model_params[64]
            lv217: R.Tensor((768,), dtype="float32") = model_params[63]
            lv235 = R.call_tir(cls.layer_norm3, (lv1721, lv216, lv217), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv218: R.Tensor((768, 3072), dtype="float32") = model_params[152]
            lv219: R.Tensor((3072,), dtype="float32") = model_params[65]
            lv1722 = R.call_tir(cls.fused_matmul32_add44_multiply18_tir_sigmoid_multiply19, (lv235, lv218, lv219), out_sinfo=R.Tensor((1, 77, 3072), dtype="float32"))
            lv220: R.Tensor((3072, 768), dtype="float32") = model_params[153]
            lv221: R.Tensor((768,), dtype="float32") = model_params[66]
            lv1723 = R.call_tir(cls.fused_matmul33_add42_add41, (lv1722, lv220, lv221, lv1721), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv222_1: R.Tensor((768,), dtype="float32") = model_params[72]
            lv223: R.Tensor((768,), dtype="float32") = model_params[71]
            lv246 = R.call_tir(cls.layer_norm3, (lv1723, lv222_1, lv223), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv224: R.Tensor((768, 768), dtype="float32") = model_params[154]
            lv225: R.Tensor((768,), dtype="float32") = model_params[79]
            lv1724 = R.call_tir(cls.fused_matmul29_add42_multiply17, (lv246, lv224, lv225), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv226_1: R.Tensor((768, 768), dtype="float32") = model_params[155]
            lv227_1: R.Tensor((768,), dtype="float32") = model_params[77]
            lv1725 = R.call_tir(cls.fused_matmul29_add42, (lv246, lv226_1, lv227_1), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv1726 = R.call_tir(cls.fused_reshape43_transpose37_reshape44_transpose38, (lv1725,), out_sinfo=R.Tensor((12, 64, 77), dtype="float32"))
            lv228: R.Tensor((768, 768), dtype="float32") = model_params[156]
            lv229: R.Tensor((768,), dtype="float32") = model_params[80]
            lv1727 = R.call_tir(cls.fused_matmul29_add42, (lv246, lv228, lv229), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv1728 = R.call_tir(cls.fused_reshape43_transpose37_reshape44, (lv1727,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv1729 = R.call_tir(cls.fused_reshape43_transpose37_reshape44, (lv1724,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv267 = R.call_tir(cls.matmul30, (lv1729, lv1726), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv1730 = R.call_tir(cls.fused_reshape45_add43_reshape46, (lv267, metadata["relax.expr.Constant"][0]), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv271 = R.call_tir(cls.softmax6, (lv1730,), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv272 = R.call_tir(cls.matmul31, (lv271, lv1728), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv1731 = R.call_tir(cls.fused_reshape47_transpose39_reshape48, (lv272,), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv230: R.Tensor((768, 768), dtype="float32") = model_params[157]
            lv231: R.Tensor((768,), dtype="float32") = model_params[78]
            lv1732 = R.call_tir(cls.fused_matmul29_add42_add41, (lv1731, lv230, lv231, lv1723), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv232: R.Tensor((768,), dtype="float32") = model_params[74]
            lv233: R.Tensor((768,), dtype="float32") = model_params[73]
            lv280 = R.call_tir(cls.layer_norm3, (lv1732, lv232, lv233), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv234: R.Tensor((768, 3072), dtype="float32") = model_params[158]
            lv235_1: R.Tensor((3072,), dtype="float32") = model_params[75]
            lv1733 = R.call_tir(cls.fused_matmul32_add44_multiply18_tir_sigmoid_multiply19, (lv280, lv234, lv235_1), out_sinfo=R.Tensor((1, 77, 3072), dtype="float32"))
            lv236: R.Tensor((3072, 768), dtype="float32") = model_params[159]
            lv237: R.Tensor((768,), dtype="float32") = model_params[76]
            lv1734 = R.call_tir(cls.fused_matmul33_add42_add41, (lv1733, lv236, lv237, lv1732), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv238: R.Tensor((768,), dtype="float32") = model_params[82]
            lv239: R.Tensor((768,), dtype="float32") = model_params[81]
            lv291 = R.call_tir(cls.layer_norm3, (lv1734, lv238, lv239), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv240: R.Tensor((768, 768), dtype="float32") = model_params[160]
            lv241: R.Tensor((768,), dtype="float32") = model_params[89]
            lv1735 = R.call_tir(cls.fused_matmul29_add42_multiply17, (lv291, lv240, lv241), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv242: R.Tensor((768, 768), dtype="float32") = model_params[161]
            lv243: R.Tensor((768,), dtype="float32") = model_params[87]
            lv1736 = R.call_tir(cls.fused_matmul29_add42, (lv291, lv242, lv243), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv1737 = R.call_tir(cls.fused_reshape43_transpose37_reshape44_transpose38, (lv1736,), out_sinfo=R.Tensor((12, 64, 77), dtype="float32"))
            lv244: R.Tensor((768, 768), dtype="float32") = model_params[162]
            lv245: R.Tensor((768,), dtype="float32") = model_params[90]
            lv1738 = R.call_tir(cls.fused_matmul29_add42, (lv291, lv244, lv245), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv1739 = R.call_tir(cls.fused_reshape43_transpose37_reshape44, (lv1738,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv1740 = R.call_tir(cls.fused_reshape43_transpose37_reshape44, (lv1735,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv312 = R.call_tir(cls.matmul30, (lv1740, lv1737), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv1741 = R.call_tir(cls.fused_reshape45_add43_reshape46, (lv312, metadata["relax.expr.Constant"][0]), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv316 = R.call_tir(cls.softmax6, (lv1741,), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv317 = R.call_tir(cls.matmul31, (lv316, lv1739), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv1742 = R.call_tir(cls.fused_reshape47_transpose39_reshape48, (lv317,), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv246_1: R.Tensor((768, 768), dtype="float32") = model_params[163]
            lv247: R.Tensor((768,), dtype="float32") = model_params[88]
            lv1743 = R.call_tir(cls.fused_matmul29_add42_add41, (lv1742, lv246_1, lv247, lv1734), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv248: R.Tensor((768,), dtype="float32") = model_params[84]
            lv249: R.Tensor((768,), dtype="float32") = model_params[83]
            lv325 = R.call_tir(cls.layer_norm3, (lv1743, lv248, lv249), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv250: R.Tensor((768, 3072), dtype="float32") = model_params[164]
            lv251: R.Tensor((3072,), dtype="float32") = model_params[85]
            lv1744 = R.call_tir(cls.fused_matmul32_add44_multiply18_tir_sigmoid_multiply19, (lv325, lv250, lv251), out_sinfo=R.Tensor((1, 77, 3072), dtype="float32"))
            lv252: R.Tensor((3072, 768), dtype="float32") = model_params[165]
            lv253: R.Tensor((768,), dtype="float32") = model_params[86]
            lv1745 = R.call_tir(cls.fused_matmul33_add42_add41, (lv1744, lv252, lv253, lv1743), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv254: R.Tensor((768,), dtype="float32") = model_params[92]
            lv255: R.Tensor((768,), dtype="float32") = model_params[91]
            lv336 = R.call_tir(cls.layer_norm3, (lv1745, lv254, lv255), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv256: R.Tensor((768, 768), dtype="float32") = model_params[166]
            lv257: R.Tensor((768,), dtype="float32") = model_params[99]
            lv1746 = R.call_tir(cls.fused_matmul29_add42_multiply17, (lv336, lv256, lv257), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv258: R.Tensor((768, 768), dtype="float32") = model_params[167]
            lv259: R.Tensor((768,), dtype="float32") = model_params[97]
            lv1747 = R.call_tir(cls.fused_matmul29_add42, (lv336, lv258, lv259), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv1748 = R.call_tir(cls.fused_reshape43_transpose37_reshape44_transpose38, (lv1747,), out_sinfo=R.Tensor((12, 64, 77), dtype="float32"))
            lv260: R.Tensor((768, 768), dtype="float32") = model_params[168]
            lv261: R.Tensor((768,), dtype="float32") = model_params[100]
            lv1749 = R.call_tir(cls.fused_matmul29_add42, (lv336, lv260, lv261), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv1750 = R.call_tir(cls.fused_reshape43_transpose37_reshape44, (lv1749,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv1751 = R.call_tir(cls.fused_reshape43_transpose37_reshape44, (lv1746,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv357 = R.call_tir(cls.matmul30, (lv1751, lv1748), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv1752 = R.call_tir(cls.fused_reshape45_add43_reshape46, (lv357, metadata["relax.expr.Constant"][0]), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv361 = R.call_tir(cls.softmax6, (lv1752,), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv362 = R.call_tir(cls.matmul31, (lv361, lv1750), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv1753 = R.call_tir(cls.fused_reshape47_transpose39_reshape48, (lv362,), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv262: R.Tensor((768, 768), dtype="float32") = model_params[169]
            lv263: R.Tensor((768,), dtype="float32") = model_params[98]
            lv1754 = R.call_tir(cls.fused_matmul29_add42_add41, (lv1753, lv262, lv263, lv1745), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv264: R.Tensor((768,), dtype="float32") = model_params[94]
            lv265: R.Tensor((768,), dtype="float32") = model_params[93]
            lv370 = R.call_tir(cls.layer_norm3, (lv1754, lv264, lv265), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv266: R.Tensor((768, 3072), dtype="float32") = model_params[170]
            lv267_1: R.Tensor((3072,), dtype="float32") = model_params[95]
            lv1755 = R.call_tir(cls.fused_matmul32_add44_multiply18_tir_sigmoid_multiply19, (lv370, lv266, lv267_1), out_sinfo=R.Tensor((1, 77, 3072), dtype="float32"))
            lv268: R.Tensor((3072, 768), dtype="float32") = model_params[171]
            lv269: R.Tensor((768,), dtype="float32") = model_params[96]
            lv1756 = R.call_tir(cls.fused_matmul33_add42_add41, (lv1755, lv268, lv269, lv1754), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv270: R.Tensor((768,), dtype="float32") = model_params[102]
            lv271_1: R.Tensor((768,), dtype="float32") = model_params[101]
            lv381 = R.call_tir(cls.layer_norm3, (lv1756, lv270, lv271_1), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv272_1: R.Tensor((768, 768), dtype="float32") = model_params[172]
            lv273: R.Tensor((768,), dtype="float32") = model_params[109]
            lv1757 = R.call_tir(cls.fused_matmul29_add42_multiply17, (lv381, lv272_1, lv273), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv274: R.Tensor((768, 768), dtype="float32") = model_params[173]
            lv275: R.Tensor((768,), dtype="float32") = model_params[107]
            lv1758 = R.call_tir(cls.fused_matmul29_add42, (lv381, lv274, lv275), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv1759 = R.call_tir(cls.fused_reshape43_transpose37_reshape44_transpose38, (lv1758,), out_sinfo=R.Tensor((12, 64, 77), dtype="float32"))
            lv276: R.Tensor((768, 768), dtype="float32") = model_params[174]
            lv277: R.Tensor((768,), dtype="float32") = model_params[110]
            lv1760 = R.call_tir(cls.fused_matmul29_add42, (lv381, lv276, lv277), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv1761 = R.call_tir(cls.fused_reshape43_transpose37_reshape44, (lv1760,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv1762 = R.call_tir(cls.fused_reshape43_transpose37_reshape44, (lv1757,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv402 = R.call_tir(cls.matmul30, (lv1762, lv1759), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv1763 = R.call_tir(cls.fused_reshape45_add43_reshape46, (lv402, metadata["relax.expr.Constant"][0]), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv406 = R.call_tir(cls.softmax6, (lv1763,), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv407 = R.call_tir(cls.matmul31, (lv406, lv1761), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv1764 = R.call_tir(cls.fused_reshape47_transpose39_reshape48, (lv407,), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv278: R.Tensor((768, 768), dtype="float32") = model_params[175]
            lv279: R.Tensor((768,), dtype="float32") = model_params[108]
            lv1765 = R.call_tir(cls.fused_matmul29_add42_add41, (lv1764, lv278, lv279, lv1756), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv280_1: R.Tensor((768,), dtype="float32") = model_params[104]
            lv281: R.Tensor((768,), dtype="float32") = model_params[103]
            lv415 = R.call_tir(cls.layer_norm3, (lv1765, lv280_1, lv281), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv282: R.Tensor((768, 3072), dtype="float32") = model_params[176]
            lv283: R.Tensor((3072,), dtype="float32") = model_params[105]
            lv1766 = R.call_tir(cls.fused_matmul32_add44_multiply18_tir_sigmoid_multiply19, (lv415, lv282, lv283), out_sinfo=R.Tensor((1, 77, 3072), dtype="float32"))
            lv284: R.Tensor((3072, 768), dtype="float32") = model_params[177]
            lv285: R.Tensor((768,), dtype="float32") = model_params[106]
            lv1767 = R.call_tir(cls.fused_matmul33_add42_add41, (lv1766, lv284, lv285, lv1765), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv286: R.Tensor((768,), dtype="float32") = model_params[112]
            lv287: R.Tensor((768,), dtype="float32") = model_params[111]
            lv426 = R.call_tir(cls.layer_norm3, (lv1767, lv286, lv287), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv288: R.Tensor((768, 768), dtype="float32") = model_params[178]
            lv289: R.Tensor((768,), dtype="float32") = model_params[119]
            lv1768 = R.call_tir(cls.fused_matmul29_add42_multiply17, (lv426, lv288, lv289), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv290: R.Tensor((768, 768), dtype="float32") = model_params[179]
            lv291_1: R.Tensor((768,), dtype="float32") = model_params[117]
            lv1769 = R.call_tir(cls.fused_matmul29_add42, (lv426, lv290, lv291_1), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv1770 = R.call_tir(cls.fused_reshape43_transpose37_reshape44_transpose38, (lv1769,), out_sinfo=R.Tensor((12, 64, 77), dtype="float32"))
            lv292: R.Tensor((768, 768), dtype="float32") = model_params[180]
            lv293: R.Tensor((768,), dtype="float32") = model_params[120]
            lv1771 = R.call_tir(cls.fused_matmul29_add42, (lv426, lv292, lv293), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv1772 = R.call_tir(cls.fused_reshape43_transpose37_reshape44, (lv1771,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv1773 = R.call_tir(cls.fused_reshape43_transpose37_reshape44, (lv1768,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv447 = R.call_tir(cls.matmul30, (lv1773, lv1770), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv1774 = R.call_tir(cls.fused_reshape45_add43_reshape46, (lv447, metadata["relax.expr.Constant"][0]), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv451 = R.call_tir(cls.softmax6, (lv1774,), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv452 = R.call_tir(cls.matmul31, (lv451, lv1772), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv1775 = R.call_tir(cls.fused_reshape47_transpose39_reshape48, (lv452,), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv294: R.Tensor((768, 768), dtype="float32") = model_params[181]
            lv295: R.Tensor((768,), dtype="float32") = model_params[118]
            lv1776 = R.call_tir(cls.fused_matmul29_add42_add41, (lv1775, lv294, lv295, lv1767), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv296: R.Tensor((768,), dtype="float32") = model_params[114]
            lv297: R.Tensor((768,), dtype="float32") = model_params[113]
            lv460 = R.call_tir(cls.layer_norm3, (lv1776, lv296, lv297), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv298: R.Tensor((768, 3072), dtype="float32") = model_params[182]
            lv299: R.Tensor((3072,), dtype="float32") = model_params[115]
            lv1777 = R.call_tir(cls.fused_matmul32_add44_multiply18_tir_sigmoid_multiply19, (lv460, lv298, lv299), out_sinfo=R.Tensor((1, 77, 3072), dtype="float32"))
            lv300: R.Tensor((3072, 768), dtype="float32") = model_params[183]
            lv301: R.Tensor((768,), dtype="float32") = model_params[116]
            lv1778 = R.call_tir(cls.fused_matmul33_add42_add41, (lv1777, lv300, lv301, lv1776), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv302: R.Tensor((768,), dtype="float32") = model_params[12]
            lv303: R.Tensor((768,), dtype="float32") = model_params[11]
            lv471 = R.call_tir(cls.layer_norm3, (lv1778, lv302, lv303), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv304: R.Tensor((768, 768), dtype="float32") = model_params[184]
            lv305: R.Tensor((768,), dtype="float32") = model_params[19]
            lv1779 = R.call_tir(cls.fused_matmul29_add42_multiply17, (lv471, lv304, lv305), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv306: R.Tensor((768, 768), dtype="float32") = model_params[185]
            lv307: R.Tensor((768,), dtype="float32") = model_params[17]
            lv1780 = R.call_tir(cls.fused_matmul29_add42, (lv471, lv306, lv307), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv1781 = R.call_tir(cls.fused_reshape43_transpose37_reshape44_transpose38, (lv1780,), out_sinfo=R.Tensor((12, 64, 77), dtype="float32"))
            lv308: R.Tensor((768, 768), dtype="float32") = model_params[186]
            lv309: R.Tensor((768,), dtype="float32") = model_params[20]
            lv1782 = R.call_tir(cls.fused_matmul29_add42, (lv471, lv308, lv309), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv1783 = R.call_tir(cls.fused_reshape43_transpose37_reshape44, (lv1782,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv1784 = R.call_tir(cls.fused_reshape43_transpose37_reshape44, (lv1779,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv492 = R.call_tir(cls.matmul30, (lv1784, lv1781), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv1785 = R.call_tir(cls.fused_reshape45_add43_reshape46, (lv492, metadata["relax.expr.Constant"][0]), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv496 = R.call_tir(cls.softmax6, (lv1785,), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv497 = R.call_tir(cls.matmul31, (lv496, lv1783), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv1786 = R.call_tir(cls.fused_reshape47_transpose39_reshape48, (lv497,), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv310: R.Tensor((768, 768), dtype="float32") = model_params[187]
            lv311: R.Tensor((768,), dtype="float32") = model_params[18]
            lv1787 = R.call_tir(cls.fused_matmul29_add42_add41, (lv1786, lv310, lv311, lv1778), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv312_1: R.Tensor((768,), dtype="float32") = model_params[14]
            lv313: R.Tensor((768,), dtype="float32") = model_params[13]
            lv505 = R.call_tir(cls.layer_norm3, (lv1787, lv312_1, lv313), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv314: R.Tensor((768, 3072), dtype="float32") = model_params[188]
            lv315: R.Tensor((3072,), dtype="float32") = model_params[15]
            lv1788 = R.call_tir(cls.fused_matmul32_add44_multiply18_tir_sigmoid_multiply19, (lv505, lv314, lv315), out_sinfo=R.Tensor((1, 77, 3072), dtype="float32"))
            lv316_1: R.Tensor((3072, 768), dtype="float32") = model_params[189]
            lv317_1: R.Tensor((768,), dtype="float32") = model_params[16]
            lv1789 = R.call_tir(cls.fused_matmul33_add42_add41, (lv1788, lv316_1, lv317_1, lv1787), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv318: R.Tensor((768,), dtype="float32") = model_params[22]
            lv319: R.Tensor((768,), dtype="float32") = model_params[21]
            lv516 = R.call_tir(cls.layer_norm3, (lv1789, lv318, lv319), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv320: R.Tensor((768, 768), dtype="float32") = model_params[190]
            lv321: R.Tensor((768,), dtype="float32") = model_params[29]
            lv1790 = R.call_tir(cls.fused_matmul29_add42_multiply17, (lv516, lv320, lv321), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv322: R.Tensor((768, 768), dtype="float32") = model_params[191]
            lv323: R.Tensor((768,), dtype="float32") = model_params[27]
            lv1791 = R.call_tir(cls.fused_matmul29_add42, (lv516, lv322, lv323), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv1792 = R.call_tir(cls.fused_reshape43_transpose37_reshape44_transpose38, (lv1791,), out_sinfo=R.Tensor((12, 64, 77), dtype="float32"))
            lv324: R.Tensor((768, 768), dtype="float32") = model_params[192]
            lv325_1: R.Tensor((768,), dtype="float32") = model_params[30]
            lv1793 = R.call_tir(cls.fused_matmul29_add42, (lv516, lv324, lv325_1), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv1794 = R.call_tir(cls.fused_reshape43_transpose37_reshape44, (lv1793,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv1795 = R.call_tir(cls.fused_reshape43_transpose37_reshape44, (lv1790,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv537 = R.call_tir(cls.matmul30, (lv1795, lv1792), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv1796 = R.call_tir(cls.fused_reshape45_add43_reshape46, (lv537, metadata["relax.expr.Constant"][0]), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv541 = R.call_tir(cls.softmax6, (lv1796,), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv542 = R.call_tir(cls.matmul31, (lv541, lv1794), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv1797 = R.call_tir(cls.fused_reshape47_transpose39_reshape48, (lv542,), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv326: R.Tensor((768, 768), dtype="float32") = model_params[193]
            lv327: R.Tensor((768,), dtype="float32") = model_params[28]
            lv1798 = R.call_tir(cls.fused_matmul29_add42_add41, (lv1797, lv326, lv327, lv1789), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv328: R.Tensor((768,), dtype="float32") = model_params[24]
            lv329: R.Tensor((768,), dtype="float32") = model_params[23]
            lv550 = R.call_tir(cls.layer_norm3, (lv1798, lv328, lv329), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv330: R.Tensor((768, 3072), dtype="float32") = model_params[194]
            lv331: R.Tensor((3072,), dtype="float32") = model_params[25]
            lv1799 = R.call_tir(cls.fused_matmul32_add44_multiply18_tir_sigmoid_multiply19, (lv550, lv330, lv331), out_sinfo=R.Tensor((1, 77, 3072), dtype="float32"))
            lv332: R.Tensor((3072, 768), dtype="float32") = model_params[195]
            lv333: R.Tensor((768,), dtype="float32") = model_params[26]
            lv1800 = R.call_tir(cls.fused_matmul33_add42_add41, (lv1799, lv332, lv333, lv1798), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv334: R.Tensor((768,), dtype="float32") = model_params[122]
            lv335: R.Tensor((768,), dtype="float32") = model_params[121]
            lv561 = R.call_tir(cls.layer_norm3, (lv1800, lv334, lv335), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            gv: R.Tuple(R.Tensor((1, 77, 768), dtype="float32"), R.Tensor((1, 77, 768), dtype="float32")) = lv1789, lv561
            R.output(gv)
        return gv

    @R.function
    def clip2(inp_0: R.Tensor((1, 77), dtype="int32"), model_params: R.Tuple(R.Tensor((49408, 1280), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((77, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"))) -> R.Tuple(R.Tensor((1, 77, 1280), dtype="float32"), R.Tensor((1, 1280), dtype="float32")):
        R.func_attr({"global_symbol": "subgraph_0", "num_input": 1})
        cls = Module
        with R.dataflow():
            lv = R.call_tir(cls.reshape, (inp_0,), out_sinfo=R.Tensor((1, 77), dtype="int32"))
            lv_1 = R.call_tir(cls.fused_cast_reshape1, (lv,), out_sinfo=R.Tensor((77,), dtype="int32"))
            lv2016: R.Tensor((49408, 1280), dtype="float32") = model_params[0]
            lv3 = R.call_tir(cls.take, (lv2016, lv_1), out_sinfo=R.Tensor((77, 1280), dtype="float32"))
            lv2017: R.Tensor((77, 1280), dtype="float32") = model_params[323]
            lv1 = R.call_tir(cls.fused_reshape2_reshape2_add2, (lv3, lv2017), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2018: R.Tensor((1280,), dtype="float32") = model_params[2]
            lv2019: R.Tensor((1280,), dtype="float32") = model_params[1]
            lv21 = R.call_tir(cls.layer_norm, (lv1, lv2018, lv2019), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2020: R.Tensor((1280, 1280), dtype="float32") = model_params[324]
            lv2021: R.Tensor((1280,), dtype="float32") = model_params[9]
            lv2 = R.call_tir(cls.fused_matmul_add4_multiply3, (lv21, lv2020, lv2021), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2022: R.Tensor((1280, 1280), dtype="float32") = model_params[325]
            lv2023: R.Tensor((1280,), dtype="float32") = model_params[7]
            lv3_1 = R.call_tir(cls.fused_matmul_add4, (lv21, lv2022, lv2023), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv4 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv3_1,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv2024: R.Tensor((1280, 1280), dtype="float32") = model_params[326]
            lv2025: R.Tensor((1280,), dtype="float32") = model_params[10]
            lv5 = R.call_tir(cls.fused_matmul_add4, (lv21, lv2024, lv2025), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv6 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv5,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv7 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv2,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv42 = R.call_tir(cls.matmul1, (lv7, lv4), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv8 = R.call_tir(cls.fused_reshape7_add5_reshape8, (lv42, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv46 = R.call_tir(cls.softmax, (lv8,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv9 = R.call_tir(cls.fused_reshape7_reshape8, (lv46,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv49 = R.call_tir(cls.matmul2, (lv9, lv6), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv10 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv49,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2026: R.Tensor((1280, 1280), dtype="float32") = model_params[327]
            lv2027: R.Tensor((1280,), dtype="float32") = model_params[8]
            lv11 = R.call_tir(cls.fused_matmul_add4_add2, (lv10, lv2026, lv2027, lv1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2028: R.Tensor((1280,), dtype="float32") = model_params[4]
            lv2029: R.Tensor((1280,), dtype="float32") = model_params[3]
            lv57 = R.call_tir(cls.layer_norm, (lv11, lv2028, lv2029), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2030: R.Tensor((1280, 5120), dtype="float32") = model_params[328]
            lv2031: R.Tensor((5120,), dtype="float32") = model_params[5]
            lv12 = R.call_tir(cls.fused_matmul3_add6_gelu, (lv57, lv2030, lv2031), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv2032: R.Tensor((5120, 1280), dtype="float32") = model_params[329]
            lv2033: R.Tensor((1280,), dtype="float32") = model_params[6]
            lv13 = R.call_tir(cls.fused_matmul4_add4_add2, (lv12, lv2032, lv2033, lv11), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2034: R.Tensor((1280,), dtype="float32") = model_params[112]
            lv2035: R.Tensor((1280,), dtype="float32") = model_params[111]
            lv66 = R.call_tir(cls.layer_norm, (lv13, lv2034, lv2035), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2036: R.Tensor((1280, 1280), dtype="float32") = model_params[330]
            lv2037: R.Tensor((1280,), dtype="float32") = model_params[119]
            lv14 = R.call_tir(cls.fused_matmul_add4_multiply3, (lv66, lv2036, lv2037), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2038: R.Tensor((1280, 1280), dtype="float32") = model_params[331]
            lv2039: R.Tensor((1280,), dtype="float32") = model_params[117]
            lv15 = R.call_tir(cls.fused_matmul_add4, (lv66, lv2038, lv2039), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv16 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv15,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv2040: R.Tensor((1280, 1280), dtype="float32") = model_params[332]
            lv2041: R.Tensor((1280,), dtype="float32") = model_params[120]
            lv17 = R.call_tir(cls.fused_matmul_add4, (lv66, lv2040, lv2041), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv18 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv17,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv19 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv14,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv87 = R.call_tir(cls.matmul1, (lv19, lv16), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv20 = R.call_tir(cls.fused_reshape7_add5_reshape8, (lv87, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv91 = R.call_tir(cls.softmax, (lv20,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv21_1 = R.call_tir(cls.fused_reshape7_reshape8, (lv91,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv94 = R.call_tir(cls.matmul2, (lv21_1, lv18), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv22 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv94,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2042: R.Tensor((1280, 1280), dtype="float32") = model_params[333]
            lv2043: R.Tensor((1280,), dtype="float32") = model_params[118]
            lv23 = R.call_tir(cls.fused_matmul_add4_add2, (lv22, lv2042, lv2043, lv13), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2044: R.Tensor((1280,), dtype="float32") = model_params[114]
            lv2045: R.Tensor((1280,), dtype="float32") = model_params[113]
            lv102 = R.call_tir(cls.layer_norm, (lv23, lv2044, lv2045), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2046: R.Tensor((1280, 5120), dtype="float32") = model_params[334]
            lv2047: R.Tensor((5120,), dtype="float32") = model_params[115]
            lv24 = R.call_tir(cls.fused_matmul3_add6_gelu, (lv102, lv2046, lv2047), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv2048: R.Tensor((5120, 1280), dtype="float32") = model_params[335]
            lv2049: R.Tensor((1280,), dtype="float32") = model_params[116]
            lv25 = R.call_tir(cls.fused_matmul4_add4_add2, (lv24, lv2048, lv2049, lv23), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2050: R.Tensor((1280,), dtype="float32") = model_params[222]
            lv2051: R.Tensor((1280,), dtype="float32") = model_params[221]
            lv111 = R.call_tir(cls.layer_norm, (lv25, lv2050, lv2051), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2052: R.Tensor((1280, 1280), dtype="float32") = model_params[336]
            lv2053: R.Tensor((1280,), dtype="float32") = model_params[229]
            lv26 = R.call_tir(cls.fused_matmul_add4_multiply3, (lv111, lv2052, lv2053), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2054: R.Tensor((1280, 1280), dtype="float32") = model_params[337]
            lv2055: R.Tensor((1280,), dtype="float32") = model_params[227]
            lv27 = R.call_tir(cls.fused_matmul_add4, (lv111, lv2054, lv2055), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv28 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv27,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv2056: R.Tensor((1280, 1280), dtype="float32") = model_params[338]
            lv2057: R.Tensor((1280,), dtype="float32") = model_params[230]
            lv29 = R.call_tir(cls.fused_matmul_add4, (lv111, lv2056, lv2057), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv30 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv29,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv31 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv26,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv132 = R.call_tir(cls.matmul1, (lv31, lv28), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv32 = R.call_tir(cls.fused_reshape7_add5_reshape8, (lv132, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv136 = R.call_tir(cls.softmax, (lv32,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv33 = R.call_tir(cls.fused_reshape7_reshape8, (lv136,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv139 = R.call_tir(cls.matmul2, (lv33, lv30), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv34 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv139,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2058: R.Tensor((1280, 1280), dtype="float32") = model_params[339]
            lv2059: R.Tensor((1280,), dtype="float32") = model_params[228]
            lv35 = R.call_tir(cls.fused_matmul_add4_add2, (lv34, lv2058, lv2059, lv25), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2060: R.Tensor((1280,), dtype="float32") = model_params[224]
            lv2061: R.Tensor((1280,), dtype="float32") = model_params[223]
            lv147 = R.call_tir(cls.layer_norm, (lv35, lv2060, lv2061), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2062: R.Tensor((1280, 5120), dtype="float32") = model_params[340]
            lv2063: R.Tensor((5120,), dtype="float32") = model_params[225]
            lv36 = R.call_tir(cls.fused_matmul3_add6_gelu, (lv147, lv2062, lv2063), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv2064: R.Tensor((5120, 1280), dtype="float32") = model_params[341]
            lv2065: R.Tensor((1280,), dtype="float32") = model_params[226]
            lv37 = R.call_tir(cls.fused_matmul4_add4_add2, (lv36, lv2064, lv2065, lv35), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2066: R.Tensor((1280,), dtype="float32") = model_params[252]
            lv2067: R.Tensor((1280,), dtype="float32") = model_params[251]
            lv156 = R.call_tir(cls.layer_norm, (lv37, lv2066, lv2067), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2068: R.Tensor((1280, 1280), dtype="float32") = model_params[342]
            lv2069: R.Tensor((1280,), dtype="float32") = model_params[259]
            lv38 = R.call_tir(cls.fused_matmul_add4_multiply3, (lv156, lv2068, lv2069), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2070: R.Tensor((1280, 1280), dtype="float32") = model_params[343]
            lv2071: R.Tensor((1280,), dtype="float32") = model_params[257]
            lv39 = R.call_tir(cls.fused_matmul_add4, (lv156, lv2070, lv2071), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv40 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv39,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv2072: R.Tensor((1280, 1280), dtype="float32") = model_params[344]
            lv2073: R.Tensor((1280,), dtype="float32") = model_params[260]
            lv41 = R.call_tir(cls.fused_matmul_add4, (lv156, lv2072, lv2073), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv42_1 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv41,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv43 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv38,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv177 = R.call_tir(cls.matmul1, (lv43, lv40), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv44 = R.call_tir(cls.fused_reshape7_add5_reshape8, (lv177, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv181 = R.call_tir(cls.softmax, (lv44,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv45 = R.call_tir(cls.fused_reshape7_reshape8, (lv181,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv184 = R.call_tir(cls.matmul2, (lv45, lv42_1), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv46_1 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv184,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2074: R.Tensor((1280, 1280), dtype="float32") = model_params[345]
            lv2075: R.Tensor((1280,), dtype="float32") = model_params[258]
            lv47 = R.call_tir(cls.fused_matmul_add4_add2, (lv46_1, lv2074, lv2075, lv37), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2076: R.Tensor((1280,), dtype="float32") = model_params[254]
            lv2077: R.Tensor((1280,), dtype="float32") = model_params[253]
            lv192 = R.call_tir(cls.layer_norm, (lv47, lv2076, lv2077), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2078: R.Tensor((1280, 5120), dtype="float32") = model_params[346]
            lv2079: R.Tensor((5120,), dtype="float32") = model_params[255]
            lv48 = R.call_tir(cls.fused_matmul3_add6_gelu, (lv192, lv2078, lv2079), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv2080: R.Tensor((5120, 1280), dtype="float32") = model_params[347]
            lv2081: R.Tensor((1280,), dtype="float32") = model_params[256]
            lv49_1 = R.call_tir(cls.fused_matmul4_add4_add2, (lv48, lv2080, lv2081, lv47), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2082: R.Tensor((1280,), dtype="float32") = model_params[262]
            lv2083: R.Tensor((1280,), dtype="float32") = model_params[261]
            lv201 = R.call_tir(cls.layer_norm, (lv49_1, lv2082, lv2083), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2084: R.Tensor((1280, 1280), dtype="float32") = model_params[348]
            lv2085: R.Tensor((1280,), dtype="float32") = model_params[269]
            lv50 = R.call_tir(cls.fused_matmul_add4_multiply3, (lv201, lv2084, lv2085), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2086: R.Tensor((1280, 1280), dtype="float32") = model_params[349]
            lv2087: R.Tensor((1280,), dtype="float32") = model_params[267]
            lv51 = R.call_tir(cls.fused_matmul_add4, (lv201, lv2086, lv2087), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv52 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv51,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv2088: R.Tensor((1280, 1280), dtype="float32") = model_params[350]
            lv2089: R.Tensor((1280,), dtype="float32") = model_params[270]
            lv53 = R.call_tir(cls.fused_matmul_add4, (lv201, lv2088, lv2089), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv54 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv53,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv55 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv50,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv222 = R.call_tir(cls.matmul1, (lv55, lv52), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv56 = R.call_tir(cls.fused_reshape7_add5_reshape8, (lv222, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv226 = R.call_tir(cls.softmax, (lv56,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv57_1 = R.call_tir(cls.fused_reshape7_reshape8, (lv226,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv229 = R.call_tir(cls.matmul2, (lv57_1, lv54), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv58 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv229,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2090: R.Tensor((1280, 1280), dtype="float32") = model_params[351]
            lv2091: R.Tensor((1280,), dtype="float32") = model_params[268]
            lv59 = R.call_tir(cls.fused_matmul_add4_add2, (lv58, lv2090, lv2091, lv49_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2092: R.Tensor((1280,), dtype="float32") = model_params[264]
            lv2093: R.Tensor((1280,), dtype="float32") = model_params[263]
            lv237 = R.call_tir(cls.layer_norm, (lv59, lv2092, lv2093), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2094: R.Tensor((1280, 5120), dtype="float32") = model_params[352]
            lv2095: R.Tensor((5120,), dtype="float32") = model_params[265]
            lv60 = R.call_tir(cls.fused_matmul3_add6_gelu, (lv237, lv2094, lv2095), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv2096: R.Tensor((5120, 1280), dtype="float32") = model_params[353]
            lv2097: R.Tensor((1280,), dtype="float32") = model_params[266]
            lv61 = R.call_tir(cls.fused_matmul4_add4_add2, (lv60, lv2096, lv2097, lv59), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2098: R.Tensor((1280,), dtype="float32") = model_params[272]
            lv2099: R.Tensor((1280,), dtype="float32") = model_params[271]
            lv246 = R.call_tir(cls.layer_norm, (lv61, lv2098, lv2099), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2100: R.Tensor((1280, 1280), dtype="float32") = model_params[354]
            lv2101: R.Tensor((1280,), dtype="float32") = model_params[279]
            lv62 = R.call_tir(cls.fused_matmul_add4_multiply3, (lv246, lv2100, lv2101), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2102: R.Tensor((1280, 1280), dtype="float32") = model_params[355]
            lv2103: R.Tensor((1280,), dtype="float32") = model_params[277]
            lv63 = R.call_tir(cls.fused_matmul_add4, (lv246, lv2102, lv2103), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv64 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv63,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv2104: R.Tensor((1280, 1280), dtype="float32") = model_params[356]
            lv2105: R.Tensor((1280,), dtype="float32") = model_params[280]
            lv65 = R.call_tir(cls.fused_matmul_add4, (lv246, lv2104, lv2105), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv66_1 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv65,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv67 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv62,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv267 = R.call_tir(cls.matmul1, (lv67, lv64), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv68 = R.call_tir(cls.fused_reshape7_add5_reshape8, (lv267, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv271 = R.call_tir(cls.softmax, (lv68,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv69 = R.call_tir(cls.fused_reshape7_reshape8, (lv271,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv274 = R.call_tir(cls.matmul2, (lv69, lv66_1), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv70 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv274,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2106: R.Tensor((1280, 1280), dtype="float32") = model_params[357]
            lv2107: R.Tensor((1280,), dtype="float32") = model_params[278]
            lv71 = R.call_tir(cls.fused_matmul_add4_add2, (lv70, lv2106, lv2107, lv61), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2108: R.Tensor((1280,), dtype="float32") = model_params[274]
            lv2109: R.Tensor((1280,), dtype="float32") = model_params[273]
            lv282 = R.call_tir(cls.layer_norm, (lv71, lv2108, lv2109), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2110: R.Tensor((1280, 5120), dtype="float32") = model_params[358]
            lv2111: R.Tensor((5120,), dtype="float32") = model_params[275]
            lv72 = R.call_tir(cls.fused_matmul3_add6_gelu, (lv282, lv2110, lv2111), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv2112: R.Tensor((5120, 1280), dtype="float32") = model_params[359]
            lv2113: R.Tensor((1280,), dtype="float32") = model_params[276]
            lv73 = R.call_tir(cls.fused_matmul4_add4_add2, (lv72, lv2112, lv2113, lv71), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2114: R.Tensor((1280,), dtype="float32") = model_params[282]
            lv2115: R.Tensor((1280,), dtype="float32") = model_params[281]
            lv291 = R.call_tir(cls.layer_norm, (lv73, lv2114, lv2115), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2116: R.Tensor((1280, 1280), dtype="float32") = model_params[360]
            lv2117: R.Tensor((1280,), dtype="float32") = model_params[289]
            lv74 = R.call_tir(cls.fused_matmul_add4_multiply3, (lv291, lv2116, lv2117), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2118: R.Tensor((1280, 1280), dtype="float32") = model_params[361]
            lv2119: R.Tensor((1280,), dtype="float32") = model_params[287]
            lv75 = R.call_tir(cls.fused_matmul_add4, (lv291, lv2118, lv2119), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv76 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv75,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv2120: R.Tensor((1280, 1280), dtype="float32") = model_params[362]
            lv2121: R.Tensor((1280,), dtype="float32") = model_params[290]
            lv77 = R.call_tir(cls.fused_matmul_add4, (lv291, lv2120, lv2121), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv78 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv77,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv79 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv74,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv312 = R.call_tir(cls.matmul1, (lv79, lv76), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv80 = R.call_tir(cls.fused_reshape7_add5_reshape8, (lv312, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv316 = R.call_tir(cls.softmax, (lv80,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv81 = R.call_tir(cls.fused_reshape7_reshape8, (lv316,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv319 = R.call_tir(cls.matmul2, (lv81, lv78), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv82 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv319,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2122: R.Tensor((1280, 1280), dtype="float32") = model_params[363]
            lv2123: R.Tensor((1280,), dtype="float32") = model_params[288]
            lv83 = R.call_tir(cls.fused_matmul_add4_add2, (lv82, lv2122, lv2123, lv73), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2124: R.Tensor((1280,), dtype="float32") = model_params[284]
            lv2125: R.Tensor((1280,), dtype="float32") = model_params[283]
            lv327 = R.call_tir(cls.layer_norm, (lv83, lv2124, lv2125), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2126: R.Tensor((1280, 5120), dtype="float32") = model_params[364]
            lv2127: R.Tensor((5120,), dtype="float32") = model_params[285]
            lv84 = R.call_tir(cls.fused_matmul3_add6_gelu, (lv327, lv2126, lv2127), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv2128: R.Tensor((5120, 1280), dtype="float32") = model_params[365]
            lv2129: R.Tensor((1280,), dtype="float32") = model_params[286]
            lv85 = R.call_tir(cls.fused_matmul4_add4_add2, (lv84, lv2128, lv2129, lv83), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2130: R.Tensor((1280,), dtype="float32") = model_params[292]
            lv2131: R.Tensor((1280,), dtype="float32") = model_params[291]
            lv336 = R.call_tir(cls.layer_norm, (lv85, lv2130, lv2131), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2132: R.Tensor((1280, 1280), dtype="float32") = model_params[366]
            lv2133: R.Tensor((1280,), dtype="float32") = model_params[299]
            lv86 = R.call_tir(cls.fused_matmul_add4_multiply3, (lv336, lv2132, lv2133), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2134: R.Tensor((1280, 1280), dtype="float32") = model_params[367]
            lv2135: R.Tensor((1280,), dtype="float32") = model_params[297]
            lv87_1 = R.call_tir(cls.fused_matmul_add4, (lv336, lv2134, lv2135), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv88 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv87_1,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv2136: R.Tensor((1280, 1280), dtype="float32") = model_params[368]
            lv2137: R.Tensor((1280,), dtype="float32") = model_params[300]
            lv89 = R.call_tir(cls.fused_matmul_add4, (lv336, lv2136, lv2137), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv90 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv89,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv91_1 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv86,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv357 = R.call_tir(cls.matmul1, (lv91_1, lv88), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv92 = R.call_tir(cls.fused_reshape7_add5_reshape8, (lv357, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv361 = R.call_tir(cls.softmax, (lv92,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv93 = R.call_tir(cls.fused_reshape7_reshape8, (lv361,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv364 = R.call_tir(cls.matmul2, (lv93, lv90), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv94_1 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv364,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2138: R.Tensor((1280, 1280), dtype="float32") = model_params[369]
            lv2139: R.Tensor((1280,), dtype="float32") = model_params[298]
            lv95 = R.call_tir(cls.fused_matmul_add4_add2, (lv94_1, lv2138, lv2139, lv85), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2140: R.Tensor((1280,), dtype="float32") = model_params[294]
            lv2141: R.Tensor((1280,), dtype="float32") = model_params[293]
            lv372 = R.call_tir(cls.layer_norm, (lv95, lv2140, lv2141), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2142: R.Tensor((1280, 5120), dtype="float32") = model_params[370]
            lv2143: R.Tensor((5120,), dtype="float32") = model_params[295]
            lv96 = R.call_tir(cls.fused_matmul3_add6_gelu, (lv372, lv2142, lv2143), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv2144: R.Tensor((5120, 1280), dtype="float32") = model_params[371]
            lv2145: R.Tensor((1280,), dtype="float32") = model_params[296]
            lv97 = R.call_tir(cls.fused_matmul4_add4_add2, (lv96, lv2144, lv2145, lv95), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2146: R.Tensor((1280,), dtype="float32") = model_params[302]
            lv2147: R.Tensor((1280,), dtype="float32") = model_params[301]
            lv381 = R.call_tir(cls.layer_norm, (lv97, lv2146, lv2147), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2148: R.Tensor((1280, 1280), dtype="float32") = model_params[372]
            lv2149: R.Tensor((1280,), dtype="float32") = model_params[309]
            lv98 = R.call_tir(cls.fused_matmul_add4_multiply3, (lv381, lv2148, lv2149), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2150: R.Tensor((1280, 1280), dtype="float32") = model_params[373]
            lv2151: R.Tensor((1280,), dtype="float32") = model_params[307]
            lv99 = R.call_tir(cls.fused_matmul_add4, (lv381, lv2150, lv2151), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv100 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv99,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv2152: R.Tensor((1280, 1280), dtype="float32") = model_params[374]
            lv2153: R.Tensor((1280,), dtype="float32") = model_params[310]
            lv101 = R.call_tir(cls.fused_matmul_add4, (lv381, lv2152, lv2153), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv102_1 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv101,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv103 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv98,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv402 = R.call_tir(cls.matmul1, (lv103, lv100), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv104 = R.call_tir(cls.fused_reshape7_add5_reshape8, (lv402, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv406 = R.call_tir(cls.softmax, (lv104,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv105 = R.call_tir(cls.fused_reshape7_reshape8, (lv406,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv409 = R.call_tir(cls.matmul2, (lv105, lv102_1), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv106 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv409,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2154: R.Tensor((1280, 1280), dtype="float32") = model_params[375]
            lv2155: R.Tensor((1280,), dtype="float32") = model_params[308]
            lv107 = R.call_tir(cls.fused_matmul_add4_add2, (lv106, lv2154, lv2155, lv97), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2156: R.Tensor((1280,), dtype="float32") = model_params[304]
            lv2157: R.Tensor((1280,), dtype="float32") = model_params[303]
            lv417 = R.call_tir(cls.layer_norm, (lv107, lv2156, lv2157), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2158: R.Tensor((1280, 5120), dtype="float32") = model_params[376]
            lv2159: R.Tensor((5120,), dtype="float32") = model_params[305]
            lv108 = R.call_tir(cls.fused_matmul3_add6_gelu, (lv417, lv2158, lv2159), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv2160: R.Tensor((5120, 1280), dtype="float32") = model_params[377]
            lv2161: R.Tensor((1280,), dtype="float32") = model_params[306]
            lv109 = R.call_tir(cls.fused_matmul4_add4_add2, (lv108, lv2160, lv2161, lv107), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2162: R.Tensor((1280,), dtype="float32") = model_params[312]
            lv2163: R.Tensor((1280,), dtype="float32") = model_params[311]
            lv426 = R.call_tir(cls.layer_norm, (lv109, lv2162, lv2163), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2164: R.Tensor((1280, 1280), dtype="float32") = model_params[378]
            lv2165: R.Tensor((1280,), dtype="float32") = model_params[319]
            lv110 = R.call_tir(cls.fused_matmul_add4_multiply3, (lv426, lv2164, lv2165), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2166: R.Tensor((1280, 1280), dtype="float32") = model_params[379]
            lv2167: R.Tensor((1280,), dtype="float32") = model_params[317]
            lv111_1 = R.call_tir(cls.fused_matmul_add4, (lv426, lv2166, lv2167), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv112 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv111_1,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv2168: R.Tensor((1280, 1280), dtype="float32") = model_params[380]
            lv2169: R.Tensor((1280,), dtype="float32") = model_params[320]
            lv113 = R.call_tir(cls.fused_matmul_add4, (lv426, lv2168, lv2169), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv114 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv113,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv115 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv110,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv447 = R.call_tir(cls.matmul1, (lv115, lv112), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv116 = R.call_tir(cls.fused_reshape7_add5_reshape8, (lv447, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv451 = R.call_tir(cls.softmax, (lv116,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv117 = R.call_tir(cls.fused_reshape7_reshape8, (lv451,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv454 = R.call_tir(cls.matmul2, (lv117, lv114), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv118 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv454,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2170: R.Tensor((1280, 1280), dtype="float32") = model_params[381]
            lv2171: R.Tensor((1280,), dtype="float32") = model_params[318]
            lv119 = R.call_tir(cls.fused_matmul_add4_add2, (lv118, lv2170, lv2171, lv109), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2172: R.Tensor((1280,), dtype="float32") = model_params[314]
            lv2173: R.Tensor((1280,), dtype="float32") = model_params[313]
            lv462 = R.call_tir(cls.layer_norm, (lv119, lv2172, lv2173), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2174: R.Tensor((1280, 5120), dtype="float32") = model_params[382]
            lv2175: R.Tensor((5120,), dtype="float32") = model_params[315]
            lv120 = R.call_tir(cls.fused_matmul3_add6_gelu, (lv462, lv2174, lv2175), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv2176: R.Tensor((5120, 1280), dtype="float32") = model_params[383]
            lv2177: R.Tensor((1280,), dtype="float32") = model_params[316]
            lv121 = R.call_tir(cls.fused_matmul4_add4_add2, (lv120, lv2176, lv2177, lv119), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2178: R.Tensor((1280,), dtype="float32") = model_params[12]
            lv2179: R.Tensor((1280,), dtype="float32") = model_params[11]
            lv471 = R.call_tir(cls.layer_norm, (lv121, lv2178, lv2179), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2180: R.Tensor((1280, 1280), dtype="float32") = model_params[384]
            lv2181: R.Tensor((1280,), dtype="float32") = model_params[19]
            lv122 = R.call_tir(cls.fused_matmul_add4_multiply3, (lv471, lv2180, lv2181), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2182: R.Tensor((1280, 1280), dtype="float32") = model_params[385]
            lv2183: R.Tensor((1280,), dtype="float32") = model_params[17]
            lv123 = R.call_tir(cls.fused_matmul_add4, (lv471, lv2182, lv2183), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv124 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv123,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv2184: R.Tensor((1280, 1280), dtype="float32") = model_params[386]
            lv2185: R.Tensor((1280,), dtype="float32") = model_params[20]
            lv125 = R.call_tir(cls.fused_matmul_add4, (lv471, lv2184, lv2185), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv126 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv125,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv127 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv122,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv492 = R.call_tir(cls.matmul1, (lv127, lv124), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv128 = R.call_tir(cls.fused_reshape7_add5_reshape8, (lv492, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv496 = R.call_tir(cls.softmax, (lv128,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv129 = R.call_tir(cls.fused_reshape7_reshape8, (lv496,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv499 = R.call_tir(cls.matmul2, (lv129, lv126), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv130 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv499,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2186: R.Tensor((1280, 1280), dtype="float32") = model_params[387]
            lv2187: R.Tensor((1280,), dtype="float32") = model_params[18]
            lv131 = R.call_tir(cls.fused_matmul_add4_add2, (lv130, lv2186, lv2187, lv121), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2188: R.Tensor((1280,), dtype="float32") = model_params[14]
            lv2189: R.Tensor((1280,), dtype="float32") = model_params[13]
            lv507 = R.call_tir(cls.layer_norm, (lv131, lv2188, lv2189), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2190: R.Tensor((1280, 5120), dtype="float32") = model_params[388]
            lv2191: R.Tensor((5120,), dtype="float32") = model_params[15]
            lv132_1 = R.call_tir(cls.fused_matmul3_add6_gelu, (lv507, lv2190, lv2191), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv2192: R.Tensor((5120, 1280), dtype="float32") = model_params[389]
            lv2193: R.Tensor((1280,), dtype="float32") = model_params[16]
            lv133 = R.call_tir(cls.fused_matmul4_add4_add2, (lv132_1, lv2192, lv2193, lv131), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2194: R.Tensor((1280,), dtype="float32") = model_params[22]
            lv2195: R.Tensor((1280,), dtype="float32") = model_params[21]
            lv516 = R.call_tir(cls.layer_norm, (lv133, lv2194, lv2195), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2196: R.Tensor((1280, 1280), dtype="float32") = model_params[390]
            lv2197: R.Tensor((1280,), dtype="float32") = model_params[29]
            lv134 = R.call_tir(cls.fused_matmul_add4_multiply3, (lv516, lv2196, lv2197), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2198: R.Tensor((1280, 1280), dtype="float32") = model_params[391]
            lv2199: R.Tensor((1280,), dtype="float32") = model_params[27]
            lv135 = R.call_tir(cls.fused_matmul_add4, (lv516, lv2198, lv2199), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv136_1 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv135,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv2200: R.Tensor((1280, 1280), dtype="float32") = model_params[392]
            lv2201: R.Tensor((1280,), dtype="float32") = model_params[30]
            lv137 = R.call_tir(cls.fused_matmul_add4, (lv516, lv2200, lv2201), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv138 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv137,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv139_1 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv134,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv537 = R.call_tir(cls.matmul1, (lv139_1, lv136_1), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv140 = R.call_tir(cls.fused_reshape7_add5_reshape8, (lv537, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv541 = R.call_tir(cls.softmax, (lv140,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv141 = R.call_tir(cls.fused_reshape7_reshape8, (lv541,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv544 = R.call_tir(cls.matmul2, (lv141, lv138), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv142 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv544,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2202: R.Tensor((1280, 1280), dtype="float32") = model_params[393]
            lv2203: R.Tensor((1280,), dtype="float32") = model_params[28]
            lv143 = R.call_tir(cls.fused_matmul_add4_add2, (lv142, lv2202, lv2203, lv133), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2204: R.Tensor((1280,), dtype="float32") = model_params[24]
            lv2205: R.Tensor((1280,), dtype="float32") = model_params[23]
            lv552 = R.call_tir(cls.layer_norm, (lv143, lv2204, lv2205), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2206: R.Tensor((1280, 5120), dtype="float32") = model_params[394]
            lv2207: R.Tensor((5120,), dtype="float32") = model_params[25]
            lv144 = R.call_tir(cls.fused_matmul3_add6_gelu, (lv552, lv2206, lv2207), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv2208: R.Tensor((5120, 1280), dtype="float32") = model_params[395]
            lv2209: R.Tensor((1280,), dtype="float32") = model_params[26]
            lv145 = R.call_tir(cls.fused_matmul4_add4_add2, (lv144, lv2208, lv2209, lv143), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2210: R.Tensor((1280,), dtype="float32") = model_params[32]
            lv2211: R.Tensor((1280,), dtype="float32") = model_params[31]
            lv561 = R.call_tir(cls.layer_norm, (lv145, lv2210, lv2211), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2212: R.Tensor((1280, 1280), dtype="float32") = model_params[396]
            lv2213: R.Tensor((1280,), dtype="float32") = model_params[39]
            lv146 = R.call_tir(cls.fused_matmul_add4_multiply3, (lv561, lv2212, lv2213), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2214: R.Tensor((1280, 1280), dtype="float32") = model_params[397]
            lv2215: R.Tensor((1280,), dtype="float32") = model_params[37]
            lv147_1 = R.call_tir(cls.fused_matmul_add4, (lv561, lv2214, lv2215), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv148 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv147_1,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv2216: R.Tensor((1280, 1280), dtype="float32") = model_params[398]
            lv2217: R.Tensor((1280,), dtype="float32") = model_params[40]
            lv149 = R.call_tir(cls.fused_matmul_add4, (lv561, lv2216, lv2217), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv150 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv149,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv151 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv146,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv582 = R.call_tir(cls.matmul1, (lv151, lv148), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv152 = R.call_tir(cls.fused_reshape7_add5_reshape8, (lv582, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv586 = R.call_tir(cls.softmax, (lv152,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv153 = R.call_tir(cls.fused_reshape7_reshape8, (lv586,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv589 = R.call_tir(cls.matmul2, (lv153, lv150), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv154 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv589,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2218: R.Tensor((1280, 1280), dtype="float32") = model_params[399]
            lv2219: R.Tensor((1280,), dtype="float32") = model_params[38]
            lv155 = R.call_tir(cls.fused_matmul_add4_add2, (lv154, lv2218, lv2219, lv145), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2220: R.Tensor((1280,), dtype="float32") = model_params[34]
            lv2221: R.Tensor((1280,), dtype="float32") = model_params[33]
            lv597 = R.call_tir(cls.layer_norm, (lv155, lv2220, lv2221), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2222: R.Tensor((1280, 5120), dtype="float32") = model_params[400]
            lv2223: R.Tensor((5120,), dtype="float32") = model_params[35]
            lv156_1 = R.call_tir(cls.fused_matmul3_add6_gelu, (lv597, lv2222, lv2223), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv2224: R.Tensor((5120, 1280), dtype="float32") = model_params[401]
            lv2225: R.Tensor((1280,), dtype="float32") = model_params[36]
            lv157 = R.call_tir(cls.fused_matmul4_add4_add2, (lv156_1, lv2224, lv2225, lv155), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2226: R.Tensor((1280,), dtype="float32") = model_params[42]
            lv2227: R.Tensor((1280,), dtype="float32") = model_params[41]
            lv606 = R.call_tir(cls.layer_norm, (lv157, lv2226, lv2227), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2228: R.Tensor((1280, 1280), dtype="float32") = model_params[402]
            lv2229: R.Tensor((1280,), dtype="float32") = model_params[49]
            lv158 = R.call_tir(cls.fused_matmul_add4_multiply3, (lv606, lv2228, lv2229), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2230: R.Tensor((1280, 1280), dtype="float32") = model_params[403]
            lv2231: R.Tensor((1280,), dtype="float32") = model_params[47]
            lv159 = R.call_tir(cls.fused_matmul_add4, (lv606, lv2230, lv2231), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv160 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv159,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv2232: R.Tensor((1280, 1280), dtype="float32") = model_params[404]
            lv2233: R.Tensor((1280,), dtype="float32") = model_params[50]
            lv161 = R.call_tir(cls.fused_matmul_add4, (lv606, lv2232, lv2233), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv162 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv161,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv163 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv158,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv627 = R.call_tir(cls.matmul1, (lv163, lv160), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv164 = R.call_tir(cls.fused_reshape7_add5_reshape8, (lv627, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv631 = R.call_tir(cls.softmax, (lv164,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv165 = R.call_tir(cls.fused_reshape7_reshape8, (lv631,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv634 = R.call_tir(cls.matmul2, (lv165, lv162), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv166 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv634,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2234: R.Tensor((1280, 1280), dtype="float32") = model_params[405]
            lv2235: R.Tensor((1280,), dtype="float32") = model_params[48]
            lv167 = R.call_tir(cls.fused_matmul_add4_add2, (lv166, lv2234, lv2235, lv157), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2236: R.Tensor((1280,), dtype="float32") = model_params[44]
            lv2237: R.Tensor((1280,), dtype="float32") = model_params[43]
            lv642 = R.call_tir(cls.layer_norm, (lv167, lv2236, lv2237), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2238: R.Tensor((1280, 5120), dtype="float32") = model_params[406]
            lv2239: R.Tensor((5120,), dtype="float32") = model_params[45]
            lv168 = R.call_tir(cls.fused_matmul3_add6_gelu, (lv642, lv2238, lv2239), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv2240: R.Tensor((5120, 1280), dtype="float32") = model_params[407]
            lv2241: R.Tensor((1280,), dtype="float32") = model_params[46]
            lv169 = R.call_tir(cls.fused_matmul4_add4_add2, (lv168, lv2240, lv2241, lv167), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2242: R.Tensor((1280,), dtype="float32") = model_params[52]
            lv2243: R.Tensor((1280,), dtype="float32") = model_params[51]
            lv651 = R.call_tir(cls.layer_norm, (lv169, lv2242, lv2243), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2244: R.Tensor((1280, 1280), dtype="float32") = model_params[408]
            lv2245: R.Tensor((1280,), dtype="float32") = model_params[59]
            lv170 = R.call_tir(cls.fused_matmul_add4_multiply3, (lv651, lv2244, lv2245), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2246: R.Tensor((1280, 1280), dtype="float32") = model_params[409]
            lv2247: R.Tensor((1280,), dtype="float32") = model_params[57]
            lv171 = R.call_tir(cls.fused_matmul_add4, (lv651, lv2246, lv2247), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv172 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv171,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv2248: R.Tensor((1280, 1280), dtype="float32") = model_params[410]
            lv2249: R.Tensor((1280,), dtype="float32") = model_params[60]
            lv173 = R.call_tir(cls.fused_matmul_add4, (lv651, lv2248, lv2249), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv174 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv173,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv175 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv170,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv672 = R.call_tir(cls.matmul1, (lv175, lv172), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv176 = R.call_tir(cls.fused_reshape7_add5_reshape8, (lv672, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv676 = R.call_tir(cls.softmax, (lv176,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv177_1 = R.call_tir(cls.fused_reshape7_reshape8, (lv676,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv679 = R.call_tir(cls.matmul2, (lv177_1, lv174), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv178 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv679,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2250: R.Tensor((1280, 1280), dtype="float32") = model_params[411]
            lv2251: R.Tensor((1280,), dtype="float32") = model_params[58]
            lv179 = R.call_tir(cls.fused_matmul_add4_add2, (lv178, lv2250, lv2251, lv169), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2252: R.Tensor((1280,), dtype="float32") = model_params[54]
            lv2253: R.Tensor((1280,), dtype="float32") = model_params[53]
            lv687 = R.call_tir(cls.layer_norm, (lv179, lv2252, lv2253), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2254: R.Tensor((1280, 5120), dtype="float32") = model_params[412]
            lv2255: R.Tensor((5120,), dtype="float32") = model_params[55]
            lv180 = R.call_tir(cls.fused_matmul3_add6_gelu, (lv687, lv2254, lv2255), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv2256: R.Tensor((5120, 1280), dtype="float32") = model_params[413]
            lv2257: R.Tensor((1280,), dtype="float32") = model_params[56]
            lv181_1 = R.call_tir(cls.fused_matmul4_add4_add2, (lv180, lv2256, lv2257, lv179), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2258: R.Tensor((1280,), dtype="float32") = model_params[62]
            lv2259: R.Tensor((1280,), dtype="float32") = model_params[61]
            lv696 = R.call_tir(cls.layer_norm, (lv181_1, lv2258, lv2259), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2260: R.Tensor((1280, 1280), dtype="float32") = model_params[414]
            lv2261: R.Tensor((1280,), dtype="float32") = model_params[69]
            lv182 = R.call_tir(cls.fused_matmul_add4_multiply3, (lv696, lv2260, lv2261), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2262: R.Tensor((1280, 1280), dtype="float32") = model_params[415]
            lv2263: R.Tensor((1280,), dtype="float32") = model_params[67]
            lv183 = R.call_tir(cls.fused_matmul_add4, (lv696, lv2262, lv2263), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv184_1 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv183,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv2264: R.Tensor((1280, 1280), dtype="float32") = model_params[416]
            lv2265: R.Tensor((1280,), dtype="float32") = model_params[70]
            lv185 = R.call_tir(cls.fused_matmul_add4, (lv696, lv2264, lv2265), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv186 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv185,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv187 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv182,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv717 = R.call_tir(cls.matmul1, (lv187, lv184_1), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv188 = R.call_tir(cls.fused_reshape7_add5_reshape8, (lv717, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv721 = R.call_tir(cls.softmax, (lv188,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv189 = R.call_tir(cls.fused_reshape7_reshape8, (lv721,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv724 = R.call_tir(cls.matmul2, (lv189, lv186), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv190 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv724,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2266: R.Tensor((1280, 1280), dtype="float32") = model_params[417]
            lv2267: R.Tensor((1280,), dtype="float32") = model_params[68]
            lv191 = R.call_tir(cls.fused_matmul_add4_add2, (lv190, lv2266, lv2267, lv181_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2268: R.Tensor((1280,), dtype="float32") = model_params[64]
            lv2269: R.Tensor((1280,), dtype="float32") = model_params[63]
            lv732 = R.call_tir(cls.layer_norm, (lv191, lv2268, lv2269), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2270: R.Tensor((1280, 5120), dtype="float32") = model_params[418]
            lv2271: R.Tensor((5120,), dtype="float32") = model_params[65]
            lv192_1 = R.call_tir(cls.fused_matmul3_add6_gelu, (lv732, lv2270, lv2271), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv2272: R.Tensor((5120, 1280), dtype="float32") = model_params[419]
            lv2273: R.Tensor((1280,), dtype="float32") = model_params[66]
            lv193 = R.call_tir(cls.fused_matmul4_add4_add2, (lv192_1, lv2272, lv2273, lv191), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2274: R.Tensor((1280,), dtype="float32") = model_params[72]
            lv2275: R.Tensor((1280,), dtype="float32") = model_params[71]
            lv741 = R.call_tir(cls.layer_norm, (lv193, lv2274, lv2275), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2276: R.Tensor((1280, 1280), dtype="float32") = model_params[420]
            lv2277: R.Tensor((1280,), dtype="float32") = model_params[79]
            lv194 = R.call_tir(cls.fused_matmul_add4_multiply3, (lv741, lv2276, lv2277), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2278: R.Tensor((1280, 1280), dtype="float32") = model_params[421]
            lv2279: R.Tensor((1280,), dtype="float32") = model_params[77]
            lv195 = R.call_tir(cls.fused_matmul_add4, (lv741, lv2278, lv2279), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv196 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv195,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv2280: R.Tensor((1280, 1280), dtype="float32") = model_params[422]
            lv2281: R.Tensor((1280,), dtype="float32") = model_params[80]
            lv197 = R.call_tir(cls.fused_matmul_add4, (lv741, lv2280, lv2281), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv198 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv197,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv199 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv194,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv762 = R.call_tir(cls.matmul1, (lv199, lv196), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv200 = R.call_tir(cls.fused_reshape7_add5_reshape8, (lv762, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv766 = R.call_tir(cls.softmax, (lv200,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv201_1 = R.call_tir(cls.fused_reshape7_reshape8, (lv766,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv769 = R.call_tir(cls.matmul2, (lv201_1, lv198), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv202 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv769,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2282: R.Tensor((1280, 1280), dtype="float32") = model_params[423]
            lv2283: R.Tensor((1280,), dtype="float32") = model_params[78]
            lv203 = R.call_tir(cls.fused_matmul_add4_add2, (lv202, lv2282, lv2283, lv193), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2284: R.Tensor((1280,), dtype="float32") = model_params[74]
            lv2285: R.Tensor((1280,), dtype="float32") = model_params[73]
            lv777 = R.call_tir(cls.layer_norm, (lv203, lv2284, lv2285), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2286: R.Tensor((1280, 5120), dtype="float32") = model_params[424]
            lv2287: R.Tensor((5120,), dtype="float32") = model_params[75]
            lv204 = R.call_tir(cls.fused_matmul3_add6_gelu, (lv777, lv2286, lv2287), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv2288: R.Tensor((5120, 1280), dtype="float32") = model_params[425]
            lv2289: R.Tensor((1280,), dtype="float32") = model_params[76]
            lv205 = R.call_tir(cls.fused_matmul4_add4_add2, (lv204, lv2288, lv2289, lv203), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2290: R.Tensor((1280,), dtype="float32") = model_params[82]
            lv2291: R.Tensor((1280,), dtype="float32") = model_params[81]
            lv786 = R.call_tir(cls.layer_norm, (lv205, lv2290, lv2291), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2292: R.Tensor((1280, 1280), dtype="float32") = model_params[426]
            lv2293: R.Tensor((1280,), dtype="float32") = model_params[89]
            lv206 = R.call_tir(cls.fused_matmul_add4_multiply3, (lv786, lv2292, lv2293), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2294: R.Tensor((1280, 1280), dtype="float32") = model_params[427]
            lv2295: R.Tensor((1280,), dtype="float32") = model_params[87]
            lv207 = R.call_tir(cls.fused_matmul_add4, (lv786, lv2294, lv2295), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv208 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv207,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv2296: R.Tensor((1280, 1280), dtype="float32") = model_params[428]
            lv2297: R.Tensor((1280,), dtype="float32") = model_params[90]
            lv209 = R.call_tir(cls.fused_matmul_add4, (lv786, lv2296, lv2297), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv210 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv209,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv211 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv206,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv807 = R.call_tir(cls.matmul1, (lv211, lv208), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv212 = R.call_tir(cls.fused_reshape7_add5_reshape8, (lv807, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv811 = R.call_tir(cls.softmax, (lv212,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv213 = R.call_tir(cls.fused_reshape7_reshape8, (lv811,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv814 = R.call_tir(cls.matmul2, (lv213, lv210), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv214 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv814,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2298: R.Tensor((1280, 1280), dtype="float32") = model_params[429]
            lv2299: R.Tensor((1280,), dtype="float32") = model_params[88]
            lv215 = R.call_tir(cls.fused_matmul_add4_add2, (lv214, lv2298, lv2299, lv205), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2300: R.Tensor((1280,), dtype="float32") = model_params[84]
            lv2301: R.Tensor((1280,), dtype="float32") = model_params[83]
            lv822 = R.call_tir(cls.layer_norm, (lv215, lv2300, lv2301), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2302: R.Tensor((1280, 5120), dtype="float32") = model_params[430]
            lv2303: R.Tensor((5120,), dtype="float32") = model_params[85]
            lv216 = R.call_tir(cls.fused_matmul3_add6_gelu, (lv822, lv2302, lv2303), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv2304: R.Tensor((5120, 1280), dtype="float32") = model_params[431]
            lv2305: R.Tensor((1280,), dtype="float32") = model_params[86]
            lv217 = R.call_tir(cls.fused_matmul4_add4_add2, (lv216, lv2304, lv2305, lv215), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2306: R.Tensor((1280,), dtype="float32") = model_params[92]
            lv2307: R.Tensor((1280,), dtype="float32") = model_params[91]
            lv831 = R.call_tir(cls.layer_norm, (lv217, lv2306, lv2307), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2308: R.Tensor((1280, 1280), dtype="float32") = model_params[432]
            lv2309: R.Tensor((1280,), dtype="float32") = model_params[99]
            lv218 = R.call_tir(cls.fused_matmul_add4_multiply3, (lv831, lv2308, lv2309), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2310: R.Tensor((1280, 1280), dtype="float32") = model_params[433]
            lv2311: R.Tensor((1280,), dtype="float32") = model_params[97]
            lv219 = R.call_tir(cls.fused_matmul_add4, (lv831, lv2310, lv2311), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv220 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv219,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv2312: R.Tensor((1280, 1280), dtype="float32") = model_params[434]
            lv2313: R.Tensor((1280,), dtype="float32") = model_params[100]
            lv221 = R.call_tir(cls.fused_matmul_add4, (lv831, lv2312, lv2313), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv222_1 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv221,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv223 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv218,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv852 = R.call_tir(cls.matmul1, (lv223, lv220), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv224 = R.call_tir(cls.fused_reshape7_add5_reshape8, (lv852, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv856 = R.call_tir(cls.softmax, (lv224,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv225 = R.call_tir(cls.fused_reshape7_reshape8, (lv856,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv859 = R.call_tir(cls.matmul2, (lv225, lv222_1), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv226_1 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv859,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2314: R.Tensor((1280, 1280), dtype="float32") = model_params[435]
            lv2315: R.Tensor((1280,), dtype="float32") = model_params[98]
            lv227 = R.call_tir(cls.fused_matmul_add4_add2, (lv226_1, lv2314, lv2315, lv217), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2316: R.Tensor((1280,), dtype="float32") = model_params[94]
            lv2317: R.Tensor((1280,), dtype="float32") = model_params[93]
            lv867 = R.call_tir(cls.layer_norm, (lv227, lv2316, lv2317), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2318: R.Tensor((1280, 5120), dtype="float32") = model_params[436]
            lv2319: R.Tensor((5120,), dtype="float32") = model_params[95]
            lv228 = R.call_tir(cls.fused_matmul3_add6_gelu, (lv867, lv2318, lv2319), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv2320: R.Tensor((5120, 1280), dtype="float32") = model_params[437]
            lv2321: R.Tensor((1280,), dtype="float32") = model_params[96]
            lv229_1 = R.call_tir(cls.fused_matmul4_add4_add2, (lv228, lv2320, lv2321, lv227), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2322: R.Tensor((1280,), dtype="float32") = model_params[102]
            lv2323: R.Tensor((1280,), dtype="float32") = model_params[101]
            lv876 = R.call_tir(cls.layer_norm, (lv229_1, lv2322, lv2323), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2324: R.Tensor((1280, 1280), dtype="float32") = model_params[438]
            lv2325: R.Tensor((1280,), dtype="float32") = model_params[109]
            lv230 = R.call_tir(cls.fused_matmul_add4_multiply3, (lv876, lv2324, lv2325), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2326: R.Tensor((1280, 1280), dtype="float32") = model_params[439]
            lv2327: R.Tensor((1280,), dtype="float32") = model_params[107]
            lv231 = R.call_tir(cls.fused_matmul_add4, (lv876, lv2326, lv2327), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv232 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv231,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv2328: R.Tensor((1280, 1280), dtype="float32") = model_params[440]
            lv2329: R.Tensor((1280,), dtype="float32") = model_params[110]
            lv233 = R.call_tir(cls.fused_matmul_add4, (lv876, lv2328, lv2329), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv234 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv233,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv235 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv230,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv897 = R.call_tir(cls.matmul1, (lv235, lv232), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv236 = R.call_tir(cls.fused_reshape7_add5_reshape8, (lv897, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv901 = R.call_tir(cls.softmax, (lv236,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv237_1 = R.call_tir(cls.fused_reshape7_reshape8, (lv901,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv904 = R.call_tir(cls.matmul2, (lv237_1, lv234), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv238 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv904,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2330: R.Tensor((1280, 1280), dtype="float32") = model_params[441]
            lv2331: R.Tensor((1280,), dtype="float32") = model_params[108]
            lv239 = R.call_tir(cls.fused_matmul_add4_add2, (lv238, lv2330, lv2331, lv229_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2332: R.Tensor((1280,), dtype="float32") = model_params[104]
            lv2333: R.Tensor((1280,), dtype="float32") = model_params[103]
            lv912 = R.call_tir(cls.layer_norm, (lv239, lv2332, lv2333), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2334: R.Tensor((1280, 5120), dtype="float32") = model_params[442]
            lv2335: R.Tensor((5120,), dtype="float32") = model_params[105]
            lv240 = R.call_tir(cls.fused_matmul3_add6_gelu, (lv912, lv2334, lv2335), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv2336: R.Tensor((5120, 1280), dtype="float32") = model_params[443]
            lv2337: R.Tensor((1280,), dtype="float32") = model_params[106]
            lv241 = R.call_tir(cls.fused_matmul4_add4_add2, (lv240, lv2336, lv2337, lv239), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2338: R.Tensor((1280,), dtype="float32") = model_params[122]
            lv2339: R.Tensor((1280,), dtype="float32") = model_params[121]
            lv921 = R.call_tir(cls.layer_norm, (lv241, lv2338, lv2339), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2340: R.Tensor((1280, 1280), dtype="float32") = model_params[444]
            lv2341: R.Tensor((1280,), dtype="float32") = model_params[129]
            lv242 = R.call_tir(cls.fused_matmul_add4_multiply3, (lv921, lv2340, lv2341), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2342: R.Tensor((1280, 1280), dtype="float32") = model_params[445]
            lv2343: R.Tensor((1280,), dtype="float32") = model_params[127]
            lv243 = R.call_tir(cls.fused_matmul_add4, (lv921, lv2342, lv2343), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv244 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv243,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv2344: R.Tensor((1280, 1280), dtype="float32") = model_params[446]
            lv2345: R.Tensor((1280,), dtype="float32") = model_params[130]
            lv245 = R.call_tir(cls.fused_matmul_add4, (lv921, lv2344, lv2345), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv246_1 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv245,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv247 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv242,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv942 = R.call_tir(cls.matmul1, (lv247, lv244), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv248 = R.call_tir(cls.fused_reshape7_add5_reshape8, (lv942, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv946 = R.call_tir(cls.softmax, (lv248,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv249 = R.call_tir(cls.fused_reshape7_reshape8, (lv946,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv949 = R.call_tir(cls.matmul2, (lv249, lv246_1), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv250 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv949,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2346: R.Tensor((1280, 1280), dtype="float32") = model_params[447]
            lv2347: R.Tensor((1280,), dtype="float32") = model_params[128]
            lv251 = R.call_tir(cls.fused_matmul_add4_add2, (lv250, lv2346, lv2347, lv241), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2348: R.Tensor((1280,), dtype="float32") = model_params[124]
            lv2349: R.Tensor((1280,), dtype="float32") = model_params[123]
            lv957 = R.call_tir(cls.layer_norm, (lv251, lv2348, lv2349), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2350: R.Tensor((1280, 5120), dtype="float32") = model_params[448]
            lv2351: R.Tensor((5120,), dtype="float32") = model_params[125]
            lv252 = R.call_tir(cls.fused_matmul3_add6_gelu, (lv957, lv2350, lv2351), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv2352: R.Tensor((5120, 1280), dtype="float32") = model_params[449]
            lv2353: R.Tensor((1280,), dtype="float32") = model_params[126]
            lv253 = R.call_tir(cls.fused_matmul4_add4_add2, (lv252, lv2352, lv2353, lv251), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2354: R.Tensor((1280,), dtype="float32") = model_params[132]
            lv2355: R.Tensor((1280,), dtype="float32") = model_params[131]
            lv966 = R.call_tir(cls.layer_norm, (lv253, lv2354, lv2355), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2356: R.Tensor((1280, 1280), dtype="float32") = model_params[450]
            lv2357: R.Tensor((1280,), dtype="float32") = model_params[139]
            lv254 = R.call_tir(cls.fused_matmul_add4_multiply3, (lv966, lv2356, lv2357), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2358: R.Tensor((1280, 1280), dtype="float32") = model_params[451]
            lv2359: R.Tensor((1280,), dtype="float32") = model_params[137]
            lv255 = R.call_tir(cls.fused_matmul_add4, (lv966, lv2358, lv2359), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv256 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv255,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv2360: R.Tensor((1280, 1280), dtype="float32") = model_params[452]
            lv2361: R.Tensor((1280,), dtype="float32") = model_params[140]
            lv257 = R.call_tir(cls.fused_matmul_add4, (lv966, lv2360, lv2361), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv258 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv257,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv259 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv254,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv987 = R.call_tir(cls.matmul1, (lv259, lv256), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv260 = R.call_tir(cls.fused_reshape7_add5_reshape8, (lv987, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv991 = R.call_tir(cls.softmax, (lv260,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv261 = R.call_tir(cls.fused_reshape7_reshape8, (lv991,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv994 = R.call_tir(cls.matmul2, (lv261, lv258), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv262 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv994,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2362: R.Tensor((1280, 1280), dtype="float32") = model_params[453]
            lv2363: R.Tensor((1280,), dtype="float32") = model_params[138]
            lv263 = R.call_tir(cls.fused_matmul_add4_add2, (lv262, lv2362, lv2363, lv253), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2364: R.Tensor((1280,), dtype="float32") = model_params[134]
            lv2365: R.Tensor((1280,), dtype="float32") = model_params[133]
            lv1002 = R.call_tir(cls.layer_norm, (lv263, lv2364, lv2365), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2366: R.Tensor((1280, 5120), dtype="float32") = model_params[454]
            lv2367: R.Tensor((5120,), dtype="float32") = model_params[135]
            lv264 = R.call_tir(cls.fused_matmul3_add6_gelu, (lv1002, lv2366, lv2367), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv2368: R.Tensor((5120, 1280), dtype="float32") = model_params[455]
            lv2369: R.Tensor((1280,), dtype="float32") = model_params[136]
            lv265 = R.call_tir(cls.fused_matmul4_add4_add2, (lv264, lv2368, lv2369, lv263), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2370: R.Tensor((1280,), dtype="float32") = model_params[142]
            lv2371: R.Tensor((1280,), dtype="float32") = model_params[141]
            lv1011 = R.call_tir(cls.layer_norm, (lv265, lv2370, lv2371), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2372: R.Tensor((1280, 1280), dtype="float32") = model_params[456]
            lv2373: R.Tensor((1280,), dtype="float32") = model_params[149]
            lv266 = R.call_tir(cls.fused_matmul_add4_multiply3, (lv1011, lv2372, lv2373), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2374: R.Tensor((1280, 1280), dtype="float32") = model_params[457]
            lv2375: R.Tensor((1280,), dtype="float32") = model_params[147]
            lv267_1 = R.call_tir(cls.fused_matmul_add4, (lv1011, lv2374, lv2375), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv268 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv267_1,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv2376: R.Tensor((1280, 1280), dtype="float32") = model_params[458]
            lv2377: R.Tensor((1280,), dtype="float32") = model_params[150]
            lv269 = R.call_tir(cls.fused_matmul_add4, (lv1011, lv2376, lv2377), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv270 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv269,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv271_1 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv266,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1032 = R.call_tir(cls.matmul1, (lv271_1, lv268), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv272 = R.call_tir(cls.fused_reshape7_add5_reshape8, (lv1032, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1036 = R.call_tir(cls.softmax, (lv272,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv273 = R.call_tir(cls.fused_reshape7_reshape8, (lv1036,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1039 = R.call_tir(cls.matmul2, (lv273, lv270), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv274_1 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv1039,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2378: R.Tensor((1280, 1280), dtype="float32") = model_params[459]
            lv2379: R.Tensor((1280,), dtype="float32") = model_params[148]
            lv275 = R.call_tir(cls.fused_matmul_add4_add2, (lv274_1, lv2378, lv2379, lv265), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2380: R.Tensor((1280,), dtype="float32") = model_params[144]
            lv2381: R.Tensor((1280,), dtype="float32") = model_params[143]
            lv1047 = R.call_tir(cls.layer_norm, (lv275, lv2380, lv2381), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2382: R.Tensor((1280, 5120), dtype="float32") = model_params[460]
            lv2383: R.Tensor((5120,), dtype="float32") = model_params[145]
            lv276 = R.call_tir(cls.fused_matmul3_add6_gelu, (lv1047, lv2382, lv2383), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv2384: R.Tensor((5120, 1280), dtype="float32") = model_params[461]
            lv2385: R.Tensor((1280,), dtype="float32") = model_params[146]
            lv277 = R.call_tir(cls.fused_matmul4_add4_add2, (lv276, lv2384, lv2385, lv275), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2386: R.Tensor((1280,), dtype="float32") = model_params[152]
            lv2387: R.Tensor((1280,), dtype="float32") = model_params[151]
            lv1056 = R.call_tir(cls.layer_norm, (lv277, lv2386, lv2387), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2388: R.Tensor((1280, 1280), dtype="float32") = model_params[462]
            lv2389: R.Tensor((1280,), dtype="float32") = model_params[159]
            lv278 = R.call_tir(cls.fused_matmul_add4_multiply3, (lv1056, lv2388, lv2389), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2390: R.Tensor((1280, 1280), dtype="float32") = model_params[463]
            lv2391: R.Tensor((1280,), dtype="float32") = model_params[157]
            lv279 = R.call_tir(cls.fused_matmul_add4, (lv1056, lv2390, lv2391), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv280 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv279,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv2392: R.Tensor((1280, 1280), dtype="float32") = model_params[464]
            lv2393: R.Tensor((1280,), dtype="float32") = model_params[160]
            lv281 = R.call_tir(cls.fused_matmul_add4, (lv1056, lv2392, lv2393), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv282_1 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv281,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv283 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv278,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1077 = R.call_tir(cls.matmul1, (lv283, lv280), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv284 = R.call_tir(cls.fused_reshape7_add5_reshape8, (lv1077, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1081 = R.call_tir(cls.softmax, (lv284,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv285 = R.call_tir(cls.fused_reshape7_reshape8, (lv1081,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1084 = R.call_tir(cls.matmul2, (lv285, lv282_1), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv286 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv1084,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2394: R.Tensor((1280, 1280), dtype="float32") = model_params[465]
            lv2395: R.Tensor((1280,), dtype="float32") = model_params[158]
            lv287 = R.call_tir(cls.fused_matmul_add4_add2, (lv286, lv2394, lv2395, lv277), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2396: R.Tensor((1280,), dtype="float32") = model_params[154]
            lv2397: R.Tensor((1280,), dtype="float32") = model_params[153]
            lv1092 = R.call_tir(cls.layer_norm, (lv287, lv2396, lv2397), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2398: R.Tensor((1280, 5120), dtype="float32") = model_params[466]
            lv2399: R.Tensor((5120,), dtype="float32") = model_params[155]
            lv288 = R.call_tir(cls.fused_matmul3_add6_gelu, (lv1092, lv2398, lv2399), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv2400: R.Tensor((5120, 1280), dtype="float32") = model_params[467]
            lv2401: R.Tensor((1280,), dtype="float32") = model_params[156]
            lv289 = R.call_tir(cls.fused_matmul4_add4_add2, (lv288, lv2400, lv2401, lv287), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2402: R.Tensor((1280,), dtype="float32") = model_params[162]
            lv2403: R.Tensor((1280,), dtype="float32") = model_params[161]
            lv1101 = R.call_tir(cls.layer_norm, (lv289, lv2402, lv2403), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2404: R.Tensor((1280, 1280), dtype="float32") = model_params[468]
            lv2405: R.Tensor((1280,), dtype="float32") = model_params[169]
            lv290 = R.call_tir(cls.fused_matmul_add4_multiply3, (lv1101, lv2404, lv2405), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2406: R.Tensor((1280, 1280), dtype="float32") = model_params[469]
            lv2407: R.Tensor((1280,), dtype="float32") = model_params[167]
            lv291_1 = R.call_tir(cls.fused_matmul_add4, (lv1101, lv2406, lv2407), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv292 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv291_1,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv2408: R.Tensor((1280, 1280), dtype="float32") = model_params[470]
            lv2409: R.Tensor((1280,), dtype="float32") = model_params[170]
            lv293 = R.call_tir(cls.fused_matmul_add4, (lv1101, lv2408, lv2409), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv294 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv293,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv295 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv290,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1122 = R.call_tir(cls.matmul1, (lv295, lv292), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv296 = R.call_tir(cls.fused_reshape7_add5_reshape8, (lv1122, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1126 = R.call_tir(cls.softmax, (lv296,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv297 = R.call_tir(cls.fused_reshape7_reshape8, (lv1126,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1129 = R.call_tir(cls.matmul2, (lv297, lv294), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv298 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv1129,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2410: R.Tensor((1280, 1280), dtype="float32") = model_params[471]
            lv2411: R.Tensor((1280,), dtype="float32") = model_params[168]
            lv299 = R.call_tir(cls.fused_matmul_add4_add2, (lv298, lv2410, lv2411, lv289), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2412: R.Tensor((1280,), dtype="float32") = model_params[164]
            lv2413: R.Tensor((1280,), dtype="float32") = model_params[163]
            lv1137 = R.call_tir(cls.layer_norm, (lv299, lv2412, lv2413), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2414: R.Tensor((1280, 5120), dtype="float32") = model_params[472]
            lv2415: R.Tensor((5120,), dtype="float32") = model_params[165]
            lv300 = R.call_tir(cls.fused_matmul3_add6_gelu, (lv1137, lv2414, lv2415), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv2416: R.Tensor((5120, 1280), dtype="float32") = model_params[473]
            lv2417: R.Tensor((1280,), dtype="float32") = model_params[166]
            lv301 = R.call_tir(cls.fused_matmul4_add4_add2, (lv300, lv2416, lv2417, lv299), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2418: R.Tensor((1280,), dtype="float32") = model_params[172]
            lv2419: R.Tensor((1280,), dtype="float32") = model_params[171]
            lv1146 = R.call_tir(cls.layer_norm, (lv301, lv2418, lv2419), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2420: R.Tensor((1280, 1280), dtype="float32") = model_params[474]
            lv2421: R.Tensor((1280,), dtype="float32") = model_params[179]
            lv302 = R.call_tir(cls.fused_matmul_add4_multiply3, (lv1146, lv2420, lv2421), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2422: R.Tensor((1280, 1280), dtype="float32") = model_params[475]
            lv2423: R.Tensor((1280,), dtype="float32") = model_params[177]
            lv303 = R.call_tir(cls.fused_matmul_add4, (lv1146, lv2422, lv2423), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv304 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv303,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv2424: R.Tensor((1280, 1280), dtype="float32") = model_params[476]
            lv2425: R.Tensor((1280,), dtype="float32") = model_params[180]
            lv305 = R.call_tir(cls.fused_matmul_add4, (lv1146, lv2424, lv2425), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv306 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv305,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv307 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv302,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1167 = R.call_tir(cls.matmul1, (lv307, lv304), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv308 = R.call_tir(cls.fused_reshape7_add5_reshape8, (lv1167, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1171 = R.call_tir(cls.softmax, (lv308,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv309 = R.call_tir(cls.fused_reshape7_reshape8, (lv1171,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1174 = R.call_tir(cls.matmul2, (lv309, lv306), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv310 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv1174,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2426: R.Tensor((1280, 1280), dtype="float32") = model_params[477]
            lv2427: R.Tensor((1280,), dtype="float32") = model_params[178]
            lv311 = R.call_tir(cls.fused_matmul_add4_add2, (lv310, lv2426, lv2427, lv301), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2428: R.Tensor((1280,), dtype="float32") = model_params[174]
            lv2429: R.Tensor((1280,), dtype="float32") = model_params[173]
            lv1182 = R.call_tir(cls.layer_norm, (lv311, lv2428, lv2429), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2430: R.Tensor((1280, 5120), dtype="float32") = model_params[478]
            lv2431: R.Tensor((5120,), dtype="float32") = model_params[175]
            lv312_1 = R.call_tir(cls.fused_matmul3_add6_gelu, (lv1182, lv2430, lv2431), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv2432: R.Tensor((5120, 1280), dtype="float32") = model_params[479]
            lv2433: R.Tensor((1280,), dtype="float32") = model_params[176]
            lv313 = R.call_tir(cls.fused_matmul4_add4_add2, (lv312_1, lv2432, lv2433, lv311), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2434: R.Tensor((1280,), dtype="float32") = model_params[182]
            lv2435: R.Tensor((1280,), dtype="float32") = model_params[181]
            lv1191 = R.call_tir(cls.layer_norm, (lv313, lv2434, lv2435), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2436: R.Tensor((1280, 1280), dtype="float32") = model_params[480]
            lv2437: R.Tensor((1280,), dtype="float32") = model_params[189]
            lv314 = R.call_tir(cls.fused_matmul_add4_multiply3, (lv1191, lv2436, lv2437), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2438: R.Tensor((1280, 1280), dtype="float32") = model_params[481]
            lv2439: R.Tensor((1280,), dtype="float32") = model_params[187]
            lv315 = R.call_tir(cls.fused_matmul_add4, (lv1191, lv2438, lv2439), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv316_1 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv315,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv2440: R.Tensor((1280, 1280), dtype="float32") = model_params[482]
            lv2441: R.Tensor((1280,), dtype="float32") = model_params[190]
            lv317 = R.call_tir(cls.fused_matmul_add4, (lv1191, lv2440, lv2441), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv318 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv317,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv319_1 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv314,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1212 = R.call_tir(cls.matmul1, (lv319_1, lv316_1), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv320 = R.call_tir(cls.fused_reshape7_add5_reshape8, (lv1212, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1216 = R.call_tir(cls.softmax, (lv320,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv321 = R.call_tir(cls.fused_reshape7_reshape8, (lv1216,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1219 = R.call_tir(cls.matmul2, (lv321, lv318), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv322 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv1219,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2442: R.Tensor((1280, 1280), dtype="float32") = model_params[483]
            lv2443: R.Tensor((1280,), dtype="float32") = model_params[188]
            lv323 = R.call_tir(cls.fused_matmul_add4_add2, (lv322, lv2442, lv2443, lv313), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2444: R.Tensor((1280,), dtype="float32") = model_params[184]
            lv2445: R.Tensor((1280,), dtype="float32") = model_params[183]
            lv1227 = R.call_tir(cls.layer_norm, (lv323, lv2444, lv2445), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2446: R.Tensor((1280, 5120), dtype="float32") = model_params[484]
            lv2447: R.Tensor((5120,), dtype="float32") = model_params[185]
            lv324 = R.call_tir(cls.fused_matmul3_add6_gelu, (lv1227, lv2446, lv2447), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv2448: R.Tensor((5120, 1280), dtype="float32") = model_params[485]
            lv2449: R.Tensor((1280,), dtype="float32") = model_params[186]
            lv325 = R.call_tir(cls.fused_matmul4_add4_add2, (lv324, lv2448, lv2449, lv323), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2450: R.Tensor((1280,), dtype="float32") = model_params[192]
            lv2451: R.Tensor((1280,), dtype="float32") = model_params[191]
            lv1236 = R.call_tir(cls.layer_norm, (lv325, lv2450, lv2451), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2452: R.Tensor((1280, 1280), dtype="float32") = model_params[486]
            lv2453: R.Tensor((1280,), dtype="float32") = model_params[199]
            lv326 = R.call_tir(cls.fused_matmul_add4_multiply3, (lv1236, lv2452, lv2453), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2454: R.Tensor((1280, 1280), dtype="float32") = model_params[487]
            lv2455: R.Tensor((1280,), dtype="float32") = model_params[197]
            lv327_1 = R.call_tir(cls.fused_matmul_add4, (lv1236, lv2454, lv2455), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv328 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv327_1,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv2456: R.Tensor((1280, 1280), dtype="float32") = model_params[488]
            lv2457: R.Tensor((1280,), dtype="float32") = model_params[200]
            lv329 = R.call_tir(cls.fused_matmul_add4, (lv1236, lv2456, lv2457), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv330 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv329,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv331 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv326,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1257 = R.call_tir(cls.matmul1, (lv331, lv328), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv332 = R.call_tir(cls.fused_reshape7_add5_reshape8, (lv1257, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1261 = R.call_tir(cls.softmax, (lv332,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv333 = R.call_tir(cls.fused_reshape7_reshape8, (lv1261,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1264 = R.call_tir(cls.matmul2, (lv333, lv330), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv334 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv1264,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2458: R.Tensor((1280, 1280), dtype="float32") = model_params[489]
            lv2459: R.Tensor((1280,), dtype="float32") = model_params[198]
            lv335 = R.call_tir(cls.fused_matmul_add4_add2, (lv334, lv2458, lv2459, lv325), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2460: R.Tensor((1280,), dtype="float32") = model_params[194]
            lv2461: R.Tensor((1280,), dtype="float32") = model_params[193]
            lv1272 = R.call_tir(cls.layer_norm, (lv335, lv2460, lv2461), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2462: R.Tensor((1280, 5120), dtype="float32") = model_params[490]
            lv2463: R.Tensor((5120,), dtype="float32") = model_params[195]
            lv336_1 = R.call_tir(cls.fused_matmul3_add6_gelu, (lv1272, lv2462, lv2463), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv2464: R.Tensor((5120, 1280), dtype="float32") = model_params[491]
            lv2465: R.Tensor((1280,), dtype="float32") = model_params[196]
            lv337 = R.call_tir(cls.fused_matmul4_add4_add2, (lv336_1, lv2464, lv2465, lv335), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2466: R.Tensor((1280,), dtype="float32") = model_params[202]
            lv2467: R.Tensor((1280,), dtype="float32") = model_params[201]
            lv1281 = R.call_tir(cls.layer_norm, (lv337, lv2466, lv2467), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2468: R.Tensor((1280, 1280), dtype="float32") = model_params[492]
            lv2469: R.Tensor((1280,), dtype="float32") = model_params[209]
            lv338 = R.call_tir(cls.fused_matmul_add4_multiply3, (lv1281, lv2468, lv2469), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2470: R.Tensor((1280, 1280), dtype="float32") = model_params[493]
            lv2471: R.Tensor((1280,), dtype="float32") = model_params[207]
            lv339 = R.call_tir(cls.fused_matmul_add4, (lv1281, lv2470, lv2471), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv340 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv339,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv2472: R.Tensor((1280, 1280), dtype="float32") = model_params[494]
            lv2473: R.Tensor((1280,), dtype="float32") = model_params[210]
            lv341 = R.call_tir(cls.fused_matmul_add4, (lv1281, lv2472, lv2473), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv342 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv341,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv343 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv338,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1302 = R.call_tir(cls.matmul1, (lv343, lv340), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv344 = R.call_tir(cls.fused_reshape7_add5_reshape8, (lv1302, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1306 = R.call_tir(cls.softmax, (lv344,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv345 = R.call_tir(cls.fused_reshape7_reshape8, (lv1306,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1309 = R.call_tir(cls.matmul2, (lv345, lv342), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv346 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv1309,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2474: R.Tensor((1280, 1280), dtype="float32") = model_params[495]
            lv2475: R.Tensor((1280,), dtype="float32") = model_params[208]
            lv347 = R.call_tir(cls.fused_matmul_add4_add2, (lv346, lv2474, lv2475, lv337), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2476: R.Tensor((1280,), dtype="float32") = model_params[204]
            lv2477: R.Tensor((1280,), dtype="float32") = model_params[203]
            lv1317 = R.call_tir(cls.layer_norm, (lv347, lv2476, lv2477), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2478: R.Tensor((1280, 5120), dtype="float32") = model_params[496]
            lv2479: R.Tensor((5120,), dtype="float32") = model_params[205]
            lv348 = R.call_tir(cls.fused_matmul3_add6_gelu, (lv1317, lv2478, lv2479), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv2480: R.Tensor((5120, 1280), dtype="float32") = model_params[497]
            lv2481: R.Tensor((1280,), dtype="float32") = model_params[206]
            lv349 = R.call_tir(cls.fused_matmul4_add4_add2, (lv348, lv2480, lv2481, lv347), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2482: R.Tensor((1280,), dtype="float32") = model_params[212]
            lv2483: R.Tensor((1280,), dtype="float32") = model_params[211]
            lv1326 = R.call_tir(cls.layer_norm, (lv349, lv2482, lv2483), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2484: R.Tensor((1280, 1280), dtype="float32") = model_params[498]
            lv2485: R.Tensor((1280,), dtype="float32") = model_params[219]
            lv350 = R.call_tir(cls.fused_matmul_add4_multiply3, (lv1326, lv2484, lv2485), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2486: R.Tensor((1280, 1280), dtype="float32") = model_params[499]
            lv2487: R.Tensor((1280,), dtype="float32") = model_params[217]
            lv351 = R.call_tir(cls.fused_matmul_add4, (lv1326, lv2486, lv2487), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv352 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv351,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv2488: R.Tensor((1280, 1280), dtype="float32") = model_params[500]
            lv2489: R.Tensor((1280,), dtype="float32") = model_params[220]
            lv353 = R.call_tir(cls.fused_matmul_add4, (lv1326, lv2488, lv2489), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv354 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv353,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv355 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv350,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1347 = R.call_tir(cls.matmul1, (lv355, lv352), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv356 = R.call_tir(cls.fused_reshape7_add5_reshape8, (lv1347, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1351 = R.call_tir(cls.softmax, (lv356,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv357_1 = R.call_tir(cls.fused_reshape7_reshape8, (lv1351,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1354 = R.call_tir(cls.matmul2, (lv357_1, lv354), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv358 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv1354,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2490: R.Tensor((1280, 1280), dtype="float32") = model_params[501]
            lv2491: R.Tensor((1280,), dtype="float32") = model_params[218]
            lv359 = R.call_tir(cls.fused_matmul_add4_add2, (lv358, lv2490, lv2491, lv349), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2492: R.Tensor((1280,), dtype="float32") = model_params[214]
            lv2493: R.Tensor((1280,), dtype="float32") = model_params[213]
            lv1362 = R.call_tir(cls.layer_norm, (lv359, lv2492, lv2493), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2494: R.Tensor((1280, 5120), dtype="float32") = model_params[502]
            lv2495: R.Tensor((5120,), dtype="float32") = model_params[215]
            lv360 = R.call_tir(cls.fused_matmul3_add6_gelu, (lv1362, lv2494, lv2495), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv2496: R.Tensor((5120, 1280), dtype="float32") = model_params[503]
            lv2497: R.Tensor((1280,), dtype="float32") = model_params[216]
            lv361_1 = R.call_tir(cls.fused_matmul4_add4_add2, (lv360, lv2496, lv2497, lv359), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2498: R.Tensor((1280,), dtype="float32") = model_params[232]
            lv2499: R.Tensor((1280,), dtype="float32") = model_params[231]
            lv1371 = R.call_tir(cls.layer_norm, (lv361_1, lv2498, lv2499), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2500: R.Tensor((1280, 1280), dtype="float32") = model_params[504]
            lv2501: R.Tensor((1280,), dtype="float32") = model_params[239]
            lv362 = R.call_tir(cls.fused_matmul_add4_multiply3, (lv1371, lv2500, lv2501), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2502: R.Tensor((1280, 1280), dtype="float32") = model_params[505]
            lv2503: R.Tensor((1280,), dtype="float32") = model_params[237]
            lv363 = R.call_tir(cls.fused_matmul_add4, (lv1371, lv2502, lv2503), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv364_1 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv363,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv2504: R.Tensor((1280, 1280), dtype="float32") = model_params[506]
            lv2505: R.Tensor((1280,), dtype="float32") = model_params[240]
            lv365 = R.call_tir(cls.fused_matmul_add4, (lv1371, lv2504, lv2505), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv366 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv365,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv367 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv362,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1392 = R.call_tir(cls.matmul1, (lv367, lv364_1), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv368 = R.call_tir(cls.fused_reshape7_add5_reshape8, (lv1392, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1396 = R.call_tir(cls.softmax, (lv368,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv369 = R.call_tir(cls.fused_reshape7_reshape8, (lv1396,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1399 = R.call_tir(cls.matmul2, (lv369, lv366), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv370 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv1399,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2506: R.Tensor((1280, 1280), dtype="float32") = model_params[507]
            lv2507: R.Tensor((1280,), dtype="float32") = model_params[238]
            lv371 = R.call_tir(cls.fused_matmul_add4_add2, (lv370, lv2506, lv2507, lv361_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2508: R.Tensor((1280,), dtype="float32") = model_params[234]
            lv2509: R.Tensor((1280,), dtype="float32") = model_params[233]
            lv1407 = R.call_tir(cls.layer_norm, (lv371, lv2508, lv2509), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2510: R.Tensor((1280, 5120), dtype="float32") = model_params[508]
            lv2511: R.Tensor((5120,), dtype="float32") = model_params[235]
            lv372_1 = R.call_tir(cls.fused_matmul3_add6_gelu, (lv1407, lv2510, lv2511), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv2512: R.Tensor((5120, 1280), dtype="float32") = model_params[509]
            lv2513: R.Tensor((1280,), dtype="float32") = model_params[236]
            lv373 = R.call_tir(cls.fused_matmul4_add4_add2, (lv372_1, lv2512, lv2513, lv371), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2514: R.Tensor((1280,), dtype="float32") = model_params[242]
            lv2515: R.Tensor((1280,), dtype="float32") = model_params[241]
            lv1416 = R.call_tir(cls.layer_norm, (lv373, lv2514, lv2515), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2516: R.Tensor((1280, 1280), dtype="float32") = model_params[510]
            lv2517: R.Tensor((1280,), dtype="float32") = model_params[249]
            lv374 = R.call_tir(cls.fused_matmul_add4_multiply3, (lv1416, lv2516, lv2517), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2518: R.Tensor((1280, 1280), dtype="float32") = model_params[511]
            lv2519: R.Tensor((1280,), dtype="float32") = model_params[247]
            lv375 = R.call_tir(cls.fused_matmul_add4, (lv1416, lv2518, lv2519), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv376 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv375,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv2520: R.Tensor((1280, 1280), dtype="float32") = model_params[512]
            lv2521: R.Tensor((1280,), dtype="float32") = model_params[250]
            lv377 = R.call_tir(cls.fused_matmul_add4, (lv1416, lv2520, lv2521), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv378 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv377,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv379 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv374,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1437 = R.call_tir(cls.matmul1, (lv379, lv376), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv380 = R.call_tir(cls.fused_reshape7_add5_reshape8, (lv1437, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1441 = R.call_tir(cls.softmax, (lv380,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv381_1 = R.call_tir(cls.fused_reshape7_reshape8, (lv1441,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1444 = R.call_tir(cls.matmul2, (lv381_1, lv378), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv382 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv1444,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2522: R.Tensor((1280, 1280), dtype="float32") = model_params[513]
            lv2523: R.Tensor((1280,), dtype="float32") = model_params[248]
            lv383 = R.call_tir(cls.fused_matmul_add4_add2, (lv382, lv2522, lv2523, lv373), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2524: R.Tensor((1280,), dtype="float32") = model_params[244]
            lv2525: R.Tensor((1280,), dtype="float32") = model_params[243]
            lv1452 = R.call_tir(cls.layer_norm, (lv383, lv2524, lv2525), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2526: R.Tensor((1280, 5120), dtype="float32") = model_params[514]
            lv2527: R.Tensor((5120,), dtype="float32") = model_params[245]
            lv384 = R.call_tir(cls.fused_matmul3_add6_gelu, (lv1452, lv2526, lv2527), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv2528: R.Tensor((5120, 1280), dtype="float32") = model_params[515]
            lv2529: R.Tensor((1280,), dtype="float32") = model_params[246]
            lv385 = R.call_tir(cls.fused_matmul4_add4_add2, (lv384, lv2528, lv2529, lv383), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2530: R.Tensor((1280,), dtype="float32") = model_params[322]
            lv2531: R.Tensor((1280,), dtype="float32") = model_params[321]
            lv1461 = R.call_tir(cls.layer_norm, (lv385, lv2530, lv2531), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1462 = R.call_tir(cls.squeeze, (lv1461,), out_sinfo=R.Tensor((77, 1280), dtype="float32"))
            lv1463 = R.call_tir(cls.cast, (lv,), out_sinfo=R.Tensor((1, 77), dtype="int32"))
            lv1464 = R.call_tir(cls.argmax, (lv1463,), out_sinfo=R.Tensor((1,), dtype="int64"))
            lv1465 = R.call_tir(cls.take2, (lv1462, lv1464), out_sinfo=R.Tensor((1, 1280), dtype="float32"))
            lv386 = R.call_tir(cls.fused_strided_slice_reshape11, (lv1465,), out_sinfo=R.Tensor((1, 1280), dtype="float32"))
            lv2532: R.Tensor((1280, 1280), dtype="float32") = model_params[516]
            lv1469 = R.call_tir(cls.matmul5, (lv386, lv2532), out_sinfo=R.Tensor((1, 1280), dtype="float32"))
            gv: R.Tuple(R.Tensor((1, 77, 1280), dtype="float32"), R.Tensor((1, 1280), dtype="float32")) = lv373, lv1469
            R.output(gv)
        return gv

    @R.function
    def concat_embeddings(cond_embeddings: R.Tensor((1, 77, 2048), dtype="float32"), uncond_embeddings: R.Tensor((1, 77, 2048), dtype="float32")) -> R.Tensor((2, 77, 2048), dtype="float32"):
        cls = Module
        gv = R.call_tir(cls.concatenate13, (cond_embeddings, uncond_embeddings), out_sinfo=R.Tensor((2, 77, 2048), dtype="float32"))
        return gv

    @R.function
    def concat_enocder_outputs(cond_embeddings: R.Tensor((1, 77, 768), dtype="float32"), uncond_embeddings: R.Tensor((1, 77, 1280), dtype="float32")) -> R.Tensor((1, 77, 2048), dtype="float32"):
        cls = Module
        gv = R.call_tir(cls.concatenate, (cond_embeddings, uncond_embeddings), out_sinfo=R.Tensor((1, 77, 2048), dtype="float32"))
        return gv

    @R.function
    def concat_pool_embeddings(cond_embeddings: R.Tensor((1, 1280), dtype="float32"), uncond_embeddings: R.Tensor((1, 1280), dtype="float32")) -> R.Tensor((2, 1280), dtype="float32"):
        cls = Module
        gv = R.call_tir(cls.concatenate11, (cond_embeddings, uncond_embeddings), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
        return gv

    @R.function
    def euler_ancestral_discrete_scheduler_scale(sample: R.Tensor((1, 4, 64, 64), dtype="float32"), sigma: R.Tensor((), dtype="float32")) -> R.Tensor((1, 4, 64, 64), dtype="float32"):
        cls = Module
        gv = R.call_tir(cls.power, (sigma,), out_sinfo=R.Tensor((), dtype="float32"))
        gv1 = R.call_tir(cls.add1, (gv,), out_sinfo=R.Tensor((), dtype="float32"))
        gv2 = R.call_tir(cls.power1, (gv1,), out_sinfo=R.Tensor((), dtype="float32"))
        scaled_latent_model_input = R.call_tir(cls.divide, (sample, gv2), out_sinfo=R.Tensor((1, 4, 64, 64), dtype="float32"))
        return scaled_latent_model_input

    @R.function
    def euler_ancestral_discrete_scheduler_step(sample: R.Tensor((1, 4, 64, 64), dtype="float32"), model_output: R.Tensor((1, 4, 64, 64), dtype="float32"), sigma: R.Tensor((), dtype="float32"), sigma_1: R.Tensor((), dtype="float32"), noise: R.Tensor((1, 4, 64, 64), dtype="float32")) -> R.Tensor((1, 4, 64, 64), dtype="float32"):
        cls = Module
        gv = R.call_tir(cls.multiply, (sigma, model_output), out_sinfo=R.Tensor((1, 4, 64, 64), dtype="float32"))
        gv1 = R.call_tir(cls.subtract, (sample, gv), out_sinfo=R.Tensor((1, 4, 64, 64), dtype="float32"))
        gv2 = R.call_tir(cls.subtract, (sample, gv1), out_sinfo=R.Tensor((1, 4, 64, 64), dtype="float32"))
        gv3 = R.call_tir(cls.divide, (gv2, sigma), out_sinfo=R.Tensor((1, 4, 64, 64), dtype="float32"))
        gv4 = R.call_tir(cls.power, (sigma_1,), out_sinfo=R.Tensor((), dtype="float32"))
        gv5 = R.call_tir(cls.power, (sigma_1,), out_sinfo=R.Tensor((), dtype="float32"))
        gv6 = R.call_tir(cls.power, (sigma,), out_sinfo=R.Tensor((), dtype="float32"))
        gv7 = R.call_tir(cls.power, (sigma_1,), out_sinfo=R.Tensor((), dtype="float32"))
        gv8 = R.call_tir(cls.subtract1, (gv6, gv7), out_sinfo=R.Tensor((), dtype="float32"))
        gv9 = R.call_tir(cls.multiply1, (gv5, gv8), out_sinfo=R.Tensor((), dtype="float32"))
        gv10 = R.call_tir(cls.power, (sigma,), out_sinfo=R.Tensor((), dtype="float32"))
        gv11 = R.call_tir(cls.divide1, (gv9, gv10), out_sinfo=R.Tensor((), dtype="float32"))
        gv12 = R.call_tir(cls.power1, (gv11,), out_sinfo=R.Tensor((), dtype="float32"))
        gv13 = R.call_tir(cls.power, (gv12,), out_sinfo=R.Tensor((), dtype="float32"))
        gv14 = R.call_tir(cls.subtract1, (gv4, gv13), out_sinfo=R.Tensor((), dtype="float32"))
        gv15 = R.call_tir(cls.power1, (gv14,), out_sinfo=R.Tensor((), dtype="float32"))
        gv16 = R.call_tir(cls.subtract1, (gv15, sigma), out_sinfo=R.Tensor((), dtype="float32"))
        gv17 = R.call_tir(cls.multiply2, (gv3, gv16), out_sinfo=R.Tensor((1, 4, 64, 64), dtype="float32"))
        gv18 = R.call_tir(cls.add, (sample, gv17), out_sinfo=R.Tensor((1, 4, 64, 64), dtype="float32"))
        gv19 = R.call_tir(cls.multiply2, (noise, gv12), out_sinfo=R.Tensor((1, 4, 64, 64), dtype="float32"))
        prev_sample = R.call_tir(cls.add, (gv18, gv19), out_sinfo=R.Tensor((1, 4, 64, 64), dtype="float32"))
        return prev_sample

    @R.function
    def image_to_rgba(x: R.Tensor((1, 512, 512, 3), dtype="float32")) -> R.Tensor((512, 512), dtype="uint32"):
        cls = Module
        gv = R.call_tir(cls.tir_image_to_rgba, (x,), out_sinfo=R.Tensor((512, 512), dtype="uint32"))
        return gv

    @R.function
    def unet(inp_0: R.Tensor((1, 4, 64, 64), dtype="float32"), inp_1: R.Tensor((), dtype="int32"), inp_2: R.Tensor((1, 77, 2048), dtype="float32"), inp_3: R.Tensor((1, 1280), dtype="float32"), inp_4: R.Tensor((1, 6), dtype="float32"), model_params: R.Tuple(R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((320, 4, 3, 3), dtype="float32"), R.Tensor((320,), dtype="float32"), R.Tensor((320,), dtype="float32"), R.Tensor((4, 320, 3, 3), dtype="float32"), R.Tensor((320, 320, 3, 3), dtype="float32"), R.Tensor((320, 320, 3, 3), dtype="float32"), R.Tensor((320, 320, 3, 3), dtype="float32"), R.Tensor((320,), dtype="float32"), R.Tensor((320,), dtype="float32"), R.Tensor((320,), dtype="float32"), R.Tensor((320,), dtype="float32"), R.Tensor((320,), dtype="float32"), R.Tensor((320, 320, 3, 3), dtype="float32"), R.Tensor((320, 320, 3, 3), dtype="float32"), R.Tensor((320,), dtype="float32"), R.Tensor((320,), dtype="float32"), R.Tensor((320,), dtype="float32"), R.Tensor((320,), dtype="float32"), R.Tensor((320,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640, 640, 3, 3), dtype="float32"), R.Tensor((640, 320, 3, 3), dtype="float32"), R.Tensor((640, 640, 3, 3), dtype="float32"), R.Tensor((640, 320, 1, 1), dtype="float32"), R.Tensor((320,), dtype="float32"), R.Tensor((320,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640, 640, 3, 3), dtype="float32"), R.Tensor((640, 640, 3, 3), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280, 640, 3, 3), dtype="float32"), R.Tensor((1280, 1280, 3, 3), dtype="float32"), R.Tensor((1280, 640, 1, 1), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280, 1280, 3, 3), dtype="float32"), R.Tensor((1280, 1280, 3, 3), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280, 1280, 3, 3), dtype="float32"), R.Tensor((1280, 1280, 3, 3), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280, 1280, 3, 3), dtype="float32"), R.Tensor((1280, 1280, 3, 3), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280, 2560, 3, 3), dtype="float32"), R.Tensor((1280, 1280, 3, 3), dtype="float32"), R.Tensor((1280, 2560, 1, 1), dtype="float32"), R.Tensor((2560,), dtype="float32"), R.Tensor((2560,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280, 2560, 3, 3), dtype="float32"), R.Tensor((1280, 1280, 3, 3), dtype="float32"), R.Tensor((1280, 2560, 1, 1), dtype="float32"), R.Tensor((2560,), dtype="float32"), R.Tensor((2560,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280, 1920, 3, 3), dtype="float32"), R.Tensor((1280, 1280, 3, 3), dtype="float32"), R.Tensor((1280, 1920, 1, 1), dtype="float32"), R.Tensor((1920,), dtype="float32"), R.Tensor((1920,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280, 1280, 3, 3), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640, 1920, 3, 3), dtype="float32"), R.Tensor((640, 640, 3, 3), dtype="float32"), R.Tensor((640, 1920, 1, 1), dtype="float32"), R.Tensor((1920,), dtype="float32"), R.Tensor((1920,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640, 1280, 3, 3), dtype="float32"), R.Tensor((640, 640, 3, 3), dtype="float32"), R.Tensor((640, 1280, 1, 1), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640, 960, 3, 3), dtype="float32"), R.Tensor((640, 640, 3, 3), dtype="float32"), R.Tensor((640, 960, 1, 1), dtype="float32"), R.Tensor((960,), dtype="float32"), R.Tensor((960,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640, 640, 3, 3), dtype="float32"), R.Tensor((320, 960, 3, 3), dtype="float32"), R.Tensor((320, 320, 3, 3), dtype="float32"), R.Tensor((320, 960, 1, 1), dtype="float32"), R.Tensor((960,), dtype="float32"), R.Tensor((960,), dtype="float32"), R.Tensor((320,), dtype="float32"), R.Tensor((320,), dtype="float32"), R.Tensor((320,), dtype="float32"), R.Tensor((320, 640, 3, 3), dtype="float32"), R.Tensor((320, 320, 3, 3), dtype="float32"), R.Tensor((320, 640, 1, 1), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((320,), dtype="float32"), R.Tensor((320,), dtype="float32"), R.Tensor((320,), dtype="float32"), R.Tensor((320, 640, 3, 3), dtype="float32"), R.Tensor((320, 320, 3, 3), dtype="float32"), R.Tensor((320, 640, 1, 1), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((320,), dtype="float32"), R.Tensor((320,), dtype="float32"), R.Tensor((320,), dtype="float32"), R.Tensor((320, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2816, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1, 320, 1, 1), dtype="float32"), R.Tensor((1, 320, 1, 1), dtype="float32"), R.Tensor((1280, 320), dtype="float32"), R.Tensor((1, 320, 1, 1), dtype="float32"), R.Tensor((1, 320, 1, 1), dtype="float32"), R.Tensor((1280, 320), dtype="float32"), R.Tensor((1, 320, 1, 1), dtype="float32"), R.Tensor((1, 320, 1, 1), dtype="float32"), R.Tensor((1, 640, 1, 1), dtype="float32"), R.Tensor((1280, 640), dtype="float32"), R.Tensor((1, 640, 1, 1), dtype="float32"), R.Tensor((1, 640, 1, 1), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((2048, 640), dtype="float32"), R.Tensor((2048, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 5120), dtype="float32"), R.Tensor((2560, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((2048, 640), dtype="float32"), R.Tensor((2048, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 5120), dtype="float32"), R.Tensor((2560, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((1, 640, 1, 1), dtype="float32"), R.Tensor((1280, 640), dtype="float32"), R.Tensor((1, 640, 1, 1), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((2048, 640), dtype="float32"), R.Tensor((2048, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 5120), dtype="float32"), R.Tensor((2560, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((2048, 640), dtype="float32"), R.Tensor((2048, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 5120), dtype="float32"), R.Tensor((2560, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((1, 640, 1, 1), dtype="float32"), R.Tensor((1, 1280, 1, 1), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1, 1280, 1, 1), dtype="float32"), R.Tensor((1, 1280, 1, 1), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1, 1280, 1, 1), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1, 1280, 1, 1), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1, 1280, 1, 1), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1, 1280, 1, 1), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1, 1280, 1, 1), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1, 1280, 1, 1), dtype="float32"), R.Tensor((1, 1280, 1, 1), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1, 1280, 1, 1), dtype="float32"), R.Tensor((1, 1280, 1, 1), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1, 1280, 1, 1), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1, 1280, 1, 1), dtype="float32"), R.Tensor((1, 1280, 1, 1), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1, 1280, 1, 1), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1, 1280, 1, 1), dtype="float32"), R.Tensor((1, 1280, 1, 1), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1, 1280, 1, 1), dtype="float32"), R.Tensor((1, 640, 1, 1), dtype="float32"), R.Tensor((1280, 640), dtype="float32"), R.Tensor((1, 640, 1, 1), dtype="float32"), R.Tensor((1, 640, 1, 1), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((2048, 640), dtype="float32"), R.Tensor((2048, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 5120), dtype="float32"), R.Tensor((2560, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((2048, 640), dtype="float32"), R.Tensor((2048, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 5120), dtype="float32"), R.Tensor((2560, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((1, 640, 1, 1), dtype="float32"), R.Tensor((1280, 640), dtype="float32"), R.Tensor((1, 640, 1, 1), dtype="float32"), R.Tensor((1, 640, 1, 1), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((2048, 640), dtype="float32"), R.Tensor((2048, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 5120), dtype="float32"), R.Tensor((2560, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((2048, 640), dtype="float32"), R.Tensor((2048, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 5120), dtype="float32"), R.Tensor((2560, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((1, 640, 1, 1), dtype="float32"), R.Tensor((1280, 640), dtype="float32"), R.Tensor((1, 640, 1, 1), dtype="float32"), R.Tensor((1, 640, 1, 1), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((2048, 640), dtype="float32"), R.Tensor((2048, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 5120), dtype="float32"), R.Tensor((2560, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((2048, 640), dtype="float32"), R.Tensor((2048, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 5120), dtype="float32"), R.Tensor((2560, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((1, 640, 1, 1), dtype="float32"), R.Tensor((1, 320, 1, 1), dtype="float32"), R.Tensor((1280, 320), dtype="float32"), R.Tensor((1, 320, 1, 1), dtype="float32"), R.Tensor((1, 320, 1, 1), dtype="float32"), R.Tensor((1, 320, 1, 1), dtype="float32"), R.Tensor((1280, 320), dtype="float32"), R.Tensor((1, 320, 1, 1), dtype="float32"), R.Tensor((1, 320, 1, 1), dtype="float32"), R.Tensor((1, 320, 1, 1), dtype="float32"), R.Tensor((1280, 320), dtype="float32"), R.Tensor((1, 320, 1, 1), dtype="float32"), R.Tensor((1, 320, 1, 1), dtype="float32"), R.Tensor((1, 4, 1, 1), dtype="float32"))) -> R.Tensor((1, 4, 64, 64), dtype="float32"):
        R.func_attr({"global_symbol": "main", "num_input": 5})
        cls = Module
        with R.dataflow():
            lv387 = R.call_tir(cls.fused_broadcast_to1_strided_slice1_reshape12_cast3_multiply4_multiply5_tir_sin_tir_cos_concatenate1_strided_slice2_reshape13_strided_slice3_reshape13_concatenate1_cast4, (inp_1, metadata["relax.expr.Constant"][2]), out_sinfo=R.Tensor((1, 320), dtype="float32"))
            lv336: R.Tensor((320, 1280), dtype="float32") = model_params[886]
            lv337: R.Tensor((1280,), dtype="float32") = model_params[426]
            lv388 = R.call_tir(cls.fused_matmul6_add7_silu, (lv387, lv336, lv337), out_sinfo=R.Tensor((1, 1280), dtype="float32"))
            lv389 = R.call_tir(cls.fused_reshape14_strided_slice4_reshape15_cast5_multiply6_multiply7_tir_sin1_tir_cos1_concatenate2_strided_slice5_reshape16_strided_slice6_reshape16_concatenate2_reshape17_concatenate3, (inp_4, metadata["relax.expr.Constant"][3], inp_3), out_sinfo=R.Tensor((1, 2816), dtype="float32"))
            lv338: R.Tensor((2816, 1280), dtype="float32") = model_params[888]
            lv339: R.Tensor((1280,), dtype="float32") = model_params[0]
            lv390 = R.call_tir(cls.fused_matmul7_add7_silu, (lv389, lv338, lv339), out_sinfo=R.Tensor((1, 1280), dtype="float32"))
            lv340: R.Tensor((1280, 1280), dtype="float32") = model_params[889]
            lv341: R.Tensor((1280,), dtype="float32") = model_params[1]
            lv391 = R.call_tir(cls.fused_matmul5_add7, (lv390, lv340, lv341), out_sinfo=R.Tensor((1, 1280), dtype="float32"))
            lv342: R.Tensor((1280, 1280), dtype="float32") = model_params[887]
            lv343: R.Tensor((1280,), dtype="float32") = model_params[427]
            lv392 = R.call_tir(cls.fused_matmul5_add7_add8, (lv388, lv342, lv343, lv391), out_sinfo=R.Tensor((1, 1280), dtype="float32"))
            lv344: R.Tensor((320, 4, 3, 3), dtype="float32") = model_params[2]
            lv345: R.Tensor((1, 320, 1, 1), dtype="float32") = model_params[890]
            lv393 = R.call_tir(cls.fused_conv2d_add9, (inp_0, lv344, lv345), out_sinfo=R.Tensor((1, 320, 64, 64), dtype="float32"))
            lv346: R.Tensor((320,), dtype="float32") = model_params[10]
            lv347: R.Tensor((320,), dtype="float32") = model_params[9]
            lv394 = R.call_tir(cls.fused_group_norm_silu1, (lv393, lv346, lv347), out_sinfo=R.Tensor((1, 320, 64, 64), dtype="float32"))
            lv54 = R.call_tir(cls.silu, (lv392,), out_sinfo=R.Tensor((1, 1280), dtype="float32"))
            lv348: R.Tensor((1280, 320), dtype="float32") = model_params[892]
            lv349: R.Tensor((320,), dtype="float32") = model_params[13]
            lv395 = R.call_tir(cls.fused_matmul8_add10_cast4, (lv54, lv348, lv349), out_sinfo=R.Tensor((1, 320), dtype="float32"))
            lv59 = R.call_tir(cls.reshape19, (lv395,), out_sinfo=R.Tensor((1, 320, 1, 1), dtype="float32"))
            lv350: R.Tensor((320, 320, 3, 3), dtype="float32") = model_params[7]
            lv351: R.Tensor((1, 320, 1, 1), dtype="float32") = model_params[891]
            lv396 = R.call_tir(cls.fused_conv2d1_add9_add9, (lv394, lv350, lv351, lv59), out_sinfo=R.Tensor((1, 320, 64, 64), dtype="float32"))
            lv352: R.Tensor((320,), dtype="float32") = model_params[12]
            lv353: R.Tensor((320,), dtype="float32") = model_params[11]
            lv397 = R.call_tir(cls.fused_group_norm_silu1, (lv396, lv352, lv353), out_sinfo=R.Tensor((1, 320, 64, 64), dtype="float32"))
            lv354: R.Tensor((320, 320, 3, 3), dtype="float32") = model_params[8]
            lv355: R.Tensor((1, 320, 1, 1), dtype="float32") = model_params[893]
            lv398 = R.call_tir(cls.fused_conv2d1_add9_add11_divide2, (lv397, lv354, lv355, lv393), out_sinfo=R.Tensor((1, 320, 64, 64), dtype="float32"))
            lv356: R.Tensor((320,), dtype="float32") = model_params[17]
            lv357: R.Tensor((320,), dtype="float32") = model_params[16]
            lv399 = R.call_tir(cls.fused_group_norm_silu1, (lv398, lv356, lv357), out_sinfo=R.Tensor((1, 320, 64, 64), dtype="float32"))
            lv73 = R.call_tir(cls.silu, (lv392,), out_sinfo=R.Tensor((1, 1280), dtype="float32"))
            lv358: R.Tensor((1280, 320), dtype="float32") = model_params[895]
            lv359: R.Tensor((320,), dtype="float32") = model_params[20]
            lv400 = R.call_tir(cls.fused_matmul8_add10_cast4, (lv73, lv358, lv359), out_sinfo=R.Tensor((1, 320), dtype="float32"))
            lv78 = R.call_tir(cls.reshape19, (lv400,), out_sinfo=R.Tensor((1, 320, 1, 1), dtype="float32"))
            lv360: R.Tensor((320, 320, 3, 3), dtype="float32") = model_params[14]
            lv361: R.Tensor((1, 320, 1, 1), dtype="float32") = model_params[894]
            lv401 = R.call_tir(cls.fused_conv2d1_add9_add9, (lv399, lv360, lv361, lv78), out_sinfo=R.Tensor((1, 320, 64, 64), dtype="float32"))
            lv362: R.Tensor((320,), dtype="float32") = model_params[19]
            lv363: R.Tensor((320,), dtype="float32") = model_params[18]
            lv402 = R.call_tir(cls.fused_group_norm_silu1, (lv401, lv362, lv363), out_sinfo=R.Tensor((1, 320, 64, 64), dtype="float32"))
            lv364: R.Tensor((320, 320, 3, 3), dtype="float32") = model_params[15]
            lv365: R.Tensor((1, 320, 1, 1), dtype="float32") = model_params[896]
            lv403 = R.call_tir(cls.fused_conv2d1_add9_add11_divide2, (lv402, lv364, lv365, lv398), out_sinfo=R.Tensor((1, 320, 64, 64), dtype="float32"))
            lv366: R.Tensor((320, 320, 3, 3), dtype="float32") = model_params[6]
            lv367: R.Tensor((1, 320, 1, 1), dtype="float32") = model_params[897]
            lv404 = R.call_tir(cls.fused_conv2d2_add12, (lv403, lv366, lv367), out_sinfo=R.Tensor((1, 320, 32, 32), dtype="float32"))
            lv368: R.Tensor((320,), dtype="float32") = model_params[74]
            lv369: R.Tensor((320,), dtype="float32") = model_params[73]
            lv405 = R.call_tir(cls.fused_group_norm1_silu2, (lv404, lv368, lv369), out_sinfo=R.Tensor((1, 320, 32, 32), dtype="float32"))
            lv95 = R.call_tir(cls.silu, (lv392,), out_sinfo=R.Tensor((1, 1280), dtype="float32"))
            lv370: R.Tensor((1280, 640), dtype="float32") = model_params[899]
            lv371: R.Tensor((640,), dtype="float32") = model_params[77]
            lv406 = R.call_tir(cls.fused_matmul9_add14_strided_slice7, (lv95, lv370, lv371), out_sinfo=R.Tensor((1, 640), dtype="float32"))
            lv100 = R.call_tir(cls.reshape21, (lv406,), out_sinfo=R.Tensor((1, 640, 1, 1), dtype="float32"))
            lv372: R.Tensor((640, 320, 3, 3), dtype="float32") = model_params[70]
            lv373: R.Tensor((1, 640, 1, 1), dtype="float32") = model_params[898]
            lv407 = R.call_tir(cls.fused_conv2d3_add13_add13, (lv405, lv372, lv373, lv100), out_sinfo=R.Tensor((1, 640, 32, 32), dtype="float32"))
            lv374: R.Tensor((640,), dtype="float32") = model_params[76]
            lv375: R.Tensor((640,), dtype="float32") = model_params[75]
            lv408 = R.call_tir(cls.fused_group_norm2_silu3, (lv407, lv374, lv375), out_sinfo=R.Tensor((1, 640, 32, 32), dtype="float32"))
            lv376: R.Tensor((640, 320, 1, 1), dtype="float32") = model_params[72]
            lv377: R.Tensor((1, 640, 1, 1), dtype="float32") = model_params[901]
            lv409 = R.call_tir(cls.fused_conv2d5_add13, (lv404, lv376, lv377), out_sinfo=R.Tensor((1, 640, 32, 32), dtype="float32"))
            lv378: R.Tensor((640, 640, 3, 3), dtype="float32") = model_params[71]
            lv379: R.Tensor((1, 640, 1, 1), dtype="float32") = model_params[900]
            lv410 = R.call_tir(cls.fused_conv2d4_add13_add15_divide3, (lv408, lv378, lv379, lv409), out_sinfo=R.Tensor((1, 640, 32, 32), dtype="float32"))
            lv380: R.Tensor((640,), dtype="float32") = model_params[22]
            lv381: R.Tensor((640,), dtype="float32") = model_params[21]
            lv112 = R.call_tir(cls.group_norm3, (lv410, lv380, lv381), out_sinfo=R.Tensor((1, 640, 32, 32), dtype="float32"))
            lv411 = R.call_tir(cls.fused_transpose10_reshape22, (lv112,), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv382: R.Tensor((640, 640), dtype="float32") = model_params[902]
            lv383: R.Tensor((640,), dtype="float32") = model_params[23]
            lv412 = R.call_tir(cls.fused_matmul10_add16, (lv411, lv382, lv383), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv384: R.Tensor((640,), dtype="float32") = model_params[30]
            lv385: R.Tensor((640,), dtype="float32") = model_params[29]
            lv118 = R.call_tir(cls.layer_norm1, (lv412, lv384, lv385), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv386: R.Tensor((640, 640), dtype="float32") = model_params[903]
            lv120 = R.call_tir(cls.matmul10, (lv118, lv386), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv387_1: R.Tensor((640, 640), dtype="float32") = model_params[904]
            lv122 = R.call_tir(cls.matmul10, (lv118, lv387_1), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv388_1: R.Tensor((640, 640), dtype="float32") = model_params[905]
            lv124 = R.call_tir(cls.matmul10, (lv118, lv388_1), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv413 = R.call_tir(cls.fused_reshape23_transpose12, (lv120,), out_sinfo=R.Tensor((1, 10, 1024, 64), dtype="float32"))
            lv414 = R.call_tir(cls.fused_reshape23_transpose12_transpose13, (lv122,), out_sinfo=R.Tensor((1, 10, 64, 1024), dtype="float32"))
            lv415 = R.call_tir(cls.fused_reshape23_transpose12, (lv124,), out_sinfo=R.Tensor((1, 10, 1024, 64), dtype="float32"))
            lv416 = R.call_tir(cls.fused_matmul11_multiply8, (lv413, lv414, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 10, 1024, 1024), dtype="float32"))
            lv136 = R.call_tir(cls.softmax1, (lv416,), out_sinfo=R.Tensor((1, 10, 1024, 1024), dtype="float32"))
            lv137 = R.call_tir(cls.matmul12, (lv136, lv415), out_sinfo=R.Tensor((1, 10, 1024, 64), dtype="float32"))
            lv417 = R.call_tir(cls.fused_transpose14_reshape24, (lv137,), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv389_1: R.Tensor((640, 640), dtype="float32") = model_params[906]
            lv390_1: R.Tensor((640,), dtype="float32") = model_params[25]
            lv418 = R.call_tir(cls.fused_matmul10_add16_divide5_add17, (lv417, lv389_1, lv390_1, lv412), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv391_1: R.Tensor((640,), dtype="float32") = model_params[32]
            lv392_1: R.Tensor((640,), dtype="float32") = model_params[31]
            lv145 = R.call_tir(cls.layer_norm1, (lv418, lv391_1, lv392_1), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv393_1: R.Tensor((640, 640), dtype="float32") = model_params[907]
            lv147 = R.call_tir(cls.matmul10, (lv145, lv393_1), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv394_1: R.Tensor((2048, 640), dtype="float32") = model_params[908]
            lv149 = R.call_tir(cls.matmul13, (inp_2, lv394_1), out_sinfo=R.Tensor((1, 77, 640), dtype="float32"))
            lv395_1: R.Tensor((2048, 640), dtype="float32") = model_params[909]
            lv151 = R.call_tir(cls.matmul13, (inp_2, lv395_1), out_sinfo=R.Tensor((1, 77, 640), dtype="float32"))
            lv419 = R.call_tir(cls.fused_reshape23_transpose12, (lv147,), out_sinfo=R.Tensor((1, 10, 1024, 64), dtype="float32"))
            lv420 = R.call_tir(cls.fused_reshape25_transpose16_transpose17, (lv149,), out_sinfo=R.Tensor((1, 10, 64, 77), dtype="float32"))
            lv421 = R.call_tir(cls.fused_reshape25_transpose16, (lv151,), out_sinfo=R.Tensor((1, 10, 77, 64), dtype="float32"))
            lv422 = R.call_tir(cls.fused_matmul14_multiply9, (lv419, lv420, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 10, 1024, 77), dtype="float32"))
            lv163 = R.call_tir(cls.softmax2, (lv422,), out_sinfo=R.Tensor((1, 10, 1024, 77), dtype="float32"))
            lv164 = R.call_tir(cls.matmul15, (lv163, lv421), out_sinfo=R.Tensor((1, 10, 1024, 64), dtype="float32"))
            lv423 = R.call_tir(cls.fused_transpose14_reshape24, (lv164,), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv396_1: R.Tensor((640, 640), dtype="float32") = model_params[910]
            lv397_1: R.Tensor((640,), dtype="float32") = model_params[26]
            lv424 = R.call_tir(cls.fused_matmul10_add16_divide5_add17, (lv423, lv396_1, lv397_1, lv418), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv398_1: R.Tensor((640,), dtype="float32") = model_params[34]
            lv399_1: R.Tensor((640,), dtype="float32") = model_params[33]
            lv172 = R.call_tir(cls.layer_norm1, (lv424, lv398_1, lv399_1), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv400_1: R.Tensor((640, 5120), dtype="float32") = model_params[911]
            lv401_1: R.Tensor((5120,), dtype="float32") = model_params[27]
            lv425 = R.call_tir(cls.fused_matmul16_add18, (lv172, lv400_1, lv401_1), out_sinfo=R.Tensor((1, 1024, 5120), dtype="float32"))
            lv426 = R.call_tir(cls.fused_split_gelu1_multiply10, (lv425,), out_sinfo=R.Tensor((1, 1024, 2560), dtype="float32"))
            lv402_1: R.Tensor((2560, 640), dtype="float32") = model_params[912]
            lv403_1: R.Tensor((640,), dtype="float32") = model_params[28]
            lv427 = R.call_tir(cls.fused_matmul17_add16_add17, (lv426, lv402_1, lv403_1, lv424), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv404_1: R.Tensor((640,), dtype="float32") = model_params[40]
            lv405_1: R.Tensor((640,), dtype="float32") = model_params[39]
            lv185 = R.call_tir(cls.layer_norm1, (lv427, lv404_1, lv405_1), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv406_1: R.Tensor((640, 640), dtype="float32") = model_params[913]
            lv187 = R.call_tir(cls.matmul10, (lv185, lv406_1), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv407_1: R.Tensor((640, 640), dtype="float32") = model_params[914]
            lv189 = R.call_tir(cls.matmul10, (lv185, lv407_1), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv408_1: R.Tensor((640, 640), dtype="float32") = model_params[915]
            lv191 = R.call_tir(cls.matmul10, (lv185, lv408_1), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv428 = R.call_tir(cls.fused_reshape23_transpose12, (lv187,), out_sinfo=R.Tensor((1, 10, 1024, 64), dtype="float32"))
            lv429 = R.call_tir(cls.fused_reshape23_transpose12_transpose13, (lv189,), out_sinfo=R.Tensor((1, 10, 64, 1024), dtype="float32"))
            lv430 = R.call_tir(cls.fused_reshape23_transpose12, (lv191,), out_sinfo=R.Tensor((1, 10, 1024, 64), dtype="float32"))
            lv431 = R.call_tir(cls.fused_matmul11_multiply8, (lv428, lv429, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 10, 1024, 1024), dtype="float32"))
            lv203 = R.call_tir(cls.softmax1, (lv431,), out_sinfo=R.Tensor((1, 10, 1024, 1024), dtype="float32"))
            lv204 = R.call_tir(cls.matmul12, (lv203, lv430), out_sinfo=R.Tensor((1, 10, 1024, 64), dtype="float32"))
            lv432 = R.call_tir(cls.fused_transpose14_reshape24, (lv204,), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv409_1: R.Tensor((640, 640), dtype="float32") = model_params[916]
            lv410_1: R.Tensor((640,), dtype="float32") = model_params[35]
            lv433 = R.call_tir(cls.fused_matmul10_add16_divide5_add17, (lv432, lv409_1, lv410_1, lv427), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv411_1: R.Tensor((640,), dtype="float32") = model_params[42]
            lv412_1: R.Tensor((640,), dtype="float32") = model_params[41]
            lv212 = R.call_tir(cls.layer_norm1, (lv433, lv411_1, lv412_1), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv413_1: R.Tensor((640, 640), dtype="float32") = model_params[917]
            lv214 = R.call_tir(cls.matmul10, (lv212, lv413_1), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv414_1: R.Tensor((2048, 640), dtype="float32") = model_params[918]
            lv216 = R.call_tir(cls.matmul13, (inp_2, lv414_1), out_sinfo=R.Tensor((1, 77, 640), dtype="float32"))
            lv415_1: R.Tensor((2048, 640), dtype="float32") = model_params[919]
            lv218 = R.call_tir(cls.matmul13, (inp_2, lv415_1), out_sinfo=R.Tensor((1, 77, 640), dtype="float32"))
            lv434 = R.call_tir(cls.fused_reshape23_transpose12, (lv214,), out_sinfo=R.Tensor((1, 10, 1024, 64), dtype="float32"))
            lv435 = R.call_tir(cls.fused_reshape25_transpose16_transpose17, (lv216,), out_sinfo=R.Tensor((1, 10, 64, 77), dtype="float32"))
            lv436 = R.call_tir(cls.fused_reshape25_transpose16, (lv218,), out_sinfo=R.Tensor((1, 10, 77, 64), dtype="float32"))
            lv437 = R.call_tir(cls.fused_matmul14_multiply9, (lv434, lv435, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 10, 1024, 77), dtype="float32"))
            lv230 = R.call_tir(cls.softmax2, (lv437,), out_sinfo=R.Tensor((1, 10, 1024, 77), dtype="float32"))
            lv231 = R.call_tir(cls.matmul15, (lv230, lv436), out_sinfo=R.Tensor((1, 10, 1024, 64), dtype="float32"))
            lv438 = R.call_tir(cls.fused_transpose14_reshape24, (lv231,), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv416_1: R.Tensor((640, 640), dtype="float32") = model_params[920]
            lv417_1: R.Tensor((640,), dtype="float32") = model_params[36]
            lv439 = R.call_tir(cls.fused_matmul10_add16_divide5_add17, (lv438, lv416_1, lv417_1, lv433), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv418_1: R.Tensor((640,), dtype="float32") = model_params[44]
            lv419_1: R.Tensor((640,), dtype="float32") = model_params[43]
            lv239 = R.call_tir(cls.layer_norm1, (lv439, lv418_1, lv419_1), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv420_1: R.Tensor((640, 5120), dtype="float32") = model_params[921]
            lv421_1: R.Tensor((5120,), dtype="float32") = model_params[37]
            lv440 = R.call_tir(cls.fused_matmul16_add18, (lv239, lv420_1, lv421_1), out_sinfo=R.Tensor((1, 1024, 5120), dtype="float32"))
            lv441 = R.call_tir(cls.fused_split_gelu1_multiply10, (lv440,), out_sinfo=R.Tensor((1, 1024, 2560), dtype="float32"))
            lv422_1: R.Tensor((2560, 640), dtype="float32") = model_params[922]
            lv423_1: R.Tensor((640,), dtype="float32") = model_params[38]
            lv442 = R.call_tir(cls.fused_matmul17_add16_add17, (lv441, lv422_1, lv423_1, lv439), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv424_1: R.Tensor((640, 640), dtype="float32") = model_params[923]
            lv425_1: R.Tensor((640,), dtype="float32") = model_params[24]
            lv443 = R.call_tir(cls.fused_matmul10_add16, (lv442, lv424_1, lv425_1), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv444 = R.call_tir(cls.fused_reshape26_transpose20_add15, (lv443, lv410), out_sinfo=R.Tensor((1, 640, 32, 32), dtype="float32"))
            lv426_1: R.Tensor((640,), dtype="float32") = model_params[81]
            lv427_1: R.Tensor((640,), dtype="float32") = model_params[80]
            lv445 = R.call_tir(cls.fused_group_norm2_silu3, (lv444, lv426_1, lv427_1), out_sinfo=R.Tensor((1, 640, 32, 32), dtype="float32"))
            lv263 = R.call_tir(cls.silu, (lv392,), out_sinfo=R.Tensor((1, 1280), dtype="float32"))
            lv428_1: R.Tensor((1280, 640), dtype="float32") = model_params[925]
            lv429_1: R.Tensor((640,), dtype="float32") = model_params[84]
            lv446 = R.call_tir(cls.fused_matmul9_add14_strided_slice7, (lv263, lv428_1, lv429_1), out_sinfo=R.Tensor((1, 640), dtype="float32"))
            lv268 = R.call_tir(cls.reshape21, (lv446,), out_sinfo=R.Tensor((1, 640, 1, 1), dtype="float32"))
            lv430_1: R.Tensor((640, 640, 3, 3), dtype="float32") = model_params[78]
            lv431_1: R.Tensor((1, 640, 1, 1), dtype="float32") = model_params[924]
            lv447 = R.call_tir(cls.fused_conv2d4_add13_add13, (lv445, lv430_1, lv431_1, lv268), out_sinfo=R.Tensor((1, 640, 32, 32), dtype="float32"))
            lv432_1: R.Tensor((640,), dtype="float32") = model_params[83]
            lv433_1: R.Tensor((640,), dtype="float32") = model_params[82]
            lv448 = R.call_tir(cls.fused_group_norm2_silu3, (lv447, lv432_1, lv433_1), out_sinfo=R.Tensor((1, 640, 32, 32), dtype="float32"))
            lv434_1: R.Tensor((640, 640, 3, 3), dtype="float32") = model_params[79]
            lv435_1: R.Tensor((1, 640, 1, 1), dtype="float32") = model_params[926]
            lv449 = R.call_tir(cls.fused_conv2d4_add13_add15_divide3, (lv448, lv434_1, lv435_1, lv444), out_sinfo=R.Tensor((1, 640, 32, 32), dtype="float32"))
            lv436_1: R.Tensor((640,), dtype="float32") = model_params[46]
            lv437_1: R.Tensor((640,), dtype="float32") = model_params[45]
            lv277 = R.call_tir(cls.group_norm3, (lv449, lv436_1, lv437_1), out_sinfo=R.Tensor((1, 640, 32, 32), dtype="float32"))
            lv450 = R.call_tir(cls.fused_transpose10_reshape22, (lv277,), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv438_1: R.Tensor((640, 640), dtype="float32") = model_params[927]
            lv439_1: R.Tensor((640,), dtype="float32") = model_params[47]
            lv451 = R.call_tir(cls.fused_matmul10_add16, (lv450, lv438_1, lv439_1), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv440_1: R.Tensor((640,), dtype="float32") = model_params[54]
            lv441_1: R.Tensor((640,), dtype="float32") = model_params[53]
            lv283 = R.call_tir(cls.layer_norm1, (lv451, lv440_1, lv441_1), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv442_1: R.Tensor((640, 640), dtype="float32") = model_params[928]
            lv285 = R.call_tir(cls.matmul10, (lv283, lv442_1), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv443_1: R.Tensor((640, 640), dtype="float32") = model_params[929]
            lv287 = R.call_tir(cls.matmul10, (lv283, lv443_1), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv444_1: R.Tensor((640, 640), dtype="float32") = model_params[930]
            lv289 = R.call_tir(cls.matmul10, (lv283, lv444_1), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv452 = R.call_tir(cls.fused_reshape23_transpose12, (lv285,), out_sinfo=R.Tensor((1, 10, 1024, 64), dtype="float32"))
            lv453 = R.call_tir(cls.fused_reshape23_transpose12_transpose13, (lv287,), out_sinfo=R.Tensor((1, 10, 64, 1024), dtype="float32"))
            lv454 = R.call_tir(cls.fused_reshape23_transpose12, (lv289,), out_sinfo=R.Tensor((1, 10, 1024, 64), dtype="float32"))
            lv455 = R.call_tir(cls.fused_matmul11_multiply8, (lv452, lv453, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 10, 1024, 1024), dtype="float32"))
            lv301 = R.call_tir(cls.softmax1, (lv455,), out_sinfo=R.Tensor((1, 10, 1024, 1024), dtype="float32"))
            lv302 = R.call_tir(cls.matmul12, (lv301, lv454), out_sinfo=R.Tensor((1, 10, 1024, 64), dtype="float32"))
            lv456 = R.call_tir(cls.fused_transpose14_reshape24, (lv302,), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv445_1: R.Tensor((640, 640), dtype="float32") = model_params[931]
            lv446_1: R.Tensor((640,), dtype="float32") = model_params[49]
            lv457 = R.call_tir(cls.fused_matmul10_add16_divide5_add17, (lv456, lv445_1, lv446_1, lv451), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv447_1: R.Tensor((640,), dtype="float32") = model_params[56]
            lv448_1: R.Tensor((640,), dtype="float32") = model_params[55]
            lv310 = R.call_tir(cls.layer_norm1, (lv457, lv447_1, lv448_1), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv449_1: R.Tensor((640, 640), dtype="float32") = model_params[932]
            lv312 = R.call_tir(cls.matmul10, (lv310, lv449_1), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv450_1: R.Tensor((2048, 640), dtype="float32") = model_params[933]
            lv314 = R.call_tir(cls.matmul13, (inp_2, lv450_1), out_sinfo=R.Tensor((1, 77, 640), dtype="float32"))
            lv451_1: R.Tensor((2048, 640), dtype="float32") = model_params[934]
            lv316 = R.call_tir(cls.matmul13, (inp_2, lv451_1), out_sinfo=R.Tensor((1, 77, 640), dtype="float32"))
            lv458 = R.call_tir(cls.fused_reshape23_transpose12, (lv312,), out_sinfo=R.Tensor((1, 10, 1024, 64), dtype="float32"))
            lv459 = R.call_tir(cls.fused_reshape25_transpose16_transpose17, (lv314,), out_sinfo=R.Tensor((1, 10, 64, 77), dtype="float32"))
            lv460 = R.call_tir(cls.fused_reshape25_transpose16, (lv316,), out_sinfo=R.Tensor((1, 10, 77, 64), dtype="float32"))
            lv461 = R.call_tir(cls.fused_matmul14_multiply9, (lv458, lv459, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 10, 1024, 77), dtype="float32"))
            lv328 = R.call_tir(cls.softmax2, (lv461,), out_sinfo=R.Tensor((1, 10, 1024, 77), dtype="float32"))
            lv329 = R.call_tir(cls.matmul15, (lv328, lv460), out_sinfo=R.Tensor((1, 10, 1024, 64), dtype="float32"))
            lv462 = R.call_tir(cls.fused_transpose14_reshape24, (lv329,), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv452_1: R.Tensor((640, 640), dtype="float32") = model_params[935]
            lv453_1: R.Tensor((640,), dtype="float32") = model_params[50]
            lv463 = R.call_tir(cls.fused_matmul10_add16_divide5_add17, (lv462, lv452_1, lv453_1, lv457), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv454_1: R.Tensor((640,), dtype="float32") = model_params[58]
            lv455_1: R.Tensor((640,), dtype="float32") = model_params[57]
            lv337_1 = R.call_tir(cls.layer_norm1, (lv463, lv454_1, lv455_1), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv456_1: R.Tensor((640, 5120), dtype="float32") = model_params[936]
            lv457_1: R.Tensor((5120,), dtype="float32") = model_params[51]
            lv464 = R.call_tir(cls.fused_matmul16_add18, (lv337_1, lv456_1, lv457_1), out_sinfo=R.Tensor((1, 1024, 5120), dtype="float32"))
            lv465 = R.call_tir(cls.fused_split_gelu1_multiply10, (lv464,), out_sinfo=R.Tensor((1, 1024, 2560), dtype="float32"))
            lv458_1: R.Tensor((2560, 640), dtype="float32") = model_params[937]
            lv459_1: R.Tensor((640,), dtype="float32") = model_params[52]
            lv466 = R.call_tir(cls.fused_matmul17_add16_add17, (lv465, lv458_1, lv459_1, lv463), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv460_1: R.Tensor((640,), dtype="float32") = model_params[64]
            lv461_1: R.Tensor((640,), dtype="float32") = model_params[63]
            lv350_1 = R.call_tir(cls.layer_norm1, (lv466, lv460_1, lv461_1), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv462_1: R.Tensor((640, 640), dtype="float32") = model_params[938]
            lv352_1 = R.call_tir(cls.matmul10, (lv350_1, lv462_1), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv463_1: R.Tensor((640, 640), dtype="float32") = model_params[939]
            lv354_1 = R.call_tir(cls.matmul10, (lv350_1, lv463_1), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv464_1: R.Tensor((640, 640), dtype="float32") = model_params[940]
            lv356_1 = R.call_tir(cls.matmul10, (lv350_1, lv464_1), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv467 = R.call_tir(cls.fused_reshape23_transpose12, (lv352_1,), out_sinfo=R.Tensor((1, 10, 1024, 64), dtype="float32"))
            lv468 = R.call_tir(cls.fused_reshape23_transpose12_transpose13, (lv354_1,), out_sinfo=R.Tensor((1, 10, 64, 1024), dtype="float32"))
            lv469 = R.call_tir(cls.fused_reshape23_transpose12, (lv356_1,), out_sinfo=R.Tensor((1, 10, 1024, 64), dtype="float32"))
            lv470 = R.call_tir(cls.fused_matmul11_multiply8, (lv467, lv468, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 10, 1024, 1024), dtype="float32"))
            lv368_1 = R.call_tir(cls.softmax1, (lv470,), out_sinfo=R.Tensor((1, 10, 1024, 1024), dtype="float32"))
            lv369_1 = R.call_tir(cls.matmul12, (lv368_1, lv469), out_sinfo=R.Tensor((1, 10, 1024, 64), dtype="float32"))
            lv471 = R.call_tir(cls.fused_transpose14_reshape24, (lv369_1,), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv465_1: R.Tensor((640, 640), dtype="float32") = model_params[941]
            lv466_1: R.Tensor((640,), dtype="float32") = model_params[59]
            lv472 = R.call_tir(cls.fused_matmul10_add16_divide5_add17, (lv471, lv465_1, lv466_1, lv466), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv467_1: R.Tensor((640,), dtype="float32") = model_params[66]
            lv468_1: R.Tensor((640,), dtype="float32") = model_params[65]
            lv377_1 = R.call_tir(cls.layer_norm1, (lv472, lv467_1, lv468_1), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv469_1: R.Tensor((640, 640), dtype="float32") = model_params[942]
            lv379_1 = R.call_tir(cls.matmul10, (lv377_1, lv469_1), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv470_1: R.Tensor((2048, 640), dtype="float32") = model_params[943]
            lv381_1 = R.call_tir(cls.matmul13, (inp_2, lv470_1), out_sinfo=R.Tensor((1, 77, 640), dtype="float32"))
            lv471_1: R.Tensor((2048, 640), dtype="float32") = model_params[944]
            lv383_1 = R.call_tir(cls.matmul13, (inp_2, lv471_1), out_sinfo=R.Tensor((1, 77, 640), dtype="float32"))
            lv473 = R.call_tir(cls.fused_reshape23_transpose12, (lv379_1,), out_sinfo=R.Tensor((1, 10, 1024, 64), dtype="float32"))
            lv474 = R.call_tir(cls.fused_reshape25_transpose16_transpose17, (lv381_1,), out_sinfo=R.Tensor((1, 10, 64, 77), dtype="float32"))
            lv475 = R.call_tir(cls.fused_reshape25_transpose16, (lv383_1,), out_sinfo=R.Tensor((1, 10, 77, 64), dtype="float32"))
            lv476 = R.call_tir(cls.fused_matmul14_multiply9, (lv473, lv474, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 10, 1024, 77), dtype="float32"))
            lv395_2 = R.call_tir(cls.softmax2, (lv476,), out_sinfo=R.Tensor((1, 10, 1024, 77), dtype="float32"))
            lv396_2 = R.call_tir(cls.matmul15, (lv395_2, lv475), out_sinfo=R.Tensor((1, 10, 1024, 64), dtype="float32"))
            lv477 = R.call_tir(cls.fused_transpose14_reshape24, (lv396_2,), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv472_1: R.Tensor((640, 640), dtype="float32") = model_params[945]
            lv473_1: R.Tensor((640,), dtype="float32") = model_params[60]
            lv478 = R.call_tir(cls.fused_matmul10_add16_divide5_add17, (lv477, lv472_1, lv473_1, lv472), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv474_1: R.Tensor((640,), dtype="float32") = model_params[68]
            lv475_1: R.Tensor((640,), dtype="float32") = model_params[67]
            lv404_2 = R.call_tir(cls.layer_norm1, (lv478, lv474_1, lv475_1), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv476_1: R.Tensor((640, 5120), dtype="float32") = model_params[946]
            lv477_1: R.Tensor((5120,), dtype="float32") = model_params[61]
            lv479 = R.call_tir(cls.fused_matmul16_add18, (lv404_2, lv476_1, lv477_1), out_sinfo=R.Tensor((1, 1024, 5120), dtype="float32"))
            lv480 = R.call_tir(cls.fused_split_gelu1_multiply10, (lv479,), out_sinfo=R.Tensor((1, 1024, 2560), dtype="float32"))
            lv478_1: R.Tensor((2560, 640), dtype="float32") = model_params[947]
            lv479_1: R.Tensor((640,), dtype="float32") = model_params[62]
            lv481 = R.call_tir(cls.fused_matmul17_add16_add17, (lv480, lv478_1, lv479_1, lv478), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv480_1: R.Tensor((640, 640), dtype="float32") = model_params[948]
            lv481_1: R.Tensor((640,), dtype="float32") = model_params[48]
            lv482 = R.call_tir(cls.fused_matmul10_add16, (lv481, lv480_1, lv481_1), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv483 = R.call_tir(cls.fused_reshape26_transpose20_add15, (lv482, lv449), out_sinfo=R.Tensor((1, 640, 32, 32), dtype="float32"))
            lv482_1: R.Tensor((640, 640, 3, 3), dtype="float32") = model_params[69]
            lv483_1: R.Tensor((1, 640, 1, 1), dtype="float32") = model_params[949]
            lv484 = R.call_tir(cls.fused_conv2d6_add19, (lv483, lv482_1, lv483_1), out_sinfo=R.Tensor((1, 640, 16, 16), dtype="float32"))
            lv484_1: R.Tensor((640,), dtype="float32") = model_params[297]
            lv485: R.Tensor((640,), dtype="float32") = model_params[296]
            lv485_1 = R.call_tir(cls.fused_group_norm4_silu4, (lv484, lv484_1, lv485), out_sinfo=R.Tensor((1, 640, 16, 16), dtype="float32"))
            lv431_2 = R.call_tir(cls.silu, (lv392,), out_sinfo=R.Tensor((1, 1280), dtype="float32"))
            lv486: R.Tensor((1280, 1280), dtype="float32") = model_params[951]
            lv487: R.Tensor((1280,), dtype="float32") = model_params[300]
            lv486_1 = R.call_tir(cls.fused_matmul5_add7_strided_slice, (lv431_2, lv486, lv487), out_sinfo=R.Tensor((1, 1280), dtype="float32"))
            lv436_2 = R.call_tir(cls.reshape28, (lv486_1,), out_sinfo=R.Tensor((1, 1280, 1, 1), dtype="float32"))
            lv488: R.Tensor((1280, 640, 3, 3), dtype="float32") = model_params[293]
            lv489: R.Tensor((1, 1280, 1, 1), dtype="float32") = model_params[950]
            lv487_1 = R.call_tir(cls.fused_conv2d7_add20_add20, (lv485_1, lv488, lv489, lv436_2), out_sinfo=R.Tensor((1, 1280, 16, 16), dtype="float32"))
            lv490: R.Tensor((1280,), dtype="float32") = model_params[299]
            lv491: R.Tensor((1280,), dtype="float32") = model_params[298]
            lv488_1 = R.call_tir(cls.fused_group_norm5_silu5, (lv487_1, lv490, lv491), out_sinfo=R.Tensor((1, 1280, 16, 16), dtype="float32"))
            lv492: R.Tensor((1280, 640, 1, 1), dtype="float32") = model_params[295]
            lv493: R.Tensor((1, 1280, 1, 1), dtype="float32") = model_params[953]
            lv489_1 = R.call_tir(cls.fused_conv2d9_add20, (lv484, lv492, lv493), out_sinfo=R.Tensor((1, 1280, 16, 16), dtype="float32"))
            lv494: R.Tensor((1280, 1280, 3, 3), dtype="float32") = model_params[294]
            lv495: R.Tensor((1, 1280, 1, 1), dtype="float32") = model_params[952]
            lv490_1 = R.call_tir(cls.fused_conv2d8_add20_add21_divide6, (lv488_1, lv494, lv495, lv489_1), out_sinfo=R.Tensor((1, 1280, 16, 16), dtype="float32"))
            lv496: R.Tensor((1280,), dtype="float32") = model_params[86]
            lv497: R.Tensor((1280,), dtype="float32") = model_params[85]
            lv448_2 = R.call_tir(cls.group_norm6, (lv490_1, lv496, lv497), out_sinfo=R.Tensor((1, 1280, 16, 16), dtype="float32"))
            lv491_1 = R.call_tir(cls.fused_transpose21_reshape29, (lv448_2,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv498: R.Tensor((1280, 1280), dtype="float32") = model_params[954]
            lv499: R.Tensor((1280,), dtype="float32") = model_params[87]
            lv492_1 = R.call_tir(cls.fused_matmul18_add22, (lv491_1, lv498, lv499), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv500: R.Tensor((1280,), dtype="float32") = model_params[94]
            lv501: R.Tensor((1280,), dtype="float32") = model_params[93]
            lv454_2 = R.call_tir(cls.layer_norm2, (lv492_1, lv500, lv501), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv502: R.Tensor((1280, 1280), dtype="float32") = model_params[955]
            lv456_2 = R.call_tir(cls.matmul18, (lv454_2, lv502), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv503: R.Tensor((1280, 1280), dtype="float32") = model_params[956]
            lv458_2 = R.call_tir(cls.matmul18, (lv454_2, lv503), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv504: R.Tensor((1280, 1280), dtype="float32") = model_params[957]
            lv460_2 = R.call_tir(cls.matmul18, (lv454_2, lv504), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv493_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv456_2,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv494_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv458_2,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv495_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv460_2,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv496_1 = R.call_tir(cls.fused_matmul19_multiply11, (lv493_1, lv494_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv472_2 = R.call_tir(cls.softmax3, (lv496_1,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv473_2 = R.call_tir(cls.matmul20, (lv472_2, lv495_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv497_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv473_2,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv505: R.Tensor((1280, 1280), dtype="float32") = model_params[958]
            lv506: R.Tensor((1280,), dtype="float32") = model_params[89]
            lv498_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv497_1, lv505, lv506, lv492_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv507: R.Tensor((1280,), dtype="float32") = model_params[96]
            lv508: R.Tensor((1280,), dtype="float32") = model_params[95]
            lv481_2 = R.call_tir(cls.layer_norm2, (lv498_1, lv507, lv508), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv509: R.Tensor((1280, 1280), dtype="float32") = model_params[959]
            lv483_2 = R.call_tir(cls.matmul18, (lv481_2, lv509), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv510: R.Tensor((2048, 1280), dtype="float32") = model_params[960]
            lv485_2 = R.call_tir(cls.matmul21, (inp_2, lv510), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv511: R.Tensor((2048, 1280), dtype="float32") = model_params[961]
            lv487_2 = R.call_tir(cls.matmul21, (inp_2, lv511), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv499_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv483_2,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv500_1 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv485_2,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv501_1 = R.call_tir(cls.fused_reshape5_transpose1, (lv487_2,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv502_1 = R.call_tir(cls.fused_matmul22_multiply12, (lv499_1, lv500_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv499_2 = R.call_tir(cls.softmax4, (lv502_1,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv500_2 = R.call_tir(cls.matmul23, (lv499_2, lv501_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv503_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv500_2,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv512: R.Tensor((1280, 1280), dtype="float32") = model_params[962]
            lv513: R.Tensor((1280,), dtype="float32") = model_params[90]
            lv504_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv503_1, lv512, lv513, lv498_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv514: R.Tensor((1280,), dtype="float32") = model_params[98]
            lv515: R.Tensor((1280,), dtype="float32") = model_params[97]
            lv508_1 = R.call_tir(cls.layer_norm2, (lv504_1, lv514, lv515), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv516: R.Tensor((1280, 10240), dtype="float32") = model_params[963]
            lv517: R.Tensor((10240,), dtype="float32") = model_params[91]
            lv505_1 = R.call_tir(cls.fused_matmul24_add24, (lv508_1, lv516, lv517), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv506_1 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv505_1,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv518: R.Tensor((5120, 1280), dtype="float32") = model_params[964]
            lv519: R.Tensor((1280,), dtype="float32") = model_params[92]
            lv507_1 = R.call_tir(cls.fused_matmul25_add22_add23, (lv506_1, lv518, lv519, lv504_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv520: R.Tensor((1280,), dtype="float32") = model_params[104]
            lv521: R.Tensor((1280,), dtype="float32") = model_params[103]
            lv521_1 = R.call_tir(cls.layer_norm2, (lv507_1, lv520, lv521), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv522: R.Tensor((1280, 1280), dtype="float32") = model_params[965]
            lv523 = R.call_tir(cls.matmul18, (lv521_1, lv522), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv523_1: R.Tensor((1280, 1280), dtype="float32") = model_params[966]
            lv525 = R.call_tir(cls.matmul18, (lv521_1, lv523_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv524: R.Tensor((1280, 1280), dtype="float32") = model_params[967]
            lv527 = R.call_tir(cls.matmul18, (lv521_1, lv524), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv508_2 = R.call_tir(cls.fused_reshape30_transpose22, (lv523,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv509_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv525,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv510_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv527,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv511_1 = R.call_tir(cls.fused_matmul19_multiply11, (lv508_2, lv509_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv539 = R.call_tir(cls.softmax3, (lv511_1,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv540 = R.call_tir(cls.matmul20, (lv539, lv510_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv512_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv540,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv525_1: R.Tensor((1280, 1280), dtype="float32") = model_params[968]
            lv526: R.Tensor((1280,), dtype="float32") = model_params[99]
            lv513_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv512_1, lv525_1, lv526, lv507_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv527_1: R.Tensor((1280,), dtype="float32") = model_params[106]
            lv528: R.Tensor((1280,), dtype="float32") = model_params[105]
            lv548 = R.call_tir(cls.layer_norm2, (lv513_1, lv527_1, lv528), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv529: R.Tensor((1280, 1280), dtype="float32") = model_params[969]
            lv550 = R.call_tir(cls.matmul18, (lv548, lv529), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv530: R.Tensor((2048, 1280), dtype="float32") = model_params[970]
            lv552 = R.call_tir(cls.matmul21, (inp_2, lv530), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv531: R.Tensor((2048, 1280), dtype="float32") = model_params[971]
            lv554 = R.call_tir(cls.matmul21, (inp_2, lv531), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv514_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv550,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv515_1 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv552,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv516_1 = R.call_tir(cls.fused_reshape5_transpose1, (lv554,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv517_1 = R.call_tir(cls.fused_matmul22_multiply12, (lv514_1, lv515_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv566 = R.call_tir(cls.softmax4, (lv517_1,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv567 = R.call_tir(cls.matmul23, (lv566, lv516_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv518_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv567,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv532: R.Tensor((1280, 1280), dtype="float32") = model_params[972]
            lv533: R.Tensor((1280,), dtype="float32") = model_params[100]
            lv519_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv518_1, lv532, lv533, lv513_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv534: R.Tensor((1280,), dtype="float32") = model_params[108]
            lv535: R.Tensor((1280,), dtype="float32") = model_params[107]
            lv575 = R.call_tir(cls.layer_norm2, (lv519_1, lv534, lv535), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv536: R.Tensor((1280, 10240), dtype="float32") = model_params[973]
            lv537: R.Tensor((10240,), dtype="float32") = model_params[101]
            lv520_1 = R.call_tir(cls.fused_matmul24_add24, (lv575, lv536, lv537), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv521_2 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv520_1,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv538: R.Tensor((5120, 1280), dtype="float32") = model_params[974]
            lv539_1: R.Tensor((1280,), dtype="float32") = model_params[102]
            lv522_1 = R.call_tir(cls.fused_matmul25_add22_add23, (lv521_2, lv538, lv539_1, lv519_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv540_1: R.Tensor((1280,), dtype="float32") = model_params[114]
            lv541: R.Tensor((1280,), dtype="float32") = model_params[113]
            lv588 = R.call_tir(cls.layer_norm2, (lv522_1, lv540_1, lv541), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv542: R.Tensor((1280, 1280), dtype="float32") = model_params[975]
            lv590 = R.call_tir(cls.matmul18, (lv588, lv542), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv543: R.Tensor((1280, 1280), dtype="float32") = model_params[976]
            lv592 = R.call_tir(cls.matmul18, (lv588, lv543), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv544: R.Tensor((1280, 1280), dtype="float32") = model_params[977]
            lv594 = R.call_tir(cls.matmul18, (lv588, lv544), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv523_2 = R.call_tir(cls.fused_reshape30_transpose22, (lv590,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv524_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv592,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv525_2 = R.call_tir(cls.fused_reshape30_transpose22, (lv594,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv526_1 = R.call_tir(cls.fused_matmul19_multiply11, (lv523_2, lv524_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv606 = R.call_tir(cls.softmax3, (lv526_1,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv607 = R.call_tir(cls.matmul20, (lv606, lv525_2), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv527_2 = R.call_tir(cls.fused_transpose24_reshape31, (lv607,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv545: R.Tensor((1280, 1280), dtype="float32") = model_params[978]
            lv546: R.Tensor((1280,), dtype="float32") = model_params[109]
            lv528_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv527_2, lv545, lv546, lv522_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv547: R.Tensor((1280,), dtype="float32") = model_params[116]
            lv548_1: R.Tensor((1280,), dtype="float32") = model_params[115]
            lv615 = R.call_tir(cls.layer_norm2, (lv528_1, lv547, lv548_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv549: R.Tensor((1280, 1280), dtype="float32") = model_params[979]
            lv617 = R.call_tir(cls.matmul18, (lv615, lv549), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv550_1: R.Tensor((2048, 1280), dtype="float32") = model_params[980]
            lv619 = R.call_tir(cls.matmul21, (inp_2, lv550_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv551: R.Tensor((2048, 1280), dtype="float32") = model_params[981]
            lv621 = R.call_tir(cls.matmul21, (inp_2, lv551), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv529_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv617,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv530_1 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv619,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv531_1 = R.call_tir(cls.fused_reshape5_transpose1, (lv621,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv532_1 = R.call_tir(cls.fused_matmul22_multiply12, (lv529_1, lv530_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv633 = R.call_tir(cls.softmax4, (lv532_1,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv634 = R.call_tir(cls.matmul23, (lv633, lv531_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv533_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv634,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv552_1: R.Tensor((1280, 1280), dtype="float32") = model_params[982]
            lv553: R.Tensor((1280,), dtype="float32") = model_params[110]
            lv534_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv533_1, lv552_1, lv553, lv528_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv554_1: R.Tensor((1280,), dtype="float32") = model_params[118]
            lv555: R.Tensor((1280,), dtype="float32") = model_params[117]
            lv642 = R.call_tir(cls.layer_norm2, (lv534_1, lv554_1, lv555), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv556: R.Tensor((1280, 10240), dtype="float32") = model_params[983]
            lv557: R.Tensor((10240,), dtype="float32") = model_params[111]
            lv535_1 = R.call_tir(cls.fused_matmul24_add24, (lv642, lv556, lv557), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv536_1 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv535_1,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv558: R.Tensor((5120, 1280), dtype="float32") = model_params[984]
            lv559: R.Tensor((1280,), dtype="float32") = model_params[112]
            lv537_1 = R.call_tir(cls.fused_matmul25_add22_add23, (lv536_1, lv558, lv559, lv534_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv560: R.Tensor((1280,), dtype="float32") = model_params[124]
            lv561: R.Tensor((1280,), dtype="float32") = model_params[123]
            lv655 = R.call_tir(cls.layer_norm2, (lv537_1, lv560, lv561), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv562: R.Tensor((1280, 1280), dtype="float32") = model_params[985]
            lv657 = R.call_tir(cls.matmul18, (lv655, lv562), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv563: R.Tensor((1280, 1280), dtype="float32") = model_params[986]
            lv659 = R.call_tir(cls.matmul18, (lv655, lv563), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv564: R.Tensor((1280, 1280), dtype="float32") = model_params[987]
            lv661 = R.call_tir(cls.matmul18, (lv655, lv564), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv538_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv657,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv539_2 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv659,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv540_2 = R.call_tir(cls.fused_reshape30_transpose22, (lv661,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv541_1 = R.call_tir(cls.fused_matmul19_multiply11, (lv538_1, lv539_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv673 = R.call_tir(cls.softmax3, (lv541_1,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv674 = R.call_tir(cls.matmul20, (lv673, lv540_2), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv542_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv674,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv565: R.Tensor((1280, 1280), dtype="float32") = model_params[988]
            lv566_1: R.Tensor((1280,), dtype="float32") = model_params[119]
            lv543_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv542_1, lv565, lv566_1, lv537_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv567_1: R.Tensor((1280,), dtype="float32") = model_params[126]
            lv568: R.Tensor((1280,), dtype="float32") = model_params[125]
            lv682 = R.call_tir(cls.layer_norm2, (lv543_1, lv567_1, lv568), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv569: R.Tensor((1280, 1280), dtype="float32") = model_params[989]
            lv684 = R.call_tir(cls.matmul18, (lv682, lv569), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv570: R.Tensor((2048, 1280), dtype="float32") = model_params[990]
            lv686 = R.call_tir(cls.matmul21, (inp_2, lv570), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv571: R.Tensor((2048, 1280), dtype="float32") = model_params[991]
            lv688 = R.call_tir(cls.matmul21, (inp_2, lv571), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv544_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv684,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv545_1 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv686,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv546_1 = R.call_tir(cls.fused_reshape5_transpose1, (lv688,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv547_1 = R.call_tir(cls.fused_matmul22_multiply12, (lv544_1, lv545_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv700 = R.call_tir(cls.softmax4, (lv547_1,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv701 = R.call_tir(cls.matmul23, (lv700, lv546_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv548_2 = R.call_tir(cls.fused_transpose24_reshape31, (lv701,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv572: R.Tensor((1280, 1280), dtype="float32") = model_params[992]
            lv573: R.Tensor((1280,), dtype="float32") = model_params[120]
            lv549_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv548_2, lv572, lv573, lv543_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv574: R.Tensor((1280,), dtype="float32") = model_params[128]
            lv575_1: R.Tensor((1280,), dtype="float32") = model_params[127]
            lv709 = R.call_tir(cls.layer_norm2, (lv549_1, lv574, lv575_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv576: R.Tensor((1280, 10240), dtype="float32") = model_params[993]
            lv577: R.Tensor((10240,), dtype="float32") = model_params[121]
            lv550_2 = R.call_tir(cls.fused_matmul24_add24, (lv709, lv576, lv577), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv551_1 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv550_2,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv578: R.Tensor((5120, 1280), dtype="float32") = model_params[994]
            lv579: R.Tensor((1280,), dtype="float32") = model_params[122]
            lv552_2 = R.call_tir(cls.fused_matmul25_add22_add23, (lv551_1, lv578, lv579, lv549_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv580: R.Tensor((1280,), dtype="float32") = model_params[134]
            lv581: R.Tensor((1280,), dtype="float32") = model_params[133]
            lv722 = R.call_tir(cls.layer_norm2, (lv552_2, lv580, lv581), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv582: R.Tensor((1280, 1280), dtype="float32") = model_params[995]
            lv724 = R.call_tir(cls.matmul18, (lv722, lv582), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv583: R.Tensor((1280, 1280), dtype="float32") = model_params[996]
            lv726 = R.call_tir(cls.matmul18, (lv722, lv583), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv584: R.Tensor((1280, 1280), dtype="float32") = model_params[997]
            lv728 = R.call_tir(cls.matmul18, (lv722, lv584), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv553_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv724,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv554_2 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv726,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv555_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv728,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv556_1 = R.call_tir(cls.fused_matmul19_multiply11, (lv553_1, lv554_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv740 = R.call_tir(cls.softmax3, (lv556_1,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv741 = R.call_tir(cls.matmul20, (lv740, lv555_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv557_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv741,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv585: R.Tensor((1280, 1280), dtype="float32") = model_params[998]
            lv586: R.Tensor((1280,), dtype="float32") = model_params[129]
            lv558_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv557_1, lv585, lv586, lv552_2), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv587: R.Tensor((1280,), dtype="float32") = model_params[136]
            lv588_1: R.Tensor((1280,), dtype="float32") = model_params[135]
            lv749 = R.call_tir(cls.layer_norm2, (lv558_1, lv587, lv588_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv589: R.Tensor((1280, 1280), dtype="float32") = model_params[999]
            lv751 = R.call_tir(cls.matmul18, (lv749, lv589), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv590_1: R.Tensor((2048, 1280), dtype="float32") = model_params[1000]
            lv753 = R.call_tir(cls.matmul21, (inp_2, lv590_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv591: R.Tensor((2048, 1280), dtype="float32") = model_params[1001]
            lv755 = R.call_tir(cls.matmul21, (inp_2, lv591), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv559_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv751,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv560_1 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv753,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv561_1 = R.call_tir(cls.fused_reshape5_transpose1, (lv755,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv562_1 = R.call_tir(cls.fused_matmul22_multiply12, (lv559_1, lv560_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv767 = R.call_tir(cls.softmax4, (lv562_1,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv768 = R.call_tir(cls.matmul23, (lv767, lv561_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv563_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv768,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv592_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1002]
            lv593: R.Tensor((1280,), dtype="float32") = model_params[130]
            lv564_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv563_1, lv592_1, lv593, lv558_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv594_1: R.Tensor((1280,), dtype="float32") = model_params[138]
            lv595: R.Tensor((1280,), dtype="float32") = model_params[137]
            lv776 = R.call_tir(cls.layer_norm2, (lv564_1, lv594_1, lv595), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv596: R.Tensor((1280, 10240), dtype="float32") = model_params[1003]
            lv597: R.Tensor((10240,), dtype="float32") = model_params[131]
            lv565_1 = R.call_tir(cls.fused_matmul24_add24, (lv776, lv596, lv597), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv566_2 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv565_1,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv598: R.Tensor((5120, 1280), dtype="float32") = model_params[1004]
            lv599: R.Tensor((1280,), dtype="float32") = model_params[132]
            lv567_2 = R.call_tir(cls.fused_matmul25_add22_add23, (lv566_2, lv598, lv599, lv564_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv600: R.Tensor((1280,), dtype="float32") = model_params[144]
            lv601: R.Tensor((1280,), dtype="float32") = model_params[143]
            lv789 = R.call_tir(cls.layer_norm2, (lv567_2, lv600, lv601), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv602: R.Tensor((1280, 1280), dtype="float32") = model_params[1005]
            lv791 = R.call_tir(cls.matmul18, (lv789, lv602), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv603: R.Tensor((1280, 1280), dtype="float32") = model_params[1006]
            lv793 = R.call_tir(cls.matmul18, (lv789, lv603), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv604: R.Tensor((1280, 1280), dtype="float32") = model_params[1007]
            lv795 = R.call_tir(cls.matmul18, (lv789, lv604), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv568_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv791,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv569_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv793,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv570_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv795,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv571_1 = R.call_tir(cls.fused_matmul19_multiply11, (lv568_1, lv569_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv807 = R.call_tir(cls.softmax3, (lv571_1,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv808 = R.call_tir(cls.matmul20, (lv807, lv570_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv572_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv808,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv605: R.Tensor((1280, 1280), dtype="float32") = model_params[1008]
            lv606_1: R.Tensor((1280,), dtype="float32") = model_params[139]
            lv573_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv572_1, lv605, lv606_1, lv567_2), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv607_1: R.Tensor((1280,), dtype="float32") = model_params[146]
            lv608: R.Tensor((1280,), dtype="float32") = model_params[145]
            lv816 = R.call_tir(cls.layer_norm2, (lv573_1, lv607_1, lv608), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv609: R.Tensor((1280, 1280), dtype="float32") = model_params[1009]
            lv818 = R.call_tir(cls.matmul18, (lv816, lv609), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv610: R.Tensor((2048, 1280), dtype="float32") = model_params[1010]
            lv820 = R.call_tir(cls.matmul21, (inp_2, lv610), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv611: R.Tensor((2048, 1280), dtype="float32") = model_params[1011]
            lv822 = R.call_tir(cls.matmul21, (inp_2, lv611), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv574_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv818,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv575_2 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv820,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv576_1 = R.call_tir(cls.fused_reshape5_transpose1, (lv822,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv577_1 = R.call_tir(cls.fused_matmul22_multiply12, (lv574_1, lv575_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv834 = R.call_tir(cls.softmax4, (lv577_1,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv835 = R.call_tir(cls.matmul23, (lv834, lv576_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv578_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv835,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv612: R.Tensor((1280, 1280), dtype="float32") = model_params[1012]
            lv613: R.Tensor((1280,), dtype="float32") = model_params[140]
            lv579_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv578_1, lv612, lv613, lv573_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv614: R.Tensor((1280,), dtype="float32") = model_params[148]
            lv615_1: R.Tensor((1280,), dtype="float32") = model_params[147]
            lv843 = R.call_tir(cls.layer_norm2, (lv579_1, lv614, lv615_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv616: R.Tensor((1280, 10240), dtype="float32") = model_params[1013]
            lv617_1: R.Tensor((10240,), dtype="float32") = model_params[141]
            lv580_1 = R.call_tir(cls.fused_matmul24_add24, (lv843, lv616, lv617_1), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv581_1 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv580_1,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv618: R.Tensor((5120, 1280), dtype="float32") = model_params[1014]
            lv619_1: R.Tensor((1280,), dtype="float32") = model_params[142]
            lv582_1 = R.call_tir(cls.fused_matmul25_add22_add23, (lv581_1, lv618, lv619_1, lv579_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv620: R.Tensor((1280,), dtype="float32") = model_params[154]
            lv621_1: R.Tensor((1280,), dtype="float32") = model_params[153]
            lv856 = R.call_tir(cls.layer_norm2, (lv582_1, lv620, lv621_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv622: R.Tensor((1280, 1280), dtype="float32") = model_params[1015]
            lv858 = R.call_tir(cls.matmul18, (lv856, lv622), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv623: R.Tensor((1280, 1280), dtype="float32") = model_params[1016]
            lv860 = R.call_tir(cls.matmul18, (lv856, lv623), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv624: R.Tensor((1280, 1280), dtype="float32") = model_params[1017]
            lv862 = R.call_tir(cls.matmul18, (lv856, lv624), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv583_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv858,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv584_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv860,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv585_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv862,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv586_1 = R.call_tir(cls.fused_matmul19_multiply11, (lv583_1, lv584_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv874 = R.call_tir(cls.softmax3, (lv586_1,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv875 = R.call_tir(cls.matmul20, (lv874, lv585_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv587_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv875,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv625: R.Tensor((1280, 1280), dtype="float32") = model_params[1018]
            lv626: R.Tensor((1280,), dtype="float32") = model_params[149]
            lv588_2 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv587_1, lv625, lv626, lv582_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv627: R.Tensor((1280,), dtype="float32") = model_params[156]
            lv628: R.Tensor((1280,), dtype="float32") = model_params[155]
            lv883 = R.call_tir(cls.layer_norm2, (lv588_2, lv627, lv628), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv629: R.Tensor((1280, 1280), dtype="float32") = model_params[1019]
            lv885 = R.call_tir(cls.matmul18, (lv883, lv629), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv630: R.Tensor((2048, 1280), dtype="float32") = model_params[1020]
            lv887 = R.call_tir(cls.matmul21, (inp_2, lv630), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv631: R.Tensor((2048, 1280), dtype="float32") = model_params[1021]
            lv889 = R.call_tir(cls.matmul21, (inp_2, lv631), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv589_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv885,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv590_2 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv887,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv591_1 = R.call_tir(cls.fused_reshape5_transpose1, (lv889,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv592_2 = R.call_tir(cls.fused_matmul22_multiply12, (lv589_1, lv590_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv901 = R.call_tir(cls.softmax4, (lv592_2,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv902 = R.call_tir(cls.matmul23, (lv901, lv591_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv593_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv902,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv632: R.Tensor((1280, 1280), dtype="float32") = model_params[1022]
            lv633_1: R.Tensor((1280,), dtype="float32") = model_params[150]
            lv594_2 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv593_1, lv632, lv633_1, lv588_2), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv634_1: R.Tensor((1280,), dtype="float32") = model_params[158]
            lv635: R.Tensor((1280,), dtype="float32") = model_params[157]
            lv910 = R.call_tir(cls.layer_norm2, (lv594_2, lv634_1, lv635), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv636: R.Tensor((1280, 10240), dtype="float32") = model_params[1023]
            lv637: R.Tensor((10240,), dtype="float32") = model_params[151]
            lv595_1 = R.call_tir(cls.fused_matmul24_add24, (lv910, lv636, lv637), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv596_1 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv595_1,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv638: R.Tensor((5120, 1280), dtype="float32") = model_params[1024]
            lv639: R.Tensor((1280,), dtype="float32") = model_params[152]
            lv597_1 = R.call_tir(cls.fused_matmul25_add22_add23, (lv596_1, lv638, lv639, lv594_2), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv640: R.Tensor((1280,), dtype="float32") = model_params[164]
            lv641: R.Tensor((1280,), dtype="float32") = model_params[163]
            lv923 = R.call_tir(cls.layer_norm2, (lv597_1, lv640, lv641), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv642_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1025]
            lv925 = R.call_tir(cls.matmul18, (lv923, lv642_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv643: R.Tensor((1280, 1280), dtype="float32") = model_params[1026]
            lv927 = R.call_tir(cls.matmul18, (lv923, lv643), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv644: R.Tensor((1280, 1280), dtype="float32") = model_params[1027]
            lv929 = R.call_tir(cls.matmul18, (lv923, lv644), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv598_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv925,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv599_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv927,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv600_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv929,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv601_1 = R.call_tir(cls.fused_matmul19_multiply11, (lv598_1, lv599_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv941 = R.call_tir(cls.softmax3, (lv601_1,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv942 = R.call_tir(cls.matmul20, (lv941, lv600_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv602_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv942,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv645: R.Tensor((1280, 1280), dtype="float32") = model_params[1028]
            lv646: R.Tensor((1280,), dtype="float32") = model_params[159]
            lv603_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv602_1, lv645, lv646, lv597_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv647: R.Tensor((1280,), dtype="float32") = model_params[166]
            lv648: R.Tensor((1280,), dtype="float32") = model_params[165]
            lv950 = R.call_tir(cls.layer_norm2, (lv603_1, lv647, lv648), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv649: R.Tensor((1280, 1280), dtype="float32") = model_params[1029]
            lv952 = R.call_tir(cls.matmul18, (lv950, lv649), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv650: R.Tensor((2048, 1280), dtype="float32") = model_params[1030]
            lv954 = R.call_tir(cls.matmul21, (inp_2, lv650), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv651: R.Tensor((2048, 1280), dtype="float32") = model_params[1031]
            lv956 = R.call_tir(cls.matmul21, (inp_2, lv651), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv604_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv952,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv605_1 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv954,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv606_2 = R.call_tir(cls.fused_reshape5_transpose1, (lv956,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv607_2 = R.call_tir(cls.fused_matmul22_multiply12, (lv604_1, lv605_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv968 = R.call_tir(cls.softmax4, (lv607_2,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv969 = R.call_tir(cls.matmul23, (lv968, lv606_2), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv608_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv969,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv652: R.Tensor((1280, 1280), dtype="float32") = model_params[1032]
            lv653: R.Tensor((1280,), dtype="float32") = model_params[160]
            lv609_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv608_1, lv652, lv653, lv603_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv654: R.Tensor((1280,), dtype="float32") = model_params[168]
            lv655_1: R.Tensor((1280,), dtype="float32") = model_params[167]
            lv977 = R.call_tir(cls.layer_norm2, (lv609_1, lv654, lv655_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv656: R.Tensor((1280, 10240), dtype="float32") = model_params[1033]
            lv657_1: R.Tensor((10240,), dtype="float32") = model_params[161]
            lv610_1 = R.call_tir(cls.fused_matmul24_add24, (lv977, lv656, lv657_1), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv611_1 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv610_1,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv658: R.Tensor((5120, 1280), dtype="float32") = model_params[1034]
            lv659_1: R.Tensor((1280,), dtype="float32") = model_params[162]
            lv612_1 = R.call_tir(cls.fused_matmul25_add22_add23, (lv611_1, lv658, lv659_1, lv609_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv660: R.Tensor((1280,), dtype="float32") = model_params[174]
            lv661_1: R.Tensor((1280,), dtype="float32") = model_params[173]
            lv990 = R.call_tir(cls.layer_norm2, (lv612_1, lv660, lv661_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv662: R.Tensor((1280, 1280), dtype="float32") = model_params[1035]
            lv992 = R.call_tir(cls.matmul18, (lv990, lv662), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv663: R.Tensor((1280, 1280), dtype="float32") = model_params[1036]
            lv994 = R.call_tir(cls.matmul18, (lv990, lv663), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv664: R.Tensor((1280, 1280), dtype="float32") = model_params[1037]
            lv996 = R.call_tir(cls.matmul18, (lv990, lv664), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv613_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv992,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv614_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv994,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv615_2 = R.call_tir(cls.fused_reshape30_transpose22, (lv996,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv616_1 = R.call_tir(cls.fused_matmul19_multiply11, (lv613_1, lv614_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv1008 = R.call_tir(cls.softmax3, (lv616_1,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv1009 = R.call_tir(cls.matmul20, (lv1008, lv615_2), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv617_2 = R.call_tir(cls.fused_transpose24_reshape31, (lv1009,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv665: R.Tensor((1280, 1280), dtype="float32") = model_params[1038]
            lv666: R.Tensor((1280,), dtype="float32") = model_params[169]
            lv618_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv617_2, lv665, lv666, lv612_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv667: R.Tensor((1280,), dtype="float32") = model_params[176]
            lv668: R.Tensor((1280,), dtype="float32") = model_params[175]
            lv1017 = R.call_tir(cls.layer_norm2, (lv618_1, lv667, lv668), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv669: R.Tensor((1280, 1280), dtype="float32") = model_params[1039]
            lv1019 = R.call_tir(cls.matmul18, (lv1017, lv669), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv670: R.Tensor((2048, 1280), dtype="float32") = model_params[1040]
            lv1021 = R.call_tir(cls.matmul21, (inp_2, lv670), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv671: R.Tensor((2048, 1280), dtype="float32") = model_params[1041]
            lv1023 = R.call_tir(cls.matmul21, (inp_2, lv671), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv619_2 = R.call_tir(cls.fused_reshape30_transpose22, (lv1019,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv620_1 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv1021,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv621_2 = R.call_tir(cls.fused_reshape5_transpose1, (lv1023,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv622_1 = R.call_tir(cls.fused_matmul22_multiply12, (lv619_2, lv620_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv1035 = R.call_tir(cls.softmax4, (lv622_1,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv1036 = R.call_tir(cls.matmul23, (lv1035, lv621_2), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv623_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv1036,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv672: R.Tensor((1280, 1280), dtype="float32") = model_params[1042]
            lv673_1: R.Tensor((1280,), dtype="float32") = model_params[170]
            lv624_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv623_1, lv672, lv673_1, lv618_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv674_1: R.Tensor((1280,), dtype="float32") = model_params[178]
            lv675: R.Tensor((1280,), dtype="float32") = model_params[177]
            lv1044 = R.call_tir(cls.layer_norm2, (lv624_1, lv674_1, lv675), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv676: R.Tensor((1280, 10240), dtype="float32") = model_params[1043]
            lv677: R.Tensor((10240,), dtype="float32") = model_params[171]
            lv625_1 = R.call_tir(cls.fused_matmul24_add24, (lv1044, lv676, lv677), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv626_1 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv625_1,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv678: R.Tensor((5120, 1280), dtype="float32") = model_params[1044]
            lv679: R.Tensor((1280,), dtype="float32") = model_params[172]
            lv627_1 = R.call_tir(cls.fused_matmul25_add22_add23, (lv626_1, lv678, lv679, lv624_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv680: R.Tensor((1280,), dtype="float32") = model_params[184]
            lv681: R.Tensor((1280,), dtype="float32") = model_params[183]
            lv1057 = R.call_tir(cls.layer_norm2, (lv627_1, lv680, lv681), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv682_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1045]
            lv1059 = R.call_tir(cls.matmul18, (lv1057, lv682_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv683: R.Tensor((1280, 1280), dtype="float32") = model_params[1046]
            lv1061 = R.call_tir(cls.matmul18, (lv1057, lv683), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv684_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1047]
            lv1063 = R.call_tir(cls.matmul18, (lv1057, lv684_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv628_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv1059,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv629_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv1061,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv630_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv1063,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv631_1 = R.call_tir(cls.fused_matmul19_multiply11, (lv628_1, lv629_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv1075 = R.call_tir(cls.softmax3, (lv631_1,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv1076 = R.call_tir(cls.matmul20, (lv1075, lv630_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv632_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv1076,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv685: R.Tensor((1280, 1280), dtype="float32") = model_params[1048]
            lv686_1: R.Tensor((1280,), dtype="float32") = model_params[179]
            lv633_2 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv632_1, lv685, lv686_1, lv627_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv687: R.Tensor((1280,), dtype="float32") = model_params[186]
            lv688_1: R.Tensor((1280,), dtype="float32") = model_params[185]
            lv1084 = R.call_tir(cls.layer_norm2, (lv633_2, lv687, lv688_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv689: R.Tensor((1280, 1280), dtype="float32") = model_params[1049]
            lv1086 = R.call_tir(cls.matmul18, (lv1084, lv689), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv690: R.Tensor((2048, 1280), dtype="float32") = model_params[1050]
            lv1088 = R.call_tir(cls.matmul21, (inp_2, lv690), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv691: R.Tensor((2048, 1280), dtype="float32") = model_params[1051]
            lv1090 = R.call_tir(cls.matmul21, (inp_2, lv691), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv634_2 = R.call_tir(cls.fused_reshape30_transpose22, (lv1086,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv635_1 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv1088,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv636_1 = R.call_tir(cls.fused_reshape5_transpose1, (lv1090,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv637_1 = R.call_tir(cls.fused_matmul22_multiply12, (lv634_2, lv635_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv1102 = R.call_tir(cls.softmax4, (lv637_1,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv1103 = R.call_tir(cls.matmul23, (lv1102, lv636_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv638_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv1103,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv692: R.Tensor((1280, 1280), dtype="float32") = model_params[1052]
            lv693: R.Tensor((1280,), dtype="float32") = model_params[180]
            lv639_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv638_1, lv692, lv693, lv633_2), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv694: R.Tensor((1280,), dtype="float32") = model_params[188]
            lv695: R.Tensor((1280,), dtype="float32") = model_params[187]
            lv1111 = R.call_tir(cls.layer_norm2, (lv639_1, lv694, lv695), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv696: R.Tensor((1280, 10240), dtype="float32") = model_params[1053]
            lv697: R.Tensor((10240,), dtype="float32") = model_params[181]
            lv640_1 = R.call_tir(cls.fused_matmul24_add24, (lv1111, lv696, lv697), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv641_1 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv640_1,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv698: R.Tensor((5120, 1280), dtype="float32") = model_params[1054]
            lv699: R.Tensor((1280,), dtype="float32") = model_params[182]
            lv642_2 = R.call_tir(cls.fused_matmul25_add22_add23, (lv641_1, lv698, lv699, lv639_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv700_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1055]
            lv701_1: R.Tensor((1280,), dtype="float32") = model_params[88]
            lv643_1 = R.call_tir(cls.fused_matmul18_add22, (lv642_2, lv700_1, lv701_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv644_1 = R.call_tir(cls.fused_reshape32_transpose28_add21, (lv643_1, lv490_1), out_sinfo=R.Tensor((1, 1280, 16, 16), dtype="float32"))
            lv702: R.Tensor((1280,), dtype="float32") = model_params[304]
            lv703: R.Tensor((1280,), dtype="float32") = model_params[303]
            lv645_1 = R.call_tir(cls.fused_group_norm5_silu5, (lv644_1, lv702, lv703), out_sinfo=R.Tensor((1, 1280, 16, 16), dtype="float32"))
            lv1135 = R.call_tir(cls.silu, (lv392,), out_sinfo=R.Tensor((1, 1280), dtype="float32"))
            lv704: R.Tensor((1280, 1280), dtype="float32") = model_params[1057]
            lv705: R.Tensor((1280,), dtype="float32") = model_params[307]
            lv646_1 = R.call_tir(cls.fused_matmul5_add7_strided_slice, (lv1135, lv704, lv705), out_sinfo=R.Tensor((1, 1280), dtype="float32"))
            lv1140 = R.call_tir(cls.reshape28, (lv646_1,), out_sinfo=R.Tensor((1, 1280, 1, 1), dtype="float32"))
            lv706: R.Tensor((1280, 1280, 3, 3), dtype="float32") = model_params[301]
            lv707: R.Tensor((1, 1280, 1, 1), dtype="float32") = model_params[1056]
            lv647_1 = R.call_tir(cls.fused_conv2d8_add20_add20, (lv645_1, lv706, lv707, lv1140), out_sinfo=R.Tensor((1, 1280, 16, 16), dtype="float32"))
            lv708: R.Tensor((1280,), dtype="float32") = model_params[306]
            lv709_1: R.Tensor((1280,), dtype="float32") = model_params[305]
            lv648_1 = R.call_tir(cls.fused_group_norm5_silu5, (lv647_1, lv708, lv709_1), out_sinfo=R.Tensor((1, 1280, 16, 16), dtype="float32"))
            lv710: R.Tensor((1280, 1280, 3, 3), dtype="float32") = model_params[302]
            lv711: R.Tensor((1, 1280, 1, 1), dtype="float32") = model_params[1058]
            lv649_1 = R.call_tir(cls.fused_conv2d8_add20_add21_divide6, (lv648_1, lv710, lv711, lv644_1), out_sinfo=R.Tensor((1, 1280, 16, 16), dtype="float32"))
            lv712: R.Tensor((1280,), dtype="float32") = model_params[190]
            lv713: R.Tensor((1280,), dtype="float32") = model_params[189]
            lv1149 = R.call_tir(cls.group_norm6, (lv649_1, lv712, lv713), out_sinfo=R.Tensor((1, 1280, 16, 16), dtype="float32"))
            lv650_1 = R.call_tir(cls.fused_transpose21_reshape29, (lv1149,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv714: R.Tensor((1280, 1280), dtype="float32") = model_params[1059]
            lv715: R.Tensor((1280,), dtype="float32") = model_params[191]
            lv651_1 = R.call_tir(cls.fused_matmul18_add22, (lv650_1, lv714, lv715), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv716: R.Tensor((1280,), dtype="float32") = model_params[198]
            lv717: R.Tensor((1280,), dtype="float32") = model_params[197]
            lv1155 = R.call_tir(cls.layer_norm2, (lv651_1, lv716, lv717), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv718: R.Tensor((1280, 1280), dtype="float32") = model_params[1060]
            lv1157 = R.call_tir(cls.matmul18, (lv1155, lv718), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv719: R.Tensor((1280, 1280), dtype="float32") = model_params[1061]
            lv1159 = R.call_tir(cls.matmul18, (lv1155, lv719), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv720: R.Tensor((1280, 1280), dtype="float32") = model_params[1062]
            lv1161 = R.call_tir(cls.matmul18, (lv1155, lv720), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv652_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv1157,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv653_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv1159,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv654_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv1161,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv655_2 = R.call_tir(cls.fused_matmul19_multiply11, (lv652_1, lv653_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv1173 = R.call_tir(cls.softmax3, (lv655_2,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv1174 = R.call_tir(cls.matmul20, (lv1173, lv654_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv656_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv1174,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv721: R.Tensor((1280, 1280), dtype="float32") = model_params[1063]
            lv722_1: R.Tensor((1280,), dtype="float32") = model_params[193]
            lv657_2 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv656_1, lv721, lv722_1, lv651_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv723: R.Tensor((1280,), dtype="float32") = model_params[200]
            lv724_1: R.Tensor((1280,), dtype="float32") = model_params[199]
            lv1182 = R.call_tir(cls.layer_norm2, (lv657_2, lv723, lv724_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv725: R.Tensor((1280, 1280), dtype="float32") = model_params[1064]
            lv1184 = R.call_tir(cls.matmul18, (lv1182, lv725), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv726_1: R.Tensor((2048, 1280), dtype="float32") = model_params[1065]
            lv1186 = R.call_tir(cls.matmul21, (inp_2, lv726_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv727: R.Tensor((2048, 1280), dtype="float32") = model_params[1066]
            lv1188 = R.call_tir(cls.matmul21, (inp_2, lv727), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv658_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv1184,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv659_2 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv1186,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv660_1 = R.call_tir(cls.fused_reshape5_transpose1, (lv1188,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv661_2 = R.call_tir(cls.fused_matmul22_multiply12, (lv658_1, lv659_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv1200 = R.call_tir(cls.softmax4, (lv661_2,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv1201 = R.call_tir(cls.matmul23, (lv1200, lv660_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv662_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv1201,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv728_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1067]
            lv729: R.Tensor((1280,), dtype="float32") = model_params[194]
            lv663_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv662_1, lv728_1, lv729, lv657_2), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv730: R.Tensor((1280,), dtype="float32") = model_params[202]
            lv731: R.Tensor((1280,), dtype="float32") = model_params[201]
            lv1209 = R.call_tir(cls.layer_norm2, (lv663_1, lv730, lv731), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv732: R.Tensor((1280, 10240), dtype="float32") = model_params[1068]
            lv733: R.Tensor((10240,), dtype="float32") = model_params[195]
            lv664_1 = R.call_tir(cls.fused_matmul24_add24, (lv1209, lv732, lv733), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv665_1 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv664_1,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv734: R.Tensor((5120, 1280), dtype="float32") = model_params[1069]
            lv735: R.Tensor((1280,), dtype="float32") = model_params[196]
            lv666_1 = R.call_tir(cls.fused_matmul25_add22_add23, (lv665_1, lv734, lv735, lv663_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv736: R.Tensor((1280,), dtype="float32") = model_params[208]
            lv737: R.Tensor((1280,), dtype="float32") = model_params[207]
            lv1222 = R.call_tir(cls.layer_norm2, (lv666_1, lv736, lv737), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv738: R.Tensor((1280, 1280), dtype="float32") = model_params[1070]
            lv1224 = R.call_tir(cls.matmul18, (lv1222, lv738), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv739: R.Tensor((1280, 1280), dtype="float32") = model_params[1071]
            lv1226 = R.call_tir(cls.matmul18, (lv1222, lv739), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv740_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1072]
            lv1228 = R.call_tir(cls.matmul18, (lv1222, lv740_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv667_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv1224,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv668_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv1226,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv669_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv1228,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv670_1 = R.call_tir(cls.fused_matmul19_multiply11, (lv667_1, lv668_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv1240 = R.call_tir(cls.softmax3, (lv670_1,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv1241 = R.call_tir(cls.matmul20, (lv1240, lv669_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv671_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv1241,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv741_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1073]
            lv742: R.Tensor((1280,), dtype="float32") = model_params[203]
            lv672_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv671_1, lv741_1, lv742, lv666_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv743: R.Tensor((1280,), dtype="float32") = model_params[210]
            lv744: R.Tensor((1280,), dtype="float32") = model_params[209]
            lv1249 = R.call_tir(cls.layer_norm2, (lv672_1, lv743, lv744), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv745: R.Tensor((1280, 1280), dtype="float32") = model_params[1074]
            lv1251 = R.call_tir(cls.matmul18, (lv1249, lv745), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv746: R.Tensor((2048, 1280), dtype="float32") = model_params[1075]
            lv1253 = R.call_tir(cls.matmul21, (inp_2, lv746), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv747: R.Tensor((2048, 1280), dtype="float32") = model_params[1076]
            lv1255 = R.call_tir(cls.matmul21, (inp_2, lv747), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv673_2 = R.call_tir(cls.fused_reshape30_transpose22, (lv1251,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv674_2 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv1253,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv675_1 = R.call_tir(cls.fused_reshape5_transpose1, (lv1255,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv676_1 = R.call_tir(cls.fused_matmul22_multiply12, (lv673_2, lv674_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv1267 = R.call_tir(cls.softmax4, (lv676_1,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv1268 = R.call_tir(cls.matmul23, (lv1267, lv675_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv677_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv1268,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv748: R.Tensor((1280, 1280), dtype="float32") = model_params[1077]
            lv749_1: R.Tensor((1280,), dtype="float32") = model_params[204]
            lv678_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv677_1, lv748, lv749_1, lv672_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv750: R.Tensor((1280,), dtype="float32") = model_params[212]
            lv751_1: R.Tensor((1280,), dtype="float32") = model_params[211]
            lv1276 = R.call_tir(cls.layer_norm2, (lv678_1, lv750, lv751_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv752: R.Tensor((1280, 10240), dtype="float32") = model_params[1078]
            lv753_1: R.Tensor((10240,), dtype="float32") = model_params[205]
            lv679_1 = R.call_tir(cls.fused_matmul24_add24, (lv1276, lv752, lv753_1), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv680_1 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv679_1,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv754: R.Tensor((5120, 1280), dtype="float32") = model_params[1079]
            lv755_1: R.Tensor((1280,), dtype="float32") = model_params[206]
            lv681_1 = R.call_tir(cls.fused_matmul25_add22_add23, (lv680_1, lv754, lv755_1, lv678_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv756: R.Tensor((1280,), dtype="float32") = model_params[218]
            lv757: R.Tensor((1280,), dtype="float32") = model_params[217]
            lv1289 = R.call_tir(cls.layer_norm2, (lv681_1, lv756, lv757), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv758: R.Tensor((1280, 1280), dtype="float32") = model_params[1080]
            lv1291 = R.call_tir(cls.matmul18, (lv1289, lv758), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv759: R.Tensor((1280, 1280), dtype="float32") = model_params[1081]
            lv1293 = R.call_tir(cls.matmul18, (lv1289, lv759), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv760: R.Tensor((1280, 1280), dtype="float32") = model_params[1082]
            lv1295 = R.call_tir(cls.matmul18, (lv1289, lv760), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv682_2 = R.call_tir(cls.fused_reshape30_transpose22, (lv1291,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv683_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv1293,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv684_2 = R.call_tir(cls.fused_reshape30_transpose22, (lv1295,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv685_1 = R.call_tir(cls.fused_matmul19_multiply11, (lv682_2, lv683_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv1307 = R.call_tir(cls.softmax3, (lv685_1,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv1308 = R.call_tir(cls.matmul20, (lv1307, lv684_2), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv686_2 = R.call_tir(cls.fused_transpose24_reshape31, (lv1308,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv761: R.Tensor((1280, 1280), dtype="float32") = model_params[1083]
            lv762: R.Tensor((1280,), dtype="float32") = model_params[213]
            lv687_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv686_2, lv761, lv762, lv681_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv763: R.Tensor((1280,), dtype="float32") = model_params[220]
            lv764: R.Tensor((1280,), dtype="float32") = model_params[219]
            lv1316 = R.call_tir(cls.layer_norm2, (lv687_1, lv763, lv764), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv765: R.Tensor((1280, 1280), dtype="float32") = model_params[1084]
            lv1318 = R.call_tir(cls.matmul18, (lv1316, lv765), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv766: R.Tensor((2048, 1280), dtype="float32") = model_params[1085]
            lv1320 = R.call_tir(cls.matmul21, (inp_2, lv766), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv767_1: R.Tensor((2048, 1280), dtype="float32") = model_params[1086]
            lv1322 = R.call_tir(cls.matmul21, (inp_2, lv767_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv688_2 = R.call_tir(cls.fused_reshape30_transpose22, (lv1318,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv689_1 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv1320,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv690_1 = R.call_tir(cls.fused_reshape5_transpose1, (lv1322,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv691_1 = R.call_tir(cls.fused_matmul22_multiply12, (lv688_2, lv689_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv1334 = R.call_tir(cls.softmax4, (lv691_1,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv1335 = R.call_tir(cls.matmul23, (lv1334, lv690_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv692_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv1335,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv768_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1087]
            lv769: R.Tensor((1280,), dtype="float32") = model_params[214]
            lv693_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv692_1, lv768_1, lv769, lv687_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv770: R.Tensor((1280,), dtype="float32") = model_params[222]
            lv771: R.Tensor((1280,), dtype="float32") = model_params[221]
            lv1343 = R.call_tir(cls.layer_norm2, (lv693_1, lv770, lv771), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv772: R.Tensor((1280, 10240), dtype="float32") = model_params[1088]
            lv773: R.Tensor((10240,), dtype="float32") = model_params[215]
            lv694_1 = R.call_tir(cls.fused_matmul24_add24, (lv1343, lv772, lv773), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv695_1 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv694_1,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv774: R.Tensor((5120, 1280), dtype="float32") = model_params[1089]
            lv775: R.Tensor((1280,), dtype="float32") = model_params[216]
            lv696_1 = R.call_tir(cls.fused_matmul25_add22_add23, (lv695_1, lv774, lv775, lv693_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv776_1: R.Tensor((1280,), dtype="float32") = model_params[228]
            lv777: R.Tensor((1280,), dtype="float32") = model_params[227]
            lv1356 = R.call_tir(cls.layer_norm2, (lv696_1, lv776_1, lv777), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv778: R.Tensor((1280, 1280), dtype="float32") = model_params[1090]
            lv1358 = R.call_tir(cls.matmul18, (lv1356, lv778), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv779: R.Tensor((1280, 1280), dtype="float32") = model_params[1091]
            lv1360 = R.call_tir(cls.matmul18, (lv1356, lv779), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv780: R.Tensor((1280, 1280), dtype="float32") = model_params[1092]
            lv1362 = R.call_tir(cls.matmul18, (lv1356, lv780), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv697_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv1358,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv698_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv1360,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv699_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv1362,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv700_2 = R.call_tir(cls.fused_matmul19_multiply11, (lv697_1, lv698_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv1374 = R.call_tir(cls.softmax3, (lv700_2,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv1375 = R.call_tir(cls.matmul20, (lv1374, lv699_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv701_2 = R.call_tir(cls.fused_transpose24_reshape31, (lv1375,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv781: R.Tensor((1280, 1280), dtype="float32") = model_params[1093]
            lv782: R.Tensor((1280,), dtype="float32") = model_params[223]
            lv702_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv701_2, lv781, lv782, lv696_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv783: R.Tensor((1280,), dtype="float32") = model_params[230]
            lv784: R.Tensor((1280,), dtype="float32") = model_params[229]
            lv1383 = R.call_tir(cls.layer_norm2, (lv702_1, lv783, lv784), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv785: R.Tensor((1280, 1280), dtype="float32") = model_params[1094]
            lv1385 = R.call_tir(cls.matmul18, (lv1383, lv785), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv786: R.Tensor((2048, 1280), dtype="float32") = model_params[1095]
            lv1387 = R.call_tir(cls.matmul21, (inp_2, lv786), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv787: R.Tensor((2048, 1280), dtype="float32") = model_params[1096]
            lv1389 = R.call_tir(cls.matmul21, (inp_2, lv787), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv703_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv1385,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv704_1 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv1387,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv705_1 = R.call_tir(cls.fused_reshape5_transpose1, (lv1389,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv706_1 = R.call_tir(cls.fused_matmul22_multiply12, (lv703_1, lv704_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv1401 = R.call_tir(cls.softmax4, (lv706_1,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv1402 = R.call_tir(cls.matmul23, (lv1401, lv705_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv707_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv1402,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv788: R.Tensor((1280, 1280), dtype="float32") = model_params[1097]
            lv789_1: R.Tensor((1280,), dtype="float32") = model_params[224]
            lv708_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv707_1, lv788, lv789_1, lv702_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv790: R.Tensor((1280,), dtype="float32") = model_params[232]
            lv791_1: R.Tensor((1280,), dtype="float32") = model_params[231]
            lv1410 = R.call_tir(cls.layer_norm2, (lv708_1, lv790, lv791_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv792: R.Tensor((1280, 10240), dtype="float32") = model_params[1098]
            lv793_1: R.Tensor((10240,), dtype="float32") = model_params[225]
            lv709_2 = R.call_tir(cls.fused_matmul24_add24, (lv1410, lv792, lv793_1), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv710_1 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv709_2,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv794: R.Tensor((5120, 1280), dtype="float32") = model_params[1099]
            lv795_1: R.Tensor((1280,), dtype="float32") = model_params[226]
            lv711_1 = R.call_tir(cls.fused_matmul25_add22_add23, (lv710_1, lv794, lv795_1, lv708_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv796: R.Tensor((1280,), dtype="float32") = model_params[238]
            lv797: R.Tensor((1280,), dtype="float32") = model_params[237]
            lv1423 = R.call_tir(cls.layer_norm2, (lv711_1, lv796, lv797), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv798: R.Tensor((1280, 1280), dtype="float32") = model_params[1100]
            lv1425 = R.call_tir(cls.matmul18, (lv1423, lv798), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv799: R.Tensor((1280, 1280), dtype="float32") = model_params[1101]
            lv1427 = R.call_tir(cls.matmul18, (lv1423, lv799), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv800: R.Tensor((1280, 1280), dtype="float32") = model_params[1102]
            lv1429 = R.call_tir(cls.matmul18, (lv1423, lv800), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv712_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv1425,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv713_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv1427,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv714_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv1429,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv715_1 = R.call_tir(cls.fused_matmul19_multiply11, (lv712_1, lv713_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv1441 = R.call_tir(cls.softmax3, (lv715_1,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv1442 = R.call_tir(cls.matmul20, (lv1441, lv714_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv716_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv1442,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv801: R.Tensor((1280, 1280), dtype="float32") = model_params[1103]
            lv802: R.Tensor((1280,), dtype="float32") = model_params[233]
            lv717_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv716_1, lv801, lv802, lv711_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv803: R.Tensor((1280,), dtype="float32") = model_params[240]
            lv804: R.Tensor((1280,), dtype="float32") = model_params[239]
            lv1450 = R.call_tir(cls.layer_norm2, (lv717_1, lv803, lv804), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv805: R.Tensor((1280, 1280), dtype="float32") = model_params[1104]
            lv1452 = R.call_tir(cls.matmul18, (lv1450, lv805), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv806: R.Tensor((2048, 1280), dtype="float32") = model_params[1105]
            lv1454 = R.call_tir(cls.matmul21, (inp_2, lv806), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv807_1: R.Tensor((2048, 1280), dtype="float32") = model_params[1106]
            lv1456 = R.call_tir(cls.matmul21, (inp_2, lv807_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv718_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv1452,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv719_1 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv1454,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv720_1 = R.call_tir(cls.fused_reshape5_transpose1, (lv1456,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv721_1 = R.call_tir(cls.fused_matmul22_multiply12, (lv718_1, lv719_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv1468 = R.call_tir(cls.softmax4, (lv721_1,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv1469 = R.call_tir(cls.matmul23, (lv1468, lv720_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv722_2 = R.call_tir(cls.fused_transpose24_reshape31, (lv1469,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv808_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1107]
            lv809: R.Tensor((1280,), dtype="float32") = model_params[234]
            lv723_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv722_2, lv808_1, lv809, lv717_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv810: R.Tensor((1280,), dtype="float32") = model_params[242]
            lv811: R.Tensor((1280,), dtype="float32") = model_params[241]
            lv1477 = R.call_tir(cls.layer_norm2, (lv723_1, lv810, lv811), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv812: R.Tensor((1280, 10240), dtype="float32") = model_params[1108]
            lv813: R.Tensor((10240,), dtype="float32") = model_params[235]
            lv724_2 = R.call_tir(cls.fused_matmul24_add24, (lv1477, lv812, lv813), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv725_1 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv724_2,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv814: R.Tensor((5120, 1280), dtype="float32") = model_params[1109]
            lv815: R.Tensor((1280,), dtype="float32") = model_params[236]
            lv726_2 = R.call_tir(cls.fused_matmul25_add22_add23, (lv725_1, lv814, lv815, lv723_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv816_1: R.Tensor((1280,), dtype="float32") = model_params[248]
            lv817: R.Tensor((1280,), dtype="float32") = model_params[247]
            lv1490 = R.call_tir(cls.layer_norm2, (lv726_2, lv816_1, lv817), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv818_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1110]
            lv1492 = R.call_tir(cls.matmul18, (lv1490, lv818_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv819: R.Tensor((1280, 1280), dtype="float32") = model_params[1111]
            lv1494 = R.call_tir(cls.matmul18, (lv1490, lv819), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv820_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1112]
            lv1496 = R.call_tir(cls.matmul18, (lv1490, lv820_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv727_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv1492,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv728_2 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv1494,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv729_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv1496,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv730_1 = R.call_tir(cls.fused_matmul19_multiply11, (lv727_1, lv728_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv1508 = R.call_tir(cls.softmax3, (lv730_1,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv1509 = R.call_tir(cls.matmul20, (lv1508, lv729_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv731_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv1509,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv821: R.Tensor((1280, 1280), dtype="float32") = model_params[1113]
            lv822_1: R.Tensor((1280,), dtype="float32") = model_params[243]
            lv732_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv731_1, lv821, lv822_1, lv726_2), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv823: R.Tensor((1280,), dtype="float32") = model_params[250]
            lv824: R.Tensor((1280,), dtype="float32") = model_params[249]
            lv1517 = R.call_tir(cls.layer_norm2, (lv732_1, lv823, lv824), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv825: R.Tensor((1280, 1280), dtype="float32") = model_params[1114]
            lv1519 = R.call_tir(cls.matmul18, (lv1517, lv825), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv826: R.Tensor((2048, 1280), dtype="float32") = model_params[1115]
            lv1521 = R.call_tir(cls.matmul21, (inp_2, lv826), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv827: R.Tensor((2048, 1280), dtype="float32") = model_params[1116]
            lv1523 = R.call_tir(cls.matmul21, (inp_2, lv827), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv733_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv1519,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv734_1 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv1521,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv735_1 = R.call_tir(cls.fused_reshape5_transpose1, (lv1523,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv736_1 = R.call_tir(cls.fused_matmul22_multiply12, (lv733_1, lv734_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv1535 = R.call_tir(cls.softmax4, (lv736_1,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv1536 = R.call_tir(cls.matmul23, (lv1535, lv735_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv737_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv1536,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv828: R.Tensor((1280, 1280), dtype="float32") = model_params[1117]
            lv829: R.Tensor((1280,), dtype="float32") = model_params[244]
            lv738_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv737_1, lv828, lv829, lv732_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv830: R.Tensor((1280,), dtype="float32") = model_params[252]
            lv831: R.Tensor((1280,), dtype="float32") = model_params[251]
            lv1544 = R.call_tir(cls.layer_norm2, (lv738_1, lv830, lv831), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv832: R.Tensor((1280, 10240), dtype="float32") = model_params[1118]
            lv833: R.Tensor((10240,), dtype="float32") = model_params[245]
            lv739_1 = R.call_tir(cls.fused_matmul24_add24, (lv1544, lv832, lv833), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv740_2 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv739_1,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv834_1: R.Tensor((5120, 1280), dtype="float32") = model_params[1119]
            lv835_1: R.Tensor((1280,), dtype="float32") = model_params[246]
            lv741_2 = R.call_tir(cls.fused_matmul25_add22_add23, (lv740_2, lv834_1, lv835_1, lv738_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv836: R.Tensor((1280,), dtype="float32") = model_params[258]
            lv837: R.Tensor((1280,), dtype="float32") = model_params[257]
            lv1557 = R.call_tir(cls.layer_norm2, (lv741_2, lv836, lv837), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv838: R.Tensor((1280, 1280), dtype="float32") = model_params[1120]
            lv1559 = R.call_tir(cls.matmul18, (lv1557, lv838), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv839: R.Tensor((1280, 1280), dtype="float32") = model_params[1121]
            lv1561 = R.call_tir(cls.matmul18, (lv1557, lv839), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv840: R.Tensor((1280, 1280), dtype="float32") = model_params[1122]
            lv1563 = R.call_tir(cls.matmul18, (lv1557, lv840), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv742_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv1559,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv743_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv1561,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv744_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv1563,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv745_1 = R.call_tir(cls.fused_matmul19_multiply11, (lv742_1, lv743_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv1575 = R.call_tir(cls.softmax3, (lv745_1,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv1576 = R.call_tir(cls.matmul20, (lv1575, lv744_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv746_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv1576,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv841: R.Tensor((1280, 1280), dtype="float32") = model_params[1123]
            lv842: R.Tensor((1280,), dtype="float32") = model_params[253]
            lv747_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv746_1, lv841, lv842, lv741_2), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv843_1: R.Tensor((1280,), dtype="float32") = model_params[260]
            lv844: R.Tensor((1280,), dtype="float32") = model_params[259]
            lv1584 = R.call_tir(cls.layer_norm2, (lv747_1, lv843_1, lv844), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv845: R.Tensor((1280, 1280), dtype="float32") = model_params[1124]
            lv1586 = R.call_tir(cls.matmul18, (lv1584, lv845), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv846: R.Tensor((2048, 1280), dtype="float32") = model_params[1125]
            lv1588 = R.call_tir(cls.matmul21, (inp_2, lv846), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv847: R.Tensor((2048, 1280), dtype="float32") = model_params[1126]
            lv1590 = R.call_tir(cls.matmul21, (inp_2, lv847), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv748_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv1586,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv749_2 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv1588,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv750_1 = R.call_tir(cls.fused_reshape5_transpose1, (lv1590,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv751_2 = R.call_tir(cls.fused_matmul22_multiply12, (lv748_1, lv749_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv1602 = R.call_tir(cls.softmax4, (lv751_2,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv1603 = R.call_tir(cls.matmul23, (lv1602, lv750_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv752_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv1603,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv848: R.Tensor((1280, 1280), dtype="float32") = model_params[1127]
            lv849: R.Tensor((1280,), dtype="float32") = model_params[254]
            lv753_2 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv752_1, lv848, lv849, lv747_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv850: R.Tensor((1280,), dtype="float32") = model_params[262]
            lv851: R.Tensor((1280,), dtype="float32") = model_params[261]
            lv1611 = R.call_tir(cls.layer_norm2, (lv753_2, lv850, lv851), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv852: R.Tensor((1280, 10240), dtype="float32") = model_params[1128]
            lv853: R.Tensor((10240,), dtype="float32") = model_params[255]
            lv754_1 = R.call_tir(cls.fused_matmul24_add24, (lv1611, lv852, lv853), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv755_2 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv754_1,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv854: R.Tensor((5120, 1280), dtype="float32") = model_params[1129]
            lv855: R.Tensor((1280,), dtype="float32") = model_params[256]
            lv756_1 = R.call_tir(cls.fused_matmul25_add22_add23, (lv755_2, lv854, lv855, lv753_2), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv856_1: R.Tensor((1280,), dtype="float32") = model_params[268]
            lv857: R.Tensor((1280,), dtype="float32") = model_params[267]
            lv1624 = R.call_tir(cls.layer_norm2, (lv756_1, lv856_1, lv857), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv858_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1130]
            lv1626 = R.call_tir(cls.matmul18, (lv1624, lv858_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv859: R.Tensor((1280, 1280), dtype="float32") = model_params[1131]
            lv1628 = R.call_tir(cls.matmul18, (lv1624, lv859), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv860_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1132]
            lv1630 = R.call_tir(cls.matmul18, (lv1624, lv860_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv757_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv1626,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv758_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv1628,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv759_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv1630,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv760_1 = R.call_tir(cls.fused_matmul19_multiply11, (lv757_1, lv758_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv1642 = R.call_tir(cls.softmax3, (lv760_1,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv1643 = R.call_tir(cls.matmul20, (lv1642, lv759_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv761_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv1643,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv861: R.Tensor((1280, 1280), dtype="float32") = model_params[1133]
            lv862_1: R.Tensor((1280,), dtype="float32") = model_params[263]
            lv762_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv761_1, lv861, lv862_1, lv756_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv863: R.Tensor((1280,), dtype="float32") = model_params[270]
            lv864: R.Tensor((1280,), dtype="float32") = model_params[269]
            lv1651 = R.call_tir(cls.layer_norm2, (lv762_1, lv863, lv864), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv865: R.Tensor((1280, 1280), dtype="float32") = model_params[1134]
            lv1653 = R.call_tir(cls.matmul18, (lv1651, lv865), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv866: R.Tensor((2048, 1280), dtype="float32") = model_params[1135]
            lv1655 = R.call_tir(cls.matmul21, (inp_2, lv866), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv867: R.Tensor((2048, 1280), dtype="float32") = model_params[1136]
            lv1657 = R.call_tir(cls.matmul21, (inp_2, lv867), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv763_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv1653,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv764_1 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv1655,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv765_1 = R.call_tir(cls.fused_reshape5_transpose1, (lv1657,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv766_1 = R.call_tir(cls.fused_matmul22_multiply12, (lv763_1, lv764_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv1669 = R.call_tir(cls.softmax4, (lv766_1,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv1670 = R.call_tir(cls.matmul23, (lv1669, lv765_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv767_2 = R.call_tir(cls.fused_transpose24_reshape31, (lv1670,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv868: R.Tensor((1280, 1280), dtype="float32") = model_params[1137]
            lv869: R.Tensor((1280,), dtype="float32") = model_params[264]
            lv768_2 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv767_2, lv868, lv869, lv762_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv870: R.Tensor((1280,), dtype="float32") = model_params[272]
            lv871: R.Tensor((1280,), dtype="float32") = model_params[271]
            lv1678 = R.call_tir(cls.layer_norm2, (lv768_2, lv870, lv871), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv872: R.Tensor((1280, 10240), dtype="float32") = model_params[1138]
            lv873: R.Tensor((10240,), dtype="float32") = model_params[265]
            lv769_1 = R.call_tir(cls.fused_matmul24_add24, (lv1678, lv872, lv873), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv770_1 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv769_1,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv874_1: R.Tensor((5120, 1280), dtype="float32") = model_params[1139]
            lv875_1: R.Tensor((1280,), dtype="float32") = model_params[266]
            lv771_1 = R.call_tir(cls.fused_matmul25_add22_add23, (lv770_1, lv874_1, lv875_1, lv768_2), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv876: R.Tensor((1280,), dtype="float32") = model_params[278]
            lv877: R.Tensor((1280,), dtype="float32") = model_params[277]
            lv1691 = R.call_tir(cls.layer_norm2, (lv771_1, lv876, lv877), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv878: R.Tensor((1280, 1280), dtype="float32") = model_params[1140]
            lv1693 = R.call_tir(cls.matmul18, (lv1691, lv878), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv879: R.Tensor((1280, 1280), dtype="float32") = model_params[1141]
            lv1695 = R.call_tir(cls.matmul18, (lv1691, lv879), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv880: R.Tensor((1280, 1280), dtype="float32") = model_params[1142]
            lv1697 = R.call_tir(cls.matmul18, (lv1691, lv880), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv772_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv1693,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv773_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv1695,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv774_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv1697,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv775_1 = R.call_tir(cls.fused_matmul19_multiply11, (lv772_1, lv773_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv1709 = R.call_tir(cls.softmax3, (lv775_1,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv1710 = R.call_tir(cls.matmul20, (lv1709, lv774_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv776_2 = R.call_tir(cls.fused_transpose24_reshape31, (lv1710,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv881: R.Tensor((1280, 1280), dtype="float32") = model_params[1143]
            lv882: R.Tensor((1280,), dtype="float32") = model_params[273]
            lv777_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv776_2, lv881, lv882, lv771_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv883_1: R.Tensor((1280,), dtype="float32") = model_params[280]
            lv884: R.Tensor((1280,), dtype="float32") = model_params[279]
            lv1718 = R.call_tir(cls.layer_norm2, (lv777_1, lv883_1, lv884), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv885_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1144]
            lv1720 = R.call_tir(cls.matmul18, (lv1718, lv885_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv886: R.Tensor((2048, 1280), dtype="float32") = model_params[1145]
            lv1722 = R.call_tir(cls.matmul21, (inp_2, lv886), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv887_1: R.Tensor((2048, 1280), dtype="float32") = model_params[1146]
            lv1724 = R.call_tir(cls.matmul21, (inp_2, lv887_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv778_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv1720,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv779_1 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv1722,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv780_1 = R.call_tir(cls.fused_reshape5_transpose1, (lv1724,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv781_1 = R.call_tir(cls.fused_matmul22_multiply12, (lv778_1, lv779_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv1736 = R.call_tir(cls.softmax4, (lv781_1,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv1737 = R.call_tir(cls.matmul23, (lv1736, lv780_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv782_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv1737,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv888: R.Tensor((1280, 1280), dtype="float32") = model_params[1147]
            lv889_1: R.Tensor((1280,), dtype="float32") = model_params[274]
            lv783_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv782_1, lv888, lv889_1, lv777_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv890: R.Tensor((1280,), dtype="float32") = model_params[282]
            lv891: R.Tensor((1280,), dtype="float32") = model_params[281]
            lv1745 = R.call_tir(cls.layer_norm2, (lv783_1, lv890, lv891), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv892: R.Tensor((1280, 10240), dtype="float32") = model_params[1148]
            lv893: R.Tensor((10240,), dtype="float32") = model_params[275]
            lv784_1 = R.call_tir(cls.fused_matmul24_add24, (lv1745, lv892, lv893), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv785_1 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv784_1,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv894: R.Tensor((5120, 1280), dtype="float32") = model_params[1149]
            lv895: R.Tensor((1280,), dtype="float32") = model_params[276]
            lv786_1 = R.call_tir(cls.fused_matmul25_add22_add23, (lv785_1, lv894, lv895, lv783_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv896: R.Tensor((1280,), dtype="float32") = model_params[288]
            lv897: R.Tensor((1280,), dtype="float32") = model_params[287]
            lv1758 = R.call_tir(cls.layer_norm2, (lv786_1, lv896, lv897), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv898: R.Tensor((1280, 1280), dtype="float32") = model_params[1150]
            lv1760 = R.call_tir(cls.matmul18, (lv1758, lv898), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv899: R.Tensor((1280, 1280), dtype="float32") = model_params[1151]
            lv1762 = R.call_tir(cls.matmul18, (lv1758, lv899), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv900: R.Tensor((1280, 1280), dtype="float32") = model_params[1152]
            lv1764 = R.call_tir(cls.matmul18, (lv1758, lv900), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv787_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv1760,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv788_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv1762,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv789_2 = R.call_tir(cls.fused_reshape30_transpose22, (lv1764,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv790_1 = R.call_tir(cls.fused_matmul19_multiply11, (lv787_1, lv788_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv1776 = R.call_tir(cls.softmax3, (lv790_1,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv1777 = R.call_tir(cls.matmul20, (lv1776, lv789_2), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv791_2 = R.call_tir(cls.fused_transpose24_reshape31, (lv1777,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv901_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1153]
            lv902_1: R.Tensor((1280,), dtype="float32") = model_params[283]
            lv792_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv791_2, lv901_1, lv902_1, lv786_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv903: R.Tensor((1280,), dtype="float32") = model_params[290]
            lv904: R.Tensor((1280,), dtype="float32") = model_params[289]
            lv1785 = R.call_tir(cls.layer_norm2, (lv792_1, lv903, lv904), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv905: R.Tensor((1280, 1280), dtype="float32") = model_params[1154]
            lv1787 = R.call_tir(cls.matmul18, (lv1785, lv905), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv906: R.Tensor((2048, 1280), dtype="float32") = model_params[1155]
            lv1789 = R.call_tir(cls.matmul21, (inp_2, lv906), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv907: R.Tensor((2048, 1280), dtype="float32") = model_params[1156]
            lv1791 = R.call_tir(cls.matmul21, (inp_2, lv907), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv793_2 = R.call_tir(cls.fused_reshape30_transpose22, (lv1787,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv794_1 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv1789,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv795_2 = R.call_tir(cls.fused_reshape5_transpose1, (lv1791,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv796_1 = R.call_tir(cls.fused_matmul22_multiply12, (lv793_2, lv794_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv1803 = R.call_tir(cls.softmax4, (lv796_1,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv1804 = R.call_tir(cls.matmul23, (lv1803, lv795_2), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv797_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv1804,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv908: R.Tensor((1280, 1280), dtype="float32") = model_params[1157]
            lv909: R.Tensor((1280,), dtype="float32") = model_params[284]
            lv798_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv797_1, lv908, lv909, lv792_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv910_1: R.Tensor((1280,), dtype="float32") = model_params[292]
            lv911: R.Tensor((1280,), dtype="float32") = model_params[291]
            lv1812 = R.call_tir(cls.layer_norm2, (lv798_1, lv910_1, lv911), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv912: R.Tensor((1280, 10240), dtype="float32") = model_params[1158]
            lv913: R.Tensor((10240,), dtype="float32") = model_params[285]
            lv799_1 = R.call_tir(cls.fused_matmul24_add24, (lv1812, lv912, lv913), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv800_1 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv799_1,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv914: R.Tensor((5120, 1280), dtype="float32") = model_params[1159]
            lv915: R.Tensor((1280,), dtype="float32") = model_params[286]
            lv801_1 = R.call_tir(cls.fused_matmul25_add22_add23, (lv800_1, lv914, lv915, lv798_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv916: R.Tensor((1280, 1280), dtype="float32") = model_params[1160]
            lv917: R.Tensor((1280,), dtype="float32") = model_params[192]
            lv802_1 = R.call_tir(cls.fused_matmul18_add22, (lv801_1, lv916, lv917), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv803_1 = R.call_tir(cls.fused_reshape32_transpose28_add21, (lv802_1, lv649_1), out_sinfo=R.Tensor((1, 1280, 16, 16), dtype="float32"))
            lv918: R.Tensor((1280,), dtype="float32") = model_params[415]
            lv919: R.Tensor((1280,), dtype="float32") = model_params[414]
            lv804_1 = R.call_tir(cls.fused_group_norm5_silu5, (lv803_1, lv918, lv919), out_sinfo=R.Tensor((1, 1280, 16, 16), dtype="float32"))
            lv1836 = R.call_tir(cls.silu, (lv392,), out_sinfo=R.Tensor((1, 1280), dtype="float32"))
            lv920: R.Tensor((1280, 1280), dtype="float32") = model_params[1162]
            lv921: R.Tensor((1280,), dtype="float32") = model_params[418]
            lv805_1 = R.call_tir(cls.fused_matmul5_add7_strided_slice, (lv1836, lv920, lv921), out_sinfo=R.Tensor((1, 1280), dtype="float32"))
            lv1841 = R.call_tir(cls.reshape28, (lv805_1,), out_sinfo=R.Tensor((1, 1280, 1, 1), dtype="float32"))
            lv922: R.Tensor((1280, 1280, 3, 3), dtype="float32") = model_params[412]
            lv923_1: R.Tensor((1, 1280, 1, 1), dtype="float32") = model_params[1161]
            lv806_1 = R.call_tir(cls.fused_conv2d8_add20_add20, (lv804_1, lv922, lv923_1, lv1841), out_sinfo=R.Tensor((1, 1280, 16, 16), dtype="float32"))
            lv924: R.Tensor((1280,), dtype="float32") = model_params[417]
            lv925_1: R.Tensor((1280,), dtype="float32") = model_params[416]
            lv807_2 = R.call_tir(cls.fused_group_norm5_silu5, (lv806_1, lv924, lv925_1), out_sinfo=R.Tensor((1, 1280, 16, 16), dtype="float32"))
            lv926: R.Tensor((1280, 1280, 3, 3), dtype="float32") = model_params[413]
            lv927_1: R.Tensor((1, 1280, 1, 1), dtype="float32") = model_params[1163]
            lv808_2 = R.call_tir(cls.fused_conv2d8_add20_add21_divide6, (lv807_2, lv926, lv927_1, lv803_1), out_sinfo=R.Tensor((1, 1280, 16, 16), dtype="float32"))
            lv928: R.Tensor((1280,), dtype="float32") = model_params[309]
            lv929_1: R.Tensor((1280,), dtype="float32") = model_params[308]
            lv1850 = R.call_tir(cls.group_norm6, (lv808_2, lv928, lv929_1), out_sinfo=R.Tensor((1, 1280, 16, 16), dtype="float32"))
            lv809_1 = R.call_tir(cls.fused_transpose21_reshape29, (lv1850,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv930: R.Tensor((1280, 1280), dtype="float32") = model_params[1164]
            lv931: R.Tensor((1280,), dtype="float32") = model_params[310]
            lv810_1 = R.call_tir(cls.fused_matmul18_add22, (lv809_1, lv930, lv931), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv932: R.Tensor((1280,), dtype="float32") = model_params[317]
            lv933: R.Tensor((1280,), dtype="float32") = model_params[316]
            lv1856 = R.call_tir(cls.layer_norm2, (lv810_1, lv932, lv933), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv934: R.Tensor((1280, 1280), dtype="float32") = model_params[1165]
            lv1858 = R.call_tir(cls.matmul18, (lv1856, lv934), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv935: R.Tensor((1280, 1280), dtype="float32") = model_params[1166]
            lv1860 = R.call_tir(cls.matmul18, (lv1856, lv935), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv936: R.Tensor((1280, 1280), dtype="float32") = model_params[1167]
            lv1862 = R.call_tir(cls.matmul18, (lv1856, lv936), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv811_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv1858,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv812_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv1860,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv813_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv1862,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv814_1 = R.call_tir(cls.fused_matmul19_multiply11, (lv811_1, lv812_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv1874 = R.call_tir(cls.softmax3, (lv814_1,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv1875 = R.call_tir(cls.matmul20, (lv1874, lv813_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv815_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv1875,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv937: R.Tensor((1280, 1280), dtype="float32") = model_params[1168]
            lv938: R.Tensor((1280,), dtype="float32") = model_params[312]
            lv816_2 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv815_1, lv937, lv938, lv810_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv939: R.Tensor((1280,), dtype="float32") = model_params[319]
            lv940: R.Tensor((1280,), dtype="float32") = model_params[318]
            lv1883 = R.call_tir(cls.layer_norm2, (lv816_2, lv939, lv940), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv941_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1169]
            lv1885 = R.call_tir(cls.matmul18, (lv1883, lv941_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv942_1: R.Tensor((2048, 1280), dtype="float32") = model_params[1170]
            lv1887 = R.call_tir(cls.matmul21, (inp_2, lv942_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv943: R.Tensor((2048, 1280), dtype="float32") = model_params[1171]
            lv1889 = R.call_tir(cls.matmul21, (inp_2, lv943), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv817_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv1885,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv818_2 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv1887,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv819_1 = R.call_tir(cls.fused_reshape5_transpose1, (lv1889,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv820_2 = R.call_tir(cls.fused_matmul22_multiply12, (lv817_1, lv818_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv1901 = R.call_tir(cls.softmax4, (lv820_2,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv1902 = R.call_tir(cls.matmul23, (lv1901, lv819_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv821_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv1902,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv944: R.Tensor((1280, 1280), dtype="float32") = model_params[1172]
            lv945: R.Tensor((1280,), dtype="float32") = model_params[313]
            lv822_2 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv821_1, lv944, lv945, lv816_2), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv946: R.Tensor((1280,), dtype="float32") = model_params[321]
            lv947: R.Tensor((1280,), dtype="float32") = model_params[320]
            lv1910 = R.call_tir(cls.layer_norm2, (lv822_2, lv946, lv947), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv948: R.Tensor((1280, 10240), dtype="float32") = model_params[1173]
            lv949: R.Tensor((10240,), dtype="float32") = model_params[314]
            lv823_1 = R.call_tir(cls.fused_matmul24_add24, (lv1910, lv948, lv949), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv824_1 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv823_1,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv950_1: R.Tensor((5120, 1280), dtype="float32") = model_params[1174]
            lv951: R.Tensor((1280,), dtype="float32") = model_params[315]
            lv825_1 = R.call_tir(cls.fused_matmul25_add22_add23, (lv824_1, lv950_1, lv951, lv822_2), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv952_1: R.Tensor((1280,), dtype="float32") = model_params[327]
            lv953: R.Tensor((1280,), dtype="float32") = model_params[326]
            lv1923 = R.call_tir(cls.layer_norm2, (lv825_1, lv952_1, lv953), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv954_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1175]
            lv1925 = R.call_tir(cls.matmul18, (lv1923, lv954_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv955: R.Tensor((1280, 1280), dtype="float32") = model_params[1176]
            lv1927 = R.call_tir(cls.matmul18, (lv1923, lv955), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv956_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1177]
            lv1929 = R.call_tir(cls.matmul18, (lv1923, lv956_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv826_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv1925,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv827_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv1927,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv828_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv1929,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv829_1 = R.call_tir(cls.fused_matmul19_multiply11, (lv826_1, lv827_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv1941 = R.call_tir(cls.softmax3, (lv829_1,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv1942 = R.call_tir(cls.matmul20, (lv1941, lv828_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv830_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv1942,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv957: R.Tensor((1280, 1280), dtype="float32") = model_params[1178]
            lv958: R.Tensor((1280,), dtype="float32") = model_params[322]
            lv831_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv830_1, lv957, lv958, lv825_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv959: R.Tensor((1280,), dtype="float32") = model_params[329]
            lv960: R.Tensor((1280,), dtype="float32") = model_params[328]
            lv1950 = R.call_tir(cls.layer_norm2, (lv831_1, lv959, lv960), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv961: R.Tensor((1280, 1280), dtype="float32") = model_params[1179]
            lv1952 = R.call_tir(cls.matmul18, (lv1950, lv961), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv962: R.Tensor((2048, 1280), dtype="float32") = model_params[1180]
            lv1954 = R.call_tir(cls.matmul21, (inp_2, lv962), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv963: R.Tensor((2048, 1280), dtype="float32") = model_params[1181]
            lv1956 = R.call_tir(cls.matmul21, (inp_2, lv963), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv832_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv1952,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv833_1 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv1954,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv834_2 = R.call_tir(cls.fused_reshape5_transpose1, (lv1956,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv835_2 = R.call_tir(cls.fused_matmul22_multiply12, (lv832_1, lv833_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv1968 = R.call_tir(cls.softmax4, (lv835_2,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv1969 = R.call_tir(cls.matmul23, (lv1968, lv834_2), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv836_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv1969,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv964: R.Tensor((1280, 1280), dtype="float32") = model_params[1182]
            lv965: R.Tensor((1280,), dtype="float32") = model_params[323]
            lv837_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv836_1, lv964, lv965, lv831_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv966: R.Tensor((1280,), dtype="float32") = model_params[331]
            lv967: R.Tensor((1280,), dtype="float32") = model_params[330]
            lv1977 = R.call_tir(cls.layer_norm2, (lv837_1, lv966, lv967), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv968_1: R.Tensor((1280, 10240), dtype="float32") = model_params[1183]
            lv969_1: R.Tensor((10240,), dtype="float32") = model_params[324]
            lv838_1 = R.call_tir(cls.fused_matmul24_add24, (lv1977, lv968_1, lv969_1), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv839_1 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv838_1,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv970: R.Tensor((5120, 1280), dtype="float32") = model_params[1184]
            lv971: R.Tensor((1280,), dtype="float32") = model_params[325]
            lv840_1 = R.call_tir(cls.fused_matmul25_add22_add23, (lv839_1, lv970, lv971, lv837_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv972: R.Tensor((1280,), dtype="float32") = model_params[337]
            lv973: R.Tensor((1280,), dtype="float32") = model_params[336]
            lv1990 = R.call_tir(cls.layer_norm2, (lv840_1, lv972, lv973), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv974: R.Tensor((1280, 1280), dtype="float32") = model_params[1185]
            lv1992 = R.call_tir(cls.matmul18, (lv1990, lv974), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv975: R.Tensor((1280, 1280), dtype="float32") = model_params[1186]
            lv1994 = R.call_tir(cls.matmul18, (lv1990, lv975), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv976: R.Tensor((1280, 1280), dtype="float32") = model_params[1187]
            lv1996 = R.call_tir(cls.matmul18, (lv1990, lv976), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv841_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv1992,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv842_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv1994,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv843_2 = R.call_tir(cls.fused_reshape30_transpose22, (lv1996,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv844_1 = R.call_tir(cls.fused_matmul19_multiply11, (lv841_1, lv842_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv2008 = R.call_tir(cls.softmax3, (lv844_1,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv2009 = R.call_tir(cls.matmul20, (lv2008, lv843_2), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv845_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv2009,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv977_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1188]
            lv978: R.Tensor((1280,), dtype="float32") = model_params[332]
            lv846_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv845_1, lv977_1, lv978, lv840_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv979: R.Tensor((1280,), dtype="float32") = model_params[339]
            lv980: R.Tensor((1280,), dtype="float32") = model_params[338]
            lv2017 = R.call_tir(cls.layer_norm2, (lv846_1, lv979, lv980), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv981: R.Tensor((1280, 1280), dtype="float32") = model_params[1189]
            lv2019 = R.call_tir(cls.matmul18, (lv2017, lv981), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv982: R.Tensor((2048, 1280), dtype="float32") = model_params[1190]
            lv2021 = R.call_tir(cls.matmul21, (inp_2, lv982), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv983: R.Tensor((2048, 1280), dtype="float32") = model_params[1191]
            lv2023 = R.call_tir(cls.matmul21, (inp_2, lv983), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv847_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv2019,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv848_1 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv2021,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv849_1 = R.call_tir(cls.fused_reshape5_transpose1, (lv2023,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv850_1 = R.call_tir(cls.fused_matmul22_multiply12, (lv847_1, lv848_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv2035 = R.call_tir(cls.softmax4, (lv850_1,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv2036 = R.call_tir(cls.matmul23, (lv2035, lv849_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv851_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv2036,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv984: R.Tensor((1280, 1280), dtype="float32") = model_params[1192]
            lv985: R.Tensor((1280,), dtype="float32") = model_params[333]
            lv852_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv851_1, lv984, lv985, lv846_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv986: R.Tensor((1280,), dtype="float32") = model_params[341]
            lv987: R.Tensor((1280,), dtype="float32") = model_params[340]
            lv2044 = R.call_tir(cls.layer_norm2, (lv852_1, lv986, lv987), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv988: R.Tensor((1280, 10240), dtype="float32") = model_params[1193]
            lv989: R.Tensor((10240,), dtype="float32") = model_params[334]
            lv853_1 = R.call_tir(cls.fused_matmul24_add24, (lv2044, lv988, lv989), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv854_1 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv853_1,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv990_1: R.Tensor((5120, 1280), dtype="float32") = model_params[1194]
            lv991: R.Tensor((1280,), dtype="float32") = model_params[335]
            lv855_1 = R.call_tir(cls.fused_matmul25_add22_add23, (lv854_1, lv990_1, lv991, lv852_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv992_1: R.Tensor((1280,), dtype="float32") = model_params[347]
            lv993: R.Tensor((1280,), dtype="float32") = model_params[346]
            lv2057 = R.call_tir(cls.layer_norm2, (lv855_1, lv992_1, lv993), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv994_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1195]
            lv2059 = R.call_tir(cls.matmul18, (lv2057, lv994_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv995: R.Tensor((1280, 1280), dtype="float32") = model_params[1196]
            lv2061 = R.call_tir(cls.matmul18, (lv2057, lv995), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv996_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1197]
            lv2063 = R.call_tir(cls.matmul18, (lv2057, lv996_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv856_2 = R.call_tir(cls.fused_reshape30_transpose22, (lv2059,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv857_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv2061,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv858_2 = R.call_tir(cls.fused_reshape30_transpose22, (lv2063,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv859_1 = R.call_tir(cls.fused_matmul19_multiply11, (lv856_2, lv857_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv2075 = R.call_tir(cls.softmax3, (lv859_1,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv2076 = R.call_tir(cls.matmul20, (lv2075, lv858_2), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv860_2 = R.call_tir(cls.fused_transpose24_reshape31, (lv2076,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv997: R.Tensor((1280, 1280), dtype="float32") = model_params[1198]
            lv998: R.Tensor((1280,), dtype="float32") = model_params[342]
            lv861_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv860_2, lv997, lv998, lv855_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv999: R.Tensor((1280,), dtype="float32") = model_params[349]
            lv1000: R.Tensor((1280,), dtype="float32") = model_params[348]
            lv2084 = R.call_tir(cls.layer_norm2, (lv861_1, lv999, lv1000), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1001: R.Tensor((1280, 1280), dtype="float32") = model_params[1199]
            lv2086 = R.call_tir(cls.matmul18, (lv2084, lv1001), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1002: R.Tensor((2048, 1280), dtype="float32") = model_params[1200]
            lv2088 = R.call_tir(cls.matmul21, (inp_2, lv1002), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1003: R.Tensor((2048, 1280), dtype="float32") = model_params[1201]
            lv2090 = R.call_tir(cls.matmul21, (inp_2, lv1003), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv862_2 = R.call_tir(cls.fused_reshape30_transpose22, (lv2086,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv863_1 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv2088,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv864_1 = R.call_tir(cls.fused_reshape5_transpose1, (lv2090,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv865_1 = R.call_tir(cls.fused_matmul22_multiply12, (lv862_2, lv863_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv2102 = R.call_tir(cls.softmax4, (lv865_1,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv2103 = R.call_tir(cls.matmul23, (lv2102, lv864_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv866_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv2103,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1004: R.Tensor((1280, 1280), dtype="float32") = model_params[1202]
            lv1005: R.Tensor((1280,), dtype="float32") = model_params[343]
            lv867_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv866_1, lv1004, lv1005, lv861_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1006: R.Tensor((1280,), dtype="float32") = model_params[351]
            lv1007: R.Tensor((1280,), dtype="float32") = model_params[350]
            lv2111 = R.call_tir(cls.layer_norm2, (lv867_1, lv1006, lv1007), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1008_1: R.Tensor((1280, 10240), dtype="float32") = model_params[1203]
            lv1009_1: R.Tensor((10240,), dtype="float32") = model_params[344]
            lv868_1 = R.call_tir(cls.fused_matmul24_add24, (lv2111, lv1008_1, lv1009_1), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv869_1 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv868_1,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv1010: R.Tensor((5120, 1280), dtype="float32") = model_params[1204]
            lv1011: R.Tensor((1280,), dtype="float32") = model_params[345]
            lv870_1 = R.call_tir(cls.fused_matmul25_add22_add23, (lv869_1, lv1010, lv1011, lv867_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1012: R.Tensor((1280,), dtype="float32") = model_params[357]
            lv1013: R.Tensor((1280,), dtype="float32") = model_params[356]
            lv2124 = R.call_tir(cls.layer_norm2, (lv870_1, lv1012, lv1013), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1014: R.Tensor((1280, 1280), dtype="float32") = model_params[1205]
            lv2126 = R.call_tir(cls.matmul18, (lv2124, lv1014), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1015: R.Tensor((1280, 1280), dtype="float32") = model_params[1206]
            lv2128 = R.call_tir(cls.matmul18, (lv2124, lv1015), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1016: R.Tensor((1280, 1280), dtype="float32") = model_params[1207]
            lv2130 = R.call_tir(cls.matmul18, (lv2124, lv1016), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv871_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv2126,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv872_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv2128,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv873_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv2130,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv874_2 = R.call_tir(cls.fused_matmul19_multiply11, (lv871_1, lv872_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv2142 = R.call_tir(cls.softmax3, (lv874_2,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv2143 = R.call_tir(cls.matmul20, (lv2142, lv873_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv875_2 = R.call_tir(cls.fused_transpose24_reshape31, (lv2143,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1017_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1208]
            lv1018: R.Tensor((1280,), dtype="float32") = model_params[352]
            lv876_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv875_2, lv1017_1, lv1018, lv870_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1019_1: R.Tensor((1280,), dtype="float32") = model_params[359]
            lv1020: R.Tensor((1280,), dtype="float32") = model_params[358]
            lv2151 = R.call_tir(cls.layer_norm2, (lv876_1, lv1019_1, lv1020), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1021_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1209]
            lv2153 = R.call_tir(cls.matmul18, (lv2151, lv1021_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1022: R.Tensor((2048, 1280), dtype="float32") = model_params[1210]
            lv2155 = R.call_tir(cls.matmul21, (inp_2, lv1022), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1023_1: R.Tensor((2048, 1280), dtype="float32") = model_params[1211]
            lv2157 = R.call_tir(cls.matmul21, (inp_2, lv1023_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv877_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv2153,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv878_1 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv2155,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv879_1 = R.call_tir(cls.fused_reshape5_transpose1, (lv2157,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv880_1 = R.call_tir(cls.fused_matmul22_multiply12, (lv877_1, lv878_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv2169 = R.call_tir(cls.softmax4, (lv880_1,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv2170 = R.call_tir(cls.matmul23, (lv2169, lv879_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv881_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv2170,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1024: R.Tensor((1280, 1280), dtype="float32") = model_params[1212]
            lv1025: R.Tensor((1280,), dtype="float32") = model_params[353]
            lv882_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv881_1, lv1024, lv1025, lv876_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1026: R.Tensor((1280,), dtype="float32") = model_params[361]
            lv1027: R.Tensor((1280,), dtype="float32") = model_params[360]
            lv2178 = R.call_tir(cls.layer_norm2, (lv882_1, lv1026, lv1027), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1028: R.Tensor((1280, 10240), dtype="float32") = model_params[1213]
            lv1029: R.Tensor((10240,), dtype="float32") = model_params[354]
            lv883_2 = R.call_tir(cls.fused_matmul24_add24, (lv2178, lv1028, lv1029), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv884_1 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv883_2,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv1030: R.Tensor((5120, 1280), dtype="float32") = model_params[1214]
            lv1031: R.Tensor((1280,), dtype="float32") = model_params[355]
            lv885_2 = R.call_tir(cls.fused_matmul25_add22_add23, (lv884_1, lv1030, lv1031, lv882_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1032: R.Tensor((1280,), dtype="float32") = model_params[367]
            lv1033: R.Tensor((1280,), dtype="float32") = model_params[366]
            lv2191 = R.call_tir(cls.layer_norm2, (lv885_2, lv1032, lv1033), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1034: R.Tensor((1280, 1280), dtype="float32") = model_params[1215]
            lv2193 = R.call_tir(cls.matmul18, (lv2191, lv1034), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1035_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1216]
            lv2195 = R.call_tir(cls.matmul18, (lv2191, lv1035_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1036_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1217]
            lv2197 = R.call_tir(cls.matmul18, (lv2191, lv1036_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv886_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv2193,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv887_2 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv2195,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv888_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv2197,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv889_2 = R.call_tir(cls.fused_matmul19_multiply11, (lv886_1, lv887_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv2209 = R.call_tir(cls.softmax3, (lv889_2,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv2210 = R.call_tir(cls.matmul20, (lv2209, lv888_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv890_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv2210,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1037: R.Tensor((1280, 1280), dtype="float32") = model_params[1218]
            lv1038: R.Tensor((1280,), dtype="float32") = model_params[362]
            lv891_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv890_1, lv1037, lv1038, lv885_2), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1039: R.Tensor((1280,), dtype="float32") = model_params[369]
            lv1040: R.Tensor((1280,), dtype="float32") = model_params[368]
            lv2218 = R.call_tir(cls.layer_norm2, (lv891_1, lv1039, lv1040), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1041: R.Tensor((1280, 1280), dtype="float32") = model_params[1219]
            lv2220 = R.call_tir(cls.matmul18, (lv2218, lv1041), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1042: R.Tensor((2048, 1280), dtype="float32") = model_params[1220]
            lv2222 = R.call_tir(cls.matmul21, (inp_2, lv1042), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1043: R.Tensor((2048, 1280), dtype="float32") = model_params[1221]
            lv2224 = R.call_tir(cls.matmul21, (inp_2, lv1043), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv892_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv2220,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv893_1 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv2222,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv894_1 = R.call_tir(cls.fused_reshape5_transpose1, (lv2224,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv895_1 = R.call_tir(cls.fused_matmul22_multiply12, (lv892_1, lv893_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv2236 = R.call_tir(cls.softmax4, (lv895_1,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv2237 = R.call_tir(cls.matmul23, (lv2236, lv894_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv896_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv2237,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1044_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1222]
            lv1045: R.Tensor((1280,), dtype="float32") = model_params[363]
            lv897_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv896_1, lv1044_1, lv1045, lv891_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1046: R.Tensor((1280,), dtype="float32") = model_params[371]
            lv1047: R.Tensor((1280,), dtype="float32") = model_params[370]
            lv2245 = R.call_tir(cls.layer_norm2, (lv897_1, lv1046, lv1047), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1048: R.Tensor((1280, 10240), dtype="float32") = model_params[1223]
            lv1049: R.Tensor((10240,), dtype="float32") = model_params[364]
            lv898_1 = R.call_tir(cls.fused_matmul24_add24, (lv2245, lv1048, lv1049), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv899_1 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv898_1,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv1050: R.Tensor((5120, 1280), dtype="float32") = model_params[1224]
            lv1051: R.Tensor((1280,), dtype="float32") = model_params[365]
            lv900_1 = R.call_tir(cls.fused_matmul25_add22_add23, (lv899_1, lv1050, lv1051, lv897_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1052: R.Tensor((1280,), dtype="float32") = model_params[377]
            lv1053: R.Tensor((1280,), dtype="float32") = model_params[376]
            lv2258 = R.call_tir(cls.layer_norm2, (lv900_1, lv1052, lv1053), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1054: R.Tensor((1280, 1280), dtype="float32") = model_params[1225]
            lv2260 = R.call_tir(cls.matmul18, (lv2258, lv1054), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1055: R.Tensor((1280, 1280), dtype="float32") = model_params[1226]
            lv2262 = R.call_tir(cls.matmul18, (lv2258, lv1055), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1056: R.Tensor((1280, 1280), dtype="float32") = model_params[1227]
            lv2264 = R.call_tir(cls.matmul18, (lv2258, lv1056), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv901_2 = R.call_tir(cls.fused_reshape30_transpose22, (lv2260,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv902_2 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv2262,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv903_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv2264,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv904_1 = R.call_tir(cls.fused_matmul19_multiply11, (lv901_2, lv902_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv2276 = R.call_tir(cls.softmax3, (lv904_1,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv2277 = R.call_tir(cls.matmul20, (lv2276, lv903_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv905_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv2277,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1057_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1228]
            lv1058: R.Tensor((1280,), dtype="float32") = model_params[372]
            lv906_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv905_1, lv1057_1, lv1058, lv900_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1059_1: R.Tensor((1280,), dtype="float32") = model_params[379]
            lv1060: R.Tensor((1280,), dtype="float32") = model_params[378]
            lv2285 = R.call_tir(cls.layer_norm2, (lv906_1, lv1059_1, lv1060), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1061_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1229]
            lv2287 = R.call_tir(cls.matmul18, (lv2285, lv1061_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1062: R.Tensor((2048, 1280), dtype="float32") = model_params[1230]
            lv2289 = R.call_tir(cls.matmul21, (inp_2, lv1062), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1063_1: R.Tensor((2048, 1280), dtype="float32") = model_params[1231]
            lv2291 = R.call_tir(cls.matmul21, (inp_2, lv1063_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv907_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv2287,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv908_1 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv2289,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv909_1 = R.call_tir(cls.fused_reshape5_transpose1, (lv2291,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv910_2 = R.call_tir(cls.fused_matmul22_multiply12, (lv907_1, lv908_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv2303 = R.call_tir(cls.softmax4, (lv910_2,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv2304 = R.call_tir(cls.matmul23, (lv2303, lv909_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv911_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv2304,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1064: R.Tensor((1280, 1280), dtype="float32") = model_params[1232]
            lv1065: R.Tensor((1280,), dtype="float32") = model_params[373]
            lv912_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv911_1, lv1064, lv1065, lv906_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1066: R.Tensor((1280,), dtype="float32") = model_params[381]
            lv1067: R.Tensor((1280,), dtype="float32") = model_params[380]
            lv2312 = R.call_tir(cls.layer_norm2, (lv912_1, lv1066, lv1067), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1068: R.Tensor((1280, 10240), dtype="float32") = model_params[1233]
            lv1069: R.Tensor((10240,), dtype="float32") = model_params[374]
            lv913_1 = R.call_tir(cls.fused_matmul24_add24, (lv2312, lv1068, lv1069), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv914_1 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv913_1,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv1070: R.Tensor((5120, 1280), dtype="float32") = model_params[1234]
            lv1071: R.Tensor((1280,), dtype="float32") = model_params[375]
            lv915_1 = R.call_tir(cls.fused_matmul25_add22_add23, (lv914_1, lv1070, lv1071, lv912_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1072: R.Tensor((1280,), dtype="float32") = model_params[387]
            lv1073: R.Tensor((1280,), dtype="float32") = model_params[386]
            lv2325 = R.call_tir(cls.layer_norm2, (lv915_1, lv1072, lv1073), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1074: R.Tensor((1280, 1280), dtype="float32") = model_params[1235]
            lv2327 = R.call_tir(cls.matmul18, (lv2325, lv1074), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1075_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1236]
            lv2329 = R.call_tir(cls.matmul18, (lv2325, lv1075_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1076_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1237]
            lv2331 = R.call_tir(cls.matmul18, (lv2325, lv1076_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv916_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv2327,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv917_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv2329,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv918_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv2331,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv919_1 = R.call_tir(cls.fused_matmul19_multiply11, (lv916_1, lv917_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv2343 = R.call_tir(cls.softmax3, (lv919_1,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv2344 = R.call_tir(cls.matmul20, (lv2343, lv918_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv920_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv2344,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1077: R.Tensor((1280, 1280), dtype="float32") = model_params[1238]
            lv1078: R.Tensor((1280,), dtype="float32") = model_params[382]
            lv921_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv920_1, lv1077, lv1078, lv915_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1079: R.Tensor((1280,), dtype="float32") = model_params[389]
            lv1080: R.Tensor((1280,), dtype="float32") = model_params[388]
            lv2352 = R.call_tir(cls.layer_norm2, (lv921_1, lv1079, lv1080), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1081: R.Tensor((1280, 1280), dtype="float32") = model_params[1239]
            lv2354 = R.call_tir(cls.matmul18, (lv2352, lv1081), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1082: R.Tensor((2048, 1280), dtype="float32") = model_params[1240]
            lv2356 = R.call_tir(cls.matmul21, (inp_2, lv1082), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1083: R.Tensor((2048, 1280), dtype="float32") = model_params[1241]
            lv2358 = R.call_tir(cls.matmul21, (inp_2, lv1083), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv922_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv2354,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv923_2 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv2356,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv924_1 = R.call_tir(cls.fused_reshape5_transpose1, (lv2358,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv925_2 = R.call_tir(cls.fused_matmul22_multiply12, (lv922_1, lv923_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv2370 = R.call_tir(cls.softmax4, (lv925_2,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv2371 = R.call_tir(cls.matmul23, (lv2370, lv924_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv926_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv2371,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1084_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1242]
            lv1085: R.Tensor((1280,), dtype="float32") = model_params[383]
            lv927_2 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv926_1, lv1084_1, lv1085, lv921_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1086_1: R.Tensor((1280,), dtype="float32") = model_params[391]
            lv1087: R.Tensor((1280,), dtype="float32") = model_params[390]
            lv2379 = R.call_tir(cls.layer_norm2, (lv927_2, lv1086_1, lv1087), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1088_1: R.Tensor((1280, 10240), dtype="float32") = model_params[1243]
            lv1089: R.Tensor((10240,), dtype="float32") = model_params[384]
            lv928_1 = R.call_tir(cls.fused_matmul24_add24, (lv2379, lv1088_1, lv1089), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv929_2 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv928_1,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv1090_1: R.Tensor((5120, 1280), dtype="float32") = model_params[1244]
            lv1091: R.Tensor((1280,), dtype="float32") = model_params[385]
            lv930_1 = R.call_tir(cls.fused_matmul25_add22_add23, (lv929_2, lv1090_1, lv1091, lv927_2), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1092: R.Tensor((1280,), dtype="float32") = model_params[397]
            lv1093: R.Tensor((1280,), dtype="float32") = model_params[396]
            lv2392 = R.call_tir(cls.layer_norm2, (lv930_1, lv1092, lv1093), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1094: R.Tensor((1280, 1280), dtype="float32") = model_params[1245]
            lv2394 = R.call_tir(cls.matmul18, (lv2392, lv1094), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1095: R.Tensor((1280, 1280), dtype="float32") = model_params[1246]
            lv2396 = R.call_tir(cls.matmul18, (lv2392, lv1095), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1096: R.Tensor((1280, 1280), dtype="float32") = model_params[1247]
            lv2398 = R.call_tir(cls.matmul18, (lv2392, lv1096), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv931_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv2394,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv932_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv2396,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv933_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv2398,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv934_1 = R.call_tir(cls.fused_matmul19_multiply11, (lv931_1, lv932_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv2410 = R.call_tir(cls.softmax3, (lv934_1,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv2411 = R.call_tir(cls.matmul20, (lv2410, lv933_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv935_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv2411,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1097: R.Tensor((1280, 1280), dtype="float32") = model_params[1248]
            lv1098: R.Tensor((1280,), dtype="float32") = model_params[392]
            lv936_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv935_1, lv1097, lv1098, lv930_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1099: R.Tensor((1280,), dtype="float32") = model_params[399]
            lv1100: R.Tensor((1280,), dtype="float32") = model_params[398]
            lv2419 = R.call_tir(cls.layer_norm2, (lv936_1, lv1099, lv1100), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1101: R.Tensor((1280, 1280), dtype="float32") = model_params[1249]
            lv2421 = R.call_tir(cls.matmul18, (lv2419, lv1101), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1102_1: R.Tensor((2048, 1280), dtype="float32") = model_params[1250]
            lv2423 = R.call_tir(cls.matmul21, (inp_2, lv1102_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1103_1: R.Tensor((2048, 1280), dtype="float32") = model_params[1251]
            lv2425 = R.call_tir(cls.matmul21, (inp_2, lv1103_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv937_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv2421,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv938_1 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv2423,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv939_1 = R.call_tir(cls.fused_reshape5_transpose1, (lv2425,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv940_1 = R.call_tir(cls.fused_matmul22_multiply12, (lv937_1, lv938_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv2437 = R.call_tir(cls.softmax4, (lv940_1,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv2438 = R.call_tir(cls.matmul23, (lv2437, lv939_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv941_2 = R.call_tir(cls.fused_transpose24_reshape31, (lv2438,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1104: R.Tensor((1280, 1280), dtype="float32") = model_params[1252]
            lv1105: R.Tensor((1280,), dtype="float32") = model_params[393]
            lv942_2 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv941_2, lv1104, lv1105, lv936_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1106: R.Tensor((1280,), dtype="float32") = model_params[401]
            lv1107: R.Tensor((1280,), dtype="float32") = model_params[400]
            lv2446 = R.call_tir(cls.layer_norm2, (lv942_2, lv1106, lv1107), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1108: R.Tensor((1280, 10240), dtype="float32") = model_params[1253]
            lv1109: R.Tensor((10240,), dtype="float32") = model_params[394]
            lv943_1 = R.call_tir(cls.fused_matmul24_add24, (lv2446, lv1108, lv1109), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv944_1 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv943_1,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv1110: R.Tensor((5120, 1280), dtype="float32") = model_params[1254]
            lv1111_1: R.Tensor((1280,), dtype="float32") = model_params[395]
            lv945_1 = R.call_tir(cls.fused_matmul25_add22_add23, (lv944_1, lv1110, lv1111_1, lv942_2), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1112: R.Tensor((1280,), dtype="float32") = model_params[407]
            lv1113: R.Tensor((1280,), dtype="float32") = model_params[406]
            lv2459 = R.call_tir(cls.layer_norm2, (lv945_1, lv1112, lv1113), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1114: R.Tensor((1280, 1280), dtype="float32") = model_params[1255]
            lv2461 = R.call_tir(cls.matmul18, (lv2459, lv1114), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1115: R.Tensor((1280, 1280), dtype="float32") = model_params[1256]
            lv2463 = R.call_tir(cls.matmul18, (lv2459, lv1115), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1116: R.Tensor((1280, 1280), dtype="float32") = model_params[1257]
            lv2465 = R.call_tir(cls.matmul18, (lv2459, lv1116), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv946_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv2461,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv947_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv2463,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv948_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv2465,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv949_1 = R.call_tir(cls.fused_matmul19_multiply11, (lv946_1, lv947_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv2477 = R.call_tir(cls.softmax3, (lv949_1,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv2478 = R.call_tir(cls.matmul20, (lv2477, lv948_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv950_2 = R.call_tir(cls.fused_transpose24_reshape31, (lv2478,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1117: R.Tensor((1280, 1280), dtype="float32") = model_params[1258]
            lv1118: R.Tensor((1280,), dtype="float32") = model_params[402]
            lv951_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv950_2, lv1117, lv1118, lv945_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1119: R.Tensor((1280,), dtype="float32") = model_params[409]
            lv1120: R.Tensor((1280,), dtype="float32") = model_params[408]
            lv2486 = R.call_tir(cls.layer_norm2, (lv951_1, lv1119, lv1120), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1121: R.Tensor((1280, 1280), dtype="float32") = model_params[1259]
            lv2488 = R.call_tir(cls.matmul18, (lv2486, lv1121), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1122: R.Tensor((2048, 1280), dtype="float32") = model_params[1260]
            lv2490 = R.call_tir(cls.matmul21, (inp_2, lv1122), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1123: R.Tensor((2048, 1280), dtype="float32") = model_params[1261]
            lv2492 = R.call_tir(cls.matmul21, (inp_2, lv1123), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv952_2 = R.call_tir(cls.fused_reshape30_transpose22, (lv2488,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv953_1 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv2490,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv954_2 = R.call_tir(cls.fused_reshape5_transpose1, (lv2492,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv955_1 = R.call_tir(cls.fused_matmul22_multiply12, (lv952_2, lv953_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv2504 = R.call_tir(cls.softmax4, (lv955_1,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv2505 = R.call_tir(cls.matmul23, (lv2504, lv954_2), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv956_2 = R.call_tir(cls.fused_transpose24_reshape31, (lv2505,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1124: R.Tensor((1280, 1280), dtype="float32") = model_params[1262]
            lv1125: R.Tensor((1280,), dtype="float32") = model_params[403]
            lv957_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv956_2, lv1124, lv1125, lv951_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1126: R.Tensor((1280,), dtype="float32") = model_params[411]
            lv1127: R.Tensor((1280,), dtype="float32") = model_params[410]
            lv2513 = R.call_tir(cls.layer_norm2, (lv957_1, lv1126, lv1127), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1128: R.Tensor((1280, 10240), dtype="float32") = model_params[1263]
            lv1129: R.Tensor((10240,), dtype="float32") = model_params[404]
            lv958_1 = R.call_tir(cls.fused_matmul24_add24, (lv2513, lv1128, lv1129), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv959_1 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv958_1,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv1130: R.Tensor((5120, 1280), dtype="float32") = model_params[1264]
            lv1131: R.Tensor((1280,), dtype="float32") = model_params[405]
            lv960_1 = R.call_tir(cls.fused_matmul25_add22_add23, (lv959_1, lv1130, lv1131, lv957_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1132: R.Tensor((1280, 1280), dtype="float32") = model_params[1265]
            lv1133: R.Tensor((1280,), dtype="float32") = model_params[311]
            lv961_1 = R.call_tir(cls.fused_matmul18_add22, (lv960_1, lv1132, lv1133), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv962_1 = R.call_tir(cls.fused_reshape32_transpose28_add21, (lv961_1, lv808_2), out_sinfo=R.Tensor((1, 1280, 16, 16), dtype="float32"))
            lv1134: R.Tensor((1280,), dtype="float32") = model_params[422]
            lv1135_1: R.Tensor((1280,), dtype="float32") = model_params[421]
            lv963_1 = R.call_tir(cls.fused_group_norm5_silu5, (lv962_1, lv1134, lv1135_1), out_sinfo=R.Tensor((1, 1280, 16, 16), dtype="float32"))
            lv2537 = R.call_tir(cls.silu, (lv392,), out_sinfo=R.Tensor((1, 1280), dtype="float32"))
            lv1136: R.Tensor((1280, 1280), dtype="float32") = model_params[1267]
            lv1137: R.Tensor((1280,), dtype="float32") = model_params[425]
            lv964_1 = R.call_tir(cls.fused_matmul5_add7_strided_slice, (lv2537, lv1136, lv1137), out_sinfo=R.Tensor((1, 1280), dtype="float32"))
            lv2542 = R.call_tir(cls.reshape28, (lv964_1,), out_sinfo=R.Tensor((1, 1280, 1, 1), dtype="float32"))
            lv1138: R.Tensor((1280, 1280, 3, 3), dtype="float32") = model_params[419]
            lv1139: R.Tensor((1, 1280, 1, 1), dtype="float32") = model_params[1266]
            lv965_1 = R.call_tir(cls.fused_conv2d8_add20_add20, (lv963_1, lv1138, lv1139, lv2542), out_sinfo=R.Tensor((1, 1280, 16, 16), dtype="float32"))
            lv1140_1: R.Tensor((1280,), dtype="float32") = model_params[424]
            lv1141: R.Tensor((1280,), dtype="float32") = model_params[423]
            lv966_1 = R.call_tir(cls.fused_group_norm5_silu5, (lv965_1, lv1140_1, lv1141), out_sinfo=R.Tensor((1, 1280, 16, 16), dtype="float32"))
            lv1142: R.Tensor((1280, 1280, 3, 3), dtype="float32") = model_params[420]
            lv1143: R.Tensor((1, 1280, 1, 1), dtype="float32") = model_params[1268]
            lv967_1 = R.call_tir(cls.fused_conv2d8_add20_add21_divide6, (lv966_1, lv1142, lv1143, lv962_1), out_sinfo=R.Tensor((1, 1280, 16, 16), dtype="float32"))
            lv2551 = R.call_tir(cls.concatenate4, (lv967_1, lv803_1), out_sinfo=R.Tensor((1, 2560, 16, 16), dtype="float32"))
            lv1144: R.Tensor((2560,), dtype="float32") = model_params[744]
            lv1145: R.Tensor((2560,), dtype="float32") = model_params[743]
            lv968_2 = R.call_tir(cls.fused_group_norm7_silu6, (lv2551, lv1144, lv1145), out_sinfo=R.Tensor((1, 2560, 16, 16), dtype="float32"))
            lv2557 = R.call_tir(cls.silu, (lv392,), out_sinfo=R.Tensor((1, 1280), dtype="float32"))
            lv1146: R.Tensor((1280, 1280), dtype="float32") = model_params[1270]
            lv1147: R.Tensor((1280,), dtype="float32") = model_params[747]
            lv969_2 = R.call_tir(cls.fused_matmul5_add7_strided_slice, (lv2557, lv1146, lv1147), out_sinfo=R.Tensor((1, 1280), dtype="float32"))
            lv2562 = R.call_tir(cls.reshape28, (lv969_2,), out_sinfo=R.Tensor((1, 1280, 1, 1), dtype="float32"))
            lv1148: R.Tensor((1280, 2560, 3, 3), dtype="float32") = model_params[740]
            lv1149_1: R.Tensor((1, 1280, 1, 1), dtype="float32") = model_params[1269]
            lv970_1 = R.call_tir(cls.fused_conv2d10_add20_add20, (lv968_2, lv1148, lv1149_1, lv2562), out_sinfo=R.Tensor((1, 1280, 16, 16), dtype="float32"))
            lv1150: R.Tensor((1280,), dtype="float32") = model_params[746]
            lv1151: R.Tensor((1280,), dtype="float32") = model_params[745]
            lv971_1 = R.call_tir(cls.fused_group_norm5_silu5, (lv970_1, lv1150, lv1151), out_sinfo=R.Tensor((1, 1280, 16, 16), dtype="float32"))
            lv1152: R.Tensor((1280, 2560, 1, 1), dtype="float32") = model_params[742]
            lv1153: R.Tensor((1, 1280, 1, 1), dtype="float32") = model_params[1272]
            lv972_1 = R.call_tir(cls.fused_conv2d11_add20, (lv2551, lv1152, lv1153), out_sinfo=R.Tensor((1, 1280, 16, 16), dtype="float32"))
            lv1154: R.Tensor((1280, 1280, 3, 3), dtype="float32") = model_params[741]
            lv1155_1: R.Tensor((1, 1280, 1, 1), dtype="float32") = model_params[1271]
            lv973_1 = R.call_tir(cls.fused_conv2d8_add20_add21_divide6, (lv971_1, lv1154, lv1155_1, lv972_1), out_sinfo=R.Tensor((1, 1280, 16, 16), dtype="float32"))
            lv1156: R.Tensor((1280,), dtype="float32") = model_params[429]
            lv1157_1: R.Tensor((1280,), dtype="float32") = model_params[428]
            lv2574 = R.call_tir(cls.group_norm6, (lv973_1, lv1156, lv1157_1), out_sinfo=R.Tensor((1, 1280, 16, 16), dtype="float32"))
            lv974_1 = R.call_tir(cls.fused_transpose21_reshape29, (lv2574,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1158: R.Tensor((1280, 1280), dtype="float32") = model_params[1273]
            lv1159_1: R.Tensor((1280,), dtype="float32") = model_params[430]
            lv975_1 = R.call_tir(cls.fused_matmul18_add22, (lv974_1, lv1158, lv1159_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1160: R.Tensor((1280,), dtype="float32") = model_params[437]
            lv1161_1: R.Tensor((1280,), dtype="float32") = model_params[436]
            lv2580 = R.call_tir(cls.layer_norm2, (lv975_1, lv1160, lv1161_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1162: R.Tensor((1280, 1280), dtype="float32") = model_params[1274]
            lv2582 = R.call_tir(cls.matmul18, (lv2580, lv1162), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1163: R.Tensor((1280, 1280), dtype="float32") = model_params[1275]
            lv2584 = R.call_tir(cls.matmul18, (lv2580, lv1163), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1164: R.Tensor((1280, 1280), dtype="float32") = model_params[1276]
            lv2586 = R.call_tir(cls.matmul18, (lv2580, lv1164), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv976_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv2582,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv977_2 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv2584,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv978_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv2586,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv979_1 = R.call_tir(cls.fused_matmul19_multiply11, (lv976_1, lv977_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv2598 = R.call_tir(cls.softmax3, (lv979_1,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv2599 = R.call_tir(cls.matmul20, (lv2598, lv978_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv980_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv2599,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1165: R.Tensor((1280, 1280), dtype="float32") = model_params[1277]
            lv1166: R.Tensor((1280,), dtype="float32") = model_params[432]
            lv981_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv980_1, lv1165, lv1166, lv975_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1167: R.Tensor((1280,), dtype="float32") = model_params[439]
            lv1168: R.Tensor((1280,), dtype="float32") = model_params[438]
            lv2607 = R.call_tir(cls.layer_norm2, (lv981_1, lv1167, lv1168), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1169: R.Tensor((1280, 1280), dtype="float32") = model_params[1278]
            lv2609 = R.call_tir(cls.matmul18, (lv2607, lv1169), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1170: R.Tensor((2048, 1280), dtype="float32") = model_params[1279]
            lv2611 = R.call_tir(cls.matmul21, (inp_2, lv1170), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1171: R.Tensor((2048, 1280), dtype="float32") = model_params[1280]
            lv2613 = R.call_tir(cls.matmul21, (inp_2, lv1171), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv982_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv2609,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv983_1 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv2611,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv984_1 = R.call_tir(cls.fused_reshape5_transpose1, (lv2613,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv985_1 = R.call_tir(cls.fused_matmul22_multiply12, (lv982_1, lv983_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv2625 = R.call_tir(cls.softmax4, (lv985_1,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv2626 = R.call_tir(cls.matmul23, (lv2625, lv984_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv986_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv2626,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1172: R.Tensor((1280, 1280), dtype="float32") = model_params[1281]
            lv1173_1: R.Tensor((1280,), dtype="float32") = model_params[433]
            lv987_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv986_1, lv1172, lv1173_1, lv981_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1174_1: R.Tensor((1280,), dtype="float32") = model_params[441]
            lv1175: R.Tensor((1280,), dtype="float32") = model_params[440]
            lv2634 = R.call_tir(cls.layer_norm2, (lv987_1, lv1174_1, lv1175), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1176: R.Tensor((1280, 10240), dtype="float32") = model_params[1282]
            lv1177: R.Tensor((10240,), dtype="float32") = model_params[434]
            lv988_1 = R.call_tir(cls.fused_matmul24_add24, (lv2634, lv1176, lv1177), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv989_1 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv988_1,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv1178: R.Tensor((5120, 1280), dtype="float32") = model_params[1283]
            lv1179: R.Tensor((1280,), dtype="float32") = model_params[435]
            lv990_2 = R.call_tir(cls.fused_matmul25_add22_add23, (lv989_1, lv1178, lv1179, lv987_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1180: R.Tensor((1280,), dtype="float32") = model_params[447]
            lv1181: R.Tensor((1280,), dtype="float32") = model_params[446]
            lv2647 = R.call_tir(cls.layer_norm2, (lv990_2, lv1180, lv1181), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1182_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1284]
            lv2649 = R.call_tir(cls.matmul18, (lv2647, lv1182_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1183: R.Tensor((1280, 1280), dtype="float32") = model_params[1285]
            lv2651 = R.call_tir(cls.matmul18, (lv2647, lv1183), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1184_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1286]
            lv2653 = R.call_tir(cls.matmul18, (lv2647, lv1184_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv991_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv2649,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv992_2 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv2651,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv993_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv2653,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv994_2 = R.call_tir(cls.fused_matmul19_multiply11, (lv991_1, lv992_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv2665 = R.call_tir(cls.softmax3, (lv994_2,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv2666 = R.call_tir(cls.matmul20, (lv2665, lv993_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv995_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv2666,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1185: R.Tensor((1280, 1280), dtype="float32") = model_params[1287]
            lv1186_1: R.Tensor((1280,), dtype="float32") = model_params[442]
            lv996_2 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv995_1, lv1185, lv1186_1, lv990_2), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1187: R.Tensor((1280,), dtype="float32") = model_params[449]
            lv1188_1: R.Tensor((1280,), dtype="float32") = model_params[448]
            lv2674 = R.call_tir(cls.layer_norm2, (lv996_2, lv1187, lv1188_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1189: R.Tensor((1280, 1280), dtype="float32") = model_params[1288]
            lv2676 = R.call_tir(cls.matmul18, (lv2674, lv1189), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1190: R.Tensor((2048, 1280), dtype="float32") = model_params[1289]
            lv2678 = R.call_tir(cls.matmul21, (inp_2, lv1190), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1191: R.Tensor((2048, 1280), dtype="float32") = model_params[1290]
            lv2680 = R.call_tir(cls.matmul21, (inp_2, lv1191), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv997_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv2676,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv998_1 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv2678,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv999_1 = R.call_tir(cls.fused_reshape5_transpose1, (lv2680,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv1000_1 = R.call_tir(cls.fused_matmul22_multiply12, (lv997_1, lv998_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv2692 = R.call_tir(cls.softmax4, (lv1000_1,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv2693 = R.call_tir(cls.matmul23, (lv2692, lv999_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1001_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv2693,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1192: R.Tensor((1280, 1280), dtype="float32") = model_params[1291]
            lv1193: R.Tensor((1280,), dtype="float32") = model_params[443]
            lv1002_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1001_1, lv1192, lv1193, lv996_2), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1194: R.Tensor((1280,), dtype="float32") = model_params[451]
            lv1195: R.Tensor((1280,), dtype="float32") = model_params[450]
            lv2701 = R.call_tir(cls.layer_norm2, (lv1002_1, lv1194, lv1195), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1196: R.Tensor((1280, 10240), dtype="float32") = model_params[1292]
            lv1197: R.Tensor((10240,), dtype="float32") = model_params[444]
            lv1003_1 = R.call_tir(cls.fused_matmul24_add24, (lv2701, lv1196, lv1197), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv1004_1 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv1003_1,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv1198: R.Tensor((5120, 1280), dtype="float32") = model_params[1293]
            lv1199: R.Tensor((1280,), dtype="float32") = model_params[445]
            lv1005_1 = R.call_tir(cls.fused_matmul25_add22_add23, (lv1004_1, lv1198, lv1199, lv1002_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1200_1: R.Tensor((1280,), dtype="float32") = model_params[457]
            lv1201_1: R.Tensor((1280,), dtype="float32") = model_params[456]
            lv2714 = R.call_tir(cls.layer_norm2, (lv1005_1, lv1200_1, lv1201_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1202: R.Tensor((1280, 1280), dtype="float32") = model_params[1294]
            lv2716 = R.call_tir(cls.matmul18, (lv2714, lv1202), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1203: R.Tensor((1280, 1280), dtype="float32") = model_params[1295]
            lv2718 = R.call_tir(cls.matmul18, (lv2714, lv1203), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1204: R.Tensor((1280, 1280), dtype="float32") = model_params[1296]
            lv2720 = R.call_tir(cls.matmul18, (lv2714, lv1204), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1006_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv2716,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1007_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv2718,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv1008_2 = R.call_tir(cls.fused_reshape30_transpose22, (lv2720,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1009_2 = R.call_tir(cls.fused_matmul19_multiply11, (lv1006_1, lv1007_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv2732 = R.call_tir(cls.softmax3, (lv1009_2,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv2733 = R.call_tir(cls.matmul20, (lv2732, lv1008_2), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1010_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv2733,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1205: R.Tensor((1280, 1280), dtype="float32") = model_params[1297]
            lv1206: R.Tensor((1280,), dtype="float32") = model_params[452]
            lv1011_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1010_1, lv1205, lv1206, lv1005_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1207: R.Tensor((1280,), dtype="float32") = model_params[459]
            lv1208: R.Tensor((1280,), dtype="float32") = model_params[458]
            lv2741 = R.call_tir(cls.layer_norm2, (lv1011_1, lv1207, lv1208), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1209_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1298]
            lv2743 = R.call_tir(cls.matmul18, (lv2741, lv1209_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1210: R.Tensor((2048, 1280), dtype="float32") = model_params[1299]
            lv2745 = R.call_tir(cls.matmul21, (inp_2, lv1210), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1211: R.Tensor((2048, 1280), dtype="float32") = model_params[1300]
            lv2747 = R.call_tir(cls.matmul21, (inp_2, lv1211), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1012_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv2743,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1013_1 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv2745,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv1014_1 = R.call_tir(cls.fused_reshape5_transpose1, (lv2747,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv1015_1 = R.call_tir(cls.fused_matmul22_multiply12, (lv1012_1, lv1013_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv2759 = R.call_tir(cls.softmax4, (lv1015_1,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv2760 = R.call_tir(cls.matmul23, (lv2759, lv1014_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1016_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv2760,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1212: R.Tensor((1280, 1280), dtype="float32") = model_params[1301]
            lv1213: R.Tensor((1280,), dtype="float32") = model_params[453]
            lv1017_2 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1016_1, lv1212, lv1213, lv1011_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1214: R.Tensor((1280,), dtype="float32") = model_params[461]
            lv1215: R.Tensor((1280,), dtype="float32") = model_params[460]
            lv2768 = R.call_tir(cls.layer_norm2, (lv1017_2, lv1214, lv1215), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1216: R.Tensor((1280, 10240), dtype="float32") = model_params[1302]
            lv1217: R.Tensor((10240,), dtype="float32") = model_params[454]
            lv1018_1 = R.call_tir(cls.fused_matmul24_add24, (lv2768, lv1216, lv1217), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv1019_2 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv1018_1,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv1218: R.Tensor((5120, 1280), dtype="float32") = model_params[1303]
            lv1219: R.Tensor((1280,), dtype="float32") = model_params[455]
            lv1020_1 = R.call_tir(cls.fused_matmul25_add22_add23, (lv1019_2, lv1218, lv1219, lv1017_2), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1220: R.Tensor((1280,), dtype="float32") = model_params[467]
            lv1221: R.Tensor((1280,), dtype="float32") = model_params[466]
            lv2781 = R.call_tir(cls.layer_norm2, (lv1020_1, lv1220, lv1221), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1222_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1304]
            lv2783 = R.call_tir(cls.matmul18, (lv2781, lv1222_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1223: R.Tensor((1280, 1280), dtype="float32") = model_params[1305]
            lv2785 = R.call_tir(cls.matmul18, (lv2781, lv1223), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1224_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1306]
            lv2787 = R.call_tir(cls.matmul18, (lv2781, lv1224_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1021_2 = R.call_tir(cls.fused_reshape30_transpose22, (lv2783,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1022_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv2785,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv1023_2 = R.call_tir(cls.fused_reshape30_transpose22, (lv2787,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1024_1 = R.call_tir(cls.fused_matmul19_multiply11, (lv1021_2, lv1022_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv2799 = R.call_tir(cls.softmax3, (lv1024_1,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv2800 = R.call_tir(cls.matmul20, (lv2799, lv1023_2), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1025_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv2800,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1225: R.Tensor((1280, 1280), dtype="float32") = model_params[1307]
            lv1226_1: R.Tensor((1280,), dtype="float32") = model_params[462]
            lv1026_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1025_1, lv1225, lv1226_1, lv1020_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1227: R.Tensor((1280,), dtype="float32") = model_params[469]
            lv1228_1: R.Tensor((1280,), dtype="float32") = model_params[468]
            lv2808 = R.call_tir(cls.layer_norm2, (lv1026_1, lv1227, lv1228_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1229: R.Tensor((1280, 1280), dtype="float32") = model_params[1308]
            lv2810 = R.call_tir(cls.matmul18, (lv2808, lv1229), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1230: R.Tensor((2048, 1280), dtype="float32") = model_params[1309]
            lv2812 = R.call_tir(cls.matmul21, (inp_2, lv1230), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1231: R.Tensor((2048, 1280), dtype="float32") = model_params[1310]
            lv2814 = R.call_tir(cls.matmul21, (inp_2, lv1231), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1027_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv2810,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1028_1 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv2812,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv1029_1 = R.call_tir(cls.fused_reshape5_transpose1, (lv2814,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv1030_1 = R.call_tir(cls.fused_matmul22_multiply12, (lv1027_1, lv1028_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv2826 = R.call_tir(cls.softmax4, (lv1030_1,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv2827 = R.call_tir(cls.matmul23, (lv2826, lv1029_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1031_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv2827,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1232: R.Tensor((1280, 1280), dtype="float32") = model_params[1311]
            lv1233: R.Tensor((1280,), dtype="float32") = model_params[463]
            lv1032_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1031_1, lv1232, lv1233, lv1026_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1234: R.Tensor((1280,), dtype="float32") = model_params[471]
            lv1235: R.Tensor((1280,), dtype="float32") = model_params[470]
            lv2835 = R.call_tir(cls.layer_norm2, (lv1032_1, lv1234, lv1235), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1236: R.Tensor((1280, 10240), dtype="float32") = model_params[1312]
            lv1237: R.Tensor((10240,), dtype="float32") = model_params[464]
            lv1033_1 = R.call_tir(cls.fused_matmul24_add24, (lv2835, lv1236, lv1237), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv1034_1 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv1033_1,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv1238: R.Tensor((5120, 1280), dtype="float32") = model_params[1313]
            lv1239: R.Tensor((1280,), dtype="float32") = model_params[465]
            lv1035_2 = R.call_tir(cls.fused_matmul25_add22_add23, (lv1034_1, lv1238, lv1239, lv1032_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1240_1: R.Tensor((1280,), dtype="float32") = model_params[477]
            lv1241_1: R.Tensor((1280,), dtype="float32") = model_params[476]
            lv2848 = R.call_tir(cls.layer_norm2, (lv1035_2, lv1240_1, lv1241_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1242: R.Tensor((1280, 1280), dtype="float32") = model_params[1314]
            lv2850 = R.call_tir(cls.matmul18, (lv2848, lv1242), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1243: R.Tensor((1280, 1280), dtype="float32") = model_params[1315]
            lv2852 = R.call_tir(cls.matmul18, (lv2848, lv1243), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1244: R.Tensor((1280, 1280), dtype="float32") = model_params[1316]
            lv2854 = R.call_tir(cls.matmul18, (lv2848, lv1244), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1036_2 = R.call_tir(cls.fused_reshape30_transpose22, (lv2850,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1037_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv2852,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv1038_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv2854,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1039_1 = R.call_tir(cls.fused_matmul19_multiply11, (lv1036_2, lv1037_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv2866 = R.call_tir(cls.softmax3, (lv1039_1,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv2867 = R.call_tir(cls.matmul20, (lv2866, lv1038_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1040_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv2867,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1245: R.Tensor((1280, 1280), dtype="float32") = model_params[1317]
            lv1246: R.Tensor((1280,), dtype="float32") = model_params[472]
            lv1041_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1040_1, lv1245, lv1246, lv1035_2), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1247: R.Tensor((1280,), dtype="float32") = model_params[479]
            lv1248: R.Tensor((1280,), dtype="float32") = model_params[478]
            lv2875 = R.call_tir(cls.layer_norm2, (lv1041_1, lv1247, lv1248), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1249_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1318]
            lv2877 = R.call_tir(cls.matmul18, (lv2875, lv1249_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1250: R.Tensor((2048, 1280), dtype="float32") = model_params[1319]
            lv2879 = R.call_tir(cls.matmul21, (inp_2, lv1250), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1251_1: R.Tensor((2048, 1280), dtype="float32") = model_params[1320]
            lv2881 = R.call_tir(cls.matmul21, (inp_2, lv1251_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1042_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv2877,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1043_1 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv2879,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv1044_2 = R.call_tir(cls.fused_reshape5_transpose1, (lv2881,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv1045_1 = R.call_tir(cls.fused_matmul22_multiply12, (lv1042_1, lv1043_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv2893 = R.call_tir(cls.softmax4, (lv1045_1,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv2894 = R.call_tir(cls.matmul23, (lv2893, lv1044_2), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1046_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv2894,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1252: R.Tensor((1280, 1280), dtype="float32") = model_params[1321]
            lv1253_1: R.Tensor((1280,), dtype="float32") = model_params[473]
            lv1047_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1046_1, lv1252, lv1253_1, lv1041_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1254: R.Tensor((1280,), dtype="float32") = model_params[481]
            lv1255_1: R.Tensor((1280,), dtype="float32") = model_params[480]
            lv2902 = R.call_tir(cls.layer_norm2, (lv1047_1, lv1254, lv1255_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1256: R.Tensor((1280, 10240), dtype="float32") = model_params[1322]
            lv1257: R.Tensor((10240,), dtype="float32") = model_params[474]
            lv1048_1 = R.call_tir(cls.fused_matmul24_add24, (lv2902, lv1256, lv1257), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv1049_1 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv1048_1,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv1258: R.Tensor((5120, 1280), dtype="float32") = model_params[1323]
            lv1259: R.Tensor((1280,), dtype="float32") = model_params[475]
            lv1050_1 = R.call_tir(cls.fused_matmul25_add22_add23, (lv1049_1, lv1258, lv1259, lv1047_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1260: R.Tensor((1280,), dtype="float32") = model_params[487]
            lv1261: R.Tensor((1280,), dtype="float32") = model_params[486]
            lv2915 = R.call_tir(cls.layer_norm2, (lv1050_1, lv1260, lv1261), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1262: R.Tensor((1280, 1280), dtype="float32") = model_params[1324]
            lv2917 = R.call_tir(cls.matmul18, (lv2915, lv1262), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1263: R.Tensor((1280, 1280), dtype="float32") = model_params[1325]
            lv2919 = R.call_tir(cls.matmul18, (lv2915, lv1263), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1264: R.Tensor((1280, 1280), dtype="float32") = model_params[1326]
            lv2921 = R.call_tir(cls.matmul18, (lv2915, lv1264), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1051_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv2917,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1052_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv2919,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv1053_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv2921,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1054_1 = R.call_tir(cls.fused_matmul19_multiply11, (lv1051_1, lv1052_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv2933 = R.call_tir(cls.softmax3, (lv1054_1,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv2934 = R.call_tir(cls.matmul20, (lv2933, lv1053_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1055_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv2934,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1265: R.Tensor((1280, 1280), dtype="float32") = model_params[1327]
            lv1266: R.Tensor((1280,), dtype="float32") = model_params[482]
            lv1056_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1055_1, lv1265, lv1266, lv1050_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1267_1: R.Tensor((1280,), dtype="float32") = model_params[489]
            lv1268_1: R.Tensor((1280,), dtype="float32") = model_params[488]
            lv2942 = R.call_tir(cls.layer_norm2, (lv1056_1, lv1267_1, lv1268_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1269: R.Tensor((1280, 1280), dtype="float32") = model_params[1328]
            lv2944 = R.call_tir(cls.matmul18, (lv2942, lv1269), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1270: R.Tensor((2048, 1280), dtype="float32") = model_params[1329]
            lv2946 = R.call_tir(cls.matmul21, (inp_2, lv1270), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1271: R.Tensor((2048, 1280), dtype="float32") = model_params[1330]
            lv2948 = R.call_tir(cls.matmul21, (inp_2, lv1271), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1057_2 = R.call_tir(cls.fused_reshape30_transpose22, (lv2944,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1058_1 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv2946,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv1059_2 = R.call_tir(cls.fused_reshape5_transpose1, (lv2948,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv1060_1 = R.call_tir(cls.fused_matmul22_multiply12, (lv1057_2, lv1058_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv2960 = R.call_tir(cls.softmax4, (lv1060_1,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv2961 = R.call_tir(cls.matmul23, (lv2960, lv1059_2), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1061_2 = R.call_tir(cls.fused_transpose24_reshape31, (lv2961,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1272: R.Tensor((1280, 1280), dtype="float32") = model_params[1331]
            lv1273: R.Tensor((1280,), dtype="float32") = model_params[483]
            lv1062_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1061_2, lv1272, lv1273, lv1056_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1274: R.Tensor((1280,), dtype="float32") = model_params[491]
            lv1275: R.Tensor((1280,), dtype="float32") = model_params[490]
            lv2969 = R.call_tir(cls.layer_norm2, (lv1062_1, lv1274, lv1275), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1276_1: R.Tensor((1280, 10240), dtype="float32") = model_params[1332]
            lv1277: R.Tensor((10240,), dtype="float32") = model_params[484]
            lv1063_2 = R.call_tir(cls.fused_matmul24_add24, (lv2969, lv1276_1, lv1277), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv1064_1 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv1063_2,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv1278: R.Tensor((5120, 1280), dtype="float32") = model_params[1333]
            lv1279: R.Tensor((1280,), dtype="float32") = model_params[485]
            lv1065_1 = R.call_tir(cls.fused_matmul25_add22_add23, (lv1064_1, lv1278, lv1279, lv1062_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1280: R.Tensor((1280,), dtype="float32") = model_params[497]
            lv1281: R.Tensor((1280,), dtype="float32") = model_params[496]
            lv2982 = R.call_tir(cls.layer_norm2, (lv1065_1, lv1280, lv1281), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1282: R.Tensor((1280, 1280), dtype="float32") = model_params[1334]
            lv2984 = R.call_tir(cls.matmul18, (lv2982, lv1282), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1283: R.Tensor((1280, 1280), dtype="float32") = model_params[1335]
            lv2986 = R.call_tir(cls.matmul18, (lv2982, lv1283), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1284: R.Tensor((1280, 1280), dtype="float32") = model_params[1336]
            lv2988 = R.call_tir(cls.matmul18, (lv2982, lv1284), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1066_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv2984,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1067_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv2986,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv1068_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv2988,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1069_1 = R.call_tir(cls.fused_matmul19_multiply11, (lv1066_1, lv1067_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv3000 = R.call_tir(cls.softmax3, (lv1069_1,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv3001 = R.call_tir(cls.matmul20, (lv3000, lv1068_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1070_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv3001,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1285: R.Tensor((1280, 1280), dtype="float32") = model_params[1337]
            lv1286: R.Tensor((1280,), dtype="float32") = model_params[492]
            lv1071_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1070_1, lv1285, lv1286, lv1065_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1287: R.Tensor((1280,), dtype="float32") = model_params[499]
            lv1288: R.Tensor((1280,), dtype="float32") = model_params[498]
            lv3009 = R.call_tir(cls.layer_norm2, (lv1071_1, lv1287, lv1288), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1289_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1338]
            lv3011 = R.call_tir(cls.matmul18, (lv3009, lv1289_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1290: R.Tensor((2048, 1280), dtype="float32") = model_params[1339]
            lv3013 = R.call_tir(cls.matmul21, (inp_2, lv1290), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1291_1: R.Tensor((2048, 1280), dtype="float32") = model_params[1340]
            lv3015 = R.call_tir(cls.matmul21, (inp_2, lv1291_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1072_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3011,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1073_1 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv3013,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv1074_1 = R.call_tir(cls.fused_reshape5_transpose1, (lv3015,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv1075_2 = R.call_tir(cls.fused_matmul22_multiply12, (lv1072_1, lv1073_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv3027 = R.call_tir(cls.softmax4, (lv1075_2,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv3028 = R.call_tir(cls.matmul23, (lv3027, lv1074_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1076_2 = R.call_tir(cls.fused_transpose24_reshape31, (lv3028,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1292: R.Tensor((1280, 1280), dtype="float32") = model_params[1341]
            lv1293_1: R.Tensor((1280,), dtype="float32") = model_params[493]
            lv1077_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1076_2, lv1292, lv1293_1, lv1071_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1294: R.Tensor((1280,), dtype="float32") = model_params[501]
            lv1295_1: R.Tensor((1280,), dtype="float32") = model_params[500]
            lv3036 = R.call_tir(cls.layer_norm2, (lv1077_1, lv1294, lv1295_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1296: R.Tensor((1280, 10240), dtype="float32") = model_params[1342]
            lv1297: R.Tensor((10240,), dtype="float32") = model_params[494]
            lv1078_1 = R.call_tir(cls.fused_matmul24_add24, (lv3036, lv1296, lv1297), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv1079_1 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv1078_1,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv1298: R.Tensor((5120, 1280), dtype="float32") = model_params[1343]
            lv1299: R.Tensor((1280,), dtype="float32") = model_params[495]
            lv1080_1 = R.call_tir(cls.fused_matmul25_add22_add23, (lv1079_1, lv1298, lv1299, lv1077_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1300: R.Tensor((1280,), dtype="float32") = model_params[507]
            lv1301: R.Tensor((1280,), dtype="float32") = model_params[506]
            lv3049 = R.call_tir(cls.layer_norm2, (lv1080_1, lv1300, lv1301), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1302: R.Tensor((1280, 1280), dtype="float32") = model_params[1344]
            lv3051 = R.call_tir(cls.matmul18, (lv3049, lv1302), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1303: R.Tensor((1280, 1280), dtype="float32") = model_params[1345]
            lv3053 = R.call_tir(cls.matmul18, (lv3049, lv1303), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1304: R.Tensor((1280, 1280), dtype="float32") = model_params[1346]
            lv3055 = R.call_tir(cls.matmul18, (lv3049, lv1304), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1081_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3051,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1082_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv3053,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv1083_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3055,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1084_2 = R.call_tir(cls.fused_matmul19_multiply11, (lv1081_1, lv1082_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv3067 = R.call_tir(cls.softmax3, (lv1084_2,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv3068 = R.call_tir(cls.matmul20, (lv3067, lv1083_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1085_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv3068,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1305: R.Tensor((1280, 1280), dtype="float32") = model_params[1347]
            lv1306: R.Tensor((1280,), dtype="float32") = model_params[502]
            lv1086_2 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1085_1, lv1305, lv1306, lv1080_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1307_1: R.Tensor((1280,), dtype="float32") = model_params[509]
            lv1308_1: R.Tensor((1280,), dtype="float32") = model_params[508]
            lv3076 = R.call_tir(cls.layer_norm2, (lv1086_2, lv1307_1, lv1308_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1309: R.Tensor((1280, 1280), dtype="float32") = model_params[1348]
            lv3078 = R.call_tir(cls.matmul18, (lv3076, lv1309), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1310: R.Tensor((2048, 1280), dtype="float32") = model_params[1349]
            lv3080 = R.call_tir(cls.matmul21, (inp_2, lv1310), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1311: R.Tensor((2048, 1280), dtype="float32") = model_params[1350]
            lv3082 = R.call_tir(cls.matmul21, (inp_2, lv1311), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1087_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3078,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1088_2 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv3080,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv1089_1 = R.call_tir(cls.fused_reshape5_transpose1, (lv3082,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv1090_2 = R.call_tir(cls.fused_matmul22_multiply12, (lv1087_1, lv1088_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv3094 = R.call_tir(cls.softmax4, (lv1090_2,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv3095 = R.call_tir(cls.matmul23, (lv3094, lv1089_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1091_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv3095,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1312: R.Tensor((1280, 1280), dtype="float32") = model_params[1351]
            lv1313: R.Tensor((1280,), dtype="float32") = model_params[503]
            lv1092_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1091_1, lv1312, lv1313, lv1086_2), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1314: R.Tensor((1280,), dtype="float32") = model_params[511]
            lv1315: R.Tensor((1280,), dtype="float32") = model_params[510]
            lv3103 = R.call_tir(cls.layer_norm2, (lv1092_1, lv1314, lv1315), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1316_1: R.Tensor((1280, 10240), dtype="float32") = model_params[1352]
            lv1317: R.Tensor((10240,), dtype="float32") = model_params[504]
            lv1093_1 = R.call_tir(cls.fused_matmul24_add24, (lv3103, lv1316_1, lv1317), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv1094_1 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv1093_1,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv1318_1: R.Tensor((5120, 1280), dtype="float32") = model_params[1353]
            lv1319: R.Tensor((1280,), dtype="float32") = model_params[505]
            lv1095_1 = R.call_tir(cls.fused_matmul25_add22_add23, (lv1094_1, lv1318_1, lv1319, lv1092_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1320_1: R.Tensor((1280,), dtype="float32") = model_params[517]
            lv1321: R.Tensor((1280,), dtype="float32") = model_params[516]
            lv3116 = R.call_tir(cls.layer_norm2, (lv1095_1, lv1320_1, lv1321), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1322_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1354]
            lv3118 = R.call_tir(cls.matmul18, (lv3116, lv1322_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1323: R.Tensor((1280, 1280), dtype="float32") = model_params[1355]
            lv3120 = R.call_tir(cls.matmul18, (lv3116, lv1323), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1324: R.Tensor((1280, 1280), dtype="float32") = model_params[1356]
            lv3122 = R.call_tir(cls.matmul18, (lv3116, lv1324), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1096_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3118,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1097_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv3120,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv1098_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3122,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1099_1 = R.call_tir(cls.fused_matmul19_multiply11, (lv1096_1, lv1097_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv3134 = R.call_tir(cls.softmax3, (lv1099_1,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv3135 = R.call_tir(cls.matmul20, (lv3134, lv1098_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1100_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv3135,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1325: R.Tensor((1280, 1280), dtype="float32") = model_params[1357]
            lv1326: R.Tensor((1280,), dtype="float32") = model_params[512]
            lv1101_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1100_1, lv1325, lv1326, lv1095_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1327: R.Tensor((1280,), dtype="float32") = model_params[519]
            lv1328: R.Tensor((1280,), dtype="float32") = model_params[518]
            lv3143 = R.call_tir(cls.layer_norm2, (lv1101_1, lv1327, lv1328), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1329: R.Tensor((1280, 1280), dtype="float32") = model_params[1358]
            lv3145 = R.call_tir(cls.matmul18, (lv3143, lv1329), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1330: R.Tensor((2048, 1280), dtype="float32") = model_params[1359]
            lv3147 = R.call_tir(cls.matmul21, (inp_2, lv1330), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1331: R.Tensor((2048, 1280), dtype="float32") = model_params[1360]
            lv3149 = R.call_tir(cls.matmul21, (inp_2, lv1331), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1102_2 = R.call_tir(cls.fused_reshape30_transpose22, (lv3145,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1103_2 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv3147,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv1104_1 = R.call_tir(cls.fused_reshape5_transpose1, (lv3149,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv1105_1 = R.call_tir(cls.fused_matmul22_multiply12, (lv1102_2, lv1103_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv3161 = R.call_tir(cls.softmax4, (lv1105_1,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv3162 = R.call_tir(cls.matmul23, (lv3161, lv1104_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1106_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv3162,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1332: R.Tensor((1280, 1280), dtype="float32") = model_params[1361]
            lv1333: R.Tensor((1280,), dtype="float32") = model_params[513]
            lv1107_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1106_1, lv1332, lv1333, lv1101_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1334_1: R.Tensor((1280,), dtype="float32") = model_params[521]
            lv1335_1: R.Tensor((1280,), dtype="float32") = model_params[520]
            lv3170 = R.call_tir(cls.layer_norm2, (lv1107_1, lv1334_1, lv1335_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1336: R.Tensor((1280, 10240), dtype="float32") = model_params[1362]
            lv1337: R.Tensor((10240,), dtype="float32") = model_params[514]
            lv1108_1 = R.call_tir(cls.fused_matmul24_add24, (lv3170, lv1336, lv1337), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv1109_1 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv1108_1,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv1338: R.Tensor((5120, 1280), dtype="float32") = model_params[1363]
            lv1339: R.Tensor((1280,), dtype="float32") = model_params[515]
            lv1110_1 = R.call_tir(cls.fused_matmul25_add22_add23, (lv1109_1, lv1338, lv1339, lv1107_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1340: R.Tensor((1280,), dtype="float32") = model_params[527]
            lv1341: R.Tensor((1280,), dtype="float32") = model_params[526]
            lv3183 = R.call_tir(cls.layer_norm2, (lv1110_1, lv1340, lv1341), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1342: R.Tensor((1280, 1280), dtype="float32") = model_params[1364]
            lv3185 = R.call_tir(cls.matmul18, (lv3183, lv1342), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1343_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1365]
            lv3187 = R.call_tir(cls.matmul18, (lv3183, lv1343_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1344: R.Tensor((1280, 1280), dtype="float32") = model_params[1366]
            lv3189 = R.call_tir(cls.matmul18, (lv3183, lv1344), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1111_2 = R.call_tir(cls.fused_reshape30_transpose22, (lv3185,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1112_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv3187,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv1113_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3189,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1114_1 = R.call_tir(cls.fused_matmul19_multiply11, (lv1111_2, lv1112_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv3201 = R.call_tir(cls.softmax3, (lv1114_1,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv3202 = R.call_tir(cls.matmul20, (lv3201, lv1113_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1115_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv3202,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1345: R.Tensor((1280, 1280), dtype="float32") = model_params[1367]
            lv1346: R.Tensor((1280,), dtype="float32") = model_params[522]
            lv1116_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1115_1, lv1345, lv1346, lv1110_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1347: R.Tensor((1280,), dtype="float32") = model_params[529]
            lv1348: R.Tensor((1280,), dtype="float32") = model_params[528]
            lv3210 = R.call_tir(cls.layer_norm2, (lv1116_1, lv1347, lv1348), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1349: R.Tensor((1280, 1280), dtype="float32") = model_params[1368]
            lv3212 = R.call_tir(cls.matmul18, (lv3210, lv1349), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1350: R.Tensor((2048, 1280), dtype="float32") = model_params[1369]
            lv3214 = R.call_tir(cls.matmul21, (inp_2, lv1350), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1351: R.Tensor((2048, 1280), dtype="float32") = model_params[1370]
            lv3216 = R.call_tir(cls.matmul21, (inp_2, lv1351), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1117_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3212,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1118_1 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv3214,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv1119_1 = R.call_tir(cls.fused_reshape5_transpose1, (lv3216,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv1120_1 = R.call_tir(cls.fused_matmul22_multiply12, (lv1117_1, lv1118_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv3228 = R.call_tir(cls.softmax4, (lv1120_1,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv3229 = R.call_tir(cls.matmul23, (lv3228, lv1119_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1121_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv3229,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1352: R.Tensor((1280, 1280), dtype="float32") = model_params[1371]
            lv1353: R.Tensor((1280,), dtype="float32") = model_params[523]
            lv1122_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1121_1, lv1352, lv1353, lv1116_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1354: R.Tensor((1280,), dtype="float32") = model_params[531]
            lv1355: R.Tensor((1280,), dtype="float32") = model_params[530]
            lv3237 = R.call_tir(cls.layer_norm2, (lv1122_1, lv1354, lv1355), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1356_1: R.Tensor((1280, 10240), dtype="float32") = model_params[1372]
            lv1357: R.Tensor((10240,), dtype="float32") = model_params[524]
            lv1123_1 = R.call_tir(cls.fused_matmul24_add24, (lv3237, lv1356_1, lv1357), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv1124_1 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv1123_1,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv1358_1: R.Tensor((5120, 1280), dtype="float32") = model_params[1373]
            lv1359: R.Tensor((1280,), dtype="float32") = model_params[525]
            lv1125_1 = R.call_tir(cls.fused_matmul25_add22_add23, (lv1124_1, lv1358_1, lv1359, lv1122_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1360_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1374]
            lv1361: R.Tensor((1280,), dtype="float32") = model_params[431]
            lv1126_1 = R.call_tir(cls.fused_matmul18_add22, (lv1125_1, lv1360_1, lv1361), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1127_1 = R.call_tir(cls.fused_reshape32_transpose28_add21_concatenate4, (lv1126_1, lv973_1, lv644_1), out_sinfo=R.Tensor((1, 2560, 16, 16), dtype="float32"))
            lv1362_1: R.Tensor((2560,), dtype="float32") = model_params[752]
            lv1363: R.Tensor((2560,), dtype="float32") = model_params[751]
            lv1128_1 = R.call_tir(cls.fused_group_norm7_silu6, (lv1127_1, lv1362_1, lv1363), out_sinfo=R.Tensor((1, 2560, 16, 16), dtype="float32"))
            lv3262 = R.call_tir(cls.silu, (lv392,), out_sinfo=R.Tensor((1, 1280), dtype="float32"))
            lv1364: R.Tensor((1280, 1280), dtype="float32") = model_params[1376]
            lv1365: R.Tensor((1280,), dtype="float32") = model_params[755]
            lv1129_1 = R.call_tir(cls.fused_matmul5_add7_strided_slice, (lv3262, lv1364, lv1365), out_sinfo=R.Tensor((1, 1280), dtype="float32"))
            lv3267 = R.call_tir(cls.reshape28, (lv1129_1,), out_sinfo=R.Tensor((1, 1280, 1, 1), dtype="float32"))
            lv1366: R.Tensor((1280, 2560, 3, 3), dtype="float32") = model_params[748]
            lv1367: R.Tensor((1, 1280, 1, 1), dtype="float32") = model_params[1375]
            lv1130_1 = R.call_tir(cls.fused_conv2d10_add20_add20, (lv1128_1, lv1366, lv1367, lv3267), out_sinfo=R.Tensor((1, 1280, 16, 16), dtype="float32"))
            lv1368: R.Tensor((1280,), dtype="float32") = model_params[754]
            lv1369: R.Tensor((1280,), dtype="float32") = model_params[753]
            lv1131_1 = R.call_tir(cls.fused_group_norm5_silu5, (lv1130_1, lv1368, lv1369), out_sinfo=R.Tensor((1, 1280, 16, 16), dtype="float32"))
            lv1370: R.Tensor((1280, 2560, 1, 1), dtype="float32") = model_params[750]
            lv1371: R.Tensor((1, 1280, 1, 1), dtype="float32") = model_params[1378]
            lv1132_1 = R.call_tir(cls.fused_conv2d11_add20, (lv1127_1, lv1370, lv1371), out_sinfo=R.Tensor((1, 1280, 16, 16), dtype="float32"))
            lv1372: R.Tensor((1280, 1280, 3, 3), dtype="float32") = model_params[749]
            lv1373: R.Tensor((1, 1280, 1, 1), dtype="float32") = model_params[1377]
            lv1133_1 = R.call_tir(cls.fused_conv2d8_add20_add21_divide6, (lv1131_1, lv1372, lv1373, lv1132_1), out_sinfo=R.Tensor((1, 1280, 16, 16), dtype="float32"))
            lv1374_1: R.Tensor((1280,), dtype="float32") = model_params[533]
            lv1375_1: R.Tensor((1280,), dtype="float32") = model_params[532]
            lv3279 = R.call_tir(cls.group_norm6, (lv1133_1, lv1374_1, lv1375_1), out_sinfo=R.Tensor((1, 1280, 16, 16), dtype="float32"))
            lv1134_1 = R.call_tir(cls.fused_transpose21_reshape29, (lv3279,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1376: R.Tensor((1280, 1280), dtype="float32") = model_params[1379]
            lv1377: R.Tensor((1280,), dtype="float32") = model_params[534]
            lv1135_2 = R.call_tir(cls.fused_matmul18_add22, (lv1134_1, lv1376, lv1377), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1378: R.Tensor((1280,), dtype="float32") = model_params[541]
            lv1379: R.Tensor((1280,), dtype="float32") = model_params[540]
            lv3285 = R.call_tir(cls.layer_norm2, (lv1135_2, lv1378, lv1379), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1380: R.Tensor((1280, 1280), dtype="float32") = model_params[1380]
            lv3287 = R.call_tir(cls.matmul18, (lv3285, lv1380), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1381: R.Tensor((1280, 1280), dtype="float32") = model_params[1381]
            lv3289 = R.call_tir(cls.matmul18, (lv3285, lv1381), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1382: R.Tensor((1280, 1280), dtype="float32") = model_params[1382]
            lv3291 = R.call_tir(cls.matmul18, (lv3285, lv1382), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1136_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3287,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1137_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv3289,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv1138_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3291,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1139_1 = R.call_tir(cls.fused_matmul19_multiply11, (lv1136_1, lv1137_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv3303 = R.call_tir(cls.softmax3, (lv1139_1,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv3304 = R.call_tir(cls.matmul20, (lv3303, lv1138_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1140_2 = R.call_tir(cls.fused_transpose24_reshape31, (lv3304,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1383_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1383]
            lv1384: R.Tensor((1280,), dtype="float32") = model_params[536]
            lv1141_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1140_2, lv1383_1, lv1384, lv1135_2), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1385_1: R.Tensor((1280,), dtype="float32") = model_params[543]
            lv1386: R.Tensor((1280,), dtype="float32") = model_params[542]
            lv3312 = R.call_tir(cls.layer_norm2, (lv1141_1, lv1385_1, lv1386), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1387_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1384]
            lv3314 = R.call_tir(cls.matmul18, (lv3312, lv1387_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1388: R.Tensor((2048, 1280), dtype="float32") = model_params[1385]
            lv3316 = R.call_tir(cls.matmul21, (inp_2, lv1388), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1389_1: R.Tensor((2048, 1280), dtype="float32") = model_params[1386]
            lv3318 = R.call_tir(cls.matmul21, (inp_2, lv1389_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1142_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3314,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1143_1 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv3316,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv1144_1 = R.call_tir(cls.fused_reshape5_transpose1, (lv3318,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv1145_1 = R.call_tir(cls.fused_matmul22_multiply12, (lv1142_1, lv1143_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv3330 = R.call_tir(cls.softmax4, (lv1145_1,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv3331 = R.call_tir(cls.matmul23, (lv3330, lv1144_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1146_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv3331,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1390: R.Tensor((1280, 1280), dtype="float32") = model_params[1387]
            lv1391: R.Tensor((1280,), dtype="float32") = model_params[537]
            lv1147_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1146_1, lv1390, lv1391, lv1141_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1392: R.Tensor((1280,), dtype="float32") = model_params[545]
            lv1393: R.Tensor((1280,), dtype="float32") = model_params[544]
            lv3339 = R.call_tir(cls.layer_norm2, (lv1147_1, lv1392, lv1393), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1394: R.Tensor((1280, 10240), dtype="float32") = model_params[1388]
            lv1395: R.Tensor((10240,), dtype="float32") = model_params[538]
            lv1148_1 = R.call_tir(cls.fused_matmul24_add24, (lv3339, lv1394, lv1395), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv1149_2 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv1148_1,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv1396: R.Tensor((5120, 1280), dtype="float32") = model_params[1389]
            lv1397: R.Tensor((1280,), dtype="float32") = model_params[539]
            lv1150_1 = R.call_tir(cls.fused_matmul25_add22_add23, (lv1149_2, lv1396, lv1397, lv1147_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1398: R.Tensor((1280,), dtype="float32") = model_params[551]
            lv1399: R.Tensor((1280,), dtype="float32") = model_params[550]
            lv3352 = R.call_tir(cls.layer_norm2, (lv1150_1, lv1398, lv1399), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1400: R.Tensor((1280, 1280), dtype="float32") = model_params[1390]
            lv3354 = R.call_tir(cls.matmul18, (lv3352, lv1400), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1401_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1391]
            lv3356 = R.call_tir(cls.matmul18, (lv3352, lv1401_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1402_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1392]
            lv3358 = R.call_tir(cls.matmul18, (lv3352, lv1402_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1151_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3354,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1152_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv3356,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv1153_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3358,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1154_1 = R.call_tir(cls.fused_matmul19_multiply11, (lv1151_1, lv1152_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv3370 = R.call_tir(cls.softmax3, (lv1154_1,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv3371 = R.call_tir(cls.matmul20, (lv3370, lv1153_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1155_2 = R.call_tir(cls.fused_transpose24_reshape31, (lv3371,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1403: R.Tensor((1280, 1280), dtype="float32") = model_params[1393]
            lv1404: R.Tensor((1280,), dtype="float32") = model_params[546]
            lv1156_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1155_2, lv1403, lv1404, lv1150_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1405: R.Tensor((1280,), dtype="float32") = model_params[553]
            lv1406: R.Tensor((1280,), dtype="float32") = model_params[552]
            lv3379 = R.call_tir(cls.layer_norm2, (lv1156_1, lv1405, lv1406), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1407: R.Tensor((1280, 1280), dtype="float32") = model_params[1394]
            lv3381 = R.call_tir(cls.matmul18, (lv3379, lv1407), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1408: R.Tensor((2048, 1280), dtype="float32") = model_params[1395]
            lv3383 = R.call_tir(cls.matmul21, (inp_2, lv1408), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1409: R.Tensor((2048, 1280), dtype="float32") = model_params[1396]
            lv3385 = R.call_tir(cls.matmul21, (inp_2, lv1409), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1157_2 = R.call_tir(cls.fused_reshape30_transpose22, (lv3381,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1158_1 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv3383,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv1159_2 = R.call_tir(cls.fused_reshape5_transpose1, (lv3385,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv1160_1 = R.call_tir(cls.fused_matmul22_multiply12, (lv1157_2, lv1158_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv3397 = R.call_tir(cls.softmax4, (lv1160_1,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv3398 = R.call_tir(cls.matmul23, (lv3397, lv1159_2), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1161_2 = R.call_tir(cls.fused_transpose24_reshape31, (lv3398,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1410_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1397]
            lv1411: R.Tensor((1280,), dtype="float32") = model_params[547]
            lv1162_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1161_2, lv1410_1, lv1411, lv1156_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1412: R.Tensor((1280,), dtype="float32") = model_params[555]
            lv1413: R.Tensor((1280,), dtype="float32") = model_params[554]
            lv3406 = R.call_tir(cls.layer_norm2, (lv1162_1, lv1412, lv1413), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1414: R.Tensor((1280, 10240), dtype="float32") = model_params[1398]
            lv1415: R.Tensor((10240,), dtype="float32") = model_params[548]
            lv1163_1 = R.call_tir(cls.fused_matmul24_add24, (lv3406, lv1414, lv1415), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv1164_1 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv1163_1,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv1416: R.Tensor((5120, 1280), dtype="float32") = model_params[1399]
            lv1417: R.Tensor((1280,), dtype="float32") = model_params[549]
            lv1165_1 = R.call_tir(cls.fused_matmul25_add22_add23, (lv1164_1, lv1416, lv1417, lv1162_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1418: R.Tensor((1280,), dtype="float32") = model_params[561]
            lv1419: R.Tensor((1280,), dtype="float32") = model_params[560]
            lv3419 = R.call_tir(cls.layer_norm2, (lv1165_1, lv1418, lv1419), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1420: R.Tensor((1280, 1280), dtype="float32") = model_params[1400]
            lv3421 = R.call_tir(cls.matmul18, (lv3419, lv1420), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1421: R.Tensor((1280, 1280), dtype="float32") = model_params[1401]
            lv3423 = R.call_tir(cls.matmul18, (lv3419, lv1421), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1422: R.Tensor((1280, 1280), dtype="float32") = model_params[1402]
            lv3425 = R.call_tir(cls.matmul18, (lv3419, lv1422), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1166_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3421,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1167_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv3423,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv1168_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3425,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1169_1 = R.call_tir(cls.fused_matmul19_multiply11, (lv1166_1, lv1167_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv3437 = R.call_tir(cls.softmax3, (lv1169_1,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv3438 = R.call_tir(cls.matmul20, (lv3437, lv1168_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1170_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv3438,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1423_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1403]
            lv1424: R.Tensor((1280,), dtype="float32") = model_params[556]
            lv1171_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1170_1, lv1423_1, lv1424, lv1165_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1425_1: R.Tensor((1280,), dtype="float32") = model_params[563]
            lv1426: R.Tensor((1280,), dtype="float32") = model_params[562]
            lv3446 = R.call_tir(cls.layer_norm2, (lv1171_1, lv1425_1, lv1426), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1427_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1404]
            lv3448 = R.call_tir(cls.matmul18, (lv3446, lv1427_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1428: R.Tensor((2048, 1280), dtype="float32") = model_params[1405]
            lv3450 = R.call_tir(cls.matmul21, (inp_2, lv1428), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1429_1: R.Tensor((2048, 1280), dtype="float32") = model_params[1406]
            lv3452 = R.call_tir(cls.matmul21, (inp_2, lv1429_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1172_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3448,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1173_2 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv3450,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv1174_2 = R.call_tir(cls.fused_reshape5_transpose1, (lv3452,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv1175_1 = R.call_tir(cls.fused_matmul22_multiply12, (lv1172_1, lv1173_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv3464 = R.call_tir(cls.softmax4, (lv1175_1,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv3465 = R.call_tir(cls.matmul23, (lv3464, lv1174_2), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1176_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv3465,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1430: R.Tensor((1280, 1280), dtype="float32") = model_params[1407]
            lv1431: R.Tensor((1280,), dtype="float32") = model_params[557]
            lv1177_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1176_1, lv1430, lv1431, lv1171_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1432: R.Tensor((1280,), dtype="float32") = model_params[565]
            lv1433: R.Tensor((1280,), dtype="float32") = model_params[564]
            lv3473 = R.call_tir(cls.layer_norm2, (lv1177_1, lv1432, lv1433), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1434: R.Tensor((1280, 10240), dtype="float32") = model_params[1408]
            lv1435: R.Tensor((10240,), dtype="float32") = model_params[558]
            lv1178_1 = R.call_tir(cls.fused_matmul24_add24, (lv3473, lv1434, lv1435), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv1179_1 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv1178_1,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv1436: R.Tensor((5120, 1280), dtype="float32") = model_params[1409]
            lv1437: R.Tensor((1280,), dtype="float32") = model_params[559]
            lv1180_1 = R.call_tir(cls.fused_matmul25_add22_add23, (lv1179_1, lv1436, lv1437, lv1177_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1438: R.Tensor((1280,), dtype="float32") = model_params[571]
            lv1439: R.Tensor((1280,), dtype="float32") = model_params[570]
            lv3486 = R.call_tir(cls.layer_norm2, (lv1180_1, lv1438, lv1439), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1440: R.Tensor((1280, 1280), dtype="float32") = model_params[1410]
            lv3488 = R.call_tir(cls.matmul18, (lv3486, lv1440), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1441_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1411]
            lv3490 = R.call_tir(cls.matmul18, (lv3486, lv1441_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1442_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1412]
            lv3492 = R.call_tir(cls.matmul18, (lv3486, lv1442_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1181_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3488,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1182_2 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv3490,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv1183_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3492,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1184_2 = R.call_tir(cls.fused_matmul19_multiply11, (lv1181_1, lv1182_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv3504 = R.call_tir(cls.softmax3, (lv1184_2,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv3505 = R.call_tir(cls.matmul20, (lv3504, lv1183_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1185_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv3505,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1443: R.Tensor((1280, 1280), dtype="float32") = model_params[1413]
            lv1444: R.Tensor((1280,), dtype="float32") = model_params[566]
            lv1186_2 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1185_1, lv1443, lv1444, lv1180_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1445: R.Tensor((1280,), dtype="float32") = model_params[573]
            lv1446: R.Tensor((1280,), dtype="float32") = model_params[572]
            lv3513 = R.call_tir(cls.layer_norm2, (lv1186_2, lv1445, lv1446), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1447: R.Tensor((1280, 1280), dtype="float32") = model_params[1414]
            lv3515 = R.call_tir(cls.matmul18, (lv3513, lv1447), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1448: R.Tensor((2048, 1280), dtype="float32") = model_params[1415]
            lv3517 = R.call_tir(cls.matmul21, (inp_2, lv1448), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1449: R.Tensor((2048, 1280), dtype="float32") = model_params[1416]
            lv3519 = R.call_tir(cls.matmul21, (inp_2, lv1449), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1187_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3515,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1188_2 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv3517,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv1189_1 = R.call_tir(cls.fused_reshape5_transpose1, (lv3519,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv1190_1 = R.call_tir(cls.fused_matmul22_multiply12, (lv1187_1, lv1188_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv3531 = R.call_tir(cls.softmax4, (lv1190_1,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv3532 = R.call_tir(cls.matmul23, (lv3531, lv1189_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1191_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv3532,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1450_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1417]
            lv1451: R.Tensor((1280,), dtype="float32") = model_params[567]
            lv1192_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1191_1, lv1450_1, lv1451, lv1186_2), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1452_1: R.Tensor((1280,), dtype="float32") = model_params[575]
            lv1453: R.Tensor((1280,), dtype="float32") = model_params[574]
            lv3540 = R.call_tir(cls.layer_norm2, (lv1192_1, lv1452_1, lv1453), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1454_1: R.Tensor((1280, 10240), dtype="float32") = model_params[1418]
            lv1455: R.Tensor((10240,), dtype="float32") = model_params[568]
            lv1193_1 = R.call_tir(cls.fused_matmul24_add24, (lv3540, lv1454_1, lv1455), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv1194_1 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv1193_1,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv1456_1: R.Tensor((5120, 1280), dtype="float32") = model_params[1419]
            lv1457: R.Tensor((1280,), dtype="float32") = model_params[569]
            lv1195_1 = R.call_tir(cls.fused_matmul25_add22_add23, (lv1194_1, lv1456_1, lv1457, lv1192_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1458: R.Tensor((1280,), dtype="float32") = model_params[581]
            lv1459: R.Tensor((1280,), dtype="float32") = model_params[580]
            lv3553 = R.call_tir(cls.layer_norm2, (lv1195_1, lv1458, lv1459), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1460: R.Tensor((1280, 1280), dtype="float32") = model_params[1420]
            lv3555 = R.call_tir(cls.matmul18, (lv3553, lv1460), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1461: R.Tensor((1280, 1280), dtype="float32") = model_params[1421]
            lv3557 = R.call_tir(cls.matmul18, (lv3553, lv1461), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1462: R.Tensor((1280, 1280), dtype="float32") = model_params[1422]
            lv3559 = R.call_tir(cls.matmul18, (lv3553, lv1462), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1196_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3555,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1197_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv3557,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv1198_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3559,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1199_1 = R.call_tir(cls.fused_matmul19_multiply11, (lv1196_1, lv1197_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv3571 = R.call_tir(cls.softmax3, (lv1199_1,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv3572 = R.call_tir(cls.matmul20, (lv3571, lv1198_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1200_2 = R.call_tir(cls.fused_transpose24_reshape31, (lv3572,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1463: R.Tensor((1280, 1280), dtype="float32") = model_params[1423]
            lv1464: R.Tensor((1280,), dtype="float32") = model_params[576]
            lv1201_2 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1200_2, lv1463, lv1464, lv1195_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1465: R.Tensor((1280,), dtype="float32") = model_params[583]
            lv1466: R.Tensor((1280,), dtype="float32") = model_params[582]
            lv3580 = R.call_tir(cls.layer_norm2, (lv1201_2, lv1465, lv1466), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1467: R.Tensor((1280, 1280), dtype="float32") = model_params[1424]
            lv3582 = R.call_tir(cls.matmul18, (lv3580, lv1467), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1468_1: R.Tensor((2048, 1280), dtype="float32") = model_params[1425]
            lv3584 = R.call_tir(cls.matmul21, (inp_2, lv1468_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1469_1: R.Tensor((2048, 1280), dtype="float32") = model_params[1426]
            lv3586 = R.call_tir(cls.matmul21, (inp_2, lv1469_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1202_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3582,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1203_1 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv3584,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv1204_1 = R.call_tir(cls.fused_reshape5_transpose1, (lv3586,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv1205_1 = R.call_tir(cls.fused_matmul22_multiply12, (lv1202_1, lv1203_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv3598 = R.call_tir(cls.softmax4, (lv1205_1,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv3599 = R.call_tir(cls.matmul23, (lv3598, lv1204_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1206_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv3599,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1470: R.Tensor((1280, 1280), dtype="float32") = model_params[1427]
            lv1471: R.Tensor((1280,), dtype="float32") = model_params[577]
            lv1207_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1206_1, lv1470, lv1471, lv1201_2), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1472: R.Tensor((1280,), dtype="float32") = model_params[585]
            lv1473: R.Tensor((1280,), dtype="float32") = model_params[584]
            lv3607 = R.call_tir(cls.layer_norm2, (lv1207_1, lv1472, lv1473), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1474: R.Tensor((1280, 10240), dtype="float32") = model_params[1428]
            lv1475: R.Tensor((10240,), dtype="float32") = model_params[578]
            lv1208_1 = R.call_tir(cls.fused_matmul24_add24, (lv3607, lv1474, lv1475), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv1209_2 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv1208_1,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv1476: R.Tensor((5120, 1280), dtype="float32") = model_params[1429]
            lv1477_1: R.Tensor((1280,), dtype="float32") = model_params[579]
            lv1210_1 = R.call_tir(cls.fused_matmul25_add22_add23, (lv1209_2, lv1476, lv1477_1, lv1207_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1478: R.Tensor((1280,), dtype="float32") = model_params[591]
            lv1479: R.Tensor((1280,), dtype="float32") = model_params[590]
            lv3620 = R.call_tir(cls.layer_norm2, (lv1210_1, lv1478, lv1479), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1480: R.Tensor((1280, 1280), dtype="float32") = model_params[1430]
            lv3622 = R.call_tir(cls.matmul18, (lv3620, lv1480), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1481: R.Tensor((1280, 1280), dtype="float32") = model_params[1431]
            lv3624 = R.call_tir(cls.matmul18, (lv3620, lv1481), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1482: R.Tensor((1280, 1280), dtype="float32") = model_params[1432]
            lv3626 = R.call_tir(cls.matmul18, (lv3620, lv1482), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1211_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3622,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1212_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv3624,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv1213_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3626,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1214_1 = R.call_tir(cls.fused_matmul19_multiply11, (lv1211_1, lv1212_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv3638 = R.call_tir(cls.softmax3, (lv1214_1,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv3639 = R.call_tir(cls.matmul20, (lv3638, lv1213_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1215_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv3639,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1483: R.Tensor((1280, 1280), dtype="float32") = model_params[1433]
            lv1484: R.Tensor((1280,), dtype="float32") = model_params[586]
            lv1216_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1215_1, lv1483, lv1484, lv1210_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1485: R.Tensor((1280,), dtype="float32") = model_params[593]
            lv1486: R.Tensor((1280,), dtype="float32") = model_params[592]
            lv3647 = R.call_tir(cls.layer_norm2, (lv1216_1, lv1485, lv1486), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1487: R.Tensor((1280, 1280), dtype="float32") = model_params[1434]
            lv3649 = R.call_tir(cls.matmul18, (lv3647, lv1487), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1488: R.Tensor((2048, 1280), dtype="float32") = model_params[1435]
            lv3651 = R.call_tir(cls.matmul21, (inp_2, lv1488), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1489: R.Tensor((2048, 1280), dtype="float32") = model_params[1436]
            lv3653 = R.call_tir(cls.matmul21, (inp_2, lv1489), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1217_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3649,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1218_1 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv3651,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv1219_1 = R.call_tir(cls.fused_reshape5_transpose1, (lv3653,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv1220_1 = R.call_tir(cls.fused_matmul22_multiply12, (lv1217_1, lv1218_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv3665 = R.call_tir(cls.softmax4, (lv1220_1,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv3666 = R.call_tir(cls.matmul23, (lv3665, lv1219_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1221_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv3666,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1490_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1437]
            lv1491: R.Tensor((1280,), dtype="float32") = model_params[587]
            lv1222_2 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1221_1, lv1490_1, lv1491, lv1216_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1492_1: R.Tensor((1280,), dtype="float32") = model_params[595]
            lv1493: R.Tensor((1280,), dtype="float32") = model_params[594]
            lv3674 = R.call_tir(cls.layer_norm2, (lv1222_2, lv1492_1, lv1493), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1494_1: R.Tensor((1280, 10240), dtype="float32") = model_params[1438]
            lv1495: R.Tensor((10240,), dtype="float32") = model_params[588]
            lv1223_1 = R.call_tir(cls.fused_matmul24_add24, (lv3674, lv1494_1, lv1495), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv1224_2 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv1223_1,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv1496_1: R.Tensor((5120, 1280), dtype="float32") = model_params[1439]
            lv1497: R.Tensor((1280,), dtype="float32") = model_params[589]
            lv1225_1 = R.call_tir(cls.fused_matmul25_add22_add23, (lv1224_2, lv1496_1, lv1497, lv1222_2), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1498: R.Tensor((1280,), dtype="float32") = model_params[601]
            lv1499: R.Tensor((1280,), dtype="float32") = model_params[600]
            lv3687 = R.call_tir(cls.layer_norm2, (lv1225_1, lv1498, lv1499), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1500: R.Tensor((1280, 1280), dtype="float32") = model_params[1440]
            lv3689 = R.call_tir(cls.matmul18, (lv3687, lv1500), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1501: R.Tensor((1280, 1280), dtype="float32") = model_params[1441]
            lv3691 = R.call_tir(cls.matmul18, (lv3687, lv1501), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1502: R.Tensor((1280, 1280), dtype="float32") = model_params[1442]
            lv3693 = R.call_tir(cls.matmul18, (lv3687, lv1502), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1226_2 = R.call_tir(cls.fused_reshape30_transpose22, (lv3689,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1227_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv3691,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv1228_2 = R.call_tir(cls.fused_reshape30_transpose22, (lv3693,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1229_1 = R.call_tir(cls.fused_matmul19_multiply11, (lv1226_2, lv1227_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv3705 = R.call_tir(cls.softmax3, (lv1229_1,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv3706 = R.call_tir(cls.matmul20, (lv3705, lv1228_2), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1230_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv3706,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1503: R.Tensor((1280, 1280), dtype="float32") = model_params[1443]
            lv1504: R.Tensor((1280,), dtype="float32") = model_params[596]
            lv1231_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1230_1, lv1503, lv1504, lv1225_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1505: R.Tensor((1280,), dtype="float32") = model_params[603]
            lv1506: R.Tensor((1280,), dtype="float32") = model_params[602]
            lv3714 = R.call_tir(cls.layer_norm2, (lv1231_1, lv1505, lv1506), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1507: R.Tensor((1280, 1280), dtype="float32") = model_params[1444]
            lv3716 = R.call_tir(cls.matmul18, (lv3714, lv1507), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1508_1: R.Tensor((2048, 1280), dtype="float32") = model_params[1445]
            lv3718 = R.call_tir(cls.matmul21, (inp_2, lv1508_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1509_1: R.Tensor((2048, 1280), dtype="float32") = model_params[1446]
            lv3720 = R.call_tir(cls.matmul21, (inp_2, lv1509_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1232_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3716,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1233_1 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv3718,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv1234_1 = R.call_tir(cls.fused_reshape5_transpose1, (lv3720,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv1235_1 = R.call_tir(cls.fused_matmul22_multiply12, (lv1232_1, lv1233_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv3732 = R.call_tir(cls.softmax4, (lv1235_1,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv3733 = R.call_tir(cls.matmul23, (lv3732, lv1234_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1236_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv3733,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1510: R.Tensor((1280, 1280), dtype="float32") = model_params[1447]
            lv1511: R.Tensor((1280,), dtype="float32") = model_params[597]
            lv1237_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1236_1, lv1510, lv1511, lv1231_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1512: R.Tensor((1280,), dtype="float32") = model_params[605]
            lv1513: R.Tensor((1280,), dtype="float32") = model_params[604]
            lv3741 = R.call_tir(cls.layer_norm2, (lv1237_1, lv1512, lv1513), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1514: R.Tensor((1280, 10240), dtype="float32") = model_params[1448]
            lv1515: R.Tensor((10240,), dtype="float32") = model_params[598]
            lv1238_1 = R.call_tir(cls.fused_matmul24_add24, (lv3741, lv1514, lv1515), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv1239_1 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv1238_1,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv1516: R.Tensor((5120, 1280), dtype="float32") = model_params[1449]
            lv1517_1: R.Tensor((1280,), dtype="float32") = model_params[599]
            lv1240_2 = R.call_tir(cls.fused_matmul25_add22_add23, (lv1239_1, lv1516, lv1517_1, lv1237_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1518: R.Tensor((1280,), dtype="float32") = model_params[611]
            lv1519_1: R.Tensor((1280,), dtype="float32") = model_params[610]
            lv3754 = R.call_tir(cls.layer_norm2, (lv1240_2, lv1518, lv1519_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1520: R.Tensor((1280, 1280), dtype="float32") = model_params[1450]
            lv3756 = R.call_tir(cls.matmul18, (lv3754, lv1520), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1521_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1451]
            lv3758 = R.call_tir(cls.matmul18, (lv3754, lv1521_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1522: R.Tensor((1280, 1280), dtype="float32") = model_params[1452]
            lv3760 = R.call_tir(cls.matmul18, (lv3754, lv1522), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1241_2 = R.call_tir(cls.fused_reshape30_transpose22, (lv3756,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1242_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv3758,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv1243_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3760,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1244_1 = R.call_tir(cls.fused_matmul19_multiply11, (lv1241_2, lv1242_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv3772 = R.call_tir(cls.softmax3, (lv1244_1,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv3773 = R.call_tir(cls.matmul20, (lv3772, lv1243_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1245_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv3773,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1523_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1453]
            lv1524: R.Tensor((1280,), dtype="float32") = model_params[606]
            lv1246_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1245_1, lv1523_1, lv1524, lv1240_2), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1525: R.Tensor((1280,), dtype="float32") = model_params[613]
            lv1526: R.Tensor((1280,), dtype="float32") = model_params[612]
            lv3781 = R.call_tir(cls.layer_norm2, (lv1246_1, lv1525, lv1526), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1527: R.Tensor((1280, 1280), dtype="float32") = model_params[1454]
            lv3783 = R.call_tir(cls.matmul18, (lv3781, lv1527), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1528: R.Tensor((2048, 1280), dtype="float32") = model_params[1455]
            lv3785 = R.call_tir(cls.matmul21, (inp_2, lv1528), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1529: R.Tensor((2048, 1280), dtype="float32") = model_params[1456]
            lv3787 = R.call_tir(cls.matmul21, (inp_2, lv1529), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1247_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3783,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1248_1 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv3785,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv1249_2 = R.call_tir(cls.fused_reshape5_transpose1, (lv3787,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv1250_1 = R.call_tir(cls.fused_matmul22_multiply12, (lv1247_1, lv1248_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv3799 = R.call_tir(cls.softmax4, (lv1250_1,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv3800 = R.call_tir(cls.matmul23, (lv3799, lv1249_2), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1251_2 = R.call_tir(cls.fused_transpose24_reshape31, (lv3800,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1530: R.Tensor((1280, 1280), dtype="float32") = model_params[1457]
            lv1531: R.Tensor((1280,), dtype="float32") = model_params[607]
            lv1252_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1251_2, lv1530, lv1531, lv1246_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1532: R.Tensor((1280,), dtype="float32") = model_params[615]
            lv1533: R.Tensor((1280,), dtype="float32") = model_params[614]
            lv3808 = R.call_tir(cls.layer_norm2, (lv1252_1, lv1532, lv1533), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1534: R.Tensor((1280, 10240), dtype="float32") = model_params[1458]
            lv1535_1: R.Tensor((10240,), dtype="float32") = model_params[608]
            lv1253_2 = R.call_tir(cls.fused_matmul24_add24, (lv3808, lv1534, lv1535_1), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv1254_1 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv1253_2,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv1536_1: R.Tensor((5120, 1280), dtype="float32") = model_params[1459]
            lv1537: R.Tensor((1280,), dtype="float32") = model_params[609]
            lv1255_2 = R.call_tir(cls.fused_matmul25_add22_add23, (lv1254_1, lv1536_1, lv1537, lv1252_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1538: R.Tensor((1280,), dtype="float32") = model_params[621]
            lv1539: R.Tensor((1280,), dtype="float32") = model_params[620]
            lv3821 = R.call_tir(cls.layer_norm2, (lv1255_2, lv1538, lv1539), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1540: R.Tensor((1280, 1280), dtype="float32") = model_params[1460]
            lv3823 = R.call_tir(cls.matmul18, (lv3821, lv1540), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1541: R.Tensor((1280, 1280), dtype="float32") = model_params[1461]
            lv3825 = R.call_tir(cls.matmul18, (lv3821, lv1541), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1542: R.Tensor((1280, 1280), dtype="float32") = model_params[1462]
            lv3827 = R.call_tir(cls.matmul18, (lv3821, lv1542), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1256_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3823,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1257_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv3825,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv1258_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3827,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1259_1 = R.call_tir(cls.fused_matmul19_multiply11, (lv1256_1, lv1257_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv3839 = R.call_tir(cls.softmax3, (lv1259_1,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv3840 = R.call_tir(cls.matmul20, (lv3839, lv1258_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1260_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv3840,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1543: R.Tensor((1280, 1280), dtype="float32") = model_params[1463]
            lv1544_1: R.Tensor((1280,), dtype="float32") = model_params[616]
            lv1261_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1260_1, lv1543, lv1544_1, lv1255_2), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1545: R.Tensor((1280,), dtype="float32") = model_params[623]
            lv1546: R.Tensor((1280,), dtype="float32") = model_params[622]
            lv3848 = R.call_tir(cls.layer_norm2, (lv1261_1, lv1545, lv1546), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1547: R.Tensor((1280, 1280), dtype="float32") = model_params[1464]
            lv3850 = R.call_tir(cls.matmul18, (lv3848, lv1547), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1548: R.Tensor((2048, 1280), dtype="float32") = model_params[1465]
            lv3852 = R.call_tir(cls.matmul21, (inp_2, lv1548), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1549: R.Tensor((2048, 1280), dtype="float32") = model_params[1466]
            lv3854 = R.call_tir(cls.matmul21, (inp_2, lv1549), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1262_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3850,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1263_1 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv3852,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv1264_1 = R.call_tir(cls.fused_reshape5_transpose1, (lv3854,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv1265_1 = R.call_tir(cls.fused_matmul22_multiply12, (lv1262_1, lv1263_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv3866 = R.call_tir(cls.softmax4, (lv1265_1,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv3867 = R.call_tir(cls.matmul23, (lv3866, lv1264_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1266_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv3867,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1550: R.Tensor((1280, 1280), dtype="float32") = model_params[1467]
            lv1551: R.Tensor((1280,), dtype="float32") = model_params[617]
            lv1267_2 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1266_1, lv1550, lv1551, lv1261_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1552: R.Tensor((1280,), dtype="float32") = model_params[625]
            lv1553: R.Tensor((1280,), dtype="float32") = model_params[624]
            lv3875 = R.call_tir(cls.layer_norm2, (lv1267_2, lv1552, lv1553), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1554: R.Tensor((1280, 10240), dtype="float32") = model_params[1468]
            lv1555: R.Tensor((10240,), dtype="float32") = model_params[618]
            lv1268_2 = R.call_tir(cls.fused_matmul24_add24, (lv3875, lv1554, lv1555), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv1269_1 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv1268_2,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv1556: R.Tensor((5120, 1280), dtype="float32") = model_params[1469]
            lv1557_1: R.Tensor((1280,), dtype="float32") = model_params[619]
            lv1270_1 = R.call_tir(cls.fused_matmul25_add22_add23, (lv1269_1, lv1556, lv1557_1, lv1267_2), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1558: R.Tensor((1280,), dtype="float32") = model_params[631]
            lv1559_1: R.Tensor((1280,), dtype="float32") = model_params[630]
            lv3888 = R.call_tir(cls.layer_norm2, (lv1270_1, lv1558, lv1559_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1560: R.Tensor((1280, 1280), dtype="float32") = model_params[1470]
            lv3890 = R.call_tir(cls.matmul18, (lv3888, lv1560), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1561_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1471]
            lv3892 = R.call_tir(cls.matmul18, (lv3888, lv1561_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1562: R.Tensor((1280, 1280), dtype="float32") = model_params[1472]
            lv3894 = R.call_tir(cls.matmul18, (lv3888, lv1562), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1271_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3890,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1272_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv3892,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv1273_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3894,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1274_1 = R.call_tir(cls.fused_matmul19_multiply11, (lv1271_1, lv1272_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv3906 = R.call_tir(cls.softmax3, (lv1274_1,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv3907 = R.call_tir(cls.matmul20, (lv3906, lv1273_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1275_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv3907,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1563_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1473]
            lv1564: R.Tensor((1280,), dtype="float32") = model_params[626]
            lv1276_2 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1275_1, lv1563_1, lv1564, lv1270_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1565: R.Tensor((1280,), dtype="float32") = model_params[633]
            lv1566: R.Tensor((1280,), dtype="float32") = model_params[632]
            lv3915 = R.call_tir(cls.layer_norm2, (lv1276_2, lv1565, lv1566), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1567: R.Tensor((1280, 1280), dtype="float32") = model_params[1474]
            lv3917 = R.call_tir(cls.matmul18, (lv3915, lv1567), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1568: R.Tensor((2048, 1280), dtype="float32") = model_params[1475]
            lv3919 = R.call_tir(cls.matmul21, (inp_2, lv1568), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1569: R.Tensor((2048, 1280), dtype="float32") = model_params[1476]
            lv3921 = R.call_tir(cls.matmul21, (inp_2, lv1569), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1277_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3917,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1278_1 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv3919,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv1279_1 = R.call_tir(cls.fused_reshape5_transpose1, (lv3921,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv1280_1 = R.call_tir(cls.fused_matmul22_multiply12, (lv1277_1, lv1278_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv3933 = R.call_tir(cls.softmax4, (lv1280_1,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv3934 = R.call_tir(cls.matmul23, (lv3933, lv1279_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1281_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv3934,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1570: R.Tensor((1280, 1280), dtype="float32") = model_params[1477]
            lv1571: R.Tensor((1280,), dtype="float32") = model_params[627]
            lv1282_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1281_1, lv1570, lv1571, lv1276_2), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1572: R.Tensor((1280,), dtype="float32") = model_params[635]
            lv1573: R.Tensor((1280,), dtype="float32") = model_params[634]
            lv3942 = R.call_tir(cls.layer_norm2, (lv1282_1, lv1572, lv1573), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1574: R.Tensor((1280, 10240), dtype="float32") = model_params[1478]
            lv1575_1: R.Tensor((10240,), dtype="float32") = model_params[628]
            lv1283_1 = R.call_tir(cls.fused_matmul24_add24, (lv3942, lv1574, lv1575_1), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv1284_1 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv1283_1,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv1576_1: R.Tensor((5120, 1280), dtype="float32") = model_params[1479]
            lv1577: R.Tensor((1280,), dtype="float32") = model_params[629]
            lv1285_1 = R.call_tir(cls.fused_matmul25_add22_add23, (lv1284_1, lv1576_1, lv1577, lv1282_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1578: R.Tensor((1280, 1280), dtype="float32") = model_params[1480]
            lv1579: R.Tensor((1280,), dtype="float32") = model_params[535]
            lv1286_1 = R.call_tir(cls.fused_matmul18_add22, (lv1285_1, lv1578, lv1579), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1287_1 = R.call_tir(cls.fused_reshape32_transpose28_add21_concatenate5, (lv1286_1, lv1133_1, lv484), out_sinfo=R.Tensor((1, 1920, 16, 16), dtype="float32"))
            lv1580: R.Tensor((1920,), dtype="float32") = model_params[760]
            lv1581: R.Tensor((1920,), dtype="float32") = model_params[759]
            lv1288_1 = R.call_tir(cls.fused_group_norm8_silu7, (lv1287_1, lv1580, lv1581), out_sinfo=R.Tensor((1, 1920, 16, 16), dtype="float32"))
            lv3967 = R.call_tir(cls.silu, (lv392,), out_sinfo=R.Tensor((1, 1280), dtype="float32"))
            lv1582: R.Tensor((1280, 1280), dtype="float32") = model_params[1482]
            lv1583: R.Tensor((1280,), dtype="float32") = model_params[763]
            lv1289_2 = R.call_tir(cls.fused_matmul5_add7_strided_slice, (lv3967, lv1582, lv1583), out_sinfo=R.Tensor((1, 1280), dtype="float32"))
            lv3972 = R.call_tir(cls.reshape28, (lv1289_2,), out_sinfo=R.Tensor((1, 1280, 1, 1), dtype="float32"))
            lv1584_1: R.Tensor((1280, 1920, 3, 3), dtype="float32") = model_params[756]
            lv1585: R.Tensor((1, 1280, 1, 1), dtype="float32") = model_params[1481]
            lv1290_1 = R.call_tir(cls.fused_conv2d12_add20_add20, (lv1288_1, lv1584_1, lv1585, lv3972), out_sinfo=R.Tensor((1, 1280, 16, 16), dtype="float32"))
            lv1586_1: R.Tensor((1280,), dtype="float32") = model_params[762]
            lv1587: R.Tensor((1280,), dtype="float32") = model_params[761]
            lv1291_2 = R.call_tir(cls.fused_group_norm5_silu5, (lv1290_1, lv1586_1, lv1587), out_sinfo=R.Tensor((1, 1280, 16, 16), dtype="float32"))
            lv1588_1: R.Tensor((1280, 1920, 1, 1), dtype="float32") = model_params[758]
            lv1589: R.Tensor((1, 1280, 1, 1), dtype="float32") = model_params[1484]
            lv1292_1 = R.call_tir(cls.fused_conv2d13_add20, (lv1287_1, lv1588_1, lv1589), out_sinfo=R.Tensor((1, 1280, 16, 16), dtype="float32"))
            lv1590_1: R.Tensor((1280, 1280, 3, 3), dtype="float32") = model_params[757]
            lv1591: R.Tensor((1, 1280, 1, 1), dtype="float32") = model_params[1483]
            lv1293_2 = R.call_tir(cls.fused_conv2d8_add20_add21_divide6, (lv1291_2, lv1590_1, lv1591, lv1292_1), out_sinfo=R.Tensor((1, 1280, 16, 16), dtype="float32"))
            lv1592: R.Tensor((1280,), dtype="float32") = model_params[637]
            lv1593: R.Tensor((1280,), dtype="float32") = model_params[636]
            lv3984 = R.call_tir(cls.group_norm6, (lv1293_2, lv1592, lv1593), out_sinfo=R.Tensor((1, 1280, 16, 16), dtype="float32"))
            lv1294_1 = R.call_tir(cls.fused_transpose21_reshape29, (lv3984,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1594: R.Tensor((1280, 1280), dtype="float32") = model_params[1485]
            lv1595: R.Tensor((1280,), dtype="float32") = model_params[638]
            lv1295_2 = R.call_tir(cls.fused_matmul18_add22, (lv1294_1, lv1594, lv1595), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1596: R.Tensor((1280,), dtype="float32") = model_params[645]
            lv1597: R.Tensor((1280,), dtype="float32") = model_params[644]
            lv3990 = R.call_tir(cls.layer_norm2, (lv1295_2, lv1596, lv1597), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1598: R.Tensor((1280, 1280), dtype="float32") = model_params[1486]
            lv3992 = R.call_tir(cls.matmul18, (lv3990, lv1598), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1599: R.Tensor((1280, 1280), dtype="float32") = model_params[1487]
            lv3994 = R.call_tir(cls.matmul18, (lv3990, lv1599), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1600: R.Tensor((1280, 1280), dtype="float32") = model_params[1488]
            lv3996 = R.call_tir(cls.matmul18, (lv3990, lv1600), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1296_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3992,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1297_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv3994,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv1298_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3996,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1299_1 = R.call_tir(cls.fused_matmul19_multiply11, (lv1296_1, lv1297_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv4008 = R.call_tir(cls.softmax3, (lv1299_1,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv4009 = R.call_tir(cls.matmul20, (lv4008, lv1298_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1300_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv4009,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1601: R.Tensor((1280, 1280), dtype="float32") = model_params[1489]
            lv1602_1: R.Tensor((1280,), dtype="float32") = model_params[640]
            lv1301_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1300_1, lv1601, lv1602_1, lv1295_2), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1603_1: R.Tensor((1280,), dtype="float32") = model_params[647]
            lv1604: R.Tensor((1280,), dtype="float32") = model_params[646]
            lv4017 = R.call_tir(cls.layer_norm2, (lv1301_1, lv1603_1, lv1604), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1605: R.Tensor((1280, 1280), dtype="float32") = model_params[1490]
            lv4019 = R.call_tir(cls.matmul18, (lv4017, lv1605), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1606: R.Tensor((2048, 1280), dtype="float32") = model_params[1491]
            lv4021 = R.call_tir(cls.matmul21, (inp_2, lv1606), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1607: R.Tensor((2048, 1280), dtype="float32") = model_params[1492]
            lv4023 = R.call_tir(cls.matmul21, (inp_2, lv1607), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1302_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv4019,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1303_1 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv4021,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv1304_1 = R.call_tir(cls.fused_reshape5_transpose1, (lv4023,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv1305_1 = R.call_tir(cls.fused_matmul22_multiply12, (lv1302_1, lv1303_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv4035 = R.call_tir(cls.softmax4, (lv1305_1,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv4036 = R.call_tir(cls.matmul23, (lv4035, lv1304_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1306_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv4036,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1608: R.Tensor((1280, 1280), dtype="float32") = model_params[1493]
            lv1609: R.Tensor((1280,), dtype="float32") = model_params[641]
            lv1307_2 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1306_1, lv1608, lv1609, lv1301_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1610: R.Tensor((1280,), dtype="float32") = model_params[649]
            lv1611_1: R.Tensor((1280,), dtype="float32") = model_params[648]
            lv4044 = R.call_tir(cls.layer_norm2, (lv1307_2, lv1610, lv1611_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1612: R.Tensor((1280, 10240), dtype="float32") = model_params[1494]
            lv1613: R.Tensor((10240,), dtype="float32") = model_params[642]
            lv1308_2 = R.call_tir(cls.fused_matmul24_add24, (lv4044, lv1612, lv1613), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv1309_1 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv1308_2,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv1614: R.Tensor((5120, 1280), dtype="float32") = model_params[1495]
            lv1615: R.Tensor((1280,), dtype="float32") = model_params[643]
            lv1310_1 = R.call_tir(cls.fused_matmul25_add22_add23, (lv1309_1, lv1614, lv1615, lv1307_2), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1616: R.Tensor((1280,), dtype="float32") = model_params[655]
            lv1617: R.Tensor((1280,), dtype="float32") = model_params[654]
            lv4057 = R.call_tir(cls.layer_norm2, (lv1310_1, lv1616, lv1617), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1618: R.Tensor((1280, 1280), dtype="float32") = model_params[1496]
            lv4059 = R.call_tir(cls.matmul18, (lv4057, lv1618), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1619: R.Tensor((1280, 1280), dtype="float32") = model_params[1497]
            lv4061 = R.call_tir(cls.matmul18, (lv4057, lv1619), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1620: R.Tensor((1280, 1280), dtype="float32") = model_params[1498]
            lv4063 = R.call_tir(cls.matmul18, (lv4057, lv1620), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1311_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv4059,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1312_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv4061,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv1313_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv4063,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1314_1 = R.call_tir(cls.fused_matmul19_multiply11, (lv1311_1, lv1312_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv4075 = R.call_tir(cls.softmax3, (lv1314_1,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv4076 = R.call_tir(cls.matmul20, (lv4075, lv1313_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1315_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv4076,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1621: R.Tensor((1280, 1280), dtype="float32") = model_params[1499]
            lv1622: R.Tensor((1280,), dtype="float32") = model_params[650]
            lv1316_2 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1315_1, lv1621, lv1622, lv1310_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1623: R.Tensor((1280,), dtype="float32") = model_params[657]
            lv1624_1: R.Tensor((1280,), dtype="float32") = model_params[656]
            lv4084 = R.call_tir(cls.layer_norm2, (lv1316_2, lv1623, lv1624_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1625: R.Tensor((1280, 1280), dtype="float32") = model_params[1500]
            lv4086 = R.call_tir(cls.matmul18, (lv4084, lv1625), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1626_1: R.Tensor((2048, 1280), dtype="float32") = model_params[1501]
            lv4088 = R.call_tir(cls.matmul21, (inp_2, lv1626_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1627: R.Tensor((2048, 1280), dtype="float32") = model_params[1502]
            lv4090 = R.call_tir(cls.matmul21, (inp_2, lv1627), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1317_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv4086,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1318_2 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv4088,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv1319_1 = R.call_tir(cls.fused_reshape5_transpose1, (lv4090,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv1320_2 = R.call_tir(cls.fused_matmul22_multiply12, (lv1317_1, lv1318_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv4102 = R.call_tir(cls.softmax4, (lv1320_2,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv4103 = R.call_tir(cls.matmul23, (lv4102, lv1319_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1321_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv4103,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1628_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1503]
            lv1629: R.Tensor((1280,), dtype="float32") = model_params[651]
            lv1322_2 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1321_1, lv1628_1, lv1629, lv1316_2), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1630_1: R.Tensor((1280,), dtype="float32") = model_params[659]
            lv1631: R.Tensor((1280,), dtype="float32") = model_params[658]
            lv4111 = R.call_tir(cls.layer_norm2, (lv1322_2, lv1630_1, lv1631), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1632: R.Tensor((1280, 10240), dtype="float32") = model_params[1504]
            lv1633: R.Tensor((10240,), dtype="float32") = model_params[652]
            lv1323_1 = R.call_tir(cls.fused_matmul24_add24, (lv4111, lv1632, lv1633), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv1324_1 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv1323_1,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv1634: R.Tensor((5120, 1280), dtype="float32") = model_params[1505]
            lv1635: R.Tensor((1280,), dtype="float32") = model_params[653]
            lv1325_1 = R.call_tir(cls.fused_matmul25_add22_add23, (lv1324_1, lv1634, lv1635, lv1322_2), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1636: R.Tensor((1280,), dtype="float32") = model_params[665]
            lv1637: R.Tensor((1280,), dtype="float32") = model_params[664]
            lv4124 = R.call_tir(cls.layer_norm2, (lv1325_1, lv1636, lv1637), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1638: R.Tensor((1280, 1280), dtype="float32") = model_params[1506]
            lv4126 = R.call_tir(cls.matmul18, (lv4124, lv1638), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1639: R.Tensor((1280, 1280), dtype="float32") = model_params[1507]
            lv4128 = R.call_tir(cls.matmul18, (lv4124, lv1639), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1640: R.Tensor((1280, 1280), dtype="float32") = model_params[1508]
            lv4130 = R.call_tir(cls.matmul18, (lv4124, lv1640), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1326_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv4126,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1327_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv4128,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv1328_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv4130,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1329_1 = R.call_tir(cls.fused_matmul19_multiply11, (lv1326_1, lv1327_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv4142 = R.call_tir(cls.softmax3, (lv1329_1,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv4143 = R.call_tir(cls.matmul20, (lv4142, lv1328_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1330_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv4143,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1641: R.Tensor((1280, 1280), dtype="float32") = model_params[1509]
            lv1642_1: R.Tensor((1280,), dtype="float32") = model_params[660]
            lv1331_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1330_1, lv1641, lv1642_1, lv1325_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1643_1: R.Tensor((1280,), dtype="float32") = model_params[667]
            lv1644: R.Tensor((1280,), dtype="float32") = model_params[666]
            lv4151 = R.call_tir(cls.layer_norm2, (lv1331_1, lv1643_1, lv1644), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1645: R.Tensor((1280, 1280), dtype="float32") = model_params[1510]
            lv4153 = R.call_tir(cls.matmul18, (lv4151, lv1645), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1646: R.Tensor((2048, 1280), dtype="float32") = model_params[1511]
            lv4155 = R.call_tir(cls.matmul21, (inp_2, lv1646), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1647: R.Tensor((2048, 1280), dtype="float32") = model_params[1512]
            lv4157 = R.call_tir(cls.matmul21, (inp_2, lv1647), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1332_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv4153,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1333_1 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv4155,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv1334_2 = R.call_tir(cls.fused_reshape5_transpose1, (lv4157,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv1335_2 = R.call_tir(cls.fused_matmul22_multiply12, (lv1332_1, lv1333_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv4169 = R.call_tir(cls.softmax4, (lv1335_2,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv4170 = R.call_tir(cls.matmul23, (lv4169, lv1334_2), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1336_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv4170,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1648: R.Tensor((1280, 1280), dtype="float32") = model_params[1513]
            lv1649: R.Tensor((1280,), dtype="float32") = model_params[661]
            lv1337_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1336_1, lv1648, lv1649, lv1331_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1650: R.Tensor((1280,), dtype="float32") = model_params[669]
            lv1651_1: R.Tensor((1280,), dtype="float32") = model_params[668]
            lv4178 = R.call_tir(cls.layer_norm2, (lv1337_1, lv1650, lv1651_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1652: R.Tensor((1280, 10240), dtype="float32") = model_params[1514]
            lv1653_1: R.Tensor((10240,), dtype="float32") = model_params[662]
            lv1338_1 = R.call_tir(cls.fused_matmul24_add24, (lv4178, lv1652, lv1653_1), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv1339_1 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv1338_1,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv1654: R.Tensor((5120, 1280), dtype="float32") = model_params[1515]
            lv1655_1: R.Tensor((1280,), dtype="float32") = model_params[663]
            lv1340_1 = R.call_tir(cls.fused_matmul25_add22_add23, (lv1339_1, lv1654, lv1655_1, lv1337_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1656: R.Tensor((1280,), dtype="float32") = model_params[675]
            lv1657_1: R.Tensor((1280,), dtype="float32") = model_params[674]
            lv4191 = R.call_tir(cls.layer_norm2, (lv1340_1, lv1656, lv1657_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1658: R.Tensor((1280, 1280), dtype="float32") = model_params[1516]
            lv4193 = R.call_tir(cls.matmul18, (lv4191, lv1658), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1659: R.Tensor((1280, 1280), dtype="float32") = model_params[1517]
            lv4195 = R.call_tir(cls.matmul18, (lv4191, lv1659), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1660: R.Tensor((1280, 1280), dtype="float32") = model_params[1518]
            lv4197 = R.call_tir(cls.matmul18, (lv4191, lv1660), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1341_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv4193,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1342_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv4195,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv1343_2 = R.call_tir(cls.fused_reshape30_transpose22, (lv4197,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1344_1 = R.call_tir(cls.fused_matmul19_multiply11, (lv1341_1, lv1342_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv4209 = R.call_tir(cls.softmax3, (lv1344_1,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv4210 = R.call_tir(cls.matmul20, (lv4209, lv1343_2), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1345_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv4210,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1661: R.Tensor((1280, 1280), dtype="float32") = model_params[1519]
            lv1662: R.Tensor((1280,), dtype="float32") = model_params[670]
            lv1346_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1345_1, lv1661, lv1662, lv1340_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1663: R.Tensor((1280,), dtype="float32") = model_params[677]
            lv1664: R.Tensor((1280,), dtype="float32") = model_params[676]
            lv4218 = R.call_tir(cls.layer_norm2, (lv1346_1, lv1663, lv1664), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1665: R.Tensor((1280, 1280), dtype="float32") = model_params[1520]
            lv4220 = R.call_tir(cls.matmul18, (lv4218, lv1665), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1666: R.Tensor((2048, 1280), dtype="float32") = model_params[1521]
            lv4222 = R.call_tir(cls.matmul21, (inp_2, lv1666), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1667: R.Tensor((2048, 1280), dtype="float32") = model_params[1522]
            lv4224 = R.call_tir(cls.matmul21, (inp_2, lv1667), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1347_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv4220,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1348_1 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv4222,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv1349_1 = R.call_tir(cls.fused_reshape5_transpose1, (lv4224,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv1350_1 = R.call_tir(cls.fused_matmul22_multiply12, (lv1347_1, lv1348_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv4236 = R.call_tir(cls.softmax4, (lv1350_1,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv4237 = R.call_tir(cls.matmul23, (lv4236, lv1349_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1351_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv4237,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1668: R.Tensor((1280, 1280), dtype="float32") = model_params[1523]
            lv1669_1: R.Tensor((1280,), dtype="float32") = model_params[671]
            lv1352_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1351_1, lv1668, lv1669_1, lv1346_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1670_1: R.Tensor((1280,), dtype="float32") = model_params[679]
            lv1671: R.Tensor((1280,), dtype="float32") = model_params[678]
            lv4245 = R.call_tir(cls.layer_norm2, (lv1352_1, lv1670_1, lv1671), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1672: R.Tensor((1280, 10240), dtype="float32") = model_params[1524]
            lv1673: R.Tensor((10240,), dtype="float32") = model_params[672]
            lv1353_1 = R.call_tir(cls.fused_matmul24_add24, (lv4245, lv1672, lv1673), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv1354_1 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv1353_1,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv1674: R.Tensor((5120, 1280), dtype="float32") = model_params[1525]
            lv1675: R.Tensor((1280,), dtype="float32") = model_params[673]
            lv1355_1 = R.call_tir(cls.fused_matmul25_add22_add23, (lv1354_1, lv1674, lv1675, lv1352_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1676: R.Tensor((1280,), dtype="float32") = model_params[685]
            lv1677: R.Tensor((1280,), dtype="float32") = model_params[684]
            lv4258 = R.call_tir(cls.layer_norm2, (lv1355_1, lv1676, lv1677), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1678_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1526]
            lv4260 = R.call_tir(cls.matmul18, (lv4258, lv1678_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1679: R.Tensor((1280, 1280), dtype="float32") = model_params[1527]
            lv4262 = R.call_tir(cls.matmul18, (lv4258, lv1679), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1680: R.Tensor((1280, 1280), dtype="float32") = model_params[1528]
            lv4264 = R.call_tir(cls.matmul18, (lv4258, lv1680), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1356_2 = R.call_tir(cls.fused_reshape30_transpose22, (lv4260,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1357_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv4262,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv1358_2 = R.call_tir(cls.fused_reshape30_transpose22, (lv4264,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1359_1 = R.call_tir(cls.fused_matmul19_multiply11, (lv1356_2, lv1357_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv4276 = R.call_tir(cls.softmax3, (lv1359_1,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv4277 = R.call_tir(cls.matmul20, (lv4276, lv1358_2), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1360_2 = R.call_tir(cls.fused_transpose24_reshape31, (lv4277,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1681: R.Tensor((1280, 1280), dtype="float32") = model_params[1529]
            lv1682: R.Tensor((1280,), dtype="float32") = model_params[680]
            lv1361_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1360_2, lv1681, lv1682, lv1355_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1683: R.Tensor((1280,), dtype="float32") = model_params[687]
            lv1684: R.Tensor((1280,), dtype="float32") = model_params[686]
            lv4285 = R.call_tir(cls.layer_norm2, (lv1361_1, lv1683, lv1684), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1685: R.Tensor((1280, 1280), dtype="float32") = model_params[1530]
            lv4287 = R.call_tir(cls.matmul18, (lv4285, lv1685), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1686: R.Tensor((2048, 1280), dtype="float32") = model_params[1531]
            lv4289 = R.call_tir(cls.matmul21, (inp_2, lv1686), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1687: R.Tensor((2048, 1280), dtype="float32") = model_params[1532]
            lv4291 = R.call_tir(cls.matmul21, (inp_2, lv1687), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1362_2 = R.call_tir(cls.fused_reshape30_transpose22, (lv4287,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1363_1 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv4289,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv1364_1 = R.call_tir(cls.fused_reshape5_transpose1, (lv4291,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv1365_1 = R.call_tir(cls.fused_matmul22_multiply12, (lv1362_2, lv1363_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv4303 = R.call_tir(cls.softmax4, (lv1365_1,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv4304 = R.call_tir(cls.matmul23, (lv4303, lv1364_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1366_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv4304,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1688: R.Tensor((1280, 1280), dtype="float32") = model_params[1533]
            lv1689: R.Tensor((1280,), dtype="float32") = model_params[681]
            lv1367_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1366_1, lv1688, lv1689, lv1361_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1690: R.Tensor((1280,), dtype="float32") = model_params[689]
            lv1691_1: R.Tensor((1280,), dtype="float32") = model_params[688]
            lv4312 = R.call_tir(cls.layer_norm2, (lv1367_1, lv1690, lv1691_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1692: R.Tensor((1280, 10240), dtype="float32") = model_params[1534]
            lv1693_1: R.Tensor((10240,), dtype="float32") = model_params[682]
            lv1368_1 = R.call_tir(cls.fused_matmul24_add24, (lv4312, lv1692, lv1693_1), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv1369_1 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv1368_1,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv1694: R.Tensor((5120, 1280), dtype="float32") = model_params[1535]
            lv1695_1: R.Tensor((1280,), dtype="float32") = model_params[683]
            lv1370_1 = R.call_tir(cls.fused_matmul25_add22_add23, (lv1369_1, lv1694, lv1695_1, lv1367_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1696: R.Tensor((1280,), dtype="float32") = model_params[695]
            lv1697_1: R.Tensor((1280,), dtype="float32") = model_params[694]
            lv4325 = R.call_tir(cls.layer_norm2, (lv1370_1, lv1696, lv1697_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1698: R.Tensor((1280, 1280), dtype="float32") = model_params[1536]
            lv4327 = R.call_tir(cls.matmul18, (lv4325, lv1698), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1699: R.Tensor((1280, 1280), dtype="float32") = model_params[1537]
            lv4329 = R.call_tir(cls.matmul18, (lv4325, lv1699), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1700: R.Tensor((1280, 1280), dtype="float32") = model_params[1538]
            lv4331 = R.call_tir(cls.matmul18, (lv4325, lv1700), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1371_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv4327,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1372_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv4329,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv1373_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv4331,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1374_2 = R.call_tir(cls.fused_matmul19_multiply11, (lv1371_1, lv1372_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv4343 = R.call_tir(cls.softmax3, (lv1374_2,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv4344 = R.call_tir(cls.matmul20, (lv4343, lv1373_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1375_2 = R.call_tir(cls.fused_transpose24_reshape31, (lv4344,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1701: R.Tensor((1280, 1280), dtype="float32") = model_params[1539]
            lv1702: R.Tensor((1280,), dtype="float32") = model_params[690]
            lv1376_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1375_2, lv1701, lv1702, lv1370_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1703: R.Tensor((1280,), dtype="float32") = model_params[697]
            lv1704: R.Tensor((1280,), dtype="float32") = model_params[696]
            lv4352 = R.call_tir(cls.layer_norm2, (lv1376_1, lv1703, lv1704), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1705: R.Tensor((1280, 1280), dtype="float32") = model_params[1540]
            lv4354 = R.call_tir(cls.matmul18, (lv4352, lv1705), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1706: R.Tensor((2048, 1280), dtype="float32") = model_params[1541]
            lv4356 = R.call_tir(cls.matmul21, (inp_2, lv1706), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1707: R.Tensor((2048, 1280), dtype="float32") = model_params[1542]
            lv4358 = R.call_tir(cls.matmul21, (inp_2, lv1707), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1377_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv4354,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1378_1 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv4356,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv1379_1 = R.call_tir(cls.fused_reshape5_transpose1, (lv4358,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv1380_1 = R.call_tir(cls.fused_matmul22_multiply12, (lv1377_1, lv1378_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv4370 = R.call_tir(cls.softmax4, (lv1380_1,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv4371 = R.call_tir(cls.matmul23, (lv4370, lv1379_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1381_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv4371,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1708: R.Tensor((1280, 1280), dtype="float32") = model_params[1543]
            lv1709_1: R.Tensor((1280,), dtype="float32") = model_params[691]
            lv1382_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1381_1, lv1708, lv1709_1, lv1376_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1710_1: R.Tensor((1280,), dtype="float32") = model_params[699]
            lv1711: R.Tensor((1280,), dtype="float32") = model_params[698]
            lv4379 = R.call_tir(cls.layer_norm2, (lv1382_1, lv1710_1, lv1711), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1712: R.Tensor((1280, 10240), dtype="float32") = model_params[1544]
            lv1713: R.Tensor((10240,), dtype="float32") = model_params[692]
            lv1383_2 = R.call_tir(cls.fused_matmul24_add24, (lv4379, lv1712, lv1713), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv1384_1 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv1383_2,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv1714: R.Tensor((5120, 1280), dtype="float32") = model_params[1545]
            lv1715: R.Tensor((1280,), dtype="float32") = model_params[693]
            lv1385_2 = R.call_tir(cls.fused_matmul25_add22_add23, (lv1384_1, lv1714, lv1715, lv1382_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1716: R.Tensor((1280,), dtype="float32") = model_params[705]
            lv1717: R.Tensor((1280,), dtype="float32") = model_params[704]
            lv4392 = R.call_tir(cls.layer_norm2, (lv1385_2, lv1716, lv1717), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1718_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1546]
            lv4394 = R.call_tir(cls.matmul18, (lv4392, lv1718_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1719: R.Tensor((1280, 1280), dtype="float32") = model_params[1547]
            lv4396 = R.call_tir(cls.matmul18, (lv4392, lv1719), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1720_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1548]
            lv4398 = R.call_tir(cls.matmul18, (lv4392, lv1720_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1386_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv4394,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1387_2 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv4396,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv1388_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv4398,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1389_2 = R.call_tir(cls.fused_matmul19_multiply11, (lv1386_1, lv1387_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv4410 = R.call_tir(cls.softmax3, (lv1389_2,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv4411 = R.call_tir(cls.matmul20, (lv4410, lv1388_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1390_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv4411,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1721: R.Tensor((1280, 1280), dtype="float32") = model_params[1549]
            lv1722_1: R.Tensor((1280,), dtype="float32") = model_params[700]
            lv1391_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1390_1, lv1721, lv1722_1, lv1385_2), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1723: R.Tensor((1280,), dtype="float32") = model_params[707]
            lv1724_1: R.Tensor((1280,), dtype="float32") = model_params[706]
            lv4419 = R.call_tir(cls.layer_norm2, (lv1391_1, lv1723, lv1724_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1725: R.Tensor((1280, 1280), dtype="float32") = model_params[1550]
            lv4421 = R.call_tir(cls.matmul18, (lv4419, lv1725), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1726: R.Tensor((2048, 1280), dtype="float32") = model_params[1551]
            lv4423 = R.call_tir(cls.matmul21, (inp_2, lv1726), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1727: R.Tensor((2048, 1280), dtype="float32") = model_params[1552]
            lv4425 = R.call_tir(cls.matmul21, (inp_2, lv1727), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1392_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv4421,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1393_1 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv4423,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv1394_1 = R.call_tir(cls.fused_reshape5_transpose1, (lv4425,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv1395_1 = R.call_tir(cls.fused_matmul22_multiply12, (lv1392_1, lv1393_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv4437 = R.call_tir(cls.softmax4, (lv1395_1,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv4438 = R.call_tir(cls.matmul23, (lv4437, lv1394_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1396_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv4438,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1728: R.Tensor((1280, 1280), dtype="float32") = model_params[1553]
            lv1729: R.Tensor((1280,), dtype="float32") = model_params[701]
            lv1397_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1396_1, lv1728, lv1729, lv1391_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1730: R.Tensor((1280,), dtype="float32") = model_params[709]
            lv1731: R.Tensor((1280,), dtype="float32") = model_params[708]
            lv4446 = R.call_tir(cls.layer_norm2, (lv1397_1, lv1730, lv1731), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1732: R.Tensor((1280, 10240), dtype="float32") = model_params[1554]
            lv1733: R.Tensor((10240,), dtype="float32") = model_params[702]
            lv1398_1 = R.call_tir(cls.fused_matmul24_add24, (lv4446, lv1732, lv1733), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv1399_1 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv1398_1,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv1734: R.Tensor((5120, 1280), dtype="float32") = model_params[1555]
            lv1735: R.Tensor((1280,), dtype="float32") = model_params[703]
            lv1400_1 = R.call_tir(cls.fused_matmul25_add22_add23, (lv1399_1, lv1734, lv1735, lv1397_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1736_1: R.Tensor((1280,), dtype="float32") = model_params[715]
            lv1737_1: R.Tensor((1280,), dtype="float32") = model_params[714]
            lv4459 = R.call_tir(cls.layer_norm2, (lv1400_1, lv1736_1, lv1737_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1738: R.Tensor((1280, 1280), dtype="float32") = model_params[1556]
            lv4461 = R.call_tir(cls.matmul18, (lv4459, lv1738), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1739: R.Tensor((1280, 1280), dtype="float32") = model_params[1557]
            lv4463 = R.call_tir(cls.matmul18, (lv4459, lv1739), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1740: R.Tensor((1280, 1280), dtype="float32") = model_params[1558]
            lv4465 = R.call_tir(cls.matmul18, (lv4459, lv1740), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1401_2 = R.call_tir(cls.fused_reshape30_transpose22, (lv4461,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1402_2 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv4463,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv1403_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv4465,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1404_1 = R.call_tir(cls.fused_matmul19_multiply11, (lv1401_2, lv1402_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv4477 = R.call_tir(cls.softmax3, (lv1404_1,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv4478 = R.call_tir(cls.matmul20, (lv4477, lv1403_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1405_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv4478,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1741: R.Tensor((1280, 1280), dtype="float32") = model_params[1559]
            lv1742: R.Tensor((1280,), dtype="float32") = model_params[710]
            lv1406_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1405_1, lv1741, lv1742, lv1400_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1743: R.Tensor((1280,), dtype="float32") = model_params[717]
            lv1744: R.Tensor((1280,), dtype="float32") = model_params[716]
            lv4486 = R.call_tir(cls.layer_norm2, (lv1406_1, lv1743, lv1744), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1745_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1560]
            lv4488 = R.call_tir(cls.matmul18, (lv4486, lv1745_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1746: R.Tensor((2048, 1280), dtype="float32") = model_params[1561]
            lv4490 = R.call_tir(cls.matmul21, (inp_2, lv1746), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1747: R.Tensor((2048, 1280), dtype="float32") = model_params[1562]
            lv4492 = R.call_tir(cls.matmul21, (inp_2, lv1747), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1407_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv4488,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1408_1 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv4490,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv1409_1 = R.call_tir(cls.fused_reshape5_transpose1, (lv4492,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv1410_2 = R.call_tir(cls.fused_matmul22_multiply12, (lv1407_1, lv1408_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv4504 = R.call_tir(cls.softmax4, (lv1410_2,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv4505 = R.call_tir(cls.matmul23, (lv4504, lv1409_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1411_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv4505,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1748: R.Tensor((1280, 1280), dtype="float32") = model_params[1563]
            lv1749: R.Tensor((1280,), dtype="float32") = model_params[711]
            lv1412_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1411_1, lv1748, lv1749, lv1406_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1750: R.Tensor((1280,), dtype="float32") = model_params[719]
            lv1751: R.Tensor((1280,), dtype="float32") = model_params[718]
            lv4513 = R.call_tir(cls.layer_norm2, (lv1412_1, lv1750, lv1751), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1752: R.Tensor((1280, 10240), dtype="float32") = model_params[1564]
            lv1753: R.Tensor((10240,), dtype="float32") = model_params[712]
            lv1413_1 = R.call_tir(cls.fused_matmul24_add24, (lv4513, lv1752, lv1753), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv1414_1 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv1413_1,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv1754: R.Tensor((5120, 1280), dtype="float32") = model_params[1565]
            lv1755: R.Tensor((1280,), dtype="float32") = model_params[713]
            lv1415_1 = R.call_tir(cls.fused_matmul25_add22_add23, (lv1414_1, lv1754, lv1755, lv1412_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1756: R.Tensor((1280,), dtype="float32") = model_params[725]
            lv1757: R.Tensor((1280,), dtype="float32") = model_params[724]
            lv4526 = R.call_tir(cls.layer_norm2, (lv1415_1, lv1756, lv1757), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1758_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1566]
            lv4528 = R.call_tir(cls.matmul18, (lv4526, lv1758_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1759: R.Tensor((1280, 1280), dtype="float32") = model_params[1567]
            lv4530 = R.call_tir(cls.matmul18, (lv4526, lv1759), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1760_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1568]
            lv4532 = R.call_tir(cls.matmul18, (lv4526, lv1760_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1416_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv4528,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1417_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv4530,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv1418_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv4532,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1419_1 = R.call_tir(cls.fused_matmul19_multiply11, (lv1416_1, lv1417_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv4544 = R.call_tir(cls.softmax3, (lv1419_1,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv4545 = R.call_tir(cls.matmul20, (lv4544, lv1418_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1420_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv4545,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1761: R.Tensor((1280, 1280), dtype="float32") = model_params[1569]
            lv1762_1: R.Tensor((1280,), dtype="float32") = model_params[720]
            lv1421_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1420_1, lv1761, lv1762_1, lv1415_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1763: R.Tensor((1280,), dtype="float32") = model_params[727]
            lv1764_1: R.Tensor((1280,), dtype="float32") = model_params[726]
            lv4553 = R.call_tir(cls.layer_norm2, (lv1421_1, lv1763, lv1764_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1765: R.Tensor((1280, 1280), dtype="float32") = model_params[1570]
            lv4555 = R.call_tir(cls.matmul18, (lv4553, lv1765), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1766: R.Tensor((2048, 1280), dtype="float32") = model_params[1571]
            lv4557 = R.call_tir(cls.matmul21, (inp_2, lv1766), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1767: R.Tensor((2048, 1280), dtype="float32") = model_params[1572]
            lv4559 = R.call_tir(cls.matmul21, (inp_2, lv1767), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1422_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv4555,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1423_2 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv4557,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv1424_1 = R.call_tir(cls.fused_reshape5_transpose1, (lv4559,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv1425_2 = R.call_tir(cls.fused_matmul22_multiply12, (lv1422_1, lv1423_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv4571 = R.call_tir(cls.softmax4, (lv1425_2,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv4572 = R.call_tir(cls.matmul23, (lv4571, lv1424_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1426_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv4572,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1768: R.Tensor((1280, 1280), dtype="float32") = model_params[1573]
            lv1769: R.Tensor((1280,), dtype="float32") = model_params[721]
            lv1427_2 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1426_1, lv1768, lv1769, lv1421_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1770: R.Tensor((1280,), dtype="float32") = model_params[729]
            lv1771: R.Tensor((1280,), dtype="float32") = model_params[728]
            lv4580 = R.call_tir(cls.layer_norm2, (lv1427_2, lv1770, lv1771), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1772: R.Tensor((1280, 10240), dtype="float32") = model_params[1574]
            lv1773: R.Tensor((10240,), dtype="float32") = model_params[722]
            lv1428_1 = R.call_tir(cls.fused_matmul24_add24, (lv4580, lv1772, lv1773), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv1429_2 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv1428_1,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv1774: R.Tensor((5120, 1280), dtype="float32") = model_params[1575]
            lv1775: R.Tensor((1280,), dtype="float32") = model_params[723]
            lv1430_1 = R.call_tir(cls.fused_matmul25_add22_add23, (lv1429_2, lv1774, lv1775, lv1427_2), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1776_1: R.Tensor((1280,), dtype="float32") = model_params[735]
            lv1777_1: R.Tensor((1280,), dtype="float32") = model_params[734]
            lv4593 = R.call_tir(cls.layer_norm2, (lv1430_1, lv1776_1, lv1777_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1778: R.Tensor((1280, 1280), dtype="float32") = model_params[1576]
            lv4595 = R.call_tir(cls.matmul18, (lv4593, lv1778), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1779: R.Tensor((1280, 1280), dtype="float32") = model_params[1577]
            lv4597 = R.call_tir(cls.matmul18, (lv4593, lv1779), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1780: R.Tensor((1280, 1280), dtype="float32") = model_params[1578]
            lv4599 = R.call_tir(cls.matmul18, (lv4593, lv1780), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1431_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv4595,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1432_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv4597,), out_sinfo=R.Tensor((1, 20, 64, 256), dtype="float32"))
            lv1433_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv4599,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1434_1 = R.call_tir(cls.fused_matmul19_multiply11, (lv1431_1, lv1432_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv4611 = R.call_tir(cls.softmax3, (lv1434_1,), out_sinfo=R.Tensor((1, 20, 256, 256), dtype="float32"))
            lv4612 = R.call_tir(cls.matmul20, (lv4611, lv1433_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1435_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv4612,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1781: R.Tensor((1280, 1280), dtype="float32") = model_params[1579]
            lv1782: R.Tensor((1280,), dtype="float32") = model_params[730]
            lv1436_1 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1435_1, lv1781, lv1782, lv1430_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1783: R.Tensor((1280,), dtype="float32") = model_params[737]
            lv1784: R.Tensor((1280,), dtype="float32") = model_params[736]
            lv4620 = R.call_tir(cls.layer_norm2, (lv1436_1, lv1783, lv1784), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1785_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1580]
            lv4622 = R.call_tir(cls.matmul18, (lv4620, lv1785_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1786: R.Tensor((2048, 1280), dtype="float32") = model_params[1581]
            lv4624 = R.call_tir(cls.matmul21, (inp_2, lv1786), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1787_1: R.Tensor((2048, 1280), dtype="float32") = model_params[1582]
            lv4626 = R.call_tir(cls.matmul21, (inp_2, lv1787_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1437_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv4622,), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1438_1 = R.call_tir(cls.fused_reshape5_transpose1_transpose26, (lv4624,), out_sinfo=R.Tensor((1, 20, 64, 77), dtype="float32"))
            lv1439_1 = R.call_tir(cls.fused_reshape5_transpose1, (lv4626,), out_sinfo=R.Tensor((1, 20, 77, 64), dtype="float32"))
            lv1440_1 = R.call_tir(cls.fused_matmul22_multiply12, (lv1437_1, lv1438_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv4638 = R.call_tir(cls.softmax4, (lv1440_1,), out_sinfo=R.Tensor((1, 20, 256, 77), dtype="float32"))
            lv4639 = R.call_tir(cls.matmul23, (lv4638, lv1439_1), out_sinfo=R.Tensor((1, 20, 256, 64), dtype="float32"))
            lv1441_2 = R.call_tir(cls.fused_transpose24_reshape31, (lv4639,), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1788: R.Tensor((1280, 1280), dtype="float32") = model_params[1583]
            lv1789_1: R.Tensor((1280,), dtype="float32") = model_params[731]
            lv1442_2 = R.call_tir(cls.fused_matmul18_add22_divide7_add23, (lv1441_2, lv1788, lv1789_1, lv1436_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1790: R.Tensor((1280,), dtype="float32") = model_params[739]
            lv1791_1: R.Tensor((1280,), dtype="float32") = model_params[738]
            lv4647 = R.call_tir(cls.layer_norm2, (lv1442_2, lv1790, lv1791_1), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1792: R.Tensor((1280, 10240), dtype="float32") = model_params[1584]
            lv1793: R.Tensor((10240,), dtype="float32") = model_params[732]
            lv1443_1 = R.call_tir(cls.fused_matmul24_add24, (lv4647, lv1792, lv1793), out_sinfo=R.Tensor((1, 256, 10240), dtype="float32"))
            lv1444_1 = R.call_tir(cls.fused_split1_gelu2_multiply13, (lv1443_1,), out_sinfo=R.Tensor((1, 256, 5120), dtype="float32"))
            lv1794: R.Tensor((5120, 1280), dtype="float32") = model_params[1585]
            lv1795: R.Tensor((1280,), dtype="float32") = model_params[733]
            lv1445_1 = R.call_tir(cls.fused_matmul25_add22_add23, (lv1444_1, lv1794, lv1795, lv1442_2), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1796: R.Tensor((1280, 1280), dtype="float32") = model_params[1586]
            lv1797: R.Tensor((1280,), dtype="float32") = model_params[639]
            lv1446_1 = R.call_tir(cls.fused_matmul18_add22, (lv1445_1, lv1796, lv1797), out_sinfo=R.Tensor((1, 256, 1280), dtype="float32"))
            lv1447_1 = R.call_tir(cls.fused_reshape32_transpose28_add21_resize2d, (lv1446_1, lv1293_2), out_sinfo=R.Tensor((1, 1280, 32, 32), dtype="float32"))
            lv1798: R.Tensor((1280, 1280, 3, 3), dtype="float32") = model_params[764]
            lv1799: R.Tensor((1, 1280, 1, 1), dtype="float32") = model_params[1587]
            lv1448_1 = R.call_tir(cls.fused_conv2d14_add25, (lv1447_1, lv1798, lv1799), out_sinfo=R.Tensor((1, 1280, 32, 32), dtype="float32"))
            lv4670 = R.call_tir(cls.concatenate6, (lv1448_1, lv483), out_sinfo=R.Tensor((1, 1920, 32, 32), dtype="float32"))
            lv1800: R.Tensor((1920,), dtype="float32") = model_params[841]
            lv1801: R.Tensor((1920,), dtype="float32") = model_params[840]
            lv1449_1 = R.call_tir(cls.fused_group_norm9_silu8, (lv4670, lv1800, lv1801), out_sinfo=R.Tensor((1, 1920, 32, 32), dtype="float32"))
            lv4676 = R.call_tir(cls.silu, (lv392,), out_sinfo=R.Tensor((1, 1280), dtype="float32"))
            lv1802: R.Tensor((1280, 640), dtype="float32") = model_params[1589]
            lv1803_1: R.Tensor((640,), dtype="float32") = model_params[844]
            lv1450_2 = R.call_tir(cls.fused_matmul9_add14_strided_slice7, (lv4676, lv1802, lv1803_1), out_sinfo=R.Tensor((1, 640), dtype="float32"))
            lv4681 = R.call_tir(cls.reshape21, (lv1450_2,), out_sinfo=R.Tensor((1, 640, 1, 1), dtype="float32"))
            lv1804_1: R.Tensor((640, 1920, 3, 3), dtype="float32") = model_params[837]
            lv1805: R.Tensor((1, 640, 1, 1), dtype="float32") = model_params[1588]
            lv1451_1 = R.call_tir(cls.fused_conv2d15_add13_add13, (lv1449_1, lv1804_1, lv1805, lv4681), out_sinfo=R.Tensor((1, 640, 32, 32), dtype="float32"))
            lv1806: R.Tensor((640,), dtype="float32") = model_params[843]
            lv1807: R.Tensor((640,), dtype="float32") = model_params[842]
            lv1452_2 = R.call_tir(cls.fused_group_norm2_silu3, (lv1451_1, lv1806, lv1807), out_sinfo=R.Tensor((1, 640, 32, 32), dtype="float32"))
            lv1808: R.Tensor((640, 1920, 1, 1), dtype="float32") = model_params[839]
            lv1809: R.Tensor((1, 640, 1, 1), dtype="float32") = model_params[1591]
            lv1453_1 = R.call_tir(cls.fused_conv2d16_add13, (lv4670, lv1808, lv1809), out_sinfo=R.Tensor((1, 640, 32, 32), dtype="float32"))
            lv1810: R.Tensor((640, 640, 3, 3), dtype="float32") = model_params[838]
            lv1811: R.Tensor((1, 640, 1, 1), dtype="float32") = model_params[1590]
            lv1454_2 = R.call_tir(cls.fused_conv2d4_add13_add15_divide3, (lv1452_2, lv1810, lv1811, lv1453_1), out_sinfo=R.Tensor((1, 640, 32, 32), dtype="float32"))
            lv1812_1: R.Tensor((640,), dtype="float32") = model_params[766]
            lv1813: R.Tensor((640,), dtype="float32") = model_params[765]
            lv4693 = R.call_tir(cls.group_norm3, (lv1454_2, lv1812_1, lv1813), out_sinfo=R.Tensor((1, 640, 32, 32), dtype="float32"))
            lv1455_1 = R.call_tir(cls.fused_transpose10_reshape22, (lv4693,), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1814: R.Tensor((640, 640), dtype="float32") = model_params[1592]
            lv1815: R.Tensor((640,), dtype="float32") = model_params[767]
            lv1456_2 = R.call_tir(cls.fused_matmul10_add16, (lv1455_1, lv1814, lv1815), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1816: R.Tensor((640,), dtype="float32") = model_params[774]
            lv1817: R.Tensor((640,), dtype="float32") = model_params[773]
            lv4699 = R.call_tir(cls.layer_norm1, (lv1456_2, lv1816, lv1817), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1818: R.Tensor((640, 640), dtype="float32") = model_params[1593]
            lv4701 = R.call_tir(cls.matmul10, (lv4699, lv1818), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1819: R.Tensor((640, 640), dtype="float32") = model_params[1594]
            lv4703 = R.call_tir(cls.matmul10, (lv4699, lv1819), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1820: R.Tensor((640, 640), dtype="float32") = model_params[1595]
            lv4705 = R.call_tir(cls.matmul10, (lv4699, lv1820), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1457_1 = R.call_tir(cls.fused_reshape23_transpose12, (lv4701,), out_sinfo=R.Tensor((1, 10, 1024, 64), dtype="float32"))
            lv1458_1 = R.call_tir(cls.fused_reshape23_transpose12_transpose13, (lv4703,), out_sinfo=R.Tensor((1, 10, 64, 1024), dtype="float32"))
            lv1459_1 = R.call_tir(cls.fused_reshape23_transpose12, (lv4705,), out_sinfo=R.Tensor((1, 10, 1024, 64), dtype="float32"))
            lv1460_1 = R.call_tir(cls.fused_matmul11_multiply8, (lv1457_1, lv1458_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 10, 1024, 1024), dtype="float32"))
            lv4717 = R.call_tir(cls.softmax1, (lv1460_1,), out_sinfo=R.Tensor((1, 10, 1024, 1024), dtype="float32"))
            lv4718 = R.call_tir(cls.matmul12, (lv4717, lv1459_1), out_sinfo=R.Tensor((1, 10, 1024, 64), dtype="float32"))
            lv1461_1 = R.call_tir(cls.fused_transpose14_reshape24, (lv4718,), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1821: R.Tensor((640, 640), dtype="float32") = model_params[1596]
            lv1822: R.Tensor((640,), dtype="float32") = model_params[769]
            lv1462_1 = R.call_tir(cls.fused_matmul10_add16_divide5_add17, (lv1461_1, lv1821, lv1822, lv1456_2), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1823: R.Tensor((640,), dtype="float32") = model_params[776]
            lv1824: R.Tensor((640,), dtype="float32") = model_params[775]
            lv4726 = R.call_tir(cls.layer_norm1, (lv1462_1, lv1823, lv1824), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1825: R.Tensor((640, 640), dtype="float32") = model_params[1597]
            lv4728 = R.call_tir(cls.matmul10, (lv4726, lv1825), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1826: R.Tensor((2048, 640), dtype="float32") = model_params[1598]
            lv4730 = R.call_tir(cls.matmul13, (inp_2, lv1826), out_sinfo=R.Tensor((1, 77, 640), dtype="float32"))
            lv1827: R.Tensor((2048, 640), dtype="float32") = model_params[1599]
            lv4732 = R.call_tir(cls.matmul13, (inp_2, lv1827), out_sinfo=R.Tensor((1, 77, 640), dtype="float32"))
            lv1463_1 = R.call_tir(cls.fused_reshape23_transpose12, (lv4728,), out_sinfo=R.Tensor((1, 10, 1024, 64), dtype="float32"))
            lv1464_1 = R.call_tir(cls.fused_reshape25_transpose16_transpose17, (lv4730,), out_sinfo=R.Tensor((1, 10, 64, 77), dtype="float32"))
            lv1465_1 = R.call_tir(cls.fused_reshape25_transpose16, (lv4732,), out_sinfo=R.Tensor((1, 10, 77, 64), dtype="float32"))
            lv1466_1 = R.call_tir(cls.fused_matmul14_multiply9, (lv1463_1, lv1464_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 10, 1024, 77), dtype="float32"))
            lv4744 = R.call_tir(cls.softmax2, (lv1466_1,), out_sinfo=R.Tensor((1, 10, 1024, 77), dtype="float32"))
            lv4745 = R.call_tir(cls.matmul15, (lv4744, lv1465_1), out_sinfo=R.Tensor((1, 10, 1024, 64), dtype="float32"))
            lv1467_1 = R.call_tir(cls.fused_transpose14_reshape24, (lv4745,), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1828: R.Tensor((640, 640), dtype="float32") = model_params[1600]
            lv1829: R.Tensor((640,), dtype="float32") = model_params[770]
            lv1468_2 = R.call_tir(cls.fused_matmul10_add16_divide5_add17, (lv1467_1, lv1828, lv1829, lv1462_1), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1830: R.Tensor((640,), dtype="float32") = model_params[778]
            lv1831: R.Tensor((640,), dtype="float32") = model_params[777]
            lv4753 = R.call_tir(cls.layer_norm1, (lv1468_2, lv1830, lv1831), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1832: R.Tensor((640, 5120), dtype="float32") = model_params[1601]
            lv1833: R.Tensor((5120,), dtype="float32") = model_params[771]
            lv1469_2 = R.call_tir(cls.fused_matmul16_add18, (lv4753, lv1832, lv1833), out_sinfo=R.Tensor((1, 1024, 5120), dtype="float32"))
            lv1470_1 = R.call_tir(cls.fused_split_gelu1_multiply10, (lv1469_2,), out_sinfo=R.Tensor((1, 1024, 2560), dtype="float32"))
            lv1834: R.Tensor((2560, 640), dtype="float32") = model_params[1602]
            lv1835: R.Tensor((640,), dtype="float32") = model_params[772]
            lv1471_1 = R.call_tir(cls.fused_matmul17_add16_add17, (lv1470_1, lv1834, lv1835, lv1468_2), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1836_1: R.Tensor((640,), dtype="float32") = model_params[784]
            lv1837: R.Tensor((640,), dtype="float32") = model_params[783]
            lv4766 = R.call_tir(cls.layer_norm1, (lv1471_1, lv1836_1, lv1837), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1838: R.Tensor((640, 640), dtype="float32") = model_params[1603]
            lv4768 = R.call_tir(cls.matmul10, (lv4766, lv1838), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1839: R.Tensor((640, 640), dtype="float32") = model_params[1604]
            lv4770 = R.call_tir(cls.matmul10, (lv4766, lv1839), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1840: R.Tensor((640, 640), dtype="float32") = model_params[1605]
            lv4772 = R.call_tir(cls.matmul10, (lv4766, lv1840), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1472_1 = R.call_tir(cls.fused_reshape23_transpose12, (lv4768,), out_sinfo=R.Tensor((1, 10, 1024, 64), dtype="float32"))
            lv1473_1 = R.call_tir(cls.fused_reshape23_transpose12_transpose13, (lv4770,), out_sinfo=R.Tensor((1, 10, 64, 1024), dtype="float32"))
            lv1474_1 = R.call_tir(cls.fused_reshape23_transpose12, (lv4772,), out_sinfo=R.Tensor((1, 10, 1024, 64), dtype="float32"))
            lv1475_1 = R.call_tir(cls.fused_matmul11_multiply8, (lv1472_1, lv1473_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 10, 1024, 1024), dtype="float32"))
            lv4784 = R.call_tir(cls.softmax1, (lv1475_1,), out_sinfo=R.Tensor((1, 10, 1024, 1024), dtype="float32"))
            lv4785 = R.call_tir(cls.matmul12, (lv4784, lv1474_1), out_sinfo=R.Tensor((1, 10, 1024, 64), dtype="float32"))
            lv1476_1 = R.call_tir(cls.fused_transpose14_reshape24, (lv4785,), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1841_1: R.Tensor((640, 640), dtype="float32") = model_params[1606]
            lv1842: R.Tensor((640,), dtype="float32") = model_params[779]
            lv1477_2 = R.call_tir(cls.fused_matmul10_add16_divide5_add17, (lv1476_1, lv1841_1, lv1842, lv1471_1), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1843: R.Tensor((640,), dtype="float32") = model_params[786]
            lv1844: R.Tensor((640,), dtype="float32") = model_params[785]
            lv4793 = R.call_tir(cls.layer_norm1, (lv1477_2, lv1843, lv1844), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1845: R.Tensor((640, 640), dtype="float32") = model_params[1607]
            lv4795 = R.call_tir(cls.matmul10, (lv4793, lv1845), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1846: R.Tensor((2048, 640), dtype="float32") = model_params[1608]
            lv4797 = R.call_tir(cls.matmul13, (inp_2, lv1846), out_sinfo=R.Tensor((1, 77, 640), dtype="float32"))
            lv1847: R.Tensor((2048, 640), dtype="float32") = model_params[1609]
            lv4799 = R.call_tir(cls.matmul13, (inp_2, lv1847), out_sinfo=R.Tensor((1, 77, 640), dtype="float32"))
            lv1478_1 = R.call_tir(cls.fused_reshape23_transpose12, (lv4795,), out_sinfo=R.Tensor((1, 10, 1024, 64), dtype="float32"))
            lv1479_1 = R.call_tir(cls.fused_reshape25_transpose16_transpose17, (lv4797,), out_sinfo=R.Tensor((1, 10, 64, 77), dtype="float32"))
            lv1480_1 = R.call_tir(cls.fused_reshape25_transpose16, (lv4799,), out_sinfo=R.Tensor((1, 10, 77, 64), dtype="float32"))
            lv1481_1 = R.call_tir(cls.fused_matmul14_multiply9, (lv1478_1, lv1479_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 10, 1024, 77), dtype="float32"))
            lv4811 = R.call_tir(cls.softmax2, (lv1481_1,), out_sinfo=R.Tensor((1, 10, 1024, 77), dtype="float32"))
            lv4812 = R.call_tir(cls.matmul15, (lv4811, lv1480_1), out_sinfo=R.Tensor((1, 10, 1024, 64), dtype="float32"))
            lv1482_1 = R.call_tir(cls.fused_transpose14_reshape24, (lv4812,), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1848: R.Tensor((640, 640), dtype="float32") = model_params[1610]
            lv1849: R.Tensor((640,), dtype="float32") = model_params[780]
            lv1483_1 = R.call_tir(cls.fused_matmul10_add16_divide5_add17, (lv1482_1, lv1848, lv1849, lv1477_2), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1850_1: R.Tensor((640,), dtype="float32") = model_params[788]
            lv1851: R.Tensor((640,), dtype="float32") = model_params[787]
            lv4820 = R.call_tir(cls.layer_norm1, (lv1483_1, lv1850_1, lv1851), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1852: R.Tensor((640, 5120), dtype="float32") = model_params[1611]
            lv1853: R.Tensor((5120,), dtype="float32") = model_params[781]
            lv1484_1 = R.call_tir(cls.fused_matmul16_add18, (lv4820, lv1852, lv1853), out_sinfo=R.Tensor((1, 1024, 5120), dtype="float32"))
            lv1485_1 = R.call_tir(cls.fused_split_gelu1_multiply10, (lv1484_1,), out_sinfo=R.Tensor((1, 1024, 2560), dtype="float32"))
            lv1854: R.Tensor((2560, 640), dtype="float32") = model_params[1612]
            lv1855: R.Tensor((640,), dtype="float32") = model_params[782]
            lv1486_1 = R.call_tir(cls.fused_matmul17_add16_add17, (lv1485_1, lv1854, lv1855, lv1483_1), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1856_1: R.Tensor((640, 640), dtype="float32") = model_params[1613]
            lv1857: R.Tensor((640,), dtype="float32") = model_params[768]
            lv1487_1 = R.call_tir(cls.fused_matmul10_add16, (lv1486_1, lv1856_1, lv1857), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1488_1 = R.call_tir(cls.fused_reshape26_transpose20_add15_concatenate7, (lv1487_1, lv1454_2, lv444), out_sinfo=R.Tensor((1, 1280, 32, 32), dtype="float32"))
            lv1858_1: R.Tensor((1280,), dtype="float32") = model_params[849]
            lv1859: R.Tensor((1280,), dtype="float32") = model_params[848]
            lv1489_1 = R.call_tir(cls.fused_group_norm10_silu9, (lv1488_1, lv1858_1, lv1859), out_sinfo=R.Tensor((1, 1280, 32, 32), dtype="float32"))
            lv4845 = R.call_tir(cls.silu, (lv392,), out_sinfo=R.Tensor((1, 1280), dtype="float32"))
            lv1860_1: R.Tensor((1280, 640), dtype="float32") = model_params[1615]
            lv1861: R.Tensor((640,), dtype="float32") = model_params[852]
            lv1490_2 = R.call_tir(cls.fused_matmul9_add14_strided_slice7, (lv4845, lv1860_1, lv1861), out_sinfo=R.Tensor((1, 640), dtype="float32"))
            lv4850 = R.call_tir(cls.reshape21, (lv1490_2,), out_sinfo=R.Tensor((1, 640, 1, 1), dtype="float32"))
            lv1862_1: R.Tensor((640, 1280, 3, 3), dtype="float32") = model_params[845]
            lv1863: R.Tensor((1, 640, 1, 1), dtype="float32") = model_params[1614]
            lv1491_1 = R.call_tir(cls.fused_conv2d17_add13_add13, (lv1489_1, lv1862_1, lv1863, lv4850), out_sinfo=R.Tensor((1, 640, 32, 32), dtype="float32"))
            lv1864: R.Tensor((640,), dtype="float32") = model_params[851]
            lv1865: R.Tensor((640,), dtype="float32") = model_params[850]
            lv1492_2 = R.call_tir(cls.fused_group_norm2_silu3, (lv1491_1, lv1864, lv1865), out_sinfo=R.Tensor((1, 640, 32, 32), dtype="float32"))
            lv1866: R.Tensor((640, 1280, 1, 1), dtype="float32") = model_params[847]
            lv1867: R.Tensor((1, 640, 1, 1), dtype="float32") = model_params[1617]
            lv1493_1 = R.call_tir(cls.fused_conv2d18_add13, (lv1488_1, lv1866, lv1867), out_sinfo=R.Tensor((1, 640, 32, 32), dtype="float32"))
            lv1868: R.Tensor((640, 640, 3, 3), dtype="float32") = model_params[846]
            lv1869: R.Tensor((1, 640, 1, 1), dtype="float32") = model_params[1616]
            lv1494_2 = R.call_tir(cls.fused_conv2d4_add13_add15_divide3, (lv1492_2, lv1868, lv1869, lv1493_1), out_sinfo=R.Tensor((1, 640, 32, 32), dtype="float32"))
            lv1870: R.Tensor((640,), dtype="float32") = model_params[790]
            lv1871: R.Tensor((640,), dtype="float32") = model_params[789]
            lv4862 = R.call_tir(cls.group_norm3, (lv1494_2, lv1870, lv1871), out_sinfo=R.Tensor((1, 640, 32, 32), dtype="float32"))
            lv1495_1 = R.call_tir(cls.fused_transpose10_reshape22, (lv4862,), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1872: R.Tensor((640, 640), dtype="float32") = model_params[1618]
            lv1873: R.Tensor((640,), dtype="float32") = model_params[791]
            lv1496_2 = R.call_tir(cls.fused_matmul10_add16, (lv1495_1, lv1872, lv1873), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1874_1: R.Tensor((640,), dtype="float32") = model_params[798]
            lv1875_1: R.Tensor((640,), dtype="float32") = model_params[797]
            lv4868 = R.call_tir(cls.layer_norm1, (lv1496_2, lv1874_1, lv1875_1), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1876: R.Tensor((640, 640), dtype="float32") = model_params[1619]
            lv4870 = R.call_tir(cls.matmul10, (lv4868, lv1876), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1877: R.Tensor((640, 640), dtype="float32") = model_params[1620]
            lv4872 = R.call_tir(cls.matmul10, (lv4868, lv1877), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1878: R.Tensor((640, 640), dtype="float32") = model_params[1621]
            lv4874 = R.call_tir(cls.matmul10, (lv4868, lv1878), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1497_1 = R.call_tir(cls.fused_reshape23_transpose12, (lv4870,), out_sinfo=R.Tensor((1, 10, 1024, 64), dtype="float32"))
            lv1498_1 = R.call_tir(cls.fused_reshape23_transpose12_transpose13, (lv4872,), out_sinfo=R.Tensor((1, 10, 64, 1024), dtype="float32"))
            lv1499_1 = R.call_tir(cls.fused_reshape23_transpose12, (lv4874,), out_sinfo=R.Tensor((1, 10, 1024, 64), dtype="float32"))
            lv1500_1 = R.call_tir(cls.fused_matmul11_multiply8, (lv1497_1, lv1498_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 10, 1024, 1024), dtype="float32"))
            lv4886 = R.call_tir(cls.softmax1, (lv1500_1,), out_sinfo=R.Tensor((1, 10, 1024, 1024), dtype="float32"))
            lv4887 = R.call_tir(cls.matmul12, (lv4886, lv1499_1), out_sinfo=R.Tensor((1, 10, 1024, 64), dtype="float32"))
            lv1501_1 = R.call_tir(cls.fused_transpose14_reshape24, (lv4887,), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1879: R.Tensor((640, 640), dtype="float32") = model_params[1622]
            lv1880: R.Tensor((640,), dtype="float32") = model_params[793]
            lv1502_1 = R.call_tir(cls.fused_matmul10_add16_divide5_add17, (lv1501_1, lv1879, lv1880, lv1496_2), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1881: R.Tensor((640,), dtype="float32") = model_params[800]
            lv1882: R.Tensor((640,), dtype="float32") = model_params[799]
            lv4895 = R.call_tir(cls.layer_norm1, (lv1502_1, lv1881, lv1882), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1883_1: R.Tensor((640, 640), dtype="float32") = model_params[1623]
            lv4897 = R.call_tir(cls.matmul10, (lv4895, lv1883_1), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1884: R.Tensor((2048, 640), dtype="float32") = model_params[1624]
            lv4899 = R.call_tir(cls.matmul13, (inp_2, lv1884), out_sinfo=R.Tensor((1, 77, 640), dtype="float32"))
            lv1885_1: R.Tensor((2048, 640), dtype="float32") = model_params[1625]
            lv4901 = R.call_tir(cls.matmul13, (inp_2, lv1885_1), out_sinfo=R.Tensor((1, 77, 640), dtype="float32"))
            lv1503_1 = R.call_tir(cls.fused_reshape23_transpose12, (lv4897,), out_sinfo=R.Tensor((1, 10, 1024, 64), dtype="float32"))
            lv1504_1 = R.call_tir(cls.fused_reshape25_transpose16_transpose17, (lv4899,), out_sinfo=R.Tensor((1, 10, 64, 77), dtype="float32"))
            lv1505_1 = R.call_tir(cls.fused_reshape25_transpose16, (lv4901,), out_sinfo=R.Tensor((1, 10, 77, 64), dtype="float32"))
            lv1506_1 = R.call_tir(cls.fused_matmul14_multiply9, (lv1503_1, lv1504_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 10, 1024, 77), dtype="float32"))
            lv4913 = R.call_tir(cls.softmax2, (lv1506_1,), out_sinfo=R.Tensor((1, 10, 1024, 77), dtype="float32"))
            lv4914 = R.call_tir(cls.matmul15, (lv4913, lv1505_1), out_sinfo=R.Tensor((1, 10, 1024, 64), dtype="float32"))
            lv1507_1 = R.call_tir(cls.fused_transpose14_reshape24, (lv4914,), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1886: R.Tensor((640, 640), dtype="float32") = model_params[1626]
            lv1887_1: R.Tensor((640,), dtype="float32") = model_params[794]
            lv1508_2 = R.call_tir(cls.fused_matmul10_add16_divide5_add17, (lv1507_1, lv1886, lv1887_1, lv1502_1), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1888: R.Tensor((640,), dtype="float32") = model_params[802]
            lv1889_1: R.Tensor((640,), dtype="float32") = model_params[801]
            lv4922 = R.call_tir(cls.layer_norm1, (lv1508_2, lv1888, lv1889_1), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1890: R.Tensor((640, 5120), dtype="float32") = model_params[1627]
            lv1891: R.Tensor((5120,), dtype="float32") = model_params[795]
            lv1509_2 = R.call_tir(cls.fused_matmul16_add18, (lv4922, lv1890, lv1891), out_sinfo=R.Tensor((1, 1024, 5120), dtype="float32"))
            lv1510_1 = R.call_tir(cls.fused_split_gelu1_multiply10, (lv1509_2,), out_sinfo=R.Tensor((1, 1024, 2560), dtype="float32"))
            lv1892: R.Tensor((2560, 640), dtype="float32") = model_params[1628]
            lv1893: R.Tensor((640,), dtype="float32") = model_params[796]
            lv1511_1 = R.call_tir(cls.fused_matmul17_add16_add17, (lv1510_1, lv1892, lv1893, lv1508_2), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1894: R.Tensor((640,), dtype="float32") = model_params[808]
            lv1895: R.Tensor((640,), dtype="float32") = model_params[807]
            lv4935 = R.call_tir(cls.layer_norm1, (lv1511_1, lv1894, lv1895), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1896: R.Tensor((640, 640), dtype="float32") = model_params[1629]
            lv4937 = R.call_tir(cls.matmul10, (lv4935, lv1896), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1897: R.Tensor((640, 640), dtype="float32") = model_params[1630]
            lv4939 = R.call_tir(cls.matmul10, (lv4935, lv1897), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1898: R.Tensor((640, 640), dtype="float32") = model_params[1631]
            lv4941 = R.call_tir(cls.matmul10, (lv4935, lv1898), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1512_1 = R.call_tir(cls.fused_reshape23_transpose12, (lv4937,), out_sinfo=R.Tensor((1, 10, 1024, 64), dtype="float32"))
            lv1513_1 = R.call_tir(cls.fused_reshape23_transpose12_transpose13, (lv4939,), out_sinfo=R.Tensor((1, 10, 64, 1024), dtype="float32"))
            lv1514_1 = R.call_tir(cls.fused_reshape23_transpose12, (lv4941,), out_sinfo=R.Tensor((1, 10, 1024, 64), dtype="float32"))
            lv1515_1 = R.call_tir(cls.fused_matmul11_multiply8, (lv1512_1, lv1513_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 10, 1024, 1024), dtype="float32"))
            lv4953 = R.call_tir(cls.softmax1, (lv1515_1,), out_sinfo=R.Tensor((1, 10, 1024, 1024), dtype="float32"))
            lv4954 = R.call_tir(cls.matmul12, (lv4953, lv1514_1), out_sinfo=R.Tensor((1, 10, 1024, 64), dtype="float32"))
            lv1516_1 = R.call_tir(cls.fused_transpose14_reshape24, (lv4954,), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1899: R.Tensor((640, 640), dtype="float32") = model_params[1632]
            lv1900: R.Tensor((640,), dtype="float32") = model_params[803]
            lv1517_2 = R.call_tir(cls.fused_matmul10_add16_divide5_add17, (lv1516_1, lv1899, lv1900, lv1511_1), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1901_1: R.Tensor((640,), dtype="float32") = model_params[810]
            lv1902_1: R.Tensor((640,), dtype="float32") = model_params[809]
            lv4962 = R.call_tir(cls.layer_norm1, (lv1517_2, lv1901_1, lv1902_1), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1903: R.Tensor((640, 640), dtype="float32") = model_params[1633]
            lv4964 = R.call_tir(cls.matmul10, (lv4962, lv1903), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1904: R.Tensor((2048, 640), dtype="float32") = model_params[1634]
            lv4966 = R.call_tir(cls.matmul13, (inp_2, lv1904), out_sinfo=R.Tensor((1, 77, 640), dtype="float32"))
            lv1905: R.Tensor((2048, 640), dtype="float32") = model_params[1635]
            lv4968 = R.call_tir(cls.matmul13, (inp_2, lv1905), out_sinfo=R.Tensor((1, 77, 640), dtype="float32"))
            lv1518_1 = R.call_tir(cls.fused_reshape23_transpose12, (lv4964,), out_sinfo=R.Tensor((1, 10, 1024, 64), dtype="float32"))
            lv1519_2 = R.call_tir(cls.fused_reshape25_transpose16_transpose17, (lv4966,), out_sinfo=R.Tensor((1, 10, 64, 77), dtype="float32"))
            lv1520_1 = R.call_tir(cls.fused_reshape25_transpose16, (lv4968,), out_sinfo=R.Tensor((1, 10, 77, 64), dtype="float32"))
            lv1521_2 = R.call_tir(cls.fused_matmul14_multiply9, (lv1518_1, lv1519_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 10, 1024, 77), dtype="float32"))
            lv4980 = R.call_tir(cls.softmax2, (lv1521_2,), out_sinfo=R.Tensor((1, 10, 1024, 77), dtype="float32"))
            lv4981 = R.call_tir(cls.matmul15, (lv4980, lv1520_1), out_sinfo=R.Tensor((1, 10, 1024, 64), dtype="float32"))
            lv1522_1 = R.call_tir(cls.fused_transpose14_reshape24, (lv4981,), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1906: R.Tensor((640, 640), dtype="float32") = model_params[1636]
            lv1907: R.Tensor((640,), dtype="float32") = model_params[804]
            lv1523_2 = R.call_tir(cls.fused_matmul10_add16_divide5_add17, (lv1522_1, lv1906, lv1907, lv1517_2), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1908: R.Tensor((640,), dtype="float32") = model_params[812]
            lv1909: R.Tensor((640,), dtype="float32") = model_params[811]
            lv4989 = R.call_tir(cls.layer_norm1, (lv1523_2, lv1908, lv1909), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1910_1: R.Tensor((640, 5120), dtype="float32") = model_params[1637]
            lv1911: R.Tensor((5120,), dtype="float32") = model_params[805]
            lv1524_1 = R.call_tir(cls.fused_matmul16_add18, (lv4989, lv1910_1, lv1911), out_sinfo=R.Tensor((1, 1024, 5120), dtype="float32"))
            lv1525_1 = R.call_tir(cls.fused_split_gelu1_multiply10, (lv1524_1,), out_sinfo=R.Tensor((1, 1024, 2560), dtype="float32"))
            lv1912: R.Tensor((2560, 640), dtype="float32") = model_params[1638]
            lv1913: R.Tensor((640,), dtype="float32") = model_params[806]
            lv1526_1 = R.call_tir(cls.fused_matmul17_add16_add17, (lv1525_1, lv1912, lv1913, lv1523_2), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1914: R.Tensor((640, 640), dtype="float32") = model_params[1639]
            lv1915: R.Tensor((640,), dtype="float32") = model_params[792]
            lv1527_1 = R.call_tir(cls.fused_matmul10_add16, (lv1526_1, lv1914, lv1915), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1528_1 = R.call_tir(cls.fused_reshape26_transpose20_add15_concatenate8, (lv1527_1, lv1494_2, lv404), out_sinfo=R.Tensor((1, 960, 32, 32), dtype="float32"))
            lv1916: R.Tensor((960,), dtype="float32") = model_params[857]
            lv1917: R.Tensor((960,), dtype="float32") = model_params[856]
            lv1529_1 = R.call_tir(cls.fused_group_norm11_silu10, (lv1528_1, lv1916, lv1917), out_sinfo=R.Tensor((1, 960, 32, 32), dtype="float32"))
            lv5014 = R.call_tir(cls.silu, (lv392,), out_sinfo=R.Tensor((1, 1280), dtype="float32"))
            lv1918: R.Tensor((1280, 640), dtype="float32") = model_params[1641]
            lv1919: R.Tensor((640,), dtype="float32") = model_params[860]
            lv1530_1 = R.call_tir(cls.fused_matmul9_add14_strided_slice7, (lv5014, lv1918, lv1919), out_sinfo=R.Tensor((1, 640), dtype="float32"))
            lv5019 = R.call_tir(cls.reshape21, (lv1530_1,), out_sinfo=R.Tensor((1, 640, 1, 1), dtype="float32"))
            lv1920: R.Tensor((640, 960, 3, 3), dtype="float32") = model_params[853]
            lv1921: R.Tensor((1, 640, 1, 1), dtype="float32") = model_params[1640]
            lv1531_1 = R.call_tir(cls.fused_conv2d19_add13_add13, (lv1529_1, lv1920, lv1921, lv5019), out_sinfo=R.Tensor((1, 640, 32, 32), dtype="float32"))
            lv1922: R.Tensor((640,), dtype="float32") = model_params[859]
            lv1923_1: R.Tensor((640,), dtype="float32") = model_params[858]
            lv1532_1 = R.call_tir(cls.fused_group_norm2_silu3, (lv1531_1, lv1922, lv1923_1), out_sinfo=R.Tensor((1, 640, 32, 32), dtype="float32"))
            lv1924: R.Tensor((640, 960, 1, 1), dtype="float32") = model_params[855]
            lv1925_1: R.Tensor((1, 640, 1, 1), dtype="float32") = model_params[1643]
            lv1533_1 = R.call_tir(cls.fused_conv2d20_add13, (lv1528_1, lv1924, lv1925_1), out_sinfo=R.Tensor((1, 640, 32, 32), dtype="float32"))
            lv1926: R.Tensor((640, 640, 3, 3), dtype="float32") = model_params[854]
            lv1927_1: R.Tensor((1, 640, 1, 1), dtype="float32") = model_params[1642]
            lv1534_1 = R.call_tir(cls.fused_conv2d4_add13_add15_divide3, (lv1532_1, lv1926, lv1927_1, lv1533_1), out_sinfo=R.Tensor((1, 640, 32, 32), dtype="float32"))
            lv1928: R.Tensor((640,), dtype="float32") = model_params[814]
            lv1929_1: R.Tensor((640,), dtype="float32") = model_params[813]
            lv5031 = R.call_tir(cls.group_norm3, (lv1534_1, lv1928, lv1929_1), out_sinfo=R.Tensor((1, 640, 32, 32), dtype="float32"))
            lv1535_2 = R.call_tir(cls.fused_transpose10_reshape22, (lv5031,), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1930: R.Tensor((640, 640), dtype="float32") = model_params[1644]
            lv1931: R.Tensor((640,), dtype="float32") = model_params[815]
            lv1536_2 = R.call_tir(cls.fused_matmul10_add16, (lv1535_2, lv1930, lv1931), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1932: R.Tensor((640,), dtype="float32") = model_params[822]
            lv1933: R.Tensor((640,), dtype="float32") = model_params[821]
            lv5037 = R.call_tir(cls.layer_norm1, (lv1536_2, lv1932, lv1933), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1934: R.Tensor((640, 640), dtype="float32") = model_params[1645]
            lv5039 = R.call_tir(cls.matmul10, (lv5037, lv1934), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1935: R.Tensor((640, 640), dtype="float32") = model_params[1646]
            lv5041 = R.call_tir(cls.matmul10, (lv5037, lv1935), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1936: R.Tensor((640, 640), dtype="float32") = model_params[1647]
            lv5043 = R.call_tir(cls.matmul10, (lv5037, lv1936), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1537_1 = R.call_tir(cls.fused_reshape23_transpose12, (lv5039,), out_sinfo=R.Tensor((1, 10, 1024, 64), dtype="float32"))
            lv1538_1 = R.call_tir(cls.fused_reshape23_transpose12_transpose13, (lv5041,), out_sinfo=R.Tensor((1, 10, 64, 1024), dtype="float32"))
            lv1539_1 = R.call_tir(cls.fused_reshape23_transpose12, (lv5043,), out_sinfo=R.Tensor((1, 10, 1024, 64), dtype="float32"))
            lv1540_1 = R.call_tir(cls.fused_matmul11_multiply8, (lv1537_1, lv1538_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 10, 1024, 1024), dtype="float32"))
            lv5055 = R.call_tir(cls.softmax1, (lv1540_1,), out_sinfo=R.Tensor((1, 10, 1024, 1024), dtype="float32"))
            lv5056 = R.call_tir(cls.matmul12, (lv5055, lv1539_1), out_sinfo=R.Tensor((1, 10, 1024, 64), dtype="float32"))
            lv1541_1 = R.call_tir(cls.fused_transpose14_reshape24, (lv5056,), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1937: R.Tensor((640, 640), dtype="float32") = model_params[1648]
            lv1938: R.Tensor((640,), dtype="float32") = model_params[817]
            lv1542_1 = R.call_tir(cls.fused_matmul10_add16_divide5_add17, (lv1541_1, lv1937, lv1938, lv1536_2), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1939: R.Tensor((640,), dtype="float32") = model_params[824]
            lv1940: R.Tensor((640,), dtype="float32") = model_params[823]
            lv5064 = R.call_tir(cls.layer_norm1, (lv1542_1, lv1939, lv1940), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1941_1: R.Tensor((640, 640), dtype="float32") = model_params[1649]
            lv5066 = R.call_tir(cls.matmul10, (lv5064, lv1941_1), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1942_1: R.Tensor((2048, 640), dtype="float32") = model_params[1650]
            lv5068 = R.call_tir(cls.matmul13, (inp_2, lv1942_1), out_sinfo=R.Tensor((1, 77, 640), dtype="float32"))
            lv1943: R.Tensor((2048, 640), dtype="float32") = model_params[1651]
            lv5070 = R.call_tir(cls.matmul13, (inp_2, lv1943), out_sinfo=R.Tensor((1, 77, 640), dtype="float32"))
            lv1543_1 = R.call_tir(cls.fused_reshape23_transpose12, (lv5066,), out_sinfo=R.Tensor((1, 10, 1024, 64), dtype="float32"))
            lv1544_2 = R.call_tir(cls.fused_reshape25_transpose16_transpose17, (lv5068,), out_sinfo=R.Tensor((1, 10, 64, 77), dtype="float32"))
            lv1545_1 = R.call_tir(cls.fused_reshape25_transpose16, (lv5070,), out_sinfo=R.Tensor((1, 10, 77, 64), dtype="float32"))
            lv1546_1 = R.call_tir(cls.fused_matmul14_multiply9, (lv1543_1, lv1544_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 10, 1024, 77), dtype="float32"))
            lv5082 = R.call_tir(cls.softmax2, (lv1546_1,), out_sinfo=R.Tensor((1, 10, 1024, 77), dtype="float32"))
            lv5083 = R.call_tir(cls.matmul15, (lv5082, lv1545_1), out_sinfo=R.Tensor((1, 10, 1024, 64), dtype="float32"))
            lv1547_1 = R.call_tir(cls.fused_transpose14_reshape24, (lv5083,), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1944: R.Tensor((640, 640), dtype="float32") = model_params[1652]
            lv1945: R.Tensor((640,), dtype="float32") = model_params[818]
            lv1548_1 = R.call_tir(cls.fused_matmul10_add16_divide5_add17, (lv1547_1, lv1944, lv1945, lv1542_1), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1946: R.Tensor((640,), dtype="float32") = model_params[826]
            lv1947: R.Tensor((640,), dtype="float32") = model_params[825]
            lv5091 = R.call_tir(cls.layer_norm1, (lv1548_1, lv1946, lv1947), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1948: R.Tensor((640, 5120), dtype="float32") = model_params[1653]
            lv1949: R.Tensor((5120,), dtype="float32") = model_params[819]
            lv1549_1 = R.call_tir(cls.fused_matmul16_add18, (lv5091, lv1948, lv1949), out_sinfo=R.Tensor((1, 1024, 5120), dtype="float32"))
            lv1550_1 = R.call_tir(cls.fused_split_gelu1_multiply10, (lv1549_1,), out_sinfo=R.Tensor((1, 1024, 2560), dtype="float32"))
            lv1950_1: R.Tensor((2560, 640), dtype="float32") = model_params[1654]
            lv1951: R.Tensor((640,), dtype="float32") = model_params[820]
            lv1551_1 = R.call_tir(cls.fused_matmul17_add16_add17, (lv1550_1, lv1950_1, lv1951, lv1548_1), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1952_1: R.Tensor((640,), dtype="float32") = model_params[832]
            lv1953: R.Tensor((640,), dtype="float32") = model_params[831]
            lv5104 = R.call_tir(cls.layer_norm1, (lv1551_1, lv1952_1, lv1953), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1954_1: R.Tensor((640, 640), dtype="float32") = model_params[1655]
            lv5106 = R.call_tir(cls.matmul10, (lv5104, lv1954_1), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1955: R.Tensor((640, 640), dtype="float32") = model_params[1656]
            lv5108 = R.call_tir(cls.matmul10, (lv5104, lv1955), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1956_1: R.Tensor((640, 640), dtype="float32") = model_params[1657]
            lv5110 = R.call_tir(cls.matmul10, (lv5104, lv1956_1), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1552_1 = R.call_tir(cls.fused_reshape23_transpose12, (lv5106,), out_sinfo=R.Tensor((1, 10, 1024, 64), dtype="float32"))
            lv1553_1 = R.call_tir(cls.fused_reshape23_transpose12_transpose13, (lv5108,), out_sinfo=R.Tensor((1, 10, 64, 1024), dtype="float32"))
            lv1554_1 = R.call_tir(cls.fused_reshape23_transpose12, (lv5110,), out_sinfo=R.Tensor((1, 10, 1024, 64), dtype="float32"))
            lv1555_1 = R.call_tir(cls.fused_matmul11_multiply8, (lv1552_1, lv1553_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 10, 1024, 1024), dtype="float32"))
            lv5122 = R.call_tir(cls.softmax1, (lv1555_1,), out_sinfo=R.Tensor((1, 10, 1024, 1024), dtype="float32"))
            lv5123 = R.call_tir(cls.matmul12, (lv5122, lv1554_1), out_sinfo=R.Tensor((1, 10, 1024, 64), dtype="float32"))
            lv1556_1 = R.call_tir(cls.fused_transpose14_reshape24, (lv5123,), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1957: R.Tensor((640, 640), dtype="float32") = model_params[1658]
            lv1958: R.Tensor((640,), dtype="float32") = model_params[827]
            lv1557_2 = R.call_tir(cls.fused_matmul10_add16_divide5_add17, (lv1556_1, lv1957, lv1958, lv1551_1), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1959: R.Tensor((640,), dtype="float32") = model_params[834]
            lv1960: R.Tensor((640,), dtype="float32") = model_params[833]
            lv5131 = R.call_tir(cls.layer_norm1, (lv1557_2, lv1959, lv1960), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1961: R.Tensor((640, 640), dtype="float32") = model_params[1659]
            lv5133 = R.call_tir(cls.matmul10, (lv5131, lv1961), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1962: R.Tensor((2048, 640), dtype="float32") = model_params[1660]
            lv5135 = R.call_tir(cls.matmul13, (inp_2, lv1962), out_sinfo=R.Tensor((1, 77, 640), dtype="float32"))
            lv1963: R.Tensor((2048, 640), dtype="float32") = model_params[1661]
            lv5137 = R.call_tir(cls.matmul13, (inp_2, lv1963), out_sinfo=R.Tensor((1, 77, 640), dtype="float32"))
            lv1558_1 = R.call_tir(cls.fused_reshape23_transpose12, (lv5133,), out_sinfo=R.Tensor((1, 10, 1024, 64), dtype="float32"))
            lv1559_2 = R.call_tir(cls.fused_reshape25_transpose16_transpose17, (lv5135,), out_sinfo=R.Tensor((1, 10, 64, 77), dtype="float32"))
            lv1560_1 = R.call_tir(cls.fused_reshape25_transpose16, (lv5137,), out_sinfo=R.Tensor((1, 10, 77, 64), dtype="float32"))
            lv1561_2 = R.call_tir(cls.fused_matmul14_multiply9, (lv1558_1, lv1559_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((1, 10, 1024, 77), dtype="float32"))
            lv5149 = R.call_tir(cls.softmax2, (lv1561_2,), out_sinfo=R.Tensor((1, 10, 1024, 77), dtype="float32"))
            lv5150 = R.call_tir(cls.matmul15, (lv5149, lv1560_1), out_sinfo=R.Tensor((1, 10, 1024, 64), dtype="float32"))
            lv1562_1 = R.call_tir(cls.fused_transpose14_reshape24, (lv5150,), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1964: R.Tensor((640, 640), dtype="float32") = model_params[1662]
            lv1965: R.Tensor((640,), dtype="float32") = model_params[828]
            lv1563_2 = R.call_tir(cls.fused_matmul10_add16_divide5_add17, (lv1562_1, lv1964, lv1965, lv1557_2), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1966: R.Tensor((640,), dtype="float32") = model_params[836]
            lv1967: R.Tensor((640,), dtype="float32") = model_params[835]
            lv5158 = R.call_tir(cls.layer_norm1, (lv1563_2, lv1966, lv1967), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1968_1: R.Tensor((640, 5120), dtype="float32") = model_params[1663]
            lv1969_1: R.Tensor((5120,), dtype="float32") = model_params[829]
            lv1564_1 = R.call_tir(cls.fused_matmul16_add18, (lv5158, lv1968_1, lv1969_1), out_sinfo=R.Tensor((1, 1024, 5120), dtype="float32"))
            lv1565_1 = R.call_tir(cls.fused_split_gelu1_multiply10, (lv1564_1,), out_sinfo=R.Tensor((1, 1024, 2560), dtype="float32"))
            lv1970: R.Tensor((2560, 640), dtype="float32") = model_params[1664]
            lv1971: R.Tensor((640,), dtype="float32") = model_params[830]
            lv1566_1 = R.call_tir(cls.fused_matmul17_add16_add17, (lv1565_1, lv1970, lv1971, lv1563_2), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1972: R.Tensor((640, 640), dtype="float32") = model_params[1665]
            lv1973: R.Tensor((640,), dtype="float32") = model_params[816]
            lv1567_1 = R.call_tir(cls.fused_matmul10_add16, (lv1566_1, lv1972, lv1973), out_sinfo=R.Tensor((1, 1024, 640), dtype="float32"))
            lv1568_1 = R.call_tir(cls.fused_reshape26_transpose20_add15_resize2d1, (lv1567_1, lv1534_1), out_sinfo=R.Tensor((1, 640, 64, 64), dtype="float32"))
            lv1974: R.Tensor((640, 640, 3, 3), dtype="float32") = model_params[861]
            lv1975: R.Tensor((1, 640, 1, 1), dtype="float32") = model_params[1666]
            lv1569_1 = R.call_tir(cls.fused_conv2d21_add26, (lv1568_1, lv1974, lv1975), out_sinfo=R.Tensor((1, 640, 64, 64), dtype="float32"))
            lv5181 = R.call_tir(cls.concatenate9, (lv1569_1, lv403), out_sinfo=R.Tensor((1, 960, 64, 64), dtype="float32"))
            lv1976: R.Tensor((960,), dtype="float32") = model_params[866]
            lv1977_1: R.Tensor((960,), dtype="float32") = model_params[865]
            lv1570_1 = R.call_tir(cls.fused_group_norm12_silu11, (lv5181, lv1976, lv1977_1), out_sinfo=R.Tensor((1, 960, 64, 64), dtype="float32"))
            lv5187 = R.call_tir(cls.silu, (lv392,), out_sinfo=R.Tensor((1, 1280), dtype="float32"))
            lv1978: R.Tensor((1280, 320), dtype="float32") = model_params[1668]
            lv1979: R.Tensor((320,), dtype="float32") = model_params[869]
            lv1571_1 = R.call_tir(cls.fused_matmul8_add10_cast4, (lv5187, lv1978, lv1979), out_sinfo=R.Tensor((1, 320), dtype="float32"))
            lv5192 = R.call_tir(cls.reshape19, (lv1571_1,), out_sinfo=R.Tensor((1, 320, 1, 1), dtype="float32"))
            lv1980: R.Tensor((320, 960, 3, 3), dtype="float32") = model_params[862]
            lv1981: R.Tensor((1, 320, 1, 1), dtype="float32") = model_params[1667]
            lv1572_1 = R.call_tir(cls.fused_conv2d22_add9_add9, (lv1570_1, lv1980, lv1981, lv5192), out_sinfo=R.Tensor((1, 320, 64, 64), dtype="float32"))
            lv1982: R.Tensor((320,), dtype="float32") = model_params[868]
            lv1983: R.Tensor((320,), dtype="float32") = model_params[867]
            lv1573_1 = R.call_tir(cls.fused_group_norm_silu1, (lv1572_1, lv1982, lv1983), out_sinfo=R.Tensor((1, 320, 64, 64), dtype="float32"))
            lv1984: R.Tensor((320, 960, 1, 1), dtype="float32") = model_params[864]
            lv1985: R.Tensor((1, 320, 1, 1), dtype="float32") = model_params[1670]
            lv1574_1 = R.call_tir(cls.fused_conv2d23_add9, (lv5181, lv1984, lv1985), out_sinfo=R.Tensor((1, 320, 64, 64), dtype="float32"))
            lv1986: R.Tensor((320, 320, 3, 3), dtype="float32") = model_params[863]
            lv1987: R.Tensor((1, 320, 1, 1), dtype="float32") = model_params[1669]
            lv1575_2 = R.call_tir(cls.fused_conv2d1_add9_add11_divide2, (lv1573_1, lv1986, lv1987, lv1574_1), out_sinfo=R.Tensor((1, 320, 64, 64), dtype="float32"))
            lv5204 = R.call_tir(cls.concatenate10, (lv1575_2, lv398), out_sinfo=R.Tensor((1, 640, 64, 64), dtype="float32"))
            lv1988: R.Tensor((640,), dtype="float32") = model_params[874]
            lv1989: R.Tensor((640,), dtype="float32") = model_params[873]
            lv1576_2 = R.call_tir(cls.fused_group_norm13_silu12, (lv5204, lv1988, lv1989), out_sinfo=R.Tensor((1, 640, 64, 64), dtype="float32"))
            lv5210 = R.call_tir(cls.silu, (lv392,), out_sinfo=R.Tensor((1, 1280), dtype="float32"))
            lv1990_1: R.Tensor((1280, 320), dtype="float32") = model_params[1672]
            lv1991: R.Tensor((320,), dtype="float32") = model_params[877]
            lv1577_1 = R.call_tir(cls.fused_matmul8_add10_cast4, (lv5210, lv1990_1, lv1991), out_sinfo=R.Tensor((1, 320), dtype="float32"))
            lv5215 = R.call_tir(cls.reshape19, (lv1577_1,), out_sinfo=R.Tensor((1, 320, 1, 1), dtype="float32"))
            lv1992_1: R.Tensor((320, 640, 3, 3), dtype="float32") = model_params[870]
            lv1993: R.Tensor((1, 320, 1, 1), dtype="float32") = model_params[1671]
            lv1578_1 = R.call_tir(cls.fused_conv2d24_add9_add9, (lv1576_2, lv1992_1, lv1993, lv5215), out_sinfo=R.Tensor((1, 320, 64, 64), dtype="float32"))
            lv1994_1: R.Tensor((320,), dtype="float32") = model_params[876]
            lv1995: R.Tensor((320,), dtype="float32") = model_params[875]
            lv1579_1 = R.call_tir(cls.fused_group_norm_silu1, (lv1578_1, lv1994_1, lv1995), out_sinfo=R.Tensor((1, 320, 64, 64), dtype="float32"))
            lv1996_1: R.Tensor((320, 640, 1, 1), dtype="float32") = model_params[872]
            lv1997: R.Tensor((1, 320, 1, 1), dtype="float32") = model_params[1674]
            lv1580_1 = R.call_tir(cls.fused_conv2d25_add9, (lv5204, lv1996_1, lv1997), out_sinfo=R.Tensor((1, 320, 64, 64), dtype="float32"))
            lv1998: R.Tensor((320, 320, 3, 3), dtype="float32") = model_params[871]
            lv1999: R.Tensor((1, 320, 1, 1), dtype="float32") = model_params[1673]
            lv1581_1 = R.call_tir(cls.fused_conv2d1_add9_add11_divide2, (lv1579_1, lv1998, lv1999, lv1580_1), out_sinfo=R.Tensor((1, 320, 64, 64), dtype="float32"))
            lv5227 = R.call_tir(cls.concatenate10, (lv1581_1, lv393), out_sinfo=R.Tensor((1, 640, 64, 64), dtype="float32"))
            lv2000: R.Tensor((640,), dtype="float32") = model_params[882]
            lv2001: R.Tensor((640,), dtype="float32") = model_params[881]
            lv1582_1 = R.call_tir(cls.fused_group_norm13_silu12, (lv5227, lv2000, lv2001), out_sinfo=R.Tensor((1, 640, 64, 64), dtype="float32"))
            lv5233 = R.call_tir(cls.silu, (lv392,), out_sinfo=R.Tensor((1, 1280), dtype="float32"))
            lv2002: R.Tensor((1280, 320), dtype="float32") = model_params[1676]
            lv2003: R.Tensor((320,), dtype="float32") = model_params[885]
            lv1583_1 = R.call_tir(cls.fused_matmul8_add10_cast4, (lv5233, lv2002, lv2003), out_sinfo=R.Tensor((1, 320), dtype="float32"))
            lv5238 = R.call_tir(cls.reshape19, (lv1583_1,), out_sinfo=R.Tensor((1, 320, 1, 1), dtype="float32"))
            lv2004: R.Tensor((320, 640, 3, 3), dtype="float32") = model_params[878]
            lv2005: R.Tensor((1, 320, 1, 1), dtype="float32") = model_params[1675]
            lv1584_2 = R.call_tir(cls.fused_conv2d24_add9_add9, (lv1582_1, lv2004, lv2005, lv5238), out_sinfo=R.Tensor((1, 320, 64, 64), dtype="float32"))
            lv2006: R.Tensor((320,), dtype="float32") = model_params[884]
            lv2007: R.Tensor((320,), dtype="float32") = model_params[883]
            lv1585_1 = R.call_tir(cls.fused_group_norm_silu1, (lv1584_2, lv2006, lv2007), out_sinfo=R.Tensor((1, 320, 64, 64), dtype="float32"))
            lv2008_1: R.Tensor((320, 640, 1, 1), dtype="float32") = model_params[880]
            lv2009_1: R.Tensor((1, 320, 1, 1), dtype="float32") = model_params[1678]
            lv1586_2 = R.call_tir(cls.fused_conv2d25_add9, (lv5227, lv2008_1, lv2009_1), out_sinfo=R.Tensor((1, 320, 64, 64), dtype="float32"))
            lv2010: R.Tensor((320, 320, 3, 3), dtype="float32") = model_params[879]
            lv2011: R.Tensor((1, 320, 1, 1), dtype="float32") = model_params[1677]
            lv1587_1 = R.call_tir(cls.fused_conv2d1_add9_add11_divide2, (lv1585_1, lv2010, lv2011, lv1586_2), out_sinfo=R.Tensor((1, 320, 64, 64), dtype="float32"))
            lv2012: R.Tensor((320,), dtype="float32") = model_params[4]
            lv2013: R.Tensor((320,), dtype="float32") = model_params[3]
            lv1588_2 = R.call_tir(cls.fused_group_norm_silu1, (lv1587_1, lv2012, lv2013), out_sinfo=R.Tensor((1, 320, 64, 64), dtype="float32"))
            lv2014: R.Tensor((4, 320, 3, 3), dtype="float32") = model_params[5]
            lv2015: R.Tensor((1, 4, 1, 1), dtype="float32") = model_params[1679]
            lv1589_1 = R.call_tir(cls.fused_conv2d26_add27, (lv1588_2, lv2014, lv2015), out_sinfo=R.Tensor((1, 4, 64, 64), dtype="float32"))
            gv: R.Tensor((1, 4, 64, 64), dtype="float32") = lv1589_1
            R.output(gv)
        return gv

    @R.function
    def vae(inp_0: R.Tensor((1, 4, 64, 64), dtype="float32"), model_params: R.Tuple(R.Tensor((512, 4, 3, 3), dtype="float32"), R.Tensor((128,), dtype="float32"), R.Tensor((128,), dtype="float32"), R.Tensor((3, 128, 3, 3), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512, 512, 3, 3), dtype="float32"), R.Tensor((512, 512, 3, 3), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512, 512, 3, 3), dtype="float32"), R.Tensor((512, 512, 3, 3), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512, 512, 3, 3), dtype="float32"), R.Tensor((512, 512, 3, 3), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512, 512, 3, 3), dtype="float32"), R.Tensor((512, 512, 3, 3), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512, 512, 3, 3), dtype="float32"), R.Tensor((512, 512, 3, 3), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512, 512, 3, 3), dtype="float32"), R.Tensor((512, 512, 3, 3), dtype="float32"), R.Tensor((512, 512, 3, 3), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512, 512, 3, 3), dtype="float32"), R.Tensor((512, 512, 3, 3), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512, 512, 3, 3), dtype="float32"), R.Tensor((512, 512, 3, 3), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512, 512, 3, 3), dtype="float32"), R.Tensor((256, 512, 3, 3), dtype="float32"), R.Tensor((256, 256, 3, 3), dtype="float32"), R.Tensor((256, 512, 1, 1), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((256,), dtype="float32"), R.Tensor((256,), dtype="float32"), R.Tensor((256, 256, 3, 3), dtype="float32"), R.Tensor((256, 256, 3, 3), dtype="float32"), R.Tensor((256,), dtype="float32"), R.Tensor((256,), dtype="float32"), R.Tensor((256,), dtype="float32"), R.Tensor((256,), dtype="float32"), R.Tensor((256, 256, 3, 3), dtype="float32"), R.Tensor((256, 256, 3, 3), dtype="float32"), R.Tensor((256,), dtype="float32"), R.Tensor((256,), dtype="float32"), R.Tensor((256,), dtype="float32"), R.Tensor((256,), dtype="float32"), R.Tensor((256, 256, 3, 3), dtype="float32"), R.Tensor((128, 256, 3, 3), dtype="float32"), R.Tensor((128, 128, 3, 3), dtype="float32"), R.Tensor((128, 256, 1, 1), dtype="float32"), R.Tensor((256,), dtype="float32"), R.Tensor((256,), dtype="float32"), R.Tensor((128,), dtype="float32"), R.Tensor((128,), dtype="float32"), R.Tensor((128, 128, 3, 3), dtype="float32"), R.Tensor((128, 128, 3, 3), dtype="float32"), R.Tensor((128,), dtype="float32"), R.Tensor((128,), dtype="float32"), R.Tensor((128,), dtype="float32"), R.Tensor((128,), dtype="float32"), R.Tensor((128, 128, 3, 3), dtype="float32"), R.Tensor((128, 128, 3, 3), dtype="float32"), R.Tensor((128,), dtype="float32"), R.Tensor((128,), dtype="float32"), R.Tensor((128,), dtype="float32"), R.Tensor((128,), dtype="float32"), R.Tensor((4, 4, 1, 1), dtype="float32"), R.Tensor((1, 4, 1, 1), dtype="float32"), R.Tensor((1, 512, 1, 1), dtype="float32"), R.Tensor((1, 512, 1, 1), dtype="float32"), R.Tensor((1, 512, 1, 1), dtype="float32"), R.Tensor((512, 512), dtype="float32"), R.Tensor((512, 512), dtype="float32"), R.Tensor((512, 512), dtype="float32"), R.Tensor((512, 512), dtype="float32"), R.Tensor((1, 512, 1, 1), dtype="float32"), R.Tensor((1, 512, 1, 1), dtype="float32"), R.Tensor((1, 512, 1, 1), dtype="float32"), R.Tensor((1, 512, 1, 1), dtype="float32"), R.Tensor((1, 512, 1, 1), dtype="float32"), R.Tensor((1, 512, 1, 1), dtype="float32"), R.Tensor((1, 512, 1, 1), dtype="float32"), R.Tensor((1, 512, 1, 1), dtype="float32"), R.Tensor((1, 512, 1, 1), dtype="float32"), R.Tensor((1, 512, 1, 1), dtype="float32"), R.Tensor((1, 512, 1, 1), dtype="float32"), R.Tensor((1, 512, 1, 1), dtype="float32"), R.Tensor((1, 512, 1, 1), dtype="float32"), R.Tensor((1, 512, 1, 1), dtype="float32"), R.Tensor((1, 512, 1, 1), dtype="float32"), R.Tensor((1, 512, 1, 1), dtype="float32"), R.Tensor((1, 256, 1, 1), dtype="float32"), R.Tensor((1, 256, 1, 1), dtype="float32"), R.Tensor((1, 256, 1, 1), dtype="float32"), R.Tensor((1, 256, 1, 1), dtype="float32"), R.Tensor((1, 256, 1, 1), dtype="float32"), R.Tensor((1, 256, 1, 1), dtype="float32"), R.Tensor((1, 256, 1, 1), dtype="float32"), R.Tensor((1, 256, 1, 1), dtype="float32"), R.Tensor((1, 128, 1, 1), dtype="float32"), R.Tensor((1, 128, 1, 1), dtype="float32"), R.Tensor((1, 128, 1, 1), dtype="float32"), R.Tensor((1, 128, 1, 1), dtype="float32"), R.Tensor((1, 128, 1, 1), dtype="float32"), R.Tensor((1, 128, 1, 1), dtype="float32"), R.Tensor((1, 128, 1, 1), dtype="float32"), R.Tensor((1, 3, 1, 1), dtype="float32"))) -> R.Tensor((1, 512, 512, 3), dtype="float32"):
        R.func_attr({"global_symbol": "main", "num_input": 1})
        cls = Module
        with R.dataflow():
            lv = R.call_tir(cls.multiply14, (inp_0,), out_sinfo=R.Tensor((1, 4, 64, 64), dtype="float32"))
            lv_1: R.Tensor((4, 4, 1, 1), dtype="float32") = model_params[99]
            lv1: R.Tensor((1, 4, 1, 1), dtype="float32") = model_params[100]
            lv1590 = R.call_tir(cls.fused_conv2d27_add27, (lv, lv_1, lv1), out_sinfo=R.Tensor((1, 4, 64, 64), dtype="float32"))
            lv2: R.Tensor((512, 4, 3, 3), dtype="float32") = model_params[0]
            lv3: R.Tensor((1, 512, 1, 1), dtype="float32") = model_params[101]
            lv1591 = R.call_tir(cls.fused_conv2d28_add28, (lv1590, lv2, lv3), out_sinfo=R.Tensor((1, 512, 64, 64), dtype="float32"))
            lv4: R.Tensor((512,), dtype="float32") = model_params[13]
            lv5: R.Tensor((512,), dtype="float32") = model_params[12]
            lv1592 = R.call_tir(cls.fused_group_norm14_silu13, (lv1591, lv4, lv5), out_sinfo=R.Tensor((1, 512, 64, 64), dtype="float32"))
            lv6: R.Tensor((512, 512, 3, 3), dtype="float32") = model_params[10]
            lv7: R.Tensor((1, 512, 1, 1), dtype="float32") = model_params[102]
            lv1593 = R.call_tir(cls.fused_conv2d29_add28, (lv1592, lv6, lv7), out_sinfo=R.Tensor((1, 512, 64, 64), dtype="float32"))
            lv8: R.Tensor((512,), dtype="float32") = model_params[15]
            lv9: R.Tensor((512,), dtype="float32") = model_params[14]
            lv1594 = R.call_tir(cls.fused_group_norm14_silu13, (lv1593, lv8, lv9), out_sinfo=R.Tensor((1, 512, 64, 64), dtype="float32"))
            lv10: R.Tensor((512, 512, 3, 3), dtype="float32") = model_params[11]
            lv11: R.Tensor((1, 512, 1, 1), dtype="float32") = model_params[103]
            lv1595 = R.call_tir(cls.fused_conv2d29_add28_add29_divide8, (lv1594, lv10, lv11, lv1591), out_sinfo=R.Tensor((1, 512, 64, 64), dtype="float32"))
            lv1596 = R.call_tir(cls.fused_reshape35_transpose29_transpose30, (lv1595,), out_sinfo=R.Tensor((1, 512, 4096), dtype="float32"))
            lv12: R.Tensor((512,), dtype="float32") = model_params[5]
            lv13: R.Tensor((512,), dtype="float32") = model_params[4]
            lv22 = R.call_tir(cls.group_norm15, (lv1596, lv12, lv13), out_sinfo=R.Tensor((1, 512, 4096), dtype="float32"))
            lv23 = R.call_tir(cls.transpose29, (lv22,), out_sinfo=R.Tensor((1, 4096, 512), dtype="float32"))
            lv14: R.Tensor((512, 512), dtype="float32") = model_params[104]
            lv15: R.Tensor((512,), dtype="float32") = model_params[8]
            lv1597 = R.call_tir(cls.fused_matmul26_add30, (lv23, lv14, lv15), out_sinfo=R.Tensor((1, 4096, 512), dtype="float32"))
            lv16: R.Tensor((512, 512), dtype="float32") = model_params[105]
            lv17: R.Tensor((512,), dtype="float32") = model_params[6]
            lv1598 = R.call_tir(cls.fused_matmul26_add30, (lv23, lv16, lv17), out_sinfo=R.Tensor((1, 4096, 512), dtype="float32"))
            lv18: R.Tensor((512, 512), dtype="float32") = model_params[106]
            lv19: R.Tensor((512,), dtype="float32") = model_params[9]
            lv1599 = R.call_tir(cls.fused_matmul26_add30, (lv23, lv18, lv19), out_sinfo=R.Tensor((1, 4096, 512), dtype="float32"))
            lv1600 = R.call_tir(cls.fused_reshape36_transpose32, (lv1597,), out_sinfo=R.Tensor((1, 1, 4096, 512), dtype="float32"))
            lv1601 = R.call_tir(cls.fused_reshape36_transpose32_transpose33, (lv1598,), out_sinfo=R.Tensor((1, 1, 512, 4096), dtype="float32"))
            lv1602 = R.call_tir(cls.fused_reshape36_transpose32, (lv1599,), out_sinfo=R.Tensor((1, 1, 4096, 512), dtype="float32"))
            lv1603 = R.call_tir(cls.fused_matmul27_multiply15, (lv1600, lv1601, R.const(0.044194173067808151, "float32")), out_sinfo=R.Tensor((1, 1, 4096, 4096), dtype="float32"))
            lv44 = R.call_tir(cls.softmax5, (lv1603,), out_sinfo=R.Tensor((1, 1, 4096, 4096), dtype="float32"))
            lv45 = R.call_tir(cls.matmul28, (lv44, lv1602), out_sinfo=R.Tensor((1, 1, 4096, 512), dtype="float32"))
            lv1604 = R.call_tir(cls.fused_transpose34_reshape37, (lv45,), out_sinfo=R.Tensor((1, 4096, 512), dtype="float32"))
            lv20: R.Tensor((512, 512), dtype="float32") = model_params[107]
            lv21: R.Tensor((512,), dtype="float32") = model_params[7]
            lv1605 = R.call_tir(cls.fused_matmul26_add30, (lv1604, lv20, lv21), out_sinfo=R.Tensor((1, 4096, 512), dtype="float32"))
            lv1606 = R.call_tir(cls.fused_transpose30_reshape38_add29_divide8, (lv1605, lv1595), out_sinfo=R.Tensor((1, 512, 64, 64), dtype="float32"))
            lv22_1: R.Tensor((512,), dtype="float32") = model_params[19]
            lv23_1: R.Tensor((512,), dtype="float32") = model_params[18]
            lv1607 = R.call_tir(cls.fused_group_norm14_silu13, (lv1606, lv22_1, lv23_1), out_sinfo=R.Tensor((1, 512, 64, 64), dtype="float32"))
            lv24: R.Tensor((512, 512, 3, 3), dtype="float32") = model_params[16]
            lv25: R.Tensor((1, 512, 1, 1), dtype="float32") = model_params[108]
            lv1608 = R.call_tir(cls.fused_conv2d29_add28, (lv1607, lv24, lv25), out_sinfo=R.Tensor((1, 512, 64, 64), dtype="float32"))
            lv26: R.Tensor((512,), dtype="float32") = model_params[21]
            lv27: R.Tensor((512,), dtype="float32") = model_params[20]
            lv1609 = R.call_tir(cls.fused_group_norm14_silu13, (lv1608, lv26, lv27), out_sinfo=R.Tensor((1, 512, 64, 64), dtype="float32"))
            lv28: R.Tensor((512, 512, 3, 3), dtype="float32") = model_params[17]
            lv29: R.Tensor((1, 512, 1, 1), dtype="float32") = model_params[109]
            lv1610 = R.call_tir(cls.fused_conv2d29_add28_add29_divide8_divide8, (lv1609, lv28, lv29, lv1606), out_sinfo=R.Tensor((1, 512, 64, 64), dtype="float32"))
            lv30: R.Tensor((512,), dtype="float32") = model_params[25]
            lv31: R.Tensor((512,), dtype="float32") = model_params[24]
            lv1611 = R.call_tir(cls.fused_group_norm14_silu13, (lv1610, lv30, lv31), out_sinfo=R.Tensor((1, 512, 64, 64), dtype="float32"))
            lv32: R.Tensor((512, 512, 3, 3), dtype="float32") = model_params[22]
            lv33: R.Tensor((1, 512, 1, 1), dtype="float32") = model_params[110]
            lv1612 = R.call_tir(cls.fused_conv2d29_add28, (lv1611, lv32, lv33), out_sinfo=R.Tensor((1, 512, 64, 64), dtype="float32"))
            lv34: R.Tensor((512,), dtype="float32") = model_params[27]
            lv35: R.Tensor((512,), dtype="float32") = model_params[26]
            lv1613 = R.call_tir(cls.fused_group_norm14_silu13, (lv1612, lv34, lv35), out_sinfo=R.Tensor((1, 512, 64, 64), dtype="float32"))
            lv36: R.Tensor((512, 512, 3, 3), dtype="float32") = model_params[23]
            lv37: R.Tensor((1, 512, 1, 1), dtype="float32") = model_params[111]
            lv1614 = R.call_tir(cls.fused_conv2d29_add28_add29_divide8, (lv1613, lv36, lv37, lv1610), out_sinfo=R.Tensor((1, 512, 64, 64), dtype="float32"))
            lv38: R.Tensor((512,), dtype="float32") = model_params[31]
            lv39: R.Tensor((512,), dtype="float32") = model_params[30]
            lv1615 = R.call_tir(cls.fused_group_norm14_silu13, (lv1614, lv38, lv39), out_sinfo=R.Tensor((1, 512, 64, 64), dtype="float32"))
            lv40: R.Tensor((512, 512, 3, 3), dtype="float32") = model_params[28]
            lv41: R.Tensor((1, 512, 1, 1), dtype="float32") = model_params[112]
            lv1616 = R.call_tir(cls.fused_conv2d29_add28, (lv1615, lv40, lv41), out_sinfo=R.Tensor((1, 512, 64, 64), dtype="float32"))
            lv42: R.Tensor((512,), dtype="float32") = model_params[33]
            lv43: R.Tensor((512,), dtype="float32") = model_params[32]
            lv1617 = R.call_tir(cls.fused_group_norm14_silu13, (lv1616, lv42, lv43), out_sinfo=R.Tensor((1, 512, 64, 64), dtype="float32"))
            lv44_1: R.Tensor((512, 512, 3, 3), dtype="float32") = model_params[29]
            lv45_1: R.Tensor((1, 512, 1, 1), dtype="float32") = model_params[113]
            lv1618 = R.call_tir(cls.fused_conv2d29_add28_add29_divide8, (lv1617, lv44_1, lv45_1, lv1614), out_sinfo=R.Tensor((1, 512, 64, 64), dtype="float32"))
            lv46: R.Tensor((512,), dtype="float32") = model_params[37]
            lv47: R.Tensor((512,), dtype="float32") = model_params[36]
            lv1619 = R.call_tir(cls.fused_group_norm14_silu13, (lv1618, lv46, lv47), out_sinfo=R.Tensor((1, 512, 64, 64), dtype="float32"))
            lv48: R.Tensor((512, 512, 3, 3), dtype="float32") = model_params[34]
            lv49: R.Tensor((1, 512, 1, 1), dtype="float32") = model_params[114]
            lv1620 = R.call_tir(cls.fused_conv2d29_add28, (lv1619, lv48, lv49), out_sinfo=R.Tensor((1, 512, 64, 64), dtype="float32"))
            lv50: R.Tensor((512,), dtype="float32") = model_params[39]
            lv51: R.Tensor((512,), dtype="float32") = model_params[38]
            lv1621 = R.call_tir(cls.fused_group_norm14_silu13, (lv1620, lv50, lv51), out_sinfo=R.Tensor((1, 512, 64, 64), dtype="float32"))
            lv52: R.Tensor((512, 512, 3, 3), dtype="float32") = model_params[35]
            lv53: R.Tensor((1, 512, 1, 1), dtype="float32") = model_params[115]
            lv1622 = R.call_tir(cls.fused_conv2d29_add28_add29_divide8, (lv1621, lv52, lv53, lv1618), out_sinfo=R.Tensor((1, 512, 64, 64), dtype="float32"))
            lv104 = R.call_tir(cls.resize2d2, (lv1622,), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv54: R.Tensor((512, 512, 3, 3), dtype="float32") = model_params[40]
            lv55: R.Tensor((1, 512, 1, 1), dtype="float32") = model_params[116]
            lv1623 = R.call_tir(cls.fused_conv2d30_add31, (lv104, lv54, lv55), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv56: R.Tensor((512,), dtype="float32") = model_params[44]
            lv57: R.Tensor((512,), dtype="float32") = model_params[43]
            lv1624 = R.call_tir(cls.fused_group_norm16_silu14, (lv1623, lv56, lv57), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv58: R.Tensor((512, 512, 3, 3), dtype="float32") = model_params[41]
            lv59: R.Tensor((1, 512, 1, 1), dtype="float32") = model_params[117]
            lv1625 = R.call_tir(cls.fused_conv2d30_add31, (lv1624, lv58, lv59), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv60: R.Tensor((512,), dtype="float32") = model_params[46]
            lv61: R.Tensor((512,), dtype="float32") = model_params[45]
            lv1626 = R.call_tir(cls.fused_group_norm16_silu14, (lv1625, lv60, lv61), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv62: R.Tensor((512, 512, 3, 3), dtype="float32") = model_params[42]
            lv63: R.Tensor((1, 512, 1, 1), dtype="float32") = model_params[118]
            lv1627 = R.call_tir(cls.fused_conv2d30_add31_add32_divide9, (lv1626, lv62, lv63, lv1623), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv64: R.Tensor((512,), dtype="float32") = model_params[50]
            lv65: R.Tensor((512,), dtype="float32") = model_params[49]
            lv1628 = R.call_tir(cls.fused_group_norm16_silu14, (lv1627, lv64, lv65), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv66: R.Tensor((512, 512, 3, 3), dtype="float32") = model_params[47]
            lv67: R.Tensor((1, 512, 1, 1), dtype="float32") = model_params[119]
            lv1629 = R.call_tir(cls.fused_conv2d30_add31, (lv1628, lv66, lv67), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv68: R.Tensor((512,), dtype="float32") = model_params[52]
            lv69: R.Tensor((512,), dtype="float32") = model_params[51]
            lv1630 = R.call_tir(cls.fused_group_norm16_silu14, (lv1629, lv68, lv69), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv70: R.Tensor((512, 512, 3, 3), dtype="float32") = model_params[48]
            lv71: R.Tensor((1, 512, 1, 1), dtype="float32") = model_params[120]
            lv1631 = R.call_tir(cls.fused_conv2d30_add31_add32_divide9, (lv1630, lv70, lv71, lv1627), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv72: R.Tensor((512,), dtype="float32") = model_params[56]
            lv73: R.Tensor((512,), dtype="float32") = model_params[55]
            lv1632 = R.call_tir(cls.fused_group_norm16_silu14, (lv1631, lv72, lv73), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv74: R.Tensor((512, 512, 3, 3), dtype="float32") = model_params[53]
            lv75: R.Tensor((1, 512, 1, 1), dtype="float32") = model_params[121]
            lv1633 = R.call_tir(cls.fused_conv2d30_add31, (lv1632, lv74, lv75), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv76: R.Tensor((512,), dtype="float32") = model_params[58]
            lv77: R.Tensor((512,), dtype="float32") = model_params[57]
            lv1634 = R.call_tir(cls.fused_group_norm16_silu14, (lv1633, lv76, lv77), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv78: R.Tensor((512, 512, 3, 3), dtype="float32") = model_params[54]
            lv79: R.Tensor((1, 512, 1, 1), dtype="float32") = model_params[122]
            lv1635 = R.call_tir(cls.fused_conv2d30_add31_add32_divide9, (lv1634, lv78, lv79, lv1631), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv144 = R.call_tir(cls.resize2d3, (lv1635,), out_sinfo=R.Tensor((1, 512, 256, 256), dtype="float32"))
            lv80: R.Tensor((512, 512, 3, 3), dtype="float32") = model_params[59]
            lv81: R.Tensor((1, 512, 1, 1), dtype="float32") = model_params[123]
            lv1636 = R.call_tir(cls.fused_conv2d31_add33, (lv144, lv80, lv81), out_sinfo=R.Tensor((1, 512, 256, 256), dtype="float32"))
            lv82: R.Tensor((512,), dtype="float32") = model_params[64]
            lv83: R.Tensor((512,), dtype="float32") = model_params[63]
            lv1637 = R.call_tir(cls.fused_group_norm17_silu15, (lv1636, lv82, lv83), out_sinfo=R.Tensor((1, 512, 256, 256), dtype="float32"))
            lv84: R.Tensor((256, 512, 3, 3), dtype="float32") = model_params[60]
            lv85: R.Tensor((1, 256, 1, 1), dtype="float32") = model_params[124]
            lv1638 = R.call_tir(cls.fused_conv2d32_add34, (lv1637, lv84, lv85), out_sinfo=R.Tensor((1, 256, 256, 256), dtype="float32"))
            lv86: R.Tensor((256,), dtype="float32") = model_params[66]
            lv87: R.Tensor((256,), dtype="float32") = model_params[65]
            lv1639 = R.call_tir(cls.fused_group_norm18_silu16, (lv1638, lv86, lv87), out_sinfo=R.Tensor((1, 256, 256, 256), dtype="float32"))
            lv88: R.Tensor((256, 512, 1, 1), dtype="float32") = model_params[62]
            lv89: R.Tensor((1, 256, 1, 1), dtype="float32") = model_params[126]
            lv1640 = R.call_tir(cls.fused_conv2d34_add34, (lv1636, lv88, lv89), out_sinfo=R.Tensor((1, 256, 256, 256), dtype="float32"))
            lv90: R.Tensor((256, 256, 3, 3), dtype="float32") = model_params[61]
            lv91: R.Tensor((1, 256, 1, 1), dtype="float32") = model_params[125]
            lv1641 = R.call_tir(cls.fused_conv2d33_add34_add35_divide10, (lv1639, lv90, lv91, lv1640), out_sinfo=R.Tensor((1, 256, 256, 256), dtype="float32"))
            lv92: R.Tensor((256,), dtype="float32") = model_params[70]
            lv93: R.Tensor((256,), dtype="float32") = model_params[69]
            lv1642 = R.call_tir(cls.fused_group_norm18_silu16, (lv1641, lv92, lv93), out_sinfo=R.Tensor((1, 256, 256, 256), dtype="float32"))
            lv94: R.Tensor((256, 256, 3, 3), dtype="float32") = model_params[67]
            lv95: R.Tensor((1, 256, 1, 1), dtype="float32") = model_params[127]
            lv1643 = R.call_tir(cls.fused_conv2d33_add34, (lv1642, lv94, lv95), out_sinfo=R.Tensor((1, 256, 256, 256), dtype="float32"))
            lv96: R.Tensor((256,), dtype="float32") = model_params[72]
            lv97: R.Tensor((256,), dtype="float32") = model_params[71]
            lv1644 = R.call_tir(cls.fused_group_norm18_silu16, (lv1643, lv96, lv97), out_sinfo=R.Tensor((1, 256, 256, 256), dtype="float32"))
            lv98: R.Tensor((256, 256, 3, 3), dtype="float32") = model_params[68]
            lv99: R.Tensor((1, 256, 1, 1), dtype="float32") = model_params[128]
            lv1645 = R.call_tir(cls.fused_conv2d33_add34_add35_divide10, (lv1644, lv98, lv99, lv1641), out_sinfo=R.Tensor((1, 256, 256, 256), dtype="float32"))
            lv100: R.Tensor((256,), dtype="float32") = model_params[76]
            lv101: R.Tensor((256,), dtype="float32") = model_params[75]
            lv1646 = R.call_tir(cls.fused_group_norm18_silu16, (lv1645, lv100, lv101), out_sinfo=R.Tensor((1, 256, 256, 256), dtype="float32"))
            lv102: R.Tensor((256, 256, 3, 3), dtype="float32") = model_params[73]
            lv103: R.Tensor((1, 256, 1, 1), dtype="float32") = model_params[129]
            lv1647 = R.call_tir(cls.fused_conv2d33_add34, (lv1646, lv102, lv103), out_sinfo=R.Tensor((1, 256, 256, 256), dtype="float32"))
            lv104_1: R.Tensor((256,), dtype="float32") = model_params[78]
            lv105: R.Tensor((256,), dtype="float32") = model_params[77]
            lv1648 = R.call_tir(cls.fused_group_norm18_silu16, (lv1647, lv104_1, lv105), out_sinfo=R.Tensor((1, 256, 256, 256), dtype="float32"))
            lv106: R.Tensor((256, 256, 3, 3), dtype="float32") = model_params[74]
            lv107: R.Tensor((1, 256, 1, 1), dtype="float32") = model_params[130]
            lv1649 = R.call_tir(cls.fused_conv2d33_add34_add35_divide10, (lv1648, lv106, lv107, lv1645), out_sinfo=R.Tensor((1, 256, 256, 256), dtype="float32"))
            lv187 = R.call_tir(cls.resize2d4, (lv1649,), out_sinfo=R.Tensor((1, 256, 512, 512), dtype="float32"))
            lv108: R.Tensor((256, 256, 3, 3), dtype="float32") = model_params[79]
            lv109: R.Tensor((1, 256, 1, 1), dtype="float32") = model_params[131]
            lv1650 = R.call_tir(cls.fused_conv2d35_add36, (lv187, lv108, lv109), out_sinfo=R.Tensor((1, 256, 512, 512), dtype="float32"))
            lv110: R.Tensor((256,), dtype="float32") = model_params[84]
            lv111: R.Tensor((256,), dtype="float32") = model_params[83]
            lv1651 = R.call_tir(cls.fused_group_norm19_silu17, (lv1650, lv110, lv111), out_sinfo=R.Tensor((1, 256, 512, 512), dtype="float32"))
            lv112: R.Tensor((128, 256, 3, 3), dtype="float32") = model_params[80]
            lv113: R.Tensor((1, 128, 1, 1), dtype="float32") = model_params[132]
            lv1652 = R.call_tir(cls.fused_conv2d36_add37, (lv1651, lv112, lv113), out_sinfo=R.Tensor((1, 128, 512, 512), dtype="float32"))
            lv114: R.Tensor((128,), dtype="float32") = model_params[86]
            lv115: R.Tensor((128,), dtype="float32") = model_params[85]
            lv1653 = R.call_tir(cls.fused_group_norm20_silu18, (lv1652, lv114, lv115), out_sinfo=R.Tensor((1, 128, 512, 512), dtype="float32"))
            lv116: R.Tensor((128, 256, 1, 1), dtype="float32") = model_params[82]
            lv117: R.Tensor((1, 128, 1, 1), dtype="float32") = model_params[134]
            lv1654 = R.call_tir(cls.fused_conv2d38_add37, (lv1650, lv116, lv117), out_sinfo=R.Tensor((1, 128, 512, 512), dtype="float32"))
            lv118: R.Tensor((128, 128, 3, 3), dtype="float32") = model_params[81]
            lv119: R.Tensor((1, 128, 1, 1), dtype="float32") = model_params[133]
            lv1655 = R.call_tir(cls.fused_conv2d37_add37_add38_divide11, (lv1653, lv118, lv119, lv1654), out_sinfo=R.Tensor((1, 128, 512, 512), dtype="float32"))
            lv120: R.Tensor((128,), dtype="float32") = model_params[90]
            lv121: R.Tensor((128,), dtype="float32") = model_params[89]
            lv1656 = R.call_tir(cls.fused_group_norm20_silu18, (lv1655, lv120, lv121), out_sinfo=R.Tensor((1, 128, 512, 512), dtype="float32"))
            lv122: R.Tensor((128, 128, 3, 3), dtype="float32") = model_params[87]
            lv123: R.Tensor((1, 128, 1, 1), dtype="float32") = model_params[135]
            lv1657 = R.call_tir(cls.fused_conv2d37_add37, (lv1656, lv122, lv123), out_sinfo=R.Tensor((1, 128, 512, 512), dtype="float32"))
            lv124: R.Tensor((128,), dtype="float32") = model_params[92]
            lv125: R.Tensor((128,), dtype="float32") = model_params[91]
            lv1658 = R.call_tir(cls.fused_group_norm20_silu18, (lv1657, lv124, lv125), out_sinfo=R.Tensor((1, 128, 512, 512), dtype="float32"))
            lv126: R.Tensor((128, 128, 3, 3), dtype="float32") = model_params[88]
            lv127: R.Tensor((1, 128, 1, 1), dtype="float32") = model_params[136]
            lv1659 = R.call_tir(cls.fused_conv2d37_add37_add38_divide11, (lv1658, lv126, lv127, lv1655), out_sinfo=R.Tensor((1, 128, 512, 512), dtype="float32"))
            lv128: R.Tensor((128,), dtype="float32") = model_params[96]
            lv129: R.Tensor((128,), dtype="float32") = model_params[95]
            lv1660 = R.call_tir(cls.fused_group_norm20_silu18, (lv1659, lv128, lv129), out_sinfo=R.Tensor((1, 128, 512, 512), dtype="float32"))
            lv130: R.Tensor((128, 128, 3, 3), dtype="float32") = model_params[93]
            lv131: R.Tensor((1, 128, 1, 1), dtype="float32") = model_params[137]
            lv1661 = R.call_tir(cls.fused_conv2d37_add37, (lv1660, lv130, lv131), out_sinfo=R.Tensor((1, 128, 512, 512), dtype="float32"))
            lv132: R.Tensor((128,), dtype="float32") = model_params[98]
            lv133: R.Tensor((128,), dtype="float32") = model_params[97]
            lv1662 = R.call_tir(cls.fused_group_norm20_silu18, (lv1661, lv132, lv133), out_sinfo=R.Tensor((1, 128, 512, 512), dtype="float32"))
            lv134: R.Tensor((128, 128, 3, 3), dtype="float32") = model_params[94]
            lv135: R.Tensor((1, 128, 1, 1), dtype="float32") = model_params[138]
            lv1663 = R.call_tir(cls.fused_conv2d37_add37_add38_divide11, (lv1662, lv134, lv135, lv1659), out_sinfo=R.Tensor((1, 128, 512, 512), dtype="float32"))
            lv136: R.Tensor((128,), dtype="float32") = model_params[2]
            lv137: R.Tensor((128,), dtype="float32") = model_params[1]
            lv1664 = R.call_tir(cls.fused_group_norm20_silu18, (lv1663, lv136, lv137), out_sinfo=R.Tensor((1, 128, 512, 512), dtype="float32"))
            lv138: R.Tensor((3, 128, 3, 3), dtype="float32") = model_params[3]
            lv139: R.Tensor((1, 3, 1, 1), dtype="float32") = model_params[139]
            lv1665 = R.call_tir(cls.fused_conv2d39_add39_divide12_add40_tir_clip, (lv1664, lv138, lv139), out_sinfo=R.Tensor((1, 3, 512, 512), dtype="float32"))
            lv1666 = R.call_tir(cls.fused_transpose35_multiply16_tir_round, (lv1665,), out_sinfo=R.Tensor((1, 512, 512, 3), dtype="float32"))
            gv: R.Tensor((1, 512, 512, 3), dtype="float32") = lv1666
            R.output(gv)
        return gv
